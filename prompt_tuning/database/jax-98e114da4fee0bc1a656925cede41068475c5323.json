{
    "language": "python",
    "commit_url": "https://github.com/jax-ml/jax/commit/98e114da4fee0bc1a656925cede41068475c5323",
    "commit_message": "Rename `unmapped_local_out_avals` to `out_avals` since it can contain global avals (via GDA) as well as local avals.\n\nPiperOrigin-RevId: 430539281",
    "commit_snapshots": {
        "jax/_src/api.py": [
            [
                "# coding=utf-8\n",
                "# Copyright 2018 Google LLC\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     https://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "\"\"\"JAX user-facing transformations and utilities.\n",
                "\n",
                "The transformations here mostly wrap internal transformations, providing\n",
                "convenience flags to control behavior and handling Python containers of\n",
                "arguments and outputs. The Python containers handled are pytrees (see\n",
                "tree_util.py), which include nested tuples/lists/dicts, where the leaves are\n",
                "arrays.\n",
                "\"\"\"\n",
                "\n",
                "# flake8: noqa: F401\n",
                "import collections\n",
                "import functools\n",
                "from functools import partial\n",
                "import inspect\n",
                "import itertools as it\n",
                "import sys\n",
                "import threading\n",
                "import weakref\n",
                "import types\n",
                "from typing import (Any, Callable, Iterable, NamedTuple, Mapping, Optional,\n",
                "                    Sequence, Tuple, TypeVar, Union, overload, Dict, Hashable)\n",
                "from warnings import warn\n",
                "\n",
                "import numpy as np\n",
                "from contextlib import contextmanager, ExitStack\n",
                "\n",
                "import jax\n",
                "from jax import core\n",
                "from jax import linear_util as lu\n",
                "from jax._src import dtypes\n",
                "from jax.core import eval_jaxpr\n",
                "from jax._src.api_util import (\n",
                "    flatten_fun, apply_flat_fun, flatten_fun_nokwargs, flatten_fun_nokwargs2,\n",
                "    argnums_partial, argnums_partial_except, flatten_axes, donation_vector,\n",
                "    rebase_donate_argnums, _ensure_index, _ensure_index_tuple,\n",
                "    shaped_abstractify, _ensure_str_tuple, argnames_partial_except)\n",
                "from jax._src import traceback_util\n",
                "from jax._src.traceback_util import api_boundary\n",
                "from jax.tree_util import (tree_map, tree_flatten, tree_unflatten,\n",
                "                           tree_structure, tree_transpose, tree_leaves,\n",
                "                           tree_multimap, treedef_is_leaf, treedef_children,\n",
                "                           Partial, PyTreeDef, all_leaves)\n",
                "from jax._src.tree_util import broadcast_prefix\n",
                "from jax._src.util import (unzip2, curry, safe_map, safe_zip, prod, split_list,\n",
                "                           extend_name_stack, new_name_stack, wrap_name, cache, wraps,\n",
                "                           HashableFunction)\n",
                "from jax._src import device_array\n",
                "from jax._src import dispatch\n",
                "from jax._src import source_info_util\n",
                "from jax._src.lib import jax_jit\n",
                "from jax._src.lib import xla_bridge as xb\n",
                "from jax._src.lib import xla_client as xc\n",
                "from jax._src.lib import pmap_lib\n",
                "# Unused imports to be exported\n",
                "from jax._src.lib.xla_bridge import (device_count, local_device_count, devices,\n",
                "                                     local_devices, process_index,\n",
                "                                     process_count, host_id, host_ids,\n",
                "                                     host_count, default_backend)\n",
                "from jax.core import ShapedArray, raise_to_shaped\n",
                "from jax.interpreters import partial_eval as pe\n",
                "from jax.interpreters import xla\n",
                "from jax.interpreters import pxla\n",
                "from jax.interpreters import ad\n",
                "from jax.interpreters import batching\n",
                "from jax.interpreters import masking\n",
                "from jax.interpreters import invertible_ad as iad\n",
                "from jax.interpreters.invertible_ad import custom_ivjp\n",
                "from jax.custom_batching import custom_vmap\n",
                "from jax.custom_derivatives import (closure_convert, custom_gradient, custom_jvp,\n",
                "                                    custom_vjp, linear_call)\n",
                "from jax.custom_transpose import custom_transpose\n",
                "from jax.ad_checkpoint import checkpoint_policies\n",
                "\n",
                "from jax._src.config import (\n",
                "    flags, config, bool_env,\n",
                "    disable_jit as _disable_jit,\n",
                "    debug_nans as config_debug_nans,\n",
                "    debug_infs as config_debug_infs,\n",
                "    _thread_local_state as config_thread_local_state,\n",
                "    explicit_device_put_scope as config_explicit_device_put_scope,\n",
                "    explicit_device_get_scope as config_explicit_device_get_scope)\n",
                "\n",
                "\n",
                "traceback_util.register_exclusion(__file__)\n",
                "\n",
                "_dtype = partial(dtypes.dtype, canonicalize=True)\n",
                "\n",
                "AxisName = Any\n",
                "\n",
                "# These TypeVars are used below to express the fact that function types\n",
                "# (i.e. call signatures) are invariant under the vmap transformation.\n",
                "F = TypeVar(\"F\", bound=Callable)\n",
                "T = TypeVar(\"T\")\n",
                "U = TypeVar(\"U\")\n",
                "\n",
                "map, unsafe_map = safe_map, map\n",
                "zip, unsafe_zip = safe_zip, zip\n",
                "\n",
                "FLAGS = flags.FLAGS\n",
                "\n",
                "flags.DEFINE_bool(\n",
                "    \"experimental_cpp_jit\", bool_env(\"JAX_CPP_JIT\", True),\n",
                "    \"A flag enabling the C++ jax.jit fast path.\"\n",
                "    \"Set this to `False` only if it crashes otherwise and report \"\n",
                "    \"the error to the jax-team.\")\n",
                "flags.DEFINE_bool(\n",
                "    \"experimental_cpp_pmap\", bool_env(\"JAX_CPP_PMAP\", True),\n",
                "    \"A flag enabling the C++ jax.pmap fast path. Until the default \"\n",
                "    \"is switched to True, the feature is not supported and possibly broken \"\n",
                "    \"(e.g. it may use unreleased code from jaxlib.\")\n",
                "\n",
                "\n",
                "def _nan_check_posthook(fun, args, kwargs, output):\n",
                "  \"\"\"Hook function called by the C++ jit/pmap to perform NaN checking.\"\"\"\n",
                "  leaves = tree_leaves(output)\n",
                "\n",
                "  buffers = []\n",
                "  for da_or_sda in leaves:\n",
                "    if hasattr(da_or_sda, \"device_buffer\"):\n",
                "      buffers.append(da_or_sda.device_buffer)\n",
                "    elif hasattr(da_or_sda, \"device_buffers\"):\n",
                "      buffers.extend(da_or_sda.device_buffers)\n",
                "\n",
                "  try:\n",
                "    dispatch.check_special(xla.xla_call_p, buffers)\n",
                "  except FloatingPointError:\n",
                "    # compiled_fun can only raise in this case\n",
                "    assert config.jax_debug_nans or config.jax_debug_infs\n",
                "    print(\"Invalid nan value encountered in the output of a C++-jit/pmap \"\n",
                "          \"function. Calling the de-optimized version.\")\n",
                "    fun._cache_miss(*args, **kwargs)[0]  # probably won't return\n",
                "\n",
                "def _update_debug_special_global(_):\n",
                "  if config._read(\"jax_debug_nans\") or config._read(\"jax_debug_infs\"):\n",
                "    jax_jit.global_state().post_hook = _nan_check_posthook\n",
                "  else:\n",
                "    jax_jit.global_state().post_hook = None\n",
                "\n",
                "def _update_debug_special_thread_local(_):\n",
                "  if (getattr(config_thread_local_state, \"jax_debug_nans\", False) or\n",
                "      getattr(config_thread_local_state, \"jax_debug_infs\", False)):\n",
                "    jax_jit.thread_local_state().post_hook = _nan_check_posthook\n",
                "  else:\n",
                "    jax_jit.thread_local_state().post_hook = None\n",
                "\n",
                "config_debug_nans._add_hooks(_update_debug_special_global,\n",
                "                             _update_debug_special_thread_local)\n",
                "config_debug_infs._add_hooks(_update_debug_special_global,\n",
                "                             _update_debug_special_thread_local)\n",
                "\n",
                "\n",
                "float0 = dtypes.float0\n",
                "\n",
                "def _check_callable(fun):\n",
                "  # In Python 3.10+, the only thing stopping us from supporting staticmethods\n",
                "  # is that we can't take weak references to them, which the C++ JIT requires.\n",
                "  if isinstance(fun, staticmethod):\n",
                "    raise TypeError(f\"staticmethod arguments are not supported, got {fun}\")\n",
                "  if not callable(fun):\n",
                "    raise TypeError(f\"Expected a callable value, got {fun}\")\n",
                "  if _isgeneratorfunction(fun):\n",
                "    raise TypeError(f\"Expected a function, got a generator function: {fun}\")\n",
                "\n",
                "def _isgeneratorfunction(fun):\n",
                "  # re-implemented here because of https://bugs.python.org/issue33261\n",
                "  while inspect.ismethod(fun):\n",
                "    fun = fun.__func__\n",
                "  while isinstance(fun, functools.partial):\n",
                "    fun = fun.func\n",
                "  return inspect.isfunction(fun) and bool(fun.__code__.co_flags & inspect.CO_GENERATOR)\n",
                "\n",
                "_POSITIONAL_OR_KEYWORD = inspect.Parameter.POSITIONAL_OR_KEYWORD\n",
                "\n",
                "def _infer_argnums_and_argnames(\n",
                "    fun: Callable,\n",
                "    argnums: Union[int, Iterable[int], None],\n",
                "    argnames: Union[str, Iterable[str], None],\n",
                ") -> Tuple[Tuple[int, ...], Tuple[str, ...]]:\n",
                "  \"\"\"Infer missing argnums and argnames for a function with inspect.\"\"\"\n",
                "  if argnums is None and argnames is None:\n",
                "    argnums = ()\n",
                "    argnames = ()\n",
                "  elif argnums is not None and argnames is not None:\n",
                "    argnums = _ensure_index_tuple(argnums)\n",
                "    argnames = _ensure_str_tuple(argnames)\n",
                "  else:\n",
                "    try:\n",
                "      signature = inspect.signature(fun)\n",
                "    except ValueError:\n",
                "      # In rare cases, inspect can fail, e.g., on some builtin Python functions.\n",
                "      # In these cases, don't infer any parameters.\n",
                "      parameters: Mapping[str, inspect.Parameter] = {}\n",
                "    else:\n",
                "      parameters = signature.parameters\n",
                "    if argnums is None:\n",
                "      assert argnames is not None\n",
                "      argnames = _ensure_str_tuple(argnames)\n",
                "      argnums = tuple(\n",
                "          i for i, (k, param) in enumerate(parameters.items())\n",
                "          if param.kind == _POSITIONAL_OR_KEYWORD and k in argnames\n",
                "      )\n",
                "    else:\n",
                "      assert argnames is None\n",
                "      argnums = _ensure_index_tuple(argnums)\n",
                "      argnames = tuple(\n",
                "          k for i, (k, param) in enumerate(parameters.items())\n",
                "          if param.kind == _POSITIONAL_OR_KEYWORD and i in argnums\n",
                "      )\n",
                "  return argnums, argnames\n",
                "\n",
                "\n",
                "def jit(\n",
                "  fun: Callable,\n",
                "  *,\n",
                "  static_argnums: Union[int, Iterable[int], None] = None,\n",
                "  static_argnames: Union[str, Iterable[str], None] = None,\n",
                "  device: Optional[xc.Device] = None,\n",
                "  backend: Optional[str] = None,\n",
                "  donate_argnums: Union[int, Iterable[int]] = (),\n",
                "  inline: bool = False,\n",
                ") -> Any:\n",
                "  \"\"\"Sets up ``fun`` for just-in-time compilation with XLA.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be jitted. Should be a pure function, as side-effects may\n",
                "      only be executed once. Its arguments and return value should be arrays,\n",
                "      scalars, or (nested) standard Python containers (tuple/list/dict) thereof.\n",
                "      Positional arguments indicated by ``static_argnums`` can be anything at\n",
                "      all, provided they are hashable and have an equality operation defined.\n",
                "      Static arguments are included as part of a compilation cache key, which is\n",
                "      why hash and equality operators must be defined.\n",
                "    static_argnums: An optional int or collection of ints that specify which\n",
                "      positional arguments to treat as static (compile-time constant).\n",
                "      Operations that only depend on static arguments will be constant-folded in\n",
                "      Python (during tracing), and so the corresponding argument values can be\n",
                "      any Python object.\n",
                "\n",
                "      Static arguments should be hashable, meaning both ``__hash__`` and\n",
                "      ``__eq__`` are implemented, and immutable. Calling the jitted function\n",
                "      with different values for these constants will trigger recompilation.\n",
                "      Arguments that are not arrays or containers thereof must be marked as\n",
                "      static.\n",
                "\n",
                "      If neither ``static_argnums`` nor ``static_argnames`` is provided, no\n",
                "      arguments are treated as static. If ``static_argnums`` is not provided but\n",
                "      ``static_argnames`` is, or vice versa, JAX uses ``inspect.signature(fun)``\n",
                "      to find any positional arguments that correspond to ``static_argnames``\n",
                "      (or vice versa). If both ``static_argnums`` and ``static_argnames`` are\n",
                "      provided, ``inspect.signature`` is not used, and only actual\n",
                "      parameters listed in either ``static_argnums`` or ``static_argnames`` will\n",
                "      be treated as static.\n",
                "    static_argnames: An optional string or collection of strings specifying\n",
                "      which named arguments to treat as static (compile-time constant). See the\n",
                "      comment on ``static_argnums`` for details. If not\n",
                "      provided but ``static_argnums`` is set, the default is based on calling\n",
                "      ``inspect.signature(fun)`` to find corresponding named arguments.\n",
                "    device: This is an experimental feature and the API is likely to change.\n",
                "      Optional, the Device the jitted function will run on. (Available devices\n",
                "      can be retrieved via :py:func:`jax.devices`.) The default is inherited\n",
                "      from XLA's DeviceAssignment logic and is usually to use\n",
                "      ``jax.devices()[0]``.\n",
                "    backend: This is an experimental feature and the API is likely to change.\n",
                "      Optional, a string representing the XLA backend: ``'cpu'``, ``'gpu'``, or\n",
                "      ``'tpu'``.\n",
                "    donate_argnums: Specify which argument buffers are \"donated\" to the computation.\n",
                "      It is safe to donate argument buffers if you no longer need them once the\n",
                "      computation has finished. In some cases XLA can make use of donated\n",
                "      buffers to reduce the amount of memory needed to perform a computation,\n",
                "      for example recycling one of your input buffers to store a result. You\n",
                "      should not reuse buffers that you donate to a computation, JAX will raise\n",
                "      an error if you try to. By default, no argument buffers are donated.\n",
                "\n",
                "      For more details on buffer donation see the [FAQ](https://jax.readthedocs.io/en/latest/faq.html#buffer-donation).\n",
                "\n",
                "    inline: Specify whether this function should be inlined into enclosing\n",
                "      jaxprs (rather than being represented as an application of the xla_call\n",
                "      primitive with its own subjaxpr). Default False.\n",
                "\n",
                "  Returns:\n",
                "    A wrapped version of ``fun``, set up for just-in-time compilation.\n",
                "\n",
                "  In the following example, ``selu`` can be compiled into a single fused kernel\n",
                "  by XLA:\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> @jax.jit\n",
                "  ... def selu(x, alpha=1.67, lmbda=1.05):\n",
                "  ...   return lmbda * jax.numpy.where(x > 0, x, alpha * jax.numpy.exp(x) - alpha)\n",
                "  >>>\n",
                "  >>> key = jax.random.PRNGKey(0)\n",
                "  >>> x = jax.random.normal(key, (10,))\n",
                "  >>> print(selu(x))  # doctest: +SKIP\n",
                "  [-0.54485  0.27744 -0.29255 -0.91421 -0.62452 -0.24748\n",
                "   -0.85743 -0.78232  0.76827  0.59566 ]\n",
                "  \"\"\"\n",
                "  if FLAGS.experimental_cpp_jit:\n",
                "    return _cpp_jit(fun, static_argnums, static_argnames, device, backend,\n",
                "                    donate_argnums, inline)\n",
                "  else:\n",
                "    return _python_jit(fun, static_argnums, static_argnames, device, backend,\n",
                "                       donate_argnums, inline)\n",
                "\n",
                "\n",
                "def _prepare_jit(fun, static_argnums, static_argnames, donate_argnums,\n",
                "                 args, kwargs):\n",
                "  if max(donate_argnums, default=-1) >= len(args):\n",
                "    raise ValueError(\n",
                "        f\"jitted function has donate_argnums={donate_argnums} but \"\n",
                "        f\"was called with only {len(args)} positional arguments.\")\n",
                "\n",
                "  f = lu.wrap_init(fun)\n",
                "  f, args = argnums_partial_except(f, static_argnums, args, allow_invalid=True)\n",
                "  f, kwargs = argnames_partial_except(f, static_argnames, kwargs)\n",
                "  args_flat, in_tree = tree_flatten((args, kwargs))\n",
                "  if donate_argnums:\n",
                "    donated_invars = donation_vector(donate_argnums, args, kwargs)\n",
                "  else:\n",
                "    donated_invars = (False,) * len(args_flat)\n",
                "\n",
                "  return f, in_tree, args_flat, donated_invars\n",
                "\n",
                "\n",
                "def _python_jit(\n",
                "    fun: Callable,\n",
                "    static_argnums: Union[int, Iterable[int], None] = None,\n",
                "    static_argnames: Union[str, Iterable[str], None] = None,\n",
                "    device: Optional[xc.Device] = None,\n",
                "    backend: Optional[str] = None,\n",
                "    donate_argnums: Union[int, Iterable[int]] = (),\n",
                "    inline: bool = False,\n",
                ") -> F:\n",
                "  # The Python implementation of `jax.jit`, being slowly replaced by _cpp_jit.\n",
                "  _check_callable(fun)\n",
                "  static_argnums, static_argnames = _infer_argnums_and_argnames(\n",
                "      fun, static_argnums, static_argnames)\n",
                "  static_argnums = _ensure_index_tuple(static_argnums)\n",
                "  donate_argnums = _ensure_index_tuple(donate_argnums)\n",
                "  donate_argnums = rebase_donate_argnums(donate_argnums, static_argnums)\n",
                "\n",
                "  @wraps(fun)\n",
                "  @api_boundary\n",
                "  def f_jitted(*args, **kwargs):\n",
                "    if config.jax_disable_jit:\n",
                "      return fun(*args, **kwargs)\n",
                "    closed_fun, in_tree, args_flat, donated_invars = _prepare_jit(\n",
                "        fun, static_argnums, static_argnames, donate_argnums, args, kwargs)\n",
                "    for arg in args_flat:\n",
                "      _check_arg(arg)\n",
                "    flat_fun, out_tree = flatten_fun(closed_fun, in_tree)\n",
                "    out_flat = xla.xla_call(\n",
                "        flat_fun, *args_flat,\n",
                "        device=device, backend=backend, name=flat_fun.__name__,\n",
                "        donated_invars=donated_invars, inline=inline)\n",
                "    return tree_unflatten(out_tree(), out_flat)\n",
                "\n",
                "  f_jitted.lower = _jit_lower(fun, static_argnums, static_argnames, device,\n",
                "                              backend, donate_argnums, inline)\n",
                "  return f_jitted\n",
                "\n",
                "\n",
                "class _BackendAndDeviceInfo(NamedTuple):\n",
                "  default_device: xc.Device\n",
                "  committed_to_device: bool\n",
                "\n",
                "class _FastpathData(NamedTuple):\n",
                "  xla_executable: xla.XlaExecutable\n",
                "  out_pytree_def: Any\n",
                "  sticky_device: xc.Device\n",
                "  avals: Iterable[Any]\n",
                "  lazy_exprs: Iterable[Any]\n",
                "  kept_var_bitvec: Iterable[bool]\n",
                "\n",
                "_cpp_jit_cache = jax_jit.CompiledFunctionCache()\n",
                "\n",
                "def _cpp_jit(\n",
                "    fun: Callable,\n",
                "    static_argnums: Union[int, Iterable[int], None] = None,\n",
                "    static_argnames: Union[str, Iterable[str], None] = None,\n",
                "    device: Optional[xc.Device] = None,\n",
                "    backend: Optional[str] = None,\n",
                "    donate_argnums: Union[int, Iterable[int]] = (),\n",
                "    inline: bool = False,\n",
                ") -> Any:\n",
                "  # An implementation of `jit` that tries to do as much as possible in C++.\n",
                "  # The goal of this function is to speed up the time it takes to process the\n",
                "  # arguments, find the correct C++ executable, start the transfer of arguments\n",
                "  # and schedule the computation.\n",
                "  # As long as it does not support all features of the Python implementation\n",
                "  # the C++ code will fallback to `_python_jit` when it faces some unsupported\n",
                "  # feature.\n",
                "  _check_callable(fun)\n",
                "  static_argnums, static_argnames = _infer_argnums_and_argnames(\n",
                "      fun, static_argnums, static_argnames)\n",
                "  static_argnums = _ensure_index_tuple(static_argnums)\n",
                "  donate_argnums = _ensure_index_tuple(donate_argnums)\n",
                "  donate_argnums = rebase_donate_argnums(donate_argnums, static_argnums)\n",
                "\n",
                "  if device is not None and backend is not None:\n",
                "    raise ValueError(\"can't specify both a device and a backend for jit, \"\n",
                "                     f\"got device={device} and backend={backend}.\")\n",
                "\n",
                "  @api_boundary\n",
                "  def cache_miss(*args, **kwargs):\n",
                "    ### This first part is basically the same code as in _python_jit.\n",
                "    # An alternative would be for cache_miss to accept from C++ the arguments\n",
                "    # (dyn_args, donated_invars, args_flat, in_tree), since otherwise we have\n",
                "    # work/code that is redundant between C++ and Python. We can try that later.\n",
                "    closed_fun, in_tree, args_flat, donated_invars = _prepare_jit(\n",
                "        fun, static_argnums, static_argnames, donate_argnums, args, kwargs)\n",
                "    for arg in args_flat:\n",
                "      _check_arg(arg)\n",
                "    flat_fun, out_tree = flatten_fun(closed_fun, in_tree)\n",
                "    out_flat = xla.xla_call(\n",
                "        flat_fun, *args_flat,\n",
                "        device=device, backend=backend, name=flat_fun.__name__,\n",
                "        donated_invars=donated_invars, inline=inline)\n",
                "    out_pytree_def = out_tree()\n",
                "    out = tree_unflatten(out_pytree_def, out_flat)\n",
                "\n",
                "    ### Decide whether we can support the C++ fast path\n",
                "    # High level note: The Python tracing mechanism is complex; in particular\n",
                "    # to know whether `jax.jit(f)(x)` will execute or trace, it's not enough to\n",
                "    # inspect the argument x, we actually do need to execute it and look at the\n",
                "    # outputs that could be tracers (if f is capturing `Tracer` by closure).\n",
                "    execute: Optional[functools.partial] = (\n",
                "        dispatch._xla_callable.most_recent_entry())\n",
                "    use_fastpath = (\n",
                "        # This is if we have already executed this code-path (most-recent entry\n",
                "        # has been reset to None). Thus, we do not support the fast-path.\n",
                "        execute is not None and\n",
                "        execute.func is dispatch._execute_compiled and  # not trivial, not pmap\n",
                "        # Not supported: ShardedDeviceArray\n",
                "        all(device_array.type_is_device_array(x) for x in out_flat))\n",
                "    ### If we can use the fastpath, we return required info to the caller.\n",
                "    if use_fastpath:\n",
                "      _, xla_executable, _, result_handlers, kept_var_idx = execute.args\n",
                "      sticky_device = None\n",
                "      avals = []\n",
                "      lazy_exprs = [None] * len(result_handlers)\n",
                "      for result_handler in result_handlers:\n",
                "        aval, sticky_device = result_handler.args\n",
                "        avals.append(aval)\n",
                "      assert len(avals) == len(out_flat)\n",
                "      kept_var_bitvec = [i in kept_var_idx for i in range(len(args_flat))]\n",
                "      fastpath_data = _FastpathData(xla_executable, out_pytree_def,\n",
                "                                    sticky_device, avals, lazy_exprs,\n",
                "                                    kept_var_bitvec)\n",
                "    else:\n",
                "      fastpath_data = None\n",
                "\n",
                "    return out, fastpath_data\n",
                "\n",
                "  def get_device_info():\n",
                "    \"\"\"Backends do not exist before __main__ is being executed.\"\"\"\n",
                "    committed_to_device = device is not None or backend is not None\n",
                "\n",
                "    if device is not None:\n",
                "      default_device = device\n",
                "    else:\n",
                "      backend_ = xb.get_backend(backend)\n",
                "      default_device = backend_.get_default_device_assignment(1)[0]\n",
                "\n",
                "    return _BackendAndDeviceInfo(default_device, committed_to_device)\n",
                "\n",
                "  cpp_jitted_f = jax_jit.jit(fun, cache_miss, get_device_info,\n",
                "                             static_argnums=static_argnums,\n",
                "                             static_argnames=static_argnames,\n",
                "                             donate_argnums=donate_argnums,\n",
                "                             cache=_cpp_jit_cache)\n",
                "  f_jitted = wraps(fun)(cpp_jitted_f)\n",
                "\n",
                "  f_jitted.lower = _jit_lower(fun, static_argnums, static_argnames, device,\n",
                "                              backend, donate_argnums, inline)\n",
                "\n",
                "  return f_jitted\n",
                "\n",
                "\n",
                "class Lowered:\n",
                "  \"\"\"Lowering of a function specialized to argument types and values.\n",
                "\n",
                "  A lowering is a computation ready for compilation. This class\n",
                "  carries a lowering together with the remaining information needed to\n",
                "  later compile and execute it. It also provides a common API for\n",
                "  querying properties of lowered computations across JAX's various\n",
                "  lowering paths (``jit``, ``pmap``, etc.).\n",
                "  \"\"\"\n",
                "  __slots__ = ['in_tree', 'out_tree', 'donate_argnums', '_lowering',\n",
                "               '_no_kwargs']\n",
                "\n",
                "  in_tree: PyTreeDef\n",
                "  out_tree: PyTreeDef\n",
                "  donate_argnums: Tuple[int]\n",
                "  _lowering: Union[dispatch.XlaComputation,\n",
                "                   pxla.MeshComputation,\n",
                "                   pxla.PmapComputation]\n",
                "  _no_kwargs: bool\n",
                "\n",
                "  def __init__(self, lowering, in_tree, out_tree, donate_argnums,\n",
                "               no_kwargs=False):\n",
                "    self._lowering = lowering\n",
                "    self.in_tree = in_tree\n",
                "    self.out_tree = out_tree\n",
                "    self.donate_argnums = donate_argnums\n",
                "    self._no_kwargs = no_kwargs\n",
                "\n",
                "  def compile(self) -> 'Compiled':\n",
                "    return Compiled(\n",
                "        self._lowering.compile(), self.in_tree, self.out_tree,\n",
                "        self.donate_argnums, self._no_kwargs)\n",
                "\n",
                "  def compiler_ir(self, dialect: Optional[str] = None):\n",
                "    if dialect is None or dialect == \"mhlo\":\n",
                "      return self._lowering.mhlo()\n",
                "    elif dialect == \"hlo\":\n",
                "      return self._lowering.hlo()\n",
                "    else:\n",
                "      raise ValueError(f\"Unknown dialect {dialect}\")\n",
                "\n",
                "  # TODO(frostig): remove this in favor of `compiler_ir`\n",
                "  def _xla_computation(self):\n",
                "    return self._lowering.hlo()\n",
                "\n",
                "\n",
                "class Compiled:\n",
                "  \"\"\"Compiled representation of a function specialized to types/values.\n",
                "\n",
                "  A compiled computation is associated with an executable and the\n",
                "  remaining information needed to execute it. It also provides a\n",
                "  common API for querying properties of compiled computations across\n",
                "  JAX's various compilation paths and backends.\n",
                "  \"\"\"\n",
                "  __slots__ = ['in_tree', 'out_tree', 'donate_argnums', '_executable',\n",
                "               '_no_kwargs']\n",
                "\n",
                "  in_tree: PyTreeDef\n",
                "  out_tree: PyTreeDef\n",
                "  donate_argnums: Tuple[int]\n",
                "  _executable: Union[dispatch.XlaCompiledComputation,\n",
                "                     pxla.MeshExecutable,\n",
                "                     pxla.PmapExecutable]\n",
                "  _no_kwargs: bool\n",
                "\n",
                "  def __init__(self, executable, in_tree, out_tree, donate_argnums,\n",
                "               no_kwargs=False):\n",
                "    self._executable = executable\n",
                "    self.in_tree = in_tree\n",
                "    self.out_tree = out_tree\n",
                "    self.donate_argnums = donate_argnums\n",
                "    self._no_kwargs = no_kwargs\n",
                "\n",
                "  def compiler_ir(self):\n",
                "    \"\"\"Post-compilation IR.\n",
                "\n",
                "    Compilation typically involves code transformation and\n",
                "    optimization. This method exists to reflect the compiler's\n",
                "    representation of the program after such passes, whenever\n",
                "    possible.\n",
                "    \"\"\"\n",
                "    return self._executable.xla_executable().hlo_modules()\n",
                "\n",
                "  def runtime_executable(self):\n",
                "    return self._executable.xla_executable()\n",
                "\n",
                "  def _xla_executable(self):\n",
                "    # TODO(frostig): finalize API. For now, return the underlying\n",
                "    # executable directly via this method.\n",
                "    return self._executable.xla_executable()\n",
                "\n",
                "  def __call__(self, *args, **kwargs):\n",
                "    if self._no_kwargs:\n",
                "      if kwargs:\n",
                "        kws = ', '.join(kwargs.keys())\n",
                "        raise NotImplementedError(\n",
                "            'function was compiled by a transformation that does not support '\n",
                "            f'keyword arguments, but called with keyword arguments: {kws}')\n",
                "      args_flat, in_tree = tree_flatten(args)\n",
                "    else:\n",
                "      args_flat, in_tree = tree_flatten((args, kwargs))\n",
                "    if in_tree != self.in_tree:\n",
                "      # TODO(frostig): provide more info about the source function\n",
                "      # and transformation\n",
                "      raise TypeError(\n",
                "          f'function compiled for {self.in_tree}, called with {in_tree}')\n",
                "    try:\n",
                "      out_flat = self._executable.call(*args_flat)\n",
                "    except TypeError as e:\n",
                "      # We can't transform ahead-of-time compiled calls, since we've\n",
                "      # lowered and compiled for a fixed function signature, and JAX\n",
                "      # transformations change signatures. We interpret a Tracer\n",
                "      # argument as an indication of a transformation attempt. We\n",
                "      # could check this before the executable call, but we'd rather\n",
                "      # avoid isinstance checks on the call path. Seeing a TypeError\n",
                "      # might mean that arguments have JAX-invalid types, which in\n",
                "      # turn might mean some are Tracers.\n",
                "      for arg in args_flat:\n",
                "        if isinstance(arg, core.Tracer):\n",
                "          raise TypeError(\n",
                "              'Cannot apply JAX transformations to a function lowered and '\n",
                "              'compiled for a particular signature. Detected argument of '\n",
                "              f'Tracer type {type(arg)}.')\n",
                "      else:\n",
                "        raise\n",
                "    return tree_unflatten(self.out_tree, out_flat)\n",
                "\n",
                "\n",
                "def _jit_lower(fun, static_argnums, static_argnames, device, backend,\n",
                "               donate_argnums, inline):\n",
                "  \"\"\"Make a ``lower`` method for jitted functions.\"\"\"\n",
                "  # If the function we returned from ``jit`` were a class instance,\n",
                "  # this might naturally be a method, with ``fun`` as a ``self`` and\n",
                "  # all the other arguments stored as attributes.\n",
                "\n",
                "  def arg_spec(x):\n",
                "    # like xla.arg_spec but duck-types on x.shape and x.dtype\n",
                "    aval = shaped_abstractify(x)\n",
                "    try:\n",
                "      return aval, x._device\n",
                "    except:\n",
                "      return aval, None\n",
                "\n",
                "  @api_boundary\n",
                "  def lower(*args, **kwargs) -> Lowered:\n",
                "    \"\"\"Lower this function for the given arguments.\n",
                "\n",
                "    A lowered function is staged out of Python and translated to a\n",
                "    compiler's input language, possibly in a backend-dependent\n",
                "    manner. It is ready for compilation but not yet compiled.\n",
                "\n",
                "    Returns:\n",
                "      A ``Lowered`` instance representing the lowering.\n",
                "    \"\"\"\n",
                "    closed_fun, in_tree, args_flat, donated_invars = _prepare_jit(\n",
                "        fun, static_argnums, static_argnames, donate_argnums, args, kwargs)\n",
                "    flat_fun, out_tree = flatten_fun(closed_fun, in_tree)\n",
                "    name = flat_fun.__name__\n",
                "    arg_specs = unsafe_map(arg_spec, args_flat)\n",
                "    computation = dispatch.lower_xla_callable(\n",
                "        flat_fun, device, backend, name, donated_invars, *arg_specs)\n",
                "    return Lowered(computation, in_tree, out_tree(), donate_argnums)\n",
                "\n",
                "  return lower\n",
                "\n",
                "\n",
                "@contextmanager\n",
                "def disable_jit():\n",
                "  \"\"\"Context manager that disables :py:func:`jit` behavior under its dynamic context.\n",
                "\n",
                "  For debugging it is useful to have a mechanism that disables :py:func:`jit`\n",
                "  everywhere in a dynamic context.\n",
                "\n",
                "  Values that have a data dependence on the arguments to a jitted function are\n",
                "  traced and abstracted. For example, an abstract value may be a\n",
                "  :py:class:`ShapedArray` instance, representing the set of all possible arrays\n",
                "  with a given shape and dtype, but not representing one concrete array with\n",
                "  specific values. You might notice those if you use a benign side-effecting\n",
                "  operation in a jitted function, like a print:\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> @jax.jit\n",
                "  ... def f(x):\n",
                "  ...   y = x * 2\n",
                "  ...   print(\"Value of y is\", y)\n",
                "  ...   return y + 3\n",
                "  ...\n",
                "  >>> print(f(jax.numpy.array([1, 2, 3])))\n",
                "  Value of y is Traced<ShapedArray(int32[3])>with<DynamicJaxprTrace(level=0/1)>\n",
                "  [5 7 9]\n",
                "\n",
                "  Here ``y`` has been abstracted by :py:func:`jit` to a :py:class:`ShapedArray`,\n",
                "  which represents an array with a fixed shape and type but an arbitrary value.\n",
                "  The value of ``y`` is also traced. If we want to see a concrete value while\n",
                "  debugging, and avoid the tracer too, we can use the :py:func:`disable_jit`\n",
                "  context manager:\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> with jax.disable_jit():\n",
                "  ...   print(f(jax.numpy.array([1, 2, 3])))\n",
                "  ...\n",
                "  Value of y is [2 4 6]\n",
                "  [5 7 9]\n",
                "  \"\"\"\n",
                "  with _disable_jit(True):\n",
                "    yield\n",
                "\n",
                "\n",
                "def xla_computation(fun: Callable,\n",
                "                    static_argnums: Union[int, Iterable[int]] = (),\n",
                "                    axis_env: Optional[Sequence[Tuple[AxisName, int]]] = None,\n",
                "                    in_parts=None, out_parts=None,\n",
                "                    backend: Optional[str] = None,\n",
                "                    tuple_args: bool = False,\n",
                "                    instantiate_const_outputs: Optional[bool] = None,\n",
                "                    return_shape: bool = False,\n",
                "                    donate_argnums: Union[int, Iterable[int]] = ()) -> Callable:\n",
                "  \"\"\"Creates a function that produces its XLA computation given example args.\n",
                "\n",
                "  Args:\n",
                "    fun: Function from which to form XLA computations.\n",
                "    static_argnums: See the :py:func:`jax.jit` docstring.\n",
                "    axis_env: Optional, a sequence of pairs where the first element is an axis\n",
                "      name and the second element is a positive integer representing the size of\n",
                "      the mapped axis with that name. This parameter is useful when lowering\n",
                "      functions that involve parallel communication collectives, and it\n",
                "      specifies the axis name/size environment that would be set up by\n",
                "      applications of :py:func:`jax.pmap`. See the examples below.\n",
                "    in_parts: Optional, how each argument to ``fun`` should be partitioned or\n",
                "      replicated. This is used to specify partitioned XLA computations, see\n",
                "      ``sharded_jit`` for more info.\n",
                "    out_parts: Optional, how each output of ``fun`` should be partitioned or\n",
                "      replicated. This is used to specify partitioned XLA computations, see\n",
                "      ``sharded_jit`` for more info.\n",
                "    backend: This is an experimental feature and the API is likely to change.\n",
                "      Optional, a string representing the XLA backend: ``'cpu'``, ``'gpu'``, or\n",
                "      ``'tpu'``.\n",
                "    tuple_args: Optional bool, defaults to ``False``. If ``True``, the resulting\n",
                "      XLA computation will have a single tuple argument that is unpacked into\n",
                "      the specified function arguments. If `None`, tupling will be enabled when\n",
                "      there are more than 100 arguments, since some platforms have limits on\n",
                "      argument arity.\n",
                "    instantiate_const_outputs: Deprecated argument, does nothing.\n",
                "    return_shape: Optional boolean, defaults to ``False``. If ``True``, the\n",
                "      wrapped function returns a pair where the first element is the XLA\n",
                "      computation and the second element is a pytree with the same structure as\n",
                "      the output of ``fun`` and where the leaves are objects with ``shape``,\n",
                "      ``dtype``, and ``named_shape`` attributes representing the corresponding\n",
                "      types of the output leaves.\n",
                "    donate_argnums: Specify which arguments are \"donated\" to the computation.\n",
                "      It is safe to donate arguments if you no longer need them once the\n",
                "      computation has finished. In some cases XLA can make use of donated\n",
                "      buffers to reduce the amount of memory needed to perform a computation,\n",
                "      for example recycling one of your input buffers to store a result. You\n",
                "      should not reuse buffers that you donate to a computation, JAX will raise\n",
                "      an error if you try to.\n",
                "\n",
                "  Returns:\n",
                "    A wrapped version of ``fun`` that when applied to example arguments returns\n",
                "    a built XLA Computation (see xla_client.py), from which representations of\n",
                "    the unoptimized XLA HLO computation can be extracted using methods like\n",
                "    ``as_hlo_text``, ``as_serialized_hlo_module_proto``, and\n",
                "    ``as_hlo_dot_graph``. If the argument ``return_shape`` is ``True``, then the\n",
                "    wrapped function returns a pair where the first element is the XLA\n",
                "    Computation and the second element is a pytree representing the structure,\n",
                "    shapes, dtypes, and named shapes of the output of ``fun``.\n",
                "\n",
                "    Concrete example arguments are not always necessary. For those arguments not\n",
                "    indicated by ``static_argnums``, any object with ``shape`` and ``dtype``\n",
                "    attributes is acceptable (excepting namedtuples, which are treated as Python\n",
                "    containers).\n",
                "\n",
                "  For example:\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> def f(x): return jax.numpy.sin(jax.numpy.cos(x))\n",
                "  >>> c = jax.xla_computation(f)(3.)\n",
                "  >>> print(c.as_hlo_text())  # doctest: +SKIP\n",
                "  HloModule xla_computation_f.6\n",
                "  <BLANKLINE>\n",
                "  ENTRY xla_computation_f.6 {\n",
                "    constant.2 = pred[] constant(false)\n",
                "    parameter.1 = f32[] parameter(0)\n",
                "    cosine.3 = f32[] cosine(parameter.1)\n",
                "    sine.4 = f32[] sine(cosine.3)\n",
                "    ROOT tuple.5 = (f32[]) tuple(sine.4)\n",
                "  }\n",
                "  <BLANKLINE>\n",
                "  <BLANKLINE>\n",
                "\n",
                "\n",
                "  Alternatively, the assignment to ``c`` above could be written:\n",
                "\n",
                "  >>> import types\n",
                "  >>> scalar = types.SimpleNamespace(shape=(), dtype=np.dtype(np.float32))\n",
                "  >>> c = jax.xla_computation(f)(scalar)\n",
                "\n",
                "\n",
                "  Here's an example that involves a parallel collective and axis name:\n",
                "\n",
                "  >>> def f(x): return x - jax.lax.psum(x, 'i')\n",
                "  >>> c = jax.xla_computation(f, axis_env=[('i', 4)])(2)\n",
                "  >>> print(c.as_hlo_text())  # doctest: +SKIP\n",
                "  HloModule jaxpr_computation.9\n",
                "  primitive_computation.3 {\n",
                "    parameter.4 = s32[] parameter(0)\n",
                "    parameter.5 = s32[] parameter(1)\n",
                "    ROOT add.6 = s32[] add(parameter.4, parameter.5)\n",
                "  }\n",
                "  ENTRY jaxpr_computation.9 {\n",
                "    tuple.1 = () tuple()\n",
                "    parameter.2 = s32[] parameter(0)\n",
                "    all-reduce.7 = s32[] all-reduce(parameter.2), replica_groups={{0,1,2,3}}, to_apply=primitive_computation.3\n",
                "    ROOT subtract.8 = s32[] subtract(parameter.2, all-reduce.7)\n",
                "  }\n",
                "  <BLANKLINE>\n",
                "  <BLANKLINE>\n",
                "\n",
                "  Notice the ``replica_groups`` that were generated. Here's an example that\n",
                "  generates more interesting ``replica_groups``:\n",
                "\n",
                "  >>> from jax import lax\n",
                "  >>> def g(x):\n",
                "  ...   rowsum = lax.psum(x, 'i')\n",
                "  ...   colsum = lax.psum(x, 'j')\n",
                "  ...   allsum = lax.psum(x, ('i', 'j'))\n",
                "  ...   return rowsum, colsum, allsum\n",
                "  ...\n",
                "  >>> axis_env = [('i', 4), ('j', 2)]\n",
                "  >>> c = xla_computation(g, axis_env=axis_env)(5.)\n",
                "  >>> print(c.as_hlo_text())  # doctest: +SKIP\n",
                "  HloModule jaxpr_computation__1.19\n",
                "  [removed uninteresting text here]\n",
                "  ENTRY jaxpr_computation__1.19 {\n",
                "    tuple.1 = () tuple()\n",
                "    parameter.2 = f32[] parameter(0)\n",
                "    all-reduce.7 = f32[] all-reduce(parameter.2), replica_groups={{0,2,4,6},{1,3,5,7}}, to_apply=primitive_computation__1.3\n",
                "    all-reduce.12 = f32[] all-reduce(parameter.2), replica_groups={{0,1},{2,3},{4,5},{6,7}}, to_apply=primitive_computation__1.8\n",
                "    all-reduce.17 = f32[] all-reduce(parameter.2), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=primitive_computation__1.13\n",
                "    ROOT tuple.18 = (f32[], f32[], f32[]) tuple(all-reduce.7, all-reduce.12, all-reduce.17)\n",
                "  }\n",
                "  \"\"\"\n",
                "  del instantiate_const_outputs  # Unused\n",
                "\n",
                "  _check_callable(fun)\n",
                "  static_argnums = _ensure_index_tuple(static_argnums)\n",
                "  donate_argnums = _ensure_index_tuple(donate_argnums)\n",
                "  donate_argnums = rebase_donate_argnums(donate_argnums, static_argnums)\n",
                "\n",
                "  fun_name = getattr(fun, \"__name__\", \"unknown\")\n",
                "\n",
                "  backend = backend if backend is not None else xb.get_backend().platform\n",
                "\n",
                "  def make_axis_env(nreps):\n",
                "    if axis_env is None:\n",
                "      return xla.AxisEnv(nreps, (), ())\n",
                "    else:\n",
                "      nreps = nreps * prod(size for name, size in axis_env)\n",
                "      names, sizes = unzip2(axis_env)\n",
                "      return xla.AxisEnv(nreps, names, sizes)\n",
                "\n",
                "  @wraps(fun)\n",
                "  @api_boundary\n",
                "  def computation_maker(*args, **kwargs):\n",
                "    if max(static_argnums + donate_argnums, default=-1) >= len(args):\n",
                "      raise ValueError(f\"jitted function has static_argnums={static_argnums},\"\n",
                "                       f\" donate_argnums={donate_argnums} but \"\n",
                "                       f\"was called with only {len(args)} positional arguments.\")\n",
                "\n",
                "    f = lu.wrap_init(fun)\n",
                "    if static_argnums:\n",
                "      f, dyn_args = argnums_partial_except(f, static_argnums, args, allow_invalid=False)\n",
                "    else:\n",
                "      dyn_args = args\n",
                "    args_flat, in_tree = tree_flatten((dyn_args, kwargs))\n",
                "    if donate_argnums:\n",
                "      donated_invars = donation_vector(donate_argnums, dyn_args, kwargs)\n",
                "    else:\n",
                "      donated_invars = (False,) * len(args_flat)\n",
                "\n",
                "    if in_parts is None:\n",
                "      in_parts_flat = None\n",
                "    else:\n",
                "      in_parts_flat = tuple(flatten_axes(\n",
                "          \"xla_computation in_parts\", in_tree.children()[0], in_parts))\n",
                "    jaxtree_fun, out_tree = flatten_fun(f, in_tree)\n",
                "    avals = map(shaped_abstractify, args_flat)\n",
                "    with ExitStack() as stack:\n",
                "      for axis_name, size in axis_env or []:\n",
                "        stack.enter_context(core.extend_axis_env(axis_name, size, None))\n",
                "      jaxpr, out_avals, consts = pe.trace_to_jaxpr_dynamic(jaxtree_fun, avals)\n",
                "      jaxpr = dispatch.apply_outfeed_rewriter(jaxpr)\n",
                "      axis_env_ = make_axis_env(dispatch.jaxpr_replicas(jaxpr))\n",
                "      if out_parts is None:\n",
                "        out_parts_flat = None\n",
                "      else:\n",
                "        out_parts_flat = tuple(flatten_axes(\n",
                "            \"xla_computation out_parts\", out_tree(), out_parts))\n",
                "      c = xc.XlaBuilder(f\"xla_computation_{fun_name}\")\n",
                "      xla_consts = map(partial(xla.pyval_to_ir_constant, c), consts)\n",
                "      should_tuple = tuple_args if tuple_args is not None else (len(avals) > 100)\n",
                "      xla_args, donated_invars = xla._xla_callable_args(\n",
                "          c, avals, should_tuple, partitions=in_parts_flat, donated_invars=donated_invars)\n",
                "      name_stack = new_name_stack(wrap_name(fun_name, \"xla_computation\"))\n",
                "      ctx = xla.TranslationContext(c, backend, axis_env_, name_stack)\n",
                "      out_nodes = xla.jaxpr_subcomp(ctx, jaxpr, xla_consts, *xla_args)\n",
                "    build_out_tuple = partial(xc.ops.Tuple, c, out_nodes)\n",
                "    if out_parts is not None:\n",
                "      out_tuple = xla.with_sharding(c, out_parts_flat, build_out_tuple)\n",
                "    else:\n",
                "      out_tuple = build_out_tuple()\n",
                "\n",
                "    if any(donated_invars):\n",
                "      donated_invars = xla.set_up_aliases(c, xla_args, c.GetShape(out_tuple),\n",
                "                                          donated_invars, tuple_args)\n",
                "    if any(donated_invars):\n",
                "      shapes = [str(c.GetShape(a)) for a, d in zip(xla_args, donated_invars) if d]\n",
                "      warn(f\"Some donated buffers were not usable: {', '.join(shapes)}\")\n",
                "    built = c.build(out_tuple)\n",
                "    out_shapes_flat = [\n",
                "        ShapeDtypeStruct(a.shape, a.dtype, a.named_shape) for a in out_avals]\n",
                "    out_shape = tree_unflatten(out_tree(), out_shapes_flat)\n",
                "    for out_aval in out_avals:\n",
                "      if not isinstance(out_aval, xla.ShapedArray):\n",
                "        raise RuntimeError(\"As we want to propagate the weak_type, we need \"\n",
                "                           \"to get a ShapedArray, otherwise this \"\n",
                "                           \"information is lost\")\n",
                "\n",
                "    if return_shape:\n",
                "      return built, out_shape\n",
                "    else:\n",
                "      return built\n",
                "\n",
                "  return computation_maker\n",
                "\n",
                "def grad(fun: Callable, argnums: Union[int, Sequence[int]] = 0,\n",
                "         has_aux: bool = False, holomorphic: bool = False,\n",
                "         allow_int: bool = False,\n",
                "         reduce_axes: Sequence[AxisName] = ()) -> Callable:\n",
                "  \"\"\"Creates a function that evaluates the gradient of ``fun``.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be differentiated. Its arguments at positions specified by\n",
                "      ``argnums`` should be arrays, scalars, or standard Python containers.\n",
                "      Argument arrays in the positions specified by ``argnums`` must be of\n",
                "      inexact (i.e., floating-point or complex) type. It\n",
                "      should return a scalar (which includes arrays with shape ``()`` but not\n",
                "      arrays with shape ``(1,)`` etc.)\n",
                "    argnums: Optional, integer or sequence of integers. Specifies which\n",
                "      positional argument(s) to differentiate with respect to (default 0).\n",
                "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
                "      first element is considered the output of the mathematical function to be\n",
                "      differentiated and the second element is auxiliary data. Default False.\n",
                "    holomorphic: Optional, bool. Indicates whether ``fun`` is promised to be\n",
                "      holomorphic. If True, inputs and outputs must be complex. Default False.\n",
                "    allow_int: Optional, bool. Whether to allow differentiating with\n",
                "      respect to integer valued inputs. The gradient of an integer input will\n",
                "      have a trivial vector-space dtype (float0). Default False.\n",
                "    reduce_axes: Optional, tuple of axis names. If an axis is listed here, and\n",
                "      ``fun`` implicitly broadcasts a value over that axis, the backward pass\n",
                "      will perform a ``psum`` of the corresponding gradient. Otherwise, the\n",
                "      gradient will be per-example over named axes. For example, if ``'batch'``\n",
                "      is a named batch axis, ``grad(f, reduce_axes=('batch',))`` will create a\n",
                "      function that computes the total gradient while ``grad(f)`` will create\n",
                "      one that computes the per-example gradient.\n",
                "\n",
                "  Returns:\n",
                "    A function with the same arguments as ``fun``, that evaluates the gradient\n",
                "    of ``fun``. If ``argnums`` is an integer then the gradient has the same\n",
                "    shape and type as the positional argument indicated by that integer. If\n",
                "    argnums is a tuple of integers, the gradient is a tuple of values with the\n",
                "    same shapes and types as the corresponding arguments. If ``has_aux`` is True\n",
                "    then a pair of (gradient, auxiliary_data) is returned.\n",
                "\n",
                "  For example:\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> grad_tanh = jax.grad(jax.numpy.tanh)\n",
                "  >>> print(grad_tanh(0.2))\n",
                "  0.961043\n",
                "  \"\"\"\n",
                "  value_and_grad_f = value_and_grad(fun, argnums, has_aux=has_aux,\n",
                "                                    holomorphic=holomorphic,\n",
                "                                    allow_int=allow_int,\n",
                "                                    reduce_axes=reduce_axes)\n",
                "\n",
                "  docstr = (\"Gradient of {fun} with respect to positional argument(s) \"\n",
                "            \"{argnums}. Takes the same arguments as {fun} but returns the \"\n",
                "            \"gradient, which has the same shape as the arguments at \"\n",
                "            \"positions {argnums}.\")\n",
                "\n",
                "  @wraps(fun, docstr=docstr, argnums=argnums)\n",
                "  @api_boundary\n",
                "  def grad_f(*args, **kwargs):\n",
                "    _, g = value_and_grad_f(*args, **kwargs)\n",
                "    return g\n",
                "\n",
                "  @wraps(fun, docstr=docstr, argnums=argnums)\n",
                "  @api_boundary\n",
                "  def grad_f_aux(*args, **kwargs):\n",
                "    (_, aux), g = value_and_grad_f(*args, **kwargs)\n",
                "    return g, aux\n",
                "\n",
                "  return grad_f_aux if has_aux else grad_f\n",
                "\n",
                "def value_and_grad(fun: Callable, argnums: Union[int, Sequence[int]] = 0,\n",
                "                   has_aux: bool = False, holomorphic: bool = False,\n",
                "                   allow_int: bool = False, reduce_axes: Sequence[AxisName] = ()\n",
                ") -> Callable[..., Tuple[Any, Any]]:\n",
                "  \"\"\"Create a function that evaluates both ``fun`` and the gradient of ``fun``.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be differentiated. Its arguments at positions specified by\n",
                "      ``argnums`` should be arrays, scalars, or standard Python containers. It\n",
                "      should return a scalar (which includes arrays with shape ``()`` but not\n",
                "      arrays with shape ``(1,)`` etc.)\n",
                "    argnums: Optional, integer or sequence of integers. Specifies which\n",
                "      positional argument(s) to differentiate with respect to (default 0).\n",
                "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
                "      first element is considered the output of the mathematical function to be\n",
                "      differentiated and the second element is auxiliary data. Default False.\n",
                "    holomorphic: Optional, bool. Indicates whether ``fun`` is promised to be\n",
                "      holomorphic. If True, inputs and outputs must be complex. Default False.\n",
                "    allow_int: Optional, bool. Whether to allow differentiating with\n",
                "      respect to integer valued inputs. The gradient of an integer input will\n",
                "      have a trivial vector-space dtype (float0). Default False.\n",
                "    reduce_axes: Optional, tuple of axis names. If an axis is listed here, and\n",
                "      ``fun`` implicitly broadcasts a value over that axis, the backward pass\n",
                "      will perform a ``psum`` of the corresponding gradient. Otherwise, the\n",
                "      gradient will be per-example over named axes. For example, if ``'batch'``\n",
                "      is a named batch axis, ``value_and_grad(f, reduce_axes=('batch',))`` will\n",
                "      create a function that computes the total gradient while\n",
                "      ``value_and_grad(f)`` will create one that computes the per-example\n",
                "      gradient.\n",
                "\n",
                "  Returns:\n",
                "    A function with the same arguments as ``fun`` that evaluates both ``fun``\n",
                "    and the gradient of ``fun`` and returns them as a pair (a two-element\n",
                "    tuple). If ``argnums`` is an integer then the gradient has the same shape\n",
                "    and type as the positional argument indicated by that integer. If argnums is\n",
                "    a sequence of integers, the gradient is a tuple of values with the same\n",
                "    shapes and types as the corresponding arguments. If ``has_aux`` is True\n",
                "    then a tuple of ((value, auxiliary_data), gradient) is returned.\n",
                "  \"\"\"\n",
                "\n",
                "  docstr = (\"Value and gradient of {fun} with respect to positional \"\n",
                "            \"argument(s) {argnums}. Takes the same arguments as {fun} but \"\n",
                "            \"returns a two-element tuple where the first element is the value \"\n",
                "            \"of {fun} and the second element is the gradient, which has the \"\n",
                "            \"same shape as the arguments at positions {argnums}.\")\n",
                "\n",
                "  _check_callable(fun)\n",
                "  argnums = core.concrete_or_error(_ensure_index, argnums)\n",
                "  reduce_axes = _ensure_str_tuple(reduce_axes)\n",
                "\n",
                "  @wraps(fun, docstr=docstr, argnums=argnums)\n",
                "  @api_boundary\n",
                "  def value_and_grad_f(*args, **kwargs):\n",
                "    max_argnum = argnums if isinstance(argnums, int) else max(argnums)\n",
                "    if max_argnum >= len(args):\n",
                "      raise TypeError(f\"differentiating with respect to argnums={argnums} requires at least \"\n",
                "                      f\"{max_argnum + 1} positional arguments to be passed by the caller, \"\n",
                "                      f\"but got only {len(args)} positional arguments.\")\n",
                "\n",
                "    f = lu.wrap_init(fun, kwargs)\n",
                "    f_partial, dyn_args = argnums_partial(f, argnums, args,\n",
                "                                          require_static_args_hashable=False)\n",
                "    for leaf in tree_leaves(dyn_args):\n",
                "      _check_input_dtype_grad(holomorphic, allow_int, leaf)\n",
                "    if not has_aux:\n",
                "      ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)\n",
                "    else:\n",
                "      ans, vjp_py, aux = _vjp(\n",
                "          f_partial, *dyn_args, has_aux=True, reduce_axes=reduce_axes)\n",
                "    _check_scalar(ans)\n",
                "    tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n",
                "    g = vjp_py(jax.lax._one(ans))\n",
                "    g = g[0] if isinstance(argnums, int) else g\n",
                "    if not has_aux:\n",
                "      return ans, g\n",
                "    else:\n",
                "      return (ans, aux), g\n",
                "\n",
                "  return value_and_grad_f\n",
                "\n",
                "def _check_scalar(x):\n",
                "  msg = \"Gradient only defined for scalar-output functions. Output {}.\".format\n",
                "  try:\n",
                "    aval = core.get_aval(x)\n",
                "  except TypeError as e:\n",
                "    raise TypeError(msg(f\"was {x}\")) from e\n",
                "  else:\n",
                "    if isinstance(aval, ShapedArray):\n",
                "      if aval.shape != ():\n",
                "        raise TypeError(msg(f\"had shape: {aval.shape}\"))\n",
                "    else:\n",
                "      raise TypeError(msg(f\"had abstract value {aval}\"))\n",
                "\n",
                "def _check_input_dtype_revderiv(name, holomorphic, allow_int, x):\n",
                "  _check_arg(x)\n",
                "  aval = core.get_aval(x)\n",
                "  if holomorphic:\n",
                "    if not dtypes.issubdtype(aval.dtype, np.complexfloating):\n",
                "      raise TypeError(f\"{name} with holomorphic=True requires inputs with complex dtype, \"\n",
                "                      f\"but got {aval.dtype.name}.\")\n",
                "  if (dtypes.issubdtype(aval.dtype, np.integer) or\n",
                "      dtypes.issubdtype(aval.dtype, np.bool_)):\n",
                "    if not allow_int:\n",
                "      raise TypeError(f\"{name} requires real- or complex-valued inputs (input dtype \"\n",
                "                      f\"that is a sub-dtype of np.inexact), but got {aval.dtype.name}. \"\n",
                "                      \"If you want to use Boolean- or integer-valued inputs, use vjp \"\n",
                "                      \"or set allow_int to True.\")\n",
                "  elif not dtypes.issubdtype(aval.dtype, np.inexact):\n",
                "    raise TypeError(f\"{name} requires numerical-valued inputs (input dtype that is a \"\n",
                "                    f\"sub-dtype of np.bool_ or np.number), but got {aval.dtype.name}.\")\n",
                "_check_input_dtype_grad = partial(_check_input_dtype_revderiv, \"grad\")\n",
                "\n",
                "def _check_output_dtype_revderiv(name, holomorphic, x):\n",
                "  aval = core.get_aval(x)\n",
                "  if holomorphic:\n",
                "    if not dtypes.issubdtype(aval.dtype, np.complexfloating):\n",
                "      raise TypeError(f\"{name} with holomorphic=True requires outputs with complex dtype, \"\n",
                "                      f\"but got {aval.dtype.name}.\")\n",
                "  elif dtypes.issubdtype(aval.dtype, np.complexfloating):\n",
                "    raise TypeError(f\"{name} requires real-valued outputs (output dtype that is \"\n",
                "                    f\"a sub-dtype of np.floating), but got {aval.dtype.name}. \"\n",
                "                    \"For holomorphic differentiation, pass holomorphic=True. \"\n",
                "                    \"For differentiation of non-holomorphic functions involving complex \"\n",
                "                    \"outputs, use jax.vjp directly.\")\n",
                "  elif not dtypes.issubdtype(aval.dtype, np.floating):\n",
                "    raise TypeError(f\"{name} requires real-valued outputs (output dtype that is \"\n",
                "                    f\"a sub-dtype of np.floating), but got {aval.dtype.name}. \"\n",
                "                    \"For differentiation of functions with integer outputs, use \"\n",
                "                    \"jax.vjp directly.\")\n",
                "_check_output_dtype_grad = partial(_check_output_dtype_revderiv, \"grad\")\n",
                "\n",
                "\n",
                "def jacfwd(fun: Callable, argnums: Union[int, Sequence[int]] = 0,\n",
                "           has_aux: bool = False, holomorphic: bool = False) -> Callable:\n",
                "  \"\"\"Jacobian of ``fun`` evaluated column-by-column using forward-mode AD.\n",
                "\n",
                "  Args:\n",
                "    fun: Function whose Jacobian is to be computed.\n",
                "    argnums: Optional, integer or sequence of integers. Specifies which\n",
                "      positional argument(s) to differentiate with respect to (default ``0``).\n",
                "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
                "      first element is considered the output of the mathematical function to be\n",
                "      differentiated and the second element is auxiliary data. Default False.\n",
                "    holomorphic: Optional, bool. Indicates whether ``fun`` is promised to be\n",
                "      holomorphic. Default False.\n",
                "\n",
                "  Returns:\n",
                "    A function with the same arguments as ``fun``, that evaluates the Jacobian of\n",
                "    ``fun`` using forward-mode automatic differentiation. If ``has_aux`` is True\n",
                "    then a pair of (jacobian, auxiliary_data) is returned.\n",
                "\n",
                "  >>> import jax\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>>\n",
                "  >>> def f(x):\n",
                "  ...   return jnp.asarray(\n",
                "  ...     [x[0], 5*x[2], 4*x[1]**2 - 2*x[2], x[2] * jnp.sin(x[0])])\n",
                "  ...\n",
                "  >>> print(jax.jacfwd(f)(jnp.array([1., 2., 3.])))\n",
                "  [[ 1.       0.       0.     ]\n",
                "   [ 0.       0.       5.     ]\n",
                "   [ 0.      16.      -2.     ]\n",
                "   [ 1.6209   0.       0.84147]]\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "  argnums = _ensure_index(argnums)\n",
                "\n",
                "  def jacfun(*args, **kwargs):\n",
                "    f = lu.wrap_init(fun, kwargs)\n",
                "    f_partial, dyn_args = argnums_partial(f, argnums, args,\n",
                "                                          require_static_args_hashable=False)\n",
                "    tree_map(partial(_check_input_dtype_jacfwd, holomorphic), dyn_args)\n",
                "    if not has_aux:\n",
                "      pushfwd = partial(_jvp, f_partial, dyn_args)\n",
                "      y, jac = vmap(pushfwd, out_axes=(None, -1))(_std_basis(dyn_args))\n",
                "    else:\n",
                "      pushfwd = partial(_jvp, f_partial, dyn_args, has_aux=True)\n",
                "      y, jac, aux = vmap(pushfwd, out_axes=(None, -1, None))(_std_basis(dyn_args))\n",
                "    tree_map(partial(_check_output_dtype_jacfwd, holomorphic), y)\n",
                "    example_args = dyn_args[0] if isinstance(argnums, int) else dyn_args\n",
                "    jac_tree = tree_map(partial(_jacfwd_unravel, example_args), y, jac)\n",
                "    if not has_aux:\n",
                "      return jac_tree\n",
                "    else:\n",
                "      return jac_tree, aux\n",
                "\n",
                "  return jacfun\n",
                "\n",
                "def _check_input_dtype_jacfwd(holomorphic: bool, x: Any) -> None:\n",
                "  _check_arg(x)\n",
                "  aval = core.get_aval(x)\n",
                "  if holomorphic:\n",
                "    if not dtypes.issubdtype(aval.dtype, np.complexfloating):\n",
                "      raise TypeError(\"jacfwd with holomorphic=True requires inputs with complex \"\n",
                "                      f\"dtype, but got {aval.dtype.name}.\")\n",
                "  elif not dtypes.issubdtype(aval.dtype, np.floating):\n",
                "    raise TypeError(\"jacfwd requires real-valued inputs (input dtype that is \"\n",
                "                    f\"a sub-dtype of np.floating), but got {aval.dtype.name}. \"\n",
                "                    \"For holomorphic differentiation, pass holomorphic=True. \"\n",
                "                    \"For differentiation of non-holomorphic functions involving \"\n",
                "                    \"complex inputs or integer inputs, use jax.jvp directly.\")\n",
                "\n",
                "def _check_output_dtype_jacfwd(holomorphic, x):\n",
                "  aval = core.get_aval(x)\n",
                "  if holomorphic:\n",
                "    if not dtypes.issubdtype(aval.dtype, np.complexfloating):\n",
                "      raise TypeError(\"jacfwd with holomorphic=True requires outputs with complex dtype, \"\n",
                "                      f\"but got {aval.dtype.name}.\")\n",
                "\n",
                "def jacrev(fun: Callable, argnums: Union[int, Sequence[int]] = 0,\n",
                "           has_aux: bool = False, holomorphic: bool = False, allow_int: bool = False) -> Callable:\n",
                "  \"\"\"Jacobian of ``fun`` evaluated row-by-row using reverse-mode AD.\n",
                "\n",
                "  Args:\n",
                "    fun: Function whose Jacobian is to be computed.\n",
                "    argnums: Optional, integer or sequence of integers. Specifies which\n",
                "      positional argument(s) to differentiate with respect to (default ``0``).\n",
                "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
                "      first element is considered the output of the mathematical function to be\n",
                "      differentiated and the second element is auxiliary data. Default False.\n",
                "    holomorphic: Optional, bool. Indicates whether ``fun`` is promised to be\n",
                "      holomorphic. Default False.\n",
                "    allow_int: Optional, bool. Whether to allow differentiating with\n",
                "      respect to integer valued inputs. The gradient of an integer input will\n",
                "      have a trivial vector-space dtype (float0). Default False.\n",
                "\n",
                "  Returns:\n",
                "    A function with the same arguments as ``fun``, that evaluates the Jacobian of\n",
                "    ``fun`` using reverse-mode automatic differentiation. If ``has_aux`` is True\n",
                "    then a pair of (jacobian, auxiliary_data) is returned.\n",
                "\n",
                "  >>> import jax\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>>\n",
                "  >>> def f(x):\n",
                "  ...   return jnp.asarray(\n",
                "  ...     [x[0], 5*x[2], 4*x[1]**2 - 2*x[2], x[2] * jnp.sin(x[0])])\n",
                "  ...\n",
                "  >>> print(jax.jacrev(f)(jnp.array([1., 2., 3.])))\n",
                "  [[ 1.       0.       0.     ]\n",
                "   [ 0.       0.       5.     ]\n",
                "   [ 0.      16.      -2.     ]\n",
                "   [ 1.6209   0.       0.84147]]\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "\n",
                "  def jacfun(*args, **kwargs):\n",
                "    f = lu.wrap_init(fun, kwargs)\n",
                "    f_partial, dyn_args = argnums_partial(f, argnums, args,\n",
                "                                          require_static_args_hashable=False)\n",
                "    tree_map(partial(_check_input_dtype_jacrev, holomorphic, allow_int), dyn_args)\n",
                "    if not has_aux:\n",
                "      y, pullback = _vjp(f_partial, *dyn_args)\n",
                "    else:\n",
                "      y, pullback, aux = _vjp(f_partial, *dyn_args, has_aux=True)\n",
                "    tree_map(partial(_check_output_dtype_jacrev, holomorphic), y)\n",
                "    jac = vmap(pullback)(_std_basis(y))\n",
                "    jac = jac[0] if isinstance(argnums, int) else jac\n",
                "    example_args = dyn_args[0] if isinstance(argnums, int) else dyn_args\n",
                "    jac_tree = tree_map(partial(_jacrev_unravel, y), example_args, jac)\n",
                "    jac_tree = tree_transpose(tree_structure(example_args), tree_structure(y), jac_tree)\n",
                "    if not has_aux:\n",
                "      return jac_tree\n",
                "    else:\n",
                "      return jac_tree, aux\n",
                "\n",
                "  return jacfun\n",
                "jacobian = jacrev\n",
                "\n",
                "_check_input_dtype_jacrev = partial(_check_input_dtype_revderiv, \"jacrev\")\n",
                "_check_output_dtype_jacrev = partial(_check_output_dtype_revderiv, \"jacrev\")\n",
                "\n",
                "\n",
                "def hessian(fun: Callable, argnums: Union[int, Sequence[int]] = 0,\n",
                "            holomorphic: bool = False) -> Callable:\n",
                "  \"\"\"Hessian of ``fun`` as a dense array.\n",
                "\n",
                "  Args:\n",
                "    fun: Function whose Hessian is to be computed.  Its arguments at positions\n",
                "      specified by ``argnums`` should be arrays, scalars, or standard Python\n",
                "      containers thereof. It should return arrays, scalars, or standard Python\n",
                "      containers thereof.\n",
                "    argnums: Optional, integer or sequence of integers. Specifies which\n",
                "      positional argument(s) to differentiate with respect to (default ``0``).\n",
                "    holomorphic: Optional, bool. Indicates whether ``fun`` is promised to be\n",
                "      holomorphic. Default False.\n",
                "\n",
                "  Returns:\n",
                "    A function with the same arguments as ``fun``, that evaluates the Hessian of\n",
                "    ``fun``.\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> g = lambda x: x[0]**3 - 2*x[0]*x[1] - x[1]**6\n",
                "  >>> print(jax.hessian(g)(jax.numpy.array([1., 2.])))\n",
                "  [[   6.   -2.]\n",
                "   [  -2. -480.]]\n",
                "\n",
                "  :py:func:`hessian` is a generalization of the usual definition of the Hessian\n",
                "  that supports nested Python containers (i.e. pytrees) as inputs and outputs.\n",
                "  The tree structure of ``jax.hessian(fun)(x)`` is given by forming a tree\n",
                "  product of the structure of ``fun(x)`` with a tree product of two copies of\n",
                "  the structure of ``x``. A tree product of two tree structures is formed by\n",
                "  replacing each leaf of the first tree with a copy of the second. For example:\n",
                "\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>> f = lambda dct: {\"c\": jnp.power(dct[\"a\"], dct[\"b\"])}\n",
                "  >>> print(jax.hessian(f)({\"a\": jnp.arange(2.) + 1., \"b\": jnp.arange(2.) + 2.}))\n",
                "  {'c': {'a': {'a': DeviceArray([[[ 2.,  0.], [ 0.,  0.]],\n",
                "                                 [[ 0.,  0.], [ 0., 12.]]], dtype=float32),\n",
                "               'b': DeviceArray([[[ 1.      ,  0.      ], [ 0.      ,  0.      ]],\n",
                "                                 [[ 0.      ,  0.      ], [ 0.      , 12.317766]]], dtype=float32)},\n",
                "         'b': {'a': DeviceArray([[[ 1.      ,  0.      ], [ 0.      ,  0.      ]],\n",
                "                                 [[ 0.      ,  0.      ], [ 0.      , 12.317766]]], dtype=float32),\n",
                "               'b': DeviceArray([[[0.      , 0.      ], [0.      , 0.      ]],\n",
                "                                [[0.      , 0.      ], [0.      , 3.843624]]], dtype=float32)}}}\n",
                "\n",
                "  Thus each leaf in the tree structure of ``jax.hessian(fun)(x)`` corresponds to\n",
                "  a leaf of ``fun(x)`` and a pair of leaves of ``x``. For each leaf in\n",
                "  ``jax.hessian(fun)(x)``, if the corresponding array leaf of ``fun(x)`` has\n",
                "  shape ``(out_1, out_2, ...)`` and the corresponding array leaves of ``x`` have\n",
                "  shape ``(in_1_1, in_1_2, ...)`` and ``(in_2_1, in_2_2, ...)`` respectively,\n",
                "  then the Hessian leaf has shape ``(out_1, out_2, ..., in_1_1, in_1_2, ...,\n",
                "  in_2_1, in_2_2, ...)``. In other words, the Python tree structure represents\n",
                "  the block structure of the Hessian, with blocks determined by the input and\n",
                "  output pytrees.\n",
                "\n",
                "  In particular, an array is produced (with no pytrees involved) when the\n",
                "  function input ``x`` and output ``fun(x)`` are each a single array, as in the\n",
                "  ``g`` example above. If ``fun(x)`` has shape ``(out1, out2, ...)`` and ``x``\n",
                "  has shape ``(in1, in2, ...)`` then ``jax.hessian(fun)(x)`` has shape\n",
                "  ``(out1, out2, ..., in1, in2, ..., in1, in2, ...)``. To flatten pytrees into\n",
                "  1D vectors, consider using :py:func:`jax.flatten_util.flatten_pytree`.\n",
                "  \"\"\"\n",
                "  return jacfwd(jacrev(fun, argnums, holomorphic), argnums, holomorphic)\n",
                "\n",
                "def _std_basis(pytree):\n",
                "  leaves, _ = tree_flatten(pytree)\n",
                "  ndim = sum(map(np.size, leaves))\n",
                "  dtype = dtypes.result_type(*leaves)\n",
                "  flat_basis = jax.numpy.eye(ndim, dtype=dtype)\n",
                "  return _unravel_array_into_pytree(pytree, 1, None, flat_basis)\n",
                "\n",
                "def _jacfwd_unravel(input_pytree, output_pytree_leaf, arr):\n",
                "  return _unravel_array_into_pytree(\n",
                "    input_pytree, -1, output_pytree_leaf, arr)\n",
                "\n",
                "def _jacrev_unravel(output_pytree, input_pytree_leaf, arr):\n",
                "  return _unravel_array_into_pytree(\n",
                "    output_pytree, 0, input_pytree_leaf, arr)\n",
                "\n",
                "def _possible_downcast(x, example):\n",
                "  if (dtypes.issubdtype(x.dtype, np.complexfloating) and\n",
                "      not dtypes.issubdtype(_dtype(example), np.complexfloating)):\n",
                "    x = x.real\n",
                "  dtype = None if example is None else _dtype(example)\n",
                "  weak_type = None if example is None else dtypes.is_weakly_typed(example)\n",
                "  return jax._src.lax.lax._convert_element_type(x, dtype, weak_type)\n",
                "\n",
                "def _unravel_array_into_pytree(pytree, axis, example, arr):\n",
                "  \"\"\"Unravel an array into a PyTree with a given structure.\n",
                "  Args:\n",
                "      pytree: The pytree that provides the structure.\n",
                "      axis: The parameter axis is either -1, 0, or 1.  It controls the\n",
                "        resulting shapes.\n",
                "      example: If specified, cast the components to the matching dtype/weak_type,\n",
                "        or else use the pytree leaf type if example is None.\n",
                "      arr: The array to be unraveled.\n",
                "  \"\"\"\n",
                "  leaves, treedef = tree_flatten(pytree)\n",
                "  axis = axis % arr.ndim\n",
                "  shapes = [arr.shape[:axis] + np.shape(l) + arr.shape[axis+1:] for l in leaves]\n",
                "  parts = _split(arr, np.cumsum(map(np.size, leaves[:-1])), axis)\n",
                "  reshaped_parts = [\n",
                "      _possible_downcast(np.reshape(x, shape), leaf if example is None else example)\n",
                "      for x, shape, leaf in zip(parts, shapes, leaves)]\n",
                "  return tree_unflatten(treedef, reshaped_parts)\n",
                "\n",
                "def _split(x, indices, axis):\n",
                "  if isinstance(x, np.ndarray):\n",
                "    return np.split(x, indices, axis)\n",
                "  else:\n",
                "    return x.split(indices, axis)\n",
                "\n",
                "\n",
                "def vmap(fun: F, in_axes=0, out_axes=0, axis_name=None, axis_size=None) -> F:\n",
                "  \"\"\"Vectorizing map. Creates a function which maps ``fun`` over argument axes.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be mapped over additional axes.\n",
                "    in_axes: An integer, None, or (nested) standard Python container\n",
                "      (tuple/list/dict) thereof specifying which input array axes to map over.\n",
                "\n",
                "      If each positional argument to ``fun`` is an array, then ``in_axes`` can\n",
                "      be an integer, a None, or a tuple of integers and Nones with length equal\n",
                "      to the number of positional arguments to ``fun``. An integer or ``None``\n",
                "      indicates which array axis to map over for all arguments (with ``None``\n",
                "      indicating not to map any axis), and a tuple indicates which axis to map\n",
                "      for each corresponding positional argument. Axis integers must be in the\n",
                "      range ``[-ndim, ndim)`` for each array, where ``ndim`` is the number of\n",
                "      dimensions (axes) of the corresponding input array.\n",
                "\n",
                "      If the positional arguments to ``fun`` are container (pytree) types, the\n",
                "      corresponding element of ``in_axes`` can itself be a matching container,\n",
                "      so that distinct array axes can be mapped for different container\n",
                "      elements. ``in_axes`` must be a container tree prefix of the positional\n",
                "      argument tuple passed to ``fun``. See this link for more detail:\n",
                "      https://jax.readthedocs.io/en/latest/pytrees.html#applying-optional-parameters-to-pytrees\n",
                "\n",
                "      Either ``axis_size`` must be provided explicitly, or at least one\n",
                "      positional argument must have ``in_axes`` not None. The sizes of the\n",
                "      mapped input axes for all mapped positional arguments must all be equal.\n",
                "\n",
                "      Arguments passed as keywords are always mapped over their leading axis\n",
                "      (i.e. axis index 0).\n",
                "\n",
                "      See below for examples.\n",
                "\n",
                "    out_axes: An integer, None, or (nested) standard Python container\n",
                "      (tuple/list/dict) thereof indicating where the mapped axis should appear\n",
                "      in the output. All outputs with a mapped axis must have a non-None\n",
                "      ``out_axes`` specification. Axis integers must be in the range ``[-ndim,\n",
                "      ndim)`` for each output array, where ``ndim`` is the number of dimensions\n",
                "      (axes) of the array returned by the :func:`vmap`-ed function, which is one\n",
                "      more than the number of dimensions (axes) of the corresponding array\n",
                "      returned by ``fun``.\n",
                "    axis_name: Optional, a hashable Python object used to identify the mapped\n",
                "      axis so that parallel collectives can be applied.\n",
                "    axis_size: Optional, an integer indicating the size of the axis to be\n",
                "      mapped. If not provided, the mapped axis size is inferred from arguments.\n",
                "\n",
                "  Returns:\n",
                "    Batched/vectorized version of ``fun`` with arguments that correspond to\n",
                "    those of ``fun``, but with extra array axes at positions indicated by\n",
                "    ``in_axes``, and a return value that corresponds to that of ``fun``, but\n",
                "    with extra array axes at positions indicated by ``out_axes``.\n",
                "\n",
                "  For example, we can implement a matrix-matrix product using a vector dot\n",
                "  product:\n",
                "\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>>\n",
                "  >>> vv = lambda x, y: jnp.vdot(x, y)  #  ([a], [a]) -> []\n",
                "  >>> mv = vmap(vv, (0, None), 0)      #  ([b,a], [a]) -> [b]      (b is the mapped axis)\n",
                "  >>> mm = vmap(mv, (None, 1), 1)      #  ([b,a], [a,c]) -> [b,c]  (c is the mapped axis)\n",
                "\n",
                "  Here we use ``[a,b]`` to indicate an array with shape (a,b). Here are some\n",
                "  variants:\n",
                "\n",
                "  >>> mv1 = vmap(vv, (0, 0), 0)   #  ([b,a], [b,a]) -> [b]        (b is the mapped axis)\n",
                "  >>> mv2 = vmap(vv, (0, 1), 0)   #  ([b,a], [a,b]) -> [b]        (b is the mapped axis)\n",
                "  >>> mm2 = vmap(mv2, (1, 1), 0)  #  ([b,c,a], [a,c,b]) -> [c,b]  (c is the mapped axis)\n",
                "\n",
                "  Here's an example of using container types in ``in_axes`` to specify which\n",
                "  axes of the container elements to map over:\n",
                "\n",
                "  >>> A, B, C, D = 2, 3, 4, 5\n",
                "  >>> x = jnp.ones((A, B))\n",
                "  >>> y = jnp.ones((B, C))\n",
                "  >>> z = jnp.ones((C, D))\n",
                "  >>> def foo(tree_arg):\n",
                "  ...   x, (y, z) = tree_arg\n",
                "  ...   return jnp.dot(x, jnp.dot(y, z))\n",
                "  >>> tree = (x, (y, z))\n",
                "  >>> print(foo(tree))\n",
                "  [[12. 12. 12. 12. 12.]\n",
                "   [12. 12. 12. 12. 12.]]\n",
                "  >>> from jax import vmap\n",
                "  >>> K = 6  # batch size\n",
                "  >>> x = jnp.ones((K, A, B))  # batch axis in different locations\n",
                "  >>> y = jnp.ones((B, K, C))\n",
                "  >>> z = jnp.ones((C, D, K))\n",
                "  >>> tree = (x, (y, z))\n",
                "  >>> vfoo = vmap(foo, in_axes=((0, (1, 2)),))\n",
                "  >>> print(vfoo(tree).shape)\n",
                "  (6, 2, 5)\n",
                "\n",
                "  Here's another example using container types in ``in_axes``, this time a\n",
                "  dictionary, to specify the elements of the container to map over:\n",
                "\n",
                "  >>> dct = {'a': 0., 'b': jnp.arange(5.)}\n",
                "  >>> x = 1.\n",
                "  >>> def foo(dct, x):\n",
                "  ...  return dct['a'] + dct['b'] + x\n",
                "  >>> out = vmap(foo, in_axes=({'a': None, 'b': 0}, None))(dct, x)\n",
                "  >>> print(out)\n",
                "  [1. 2. 3. 4. 5.]\n",
                "\n",
                "  The results of a vectorized function can be mapped or unmapped. For example,\n",
                "  the function below returns a pair with the first element mapped and the second\n",
                "  unmapped. Only for unmapped results we can specify ``out_axes`` to be ``None``\n",
                "  (to keep it unmapped).\n",
                "\n",
                "  >>> print(vmap(lambda x, y: (x + y, y * 2.), in_axes=(0, None), out_axes=(0, None))(jnp.arange(2.), 4.))\n",
                "  (DeviceArray([4., 5.], dtype=float32), 8.0)\n",
                "\n",
                "  If the ``out_axes`` is specified for an unmapped result, the result is\n",
                "  broadcast across the mapped axis:\n",
                "\n",
                "  >>> print(vmap(lambda x, y: (x + y, y * 2.), in_axes=(0, None), out_axes=0)(jnp.arange(2.), 4.))\n",
                "  (DeviceArray([4., 5.], dtype=float32), DeviceArray([8., 8.], dtype=float32, weak_type=True))\n",
                "\n",
                "  If the ``out_axes`` is specified for a mapped result, the result is transposed\n",
                "  accordingly.\n",
                "\n",
                "  Finally, here's an example using ``axis_name`` together with collectives:\n",
                "\n",
                "  >>> xs = jnp.arange(3. * 4.).reshape(3, 4)\n",
                "  >>> print(vmap(lambda x: lax.psum(x, 'i'), axis_name='i')(xs))\n",
                "  [[12. 15. 18. 21.]\n",
                "   [12. 15. 18. 21.]\n",
                "   [12. 15. 18. 21.]]\n",
                "\n",
                "  See the :py:func:`jax.pmap` docstring for more examples involving collectives.\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "  docstr = (\"Vectorized version of {fun}. Takes similar arguments as {fun} \"\n",
                "            \"but with additional array axes over which {fun} is mapped.\")\n",
                "  if fun.__doc__:\n",
                "    docstr += \"\\n\\nOriginal documentation:\\n\\n\"\n",
                "    docstr += fun.__doc__\n",
                "\n",
                "  axis_name = core.no_axis_name if axis_name is None else axis_name\n",
                "\n",
                "  if isinstance(in_axes, list):\n",
                "    # To be a tree prefix of the positional args tuple, in_axes can never be a\n",
                "    # list: if in_axes is not a leaf, it must be a tuple of trees. However,\n",
                "    # in cases like these users expect tuples and lists to be treated\n",
                "    # essentially interchangeably, so we canonicalize lists to tuples here\n",
                "    # rather than raising an error. https://github.com/google/jax/issues/2367\n",
                "    in_axes = tuple(in_axes)\n",
                "\n",
                "  if not all(type(l) is int or type(l) in batching.spec_types\n",
                "             for l in tree_leaves(in_axes)):\n",
                "    raise TypeError(\"vmap in_axes must be an int, None, or (nested) container \"\n",
                "                    f\"with those types as leaves, but got {in_axes}.\")\n",
                "  if not all(type(l) is int or type(l) in batching.spec_types\n",
                "               for l in tree_leaves(out_axes)):\n",
                "    raise TypeError(\"vmap out_axes must be an int, None, or (nested) container \"\n",
                "                    f\"with those types as leaves, but got {out_axes}.\")\n",
                "\n",
                "  @wraps(fun, docstr=docstr)\n",
                "  @api_boundary\n",
                "  def vmap_f(*args, **kwargs):\n",
                "    args_flat, in_tree  = tree_flatten((args, kwargs), is_leaf=batching.is_vmappable)\n",
                "    f = lu.wrap_init(fun)\n",
                "    flat_fun, out_tree = batching.flatten_fun_for_vmap(f, in_tree)\n",
                "    in_axes_flat = flatten_axes(\"vmap in_axes\", in_tree, (in_axes, 0), kws=True)\n",
                "    axis_size_ = (axis_size if axis_size is not None else\n",
                "                  _mapped_axis_size(in_tree, args_flat, in_axes_flat, \"vmap\",\n",
                "                                    kws=True))\n",
                "    out_flat = batching.batch(\n",
                "        flat_fun, axis_name, axis_size_, in_axes_flat,\n",
                "        lambda: flatten_axes(\"vmap out_axes\", out_tree(), out_axes)\n",
                "    ).call_wrapped(*args_flat)\n",
                "    return tree_unflatten(out_tree(), out_flat)\n",
                "\n",
                "  return vmap_f\n",
                "\n",
                "def _mapped_axis_size(tree, vals, dims, name, *, kws=False):\n",
                "  if not vals:\n",
                "    args, kwargs = tree_unflatten(tree, vals)\n",
                "    raise ValueError(\n",
                "        f\"{name} wrapped function must be passed at least one argument \"\n",
                "        f\"containing an array, got empty *args={args} and **kwargs={kwargs}\"\n",
                "    )\n",
                "\n",
                "  def _get_axis_size(name: str, shape: Tuple[int, ...], axis: int):\n",
                "    try:\n",
                "      return shape[axis]\n",
                "    except (IndexError, TypeError) as e:\n",
                "      min_rank = axis + 1 if axis >= 0 else -axis\n",
                "      raise ValueError(f\"{name} was requested to map its argument along axis {axis}, \"\n",
                "                       f\"which implies that its rank should be at least {min_rank}, \"\n",
                "                       f\"but is only {len(shape)} (its shape is {shape})\") from e\n",
                "\n",
                "  mapped_axis_sizes = {_get_axis_size(name, np.shape(x), d)\n",
                "                       for x, d in zip(vals, dims)\n",
                "                       if d is not None}\n",
                "  try:\n",
                "    size, = mapped_axis_sizes\n",
                "    return size\n",
                "  except ValueError as e:\n",
                "    if not mapped_axis_sizes:\n",
                "      raise ValueError(f\"{name} must have at least one non-None value in in_axes\") from e\n",
                "    msg = f\"{name} got inconsistent sizes for array axes to be mapped:\\n\" + \"{}\"\n",
                "    # we switch the error message based on whether args is a tuple of arrays,\n",
                "    # in which case we can produce an error message based on argument indices,\n",
                "    # or if it has nested containers.\n",
                "    if kws:\n",
                "      # if keyword arguments are included in the tree, we make adapt the error\n",
                "      # message only to be about the positional arguments\n",
                "      tree, leaf = treedef_children(tree)\n",
                "      assert treedef_is_leaf(leaf)\n",
                "    # TODO(mattjj,phawkins): add a way to inspect pytree kind more directly\n",
                "    if tree == tree_flatten((core.unit,) * tree.num_leaves)[1]:\n",
                "      lines1 = [f\"arg {i} has shape {np.shape(x)} and axis {d} is to be mapped\"\n",
                "                for i, (x, d) in enumerate(zip(vals, dims))]\n",
                "      sizes = collections.defaultdict(list)\n",
                "      for i, (x, d) in enumerate(zip(vals, dims)):\n",
                "        if d is not None:\n",
                "          sizes[x.shape[d]].append(i)\n",
                "      lines2 = [\"{} {} {} {} to be mapped of size {}\".format(\n",
                "                  \"args\" if len(idxs) > 1 else \"arg\",\n",
                "                  \", \".join(map(str, idxs)),\n",
                "                  \"have\" if len(idxs) > 1 else \"has\",\n",
                "                  \"axes\" if len(idxs) > 1 else \"an axis\",\n",
                "                  size)\n",
                "                for size, idxs in sizes.items()]\n",
                "      raise ValueError(msg.format(\"\\n\".join(lines1 + [\"so\"] + lines2))) from None\n",
                "    else:\n",
                "      sizes = [x.shape[d] if d is not None else None for x, d in zip(vals, dims)]\n",
                "      sizes = tree_unflatten(tree, sizes)\n",
                "      raise ValueError(msg.format(f\"the tree of axis sizes is:\\n{sizes}\")) from None\n",
                "\n",
                "def pmap(\n",
                "  fun: Callable,\n",
                "  axis_name: Optional[AxisName] = None,\n",
                "  *,\n",
                "  in_axes=0,\n",
                "  out_axes=0,\n",
                "  static_broadcasted_argnums: Union[int, Iterable[int]] = (),\n",
                "  devices: Optional[Sequence[xc.Device]] = None,\n",
                "  backend: Optional[str] = None,\n",
                "  axis_size: Optional[int] = None,\n",
                "  donate_argnums: Union[int, Iterable[int]] = (),\n",
                "  global_arg_shapes: Optional[Tuple[Tuple[int, ...], ...]] = None,\n",
                ") -> Any:\n",
                "  \"\"\"Parallel map with support for collective operations.\n",
                "\n",
                "  The purpose of :py:func:`pmap` is to express single-program multiple-data\n",
                "  (SPMD) programs. Applying :py:func:`pmap` to a function will compile the\n",
                "  function with XLA (similarly to :py:func:`jit`), then execute it in parallel\n",
                "  on XLA devices, such as multiple GPUs or multiple TPU cores. Semantically it\n",
                "  is comparable to :py:func:`vmap` because both transformations map a function\n",
                "  over array axes, but where :py:func:`vmap` vectorizes functions by pushing the\n",
                "  mapped axis down into primitive operations, :py:func:`pmap` instead replicates\n",
                "  the function and executes each replica on its own XLA device in parallel.\n",
                "\n",
                "  The mapped axis size must be less than or equal to the number of local XLA\n",
                "  devices available, as returned by :py:func:`jax.local_device_count()` (unless\n",
                "  ``devices`` is specified, see below). For nested :py:func:`pmap` calls, the\n",
                "  product of the mapped axis sizes must be less than or equal to the number of\n",
                "  XLA devices.\n",
                "\n",
                "  .. note::\n",
                "    :py:func:`pmap` compiles ``fun``, so while it can be combined with\n",
                "    :py:func:`jit`, it's usually unnecessary.\n",
                "\n",
                "  **Multi-process platforms:** On multi-process platforms such as TPU pods,\n",
                "  :py:func:`pmap` is designed to be used in SPMD Python programs, where every\n",
                "  process is running the same Python code such that all processes run the same\n",
                "  pmapped function in the same order. Each process should still call the pmapped\n",
                "  function with mapped axis size equal to the number of *local* devices (unless\n",
                "  ``devices`` is specified, see below), and an array of the same leading axis\n",
                "  size will be returned as usual. However, any collective operations in ``fun``\n",
                "  will be computed over *all* participating devices, including those on other\n",
                "  processes, via device-to-device communication.  Conceptually, this can be\n",
                "  thought of as running a pmap over a single array sharded across processes,\n",
                "  where each process \"sees\" only its local shard of the input and output. The\n",
                "  SPMD model requires that the same multi-process pmaps must be run in the same\n",
                "  order on all devices, but they can be interspersed with arbitrary operations\n",
                "  running in a single process.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be mapped over argument axes. Its arguments and return\n",
                "      value should be arrays, scalars, or (nested) standard Python containers\n",
                "      (tuple/list/dict) thereof. Positional arguments indicated by\n",
                "      ``static_broadcasted_argnums`` can be anything at all, provided they are\n",
                "      hashable and have an equality operation defined.\n",
                "    axis_name: Optional, a hashable Python object used to identify the mapped\n",
                "      axis so that parallel collectives can be applied.\n",
                "    in_axes: A non-negative integer, None, or nested Python container thereof\n",
                "      that specifies which axes of positional arguments to map over. Arguments\n",
                "      passed as keywords are always mapped over their leading axis (i.e. axis\n",
                "      index 0). See :py:func:`vmap` for details.\n",
                "    out_axes: A non-negative integer, None, or nested Python container thereof\n",
                "      indicating where the mapped axis should appear in the output. All outputs\n",
                "      with a mapped axis must have a non-None ``out_axes`` specification\n",
                "      (see :py:func:`vmap`).\n",
                "    static_broadcasted_argnums: An int or collection of ints specifying which\n",
                "      positional arguments to treat as static (compile-time constant).\n",
                "      Operations that only depend on static arguments will be constant-folded.\n",
                "      Calling the pmapped function with different values for these constants\n",
                "      will trigger recompilation. If the pmapped function is called with fewer\n",
                "      positional arguments than indicated by ``static_argnums`` then an error is\n",
                "      raised. Each of the static arguments will be broadcasted to all devices.\n",
                "      Arguments that are not arrays or containers thereof must be marked as\n",
                "      static. Defaults to ().\n",
                "\n",
                "      Static arguments must be hashable, meaning both ``__hash__`` and\n",
                "      ``__eq__`` are implemented, and should be immutable.\n",
                "\n",
                "    devices: This is an experimental feature and the API is likely to change.\n",
                "      Optional, a sequence of Devices to map over. (Available devices can be\n",
                "      retrieved via jax.devices()). Must be given identically for each process\n",
                "      in multi-process settings (and will therefore include devices across\n",
                "      processes). If specified, the size of the mapped axis must be equal to\n",
                "      the number of devices in the sequence local to the given process. Nested\n",
                "      :py:func:`pmap` s with ``devices`` specified in either the inner or outer\n",
                "      :py:func:`pmap` are not yet supported.\n",
                "    backend: This is an experimental feature and the API is likely to change.\n",
                "      Optional, a string representing the XLA backend. 'cpu', 'gpu', or 'tpu'.\n",
                "    axis_size: Optional; the size of the mapped axis.\n",
                "    donate_argnums: Specify which argument buffers are \"donated\" to the computation.\n",
                "      It is safe to donate argument buffers if you no longer need them once the\n",
                "      computation has finished. In some cases XLA can make use of donated\n",
                "      buffers to reduce the amount of memory needed to perform a computation,\n",
                "      for example recycling one of your input buffers to store a result. You\n",
                "      should not reuse buffers that you donate to a computation, JAX will raise\n",
                "      an error if you try to.\n",
                "\n",
                "      For more details on buffer donation see the [FAQ](https://jax.readthedocs.io/en/latest/faq.html#buffer-donation).\n",
                "\n",
                "    global_arg_shapes: Optional, must be set when using pmap(sharded_jit) and\n",
                "      the partitioned values span multiple processes. The global cross-process\n",
                "      per-replica shape of each argument, i.e. does not include the leading\n",
                "      pmapped dimension. Can be None for replicated arguments. This API is\n",
                "      likely to change in the future.\n",
                "\n",
                "  Returns:\n",
                "    A parallelized version of ``fun`` with arguments that correspond to those of\n",
                "    ``fun`` but with extra array axes at positions indicated by ``in_axes`` and\n",
                "    with output that has an additional leading array axis (with the same size).\n",
                "\n",
                "  For example, assuming 8 XLA devices are available, :py:func:`pmap` can be used\n",
                "  as a map along a leading array axis:\n",
                "\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>>\n",
                "  >>> out = pmap(lambda x: x ** 2)(jnp.arange(8))  # doctest: +SKIP\n",
                "  >>> print(out)  # doctest: +SKIP\n",
                "  [0, 1, 4, 9, 16, 25, 36, 49]\n",
                "\n",
                "  When the leading dimension is smaller than the number of available devices JAX\n",
                "  will simply run on a subset of devices:\n",
                "\n",
                "  >>> x = jnp.arange(3 * 2 * 2.).reshape((3, 2, 2))\n",
                "  >>> y = jnp.arange(3 * 2 * 2.).reshape((3, 2, 2)) ** 2\n",
                "  >>> out = pmap(jnp.dot)(x, y)  # doctest: +SKIP\n",
                "  >>> print(out)  # doctest: +SKIP\n",
                "  [[[    4.     9.]\n",
                "    [   12.    29.]]\n",
                "   [[  244.   345.]\n",
                "    [  348.   493.]]\n",
                "   [[ 1412.  1737.]\n",
                "    [ 1740.  2141.]]]\n",
                "\n",
                "  If your leading dimension is larger than the number of available devices you\n",
                "  will get an error:\n",
                "\n",
                "  >>> pmap(lambda x: x ** 2)(jnp.arange(9))  # doctest: +SKIP\n",
                "  ValueError: ... requires 9 replicas, but only 8 XLA devices are available\n",
                "\n",
                "  As with :py:func:`vmap`, using ``None`` in ``in_axes`` indicates that an\n",
                "  argument doesn't have an extra axis and should be broadcasted, rather than\n",
                "  mapped, across the replicas:\n",
                "\n",
                "  >>> x, y = jnp.arange(2.), 4.\n",
                "  >>> out = pmap(lambda x, y: (x + y, y * 2.), in_axes=(0, None))(x, y)  # doctest: +SKIP\n",
                "  >>> print(out)  # doctest: +SKIP\n",
                "  ([4., 5.], [8., 8.])\n",
                "\n",
                "  Note that :py:func:`pmap` always returns values mapped over their leading axis,\n",
                "  equivalent to using ``out_axes=0`` in :py:func:`vmap`.\n",
                "\n",
                "  In addition to expressing pure maps, :py:func:`pmap` can also be used to express\n",
                "  parallel single-program multiple-data (SPMD) programs that communicate via\n",
                "  collective operations. For example:\n",
                "\n",
                "  >>> f = lambda x: x / jax.lax.psum(x, axis_name='i')\n",
                "  >>> out = pmap(f, axis_name='i')(jnp.arange(4.))  # doctest: +SKIP\n",
                "  >>> print(out)  # doctest: +SKIP\n",
                "  [ 0.          0.16666667  0.33333334  0.5       ]\n",
                "  >>> print(out.sum())  # doctest: +SKIP\n",
                "  1.0\n",
                "\n",
                "  In this example, ``axis_name`` is a string, but it can be any Python object\n",
                "  with ``__hash__`` and ``__eq__`` defined.\n",
                "\n",
                "  The argument ``axis_name`` to :py:func:`pmap` names the mapped axis so that\n",
                "  collective operations, like :func:`jax.lax.psum`, can refer to it. Axis names\n",
                "  are important particularly in the case of nested :py:func:`pmap` functions,\n",
                "  where collective operations can operate over distinct axes:\n",
                "\n",
                "  >>> from functools import partial\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> @partial(pmap, axis_name='rows')\n",
                "  ... @partial(pmap, axis_name='cols')\n",
                "  ... def normalize(x):\n",
                "  ...   row_normed = x / jax.lax.psum(x, 'rows')\n",
                "  ...   col_normed = x / jax.lax.psum(x, 'cols')\n",
                "  ...   doubly_normed = x / jax.lax.psum(x, ('rows', 'cols'))\n",
                "  ...   return row_normed, col_normed, doubly_normed\n",
                "  >>>\n",
                "  >>> x = jnp.arange(8.).reshape((4, 2))\n",
                "  >>> row_normed, col_normed, doubly_normed = normalize(x)  # doctest: +SKIP\n",
                "  >>> print(row_normed.sum(0))  # doctest: +SKIP\n",
                "  [ 1.  1.]\n",
                "  >>> print(col_normed.sum(1))  # doctest: +SKIP\n",
                "  [ 1.  1.  1.  1.]\n",
                "  >>> print(doubly_normed.sum((0, 1)))  # doctest: +SKIP\n",
                "  1.0\n",
                "\n",
                "  On multi-process platforms, collective operations operate over all devices,\n",
                "  including those on other processes. For example, assuming the following code\n",
                "  runs on two processes with 4 XLA devices each:\n",
                "\n",
                "  >>> f = lambda x: x + jax.lax.psum(x, axis_name='i')\n",
                "  >>> data = jnp.arange(4) if jax.process_index() == 0 else jnp.arange(4, 8)\n",
                "  >>> out = pmap(f, axis_name='i')(data)  # doctest: +SKIP\n",
                "  >>> print(out)  # doctest: +SKIP\n",
                "  [28 29 30 31] # on process 0\n",
                "  [32 33 34 35] # on process 1\n",
                "\n",
                "  Each process passes in a different length-4 array, corresponding to its 4\n",
                "  local devices, and the psum operates over all 8 values. Conceptually, the two\n",
                "  length-4 arrays can be thought of as a sharded length-8 array (in this example\n",
                "  equivalent to jnp.arange(8)) that is mapped over, with the length-8 mapped\n",
                "  axis given name 'i'. The pmap call on each process then returns the\n",
                "  corresponding length-4 output shard.\n",
                "\n",
                "  The ``devices`` argument can be used to specify exactly which devices are used\n",
                "  to run the parallel computation. For example, again assuming a single process\n",
                "  with 8 devices, the following code defines two parallel computations, one\n",
                "  which runs on the first six devices and one on the remaining two:\n",
                "\n",
                "  >>> from functools import partial\n",
                "  >>> @partial(pmap, axis_name='i', devices=jax.devices()[:6])\n",
                "  ... def f1(x):\n",
                "  ...   return x / jax.lax.psum(x, axis_name='i')\n",
                "  >>>\n",
                "  >>> @partial(pmap, axis_name='i', devices=jax.devices()[-2:])\n",
                "  ... def f2(x):\n",
                "  ...   return jax.lax.psum(x ** 2, axis_name='i')\n",
                "  >>>\n",
                "  >>> print(f1(jnp.arange(6.)))  # doctest: +SKIP\n",
                "  [0.         0.06666667 0.13333333 0.2        0.26666667 0.33333333]\n",
                "  >>> print(f2(jnp.array([2., 3.])))  # doctest: +SKIP\n",
                "  [ 13.  13.]\n",
                "  \"\"\"\n",
                "  if FLAGS.experimental_cpp_pmap:\n",
                "    func = _cpp_pmap\n",
                "  else:\n",
                "    func = _python_pmap\n",
                "\n",
                "  return func(\n",
                "      fun,\n",
                "      axis_name,\n",
                "      in_axes=in_axes,\n",
                "      out_axes=out_axes,\n",
                "      static_broadcasted_argnums=static_broadcasted_argnums,\n",
                "      devices=devices,\n",
                "      backend=backend,\n",
                "      axis_size=axis_size,\n",
                "      donate_argnums=donate_argnums,\n",
                "      global_arg_shapes=global_arg_shapes)\n",
                "\n",
                "\n",
                "class PmapCallInfo(NamedTuple):\n",
                "  flat_fun: lu.WrappedFun\n",
                "  in_tree: PyTreeDef\n",
                "  out_tree: PyTreeDef\n",
                "  flat_args: Sequence[Any]\n",
                "  donated_invars: Sequence[bool]\n",
                "  in_axes_flat: Sequence[Optional[int]]\n",
                "  local_axis_size: int\n",
                "  global_arg_shapes_flat: Sequence[Optional[Tuple[int, ...]]]\n",
                "  out_axes_thunk: HashableFunction\n",
                "\n",
                "\n",
                "def _prepare_pmap(fun, in_axes, out_axes, static_broadcasted_tuple,\n",
                "                  donate_tuple, global_arg_shapes, args, kwargs):\n",
                "  f = lu.wrap_init(fun)\n",
                "  if static_broadcasted_tuple:\n",
                "    if max(static_broadcasted_tuple) >= len(args):\n",
                "      raise ValueError(\n",
                "          f\"pmapped function has static_broadcasted_argnums={static_broadcasted_tuple}\"\n",
                "          f\" but was called with only {len(args)} positional \"\n",
                "          f\"argument{'s' if len(args) > 1 else ''}. \"\n",
                "          \"All static broadcasted arguments must be passed positionally.\")\n",
                "    dyn_argnums = [i for i in range(len(args))\n",
                "                   if i not in static_broadcasted_tuple]\n",
                "    f, dyn_args = argnums_partial(f, dyn_argnums, args)\n",
                "\n",
                "    if isinstance(in_axes, tuple):\n",
                "      dyn_in_axes = tuple(in_axes[i] for i in dyn_argnums)\n",
                "    else:\n",
                "      dyn_in_axes = in_axes\n",
                "      dyn_global_arg_shapes = global_arg_shapes\n",
                "\n",
                "    if isinstance(global_arg_shapes, tuple):\n",
                "      dyn_global_arg_shapes = tuple(global_arg_shapes[i] for i in dyn_argnums)\n",
                "    else:\n",
                "      dyn_global_arg_shapes = global_arg_shapes\n",
                "  else:\n",
                "    dyn_args, dyn_in_axes = args, in_axes\n",
                "    dyn_global_arg_shapes = global_arg_shapes\n",
                "  args, in_tree = tree_flatten((dyn_args, kwargs))\n",
                "\n",
                "  if donate_tuple:\n",
                "    donated_invars = donation_vector(donate_tuple, dyn_args, kwargs)\n",
                "  else:\n",
                "    donated_invars = (False,) * len(args)\n",
                "  in_axes_flat = tuple(flatten_axes(\"pmap in_axes\", in_tree, (dyn_in_axes, 0)))\n",
                "  global_arg_shapes_flat = tuple(flatten_axes(\n",
                "      \"pmap global_arg_shapes\", in_tree, (dyn_global_arg_shapes, None),\n",
                "      kws=True))\n",
                "  local_axis_size = _mapped_axis_size(\n",
                "      in_tree, args, in_axes_flat, \"pmap\", kws=True)\n",
                "\n",
                "  for arg in args:\n",
                "    _check_arg(arg)\n",
                "\n",
                "  flat_fun, out_tree = flatten_fun(f, in_tree)\n",
                "\n",
                "  if any(out_axis is None for out_axis in tree_flatten(out_axes)):\n",
                "    raise NotImplementedError(\"None out_axes in pmap are not supported yet\")\n",
                "  # NOTE: We don't put out_tree() in the closure, because it's (1) non-hashable,\n",
                "  #       (2) depends deterministically on flat_fun (at least that's the assumption\n",
                "  #       that we make).\n",
                "  if out_axes == 0:\n",
                "    # TODO(apaszke,mattjj): flatten_axes assumes that the output pytree is\n",
                "    #   functorial (i.e. it can hold leaves of any type), but some user code\n",
                "    #   breaks this assumption. This is a stop-gap solution to keep the old\n",
                "    #   out_axes == 0 path working as we look for a better solution.\n",
                "    out_axes_thunk = HashableFunction(\n",
                "        lambda: (0,) * out_tree().num_leaves,\n",
                "        closure=out_axes)\n",
                "  else:\n",
                "    # out_axes_thunk closes over the out_axes, they are flattened here to make\n",
                "    # them hashable.\n",
                "    out_axes_leaves, out_axes_treedef = tree_flatten(out_axes)\n",
                "    out_axes_thunk = HashableFunction(\n",
                "        lambda: tuple(flatten_axes(\"pmap out_axes\", out_tree(),\n",
                "                                    tree_unflatten(out_axes_treedef,\n",
                "                                                  list(out_axes_leaves)))),\n",
                "        closure=(tuple(out_axes_leaves), out_axes_treedef))\n",
                "\n",
                "  return PmapCallInfo(flat_fun=flat_fun,\n",
                "                      in_tree=in_tree,\n",
                "                      out_tree=out_tree,\n",
                "                      flat_args=args,\n",
                "                      donated_invars=donated_invars,\n",
                "                      in_axes_flat=in_axes_flat,\n",
                "                      local_axis_size=local_axis_size,\n",
                "                      global_arg_shapes_flat=global_arg_shapes_flat,\n",
                "                      out_axes_thunk=out_axes_thunk)\n",
                "\n",
                "\n",
                "def _get_f_mapped(\n",
                "    *,\n",
                "    fun: Callable,\n",
                "    axis_name: Optional[AxisName],\n",
                "    in_axes=0,\n",
                "    out_axes=0,\n",
                "    static_broadcasted_tuple: Tuple[int],\n",
                "    devices: Optional[Sequence[xc.Device]],\n",
                "    backend: Optional[str],\n",
                "    axis_size: Optional[int],\n",
                "    donate_tuple: Tuple[int],\n",
                "    global_arg_shapes: Optional[Tuple[Tuple[int, ...], ...]],\n",
                "):\n",
                "  def pmap_f(*args, **kwargs):\n",
                "    p = _prepare_pmap(\n",
                "        fun, in_axes, out_axes, static_broadcasted_tuple, donate_tuple,\n",
                "        global_arg_shapes, args, kwargs)\n",
                "    out = pxla.xla_pmap(\n",
                "        p.flat_fun, *p.flat_args, backend=backend, axis_name=axis_name,\n",
                "        axis_size=p.local_axis_size, global_axis_size=axis_size,\n",
                "        devices=None if devices is None else tuple(devices),\n",
                "        in_axes=p.in_axes_flat, out_axes_thunk=p.out_axes_thunk,\n",
                "        name=p.flat_fun.__name__, donated_invars=p.donated_invars,\n",
                "        global_arg_shapes=p.global_arg_shapes_flat)\n",
                "    return p.out_tree, out\n",
                "\n",
                "  return pmap_f\n",
                "\n",
                "\n",
                "def _shared_code_pmap(fun, axis_name, static_broadcasted_argnums,\n",
                "                      donate_argnums, in_axes, out_axes):\n",
                "  # axis_size is an optional integer representing the global axis size.  The\n",
                "  # aggregate size (across all processes) size of the mapped axis must match the\n",
                "  # given value.\n",
                "  _check_callable(fun)\n",
                "  axis_name = core._TempAxisName(fun) if axis_name is None else axis_name\n",
                "  static_broadcasted_tuple = _ensure_index_tuple(static_broadcasted_argnums)\n",
                "  donate_tuple = rebase_donate_argnums(\n",
                "      _ensure_index_tuple(donate_argnums), static_broadcasted_tuple)\n",
                "\n",
                "  if not all(type(l) is int for l in tree_leaves(in_axes)):\n",
                "    raise TypeError(\"pmap in_axes must be an int, None, or (nested) container \"\n",
                "                    f\"with those types as leaves, but got {in_axes}.\")\n",
                "  if not all(type(l) is int for l in tree_leaves(out_axes)):\n",
                "    raise TypeError(\"pmap out_axes must be an int, None, or (nested) container \"\n",
                "                    f\"with those types as leaves, but got {out_axes}.\")\n",
                "\n",
                "  return axis_name, static_broadcasted_tuple, donate_tuple\n",
                "\n",
                "\n",
                "def _python_pmap(\n",
                "    fun: Callable,\n",
                "    axis_name: Optional[AxisName] = None,\n",
                "    *,\n",
                "    in_axes=0,\n",
                "    out_axes=0,\n",
                "    static_broadcasted_argnums: Union[int, Iterable[int]] = (),\n",
                "    devices: Optional[Sequence[xc.Device]] = None,\n",
                "    backend: Optional[str] = None,\n",
                "    axis_size: Optional[int] = None,\n",
                "    donate_argnums: Union[int, Iterable[int]] = (),\n",
                "    global_arg_shapes: Optional[Tuple[Tuple[int, ...], ...]] = None,\n",
                ") -> Any:\n",
                "  \"\"\"The Python only implementation.\"\"\"\n",
                "  axis_name, static_broadcasted_tuple, donate_tuple = _shared_code_pmap(\n",
                "      fun, axis_name, static_broadcasted_argnums, donate_argnums, in_axes,\n",
                "      out_axes)\n",
                "\n",
                "  @wraps(fun)\n",
                "  @api_boundary\n",
                "  def pmap_f(*args, **kwargs):\n",
                "    f_pmapped_ = _get_f_mapped(\n",
                "        fun=fun,\n",
                "        axis_name=axis_name,\n",
                "        in_axes=in_axes,\n",
                "        out_axes=out_axes,\n",
                "        static_broadcasted_tuple=static_broadcasted_tuple,\n",
                "        devices=devices,\n",
                "        backend=backend,\n",
                "        axis_size=axis_size,\n",
                "        global_arg_shapes=global_arg_shapes,\n",
                "        donate_tuple=donate_tuple)\n",
                "\n",
                "    out_tree, out_flat = f_pmapped_(*args, **kwargs)\n",
                "    return tree_unflatten(out_tree(), out_flat)\n",
                "\n",
                "  pmap_f.lower = _pmap_lower(\n",
                "      fun, axis_name, in_axes, out_axes, static_broadcasted_tuple, devices,\n",
                "      backend, axis_size, global_arg_shapes, donate_tuple)\n",
                "\n",
                "  return pmap_f\n",
                "\n",
                "\n",
                "class _PmapFastpathData(NamedTuple):\n",
                "  version: int  # For forward and backward compatibility\n",
                "  xla_executable: xla.XlaExecutable\n",
                "  in_handler: Any\n",
                "  out_handler: Any\n",
                "  out_pytree_def: Any\n",
                "  # Data needed to handle the inputs.\n",
                "  input_sharding_specs: Sequence[pxla.ShardingSpec]\n",
                "  input_devices: Sequence[xc.Device]\n",
                "  input_indices: Sequence[pxla.Index]\n",
                "  # Data needed to build the ShardedDeviceArray from C++.\n",
                "  out_sharding_specs: Sequence[pxla.ShardingSpec]\n",
                "  out_indices: Sequence[pxla.Index]\n",
                "  out_avals: Sequence[Any]\n",
                "\n",
                "\n",
                "def _cpp_pmap(\n",
                "    fun: Callable,\n",
                "    axis_name: Optional[AxisName] = None,\n",
                "    *,\n",
                "    in_axes=0,\n",
                "    out_axes=0,\n",
                "    static_broadcasted_argnums: Union[int, Iterable[int]] = (),\n",
                "    devices: Optional[Sequence[xc.Device]] = None,\n",
                "    backend: Optional[str] = None,\n",
                "    axis_size: Optional[int] = None,\n",
                "    donate_argnums: Union[int, Iterable[int]] = (),\n",
                "    global_arg_shapes: Optional[Tuple[Tuple[int, ...], ...]] = None,\n",
                ") -> Any:\n",
                "  axis_name, static_broadcasted_tuple, donate_tuple = _shared_code_pmap(\n",
                "      fun, axis_name, static_broadcasted_argnums, donate_argnums, in_axes,\n",
                "      out_axes)\n",
                "  del static_broadcasted_argnums, donate_argnums\n",
                "\n",
                "  @api_boundary\n",
                "  def cache_miss(*args, **kwargs):\n",
                "    f_pmapped_ = _get_f_mapped(\n",
                "        fun=fun,\n",
                "        axis_name=axis_name,\n",
                "        in_axes=in_axes,\n",
                "        out_axes=out_axes,\n",
                "        static_broadcasted_tuple=static_broadcasted_tuple,\n",
                "        devices=devices,\n",
                "        backend=backend,\n",
                "        axis_size=axis_size,\n",
                "        global_arg_shapes=global_arg_shapes,\n",
                "        donate_tuple=donate_tuple)\n",
                "\n",
                "    out_tree, out_flat = f_pmapped_(*args, **kwargs)\n",
                "    out_pytree_def = out_tree()\n",
                "    out = tree_unflatten(out_pytree_def, out_flat)\n",
                "\n",
                "    ### Decide whether we can support the C++ fast path\n",
                "    execute: Optional[functools.partial] = None\n",
                "    execute = pxla.parallel_callable.most_recent_entry()\n",
                "    use_fastpath = (\n",
                "        execute is not None and\n",
                "        # We don't support JAX extension backends.\n",
                "        isinstance(execute[0], pxla.ExecuteReplicated) and\n",
                "        # No tracers in the outputs. Checking for ShardedDeviceArray should be\n",
                "        # sufficient, but we use the more general `DeviceArray`.\n",
                "        all(isinstance(x, device_array.DeviceArray) for x in out_flat))\n",
                "    ### If we can use the fastpath, we return required info to the caller.\n",
                "    if use_fastpath:\n",
                "      execute_replicated = execute[0]\n",
                "      out_handler = execute_replicated.out_handler\n",
                "      in_handler = execute_replicated.in_handler\n",
                "      fastpath_data = _PmapFastpathData(\n",
                "          version=1,\n",
                "          xla_executable=execute_replicated.xla_executable,\n",
                "          in_handler=in_handler,\n",
                "          out_handler=out_handler,\n",
                "          out_pytree_def=out_pytree_def,\n",
                "          input_sharding_specs=in_handler.sharding_specs,\n",
                "          input_devices=in_handler.local_devices,\n",
                "          input_indices=in_handler.input_indices,\n",
                "          out_sharding_specs=out_handler.out_specs,\n",
                "          out_indices=out_handler.out_indices,\n"
            ],
            {
                "type": "replace",
                "before": [
                    "          out_avals=out_handler.unmapped_local_out_avals,\n"
                ],
                "after": [
                    "          out_avals=out_handler.out_avals,\n"
                ],
                "parent_version_range": {
                    "start": 2123,
                    "end": 2124
                },
                "child_version_range": {
                    "start": 2123,
                    "end": 2124
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if use_fastpath:",
                        "start_line": 2108,
                        "end_line": 2127
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "_cpp_pmap",
                        "signature": "def _cpp_pmap(\n    fun: Callable,\n    axis_name: Optional[AxisName] = None,\n    *,\n    in_axes=0,\n    out_axes=0,\n    static_broadcasted_argnums: Union[int, Iterable[int]] = (),\n    devices: Optional[Sequence[xc.Device]] = None,\n    backend: Optional[str] = None,\n    axis_size: Optional[int] = None,\n    donate_argnums: Union[int, Iterable[int]] = (),\n    global_arg_shapes: Optional[Tuple[Tuple[int, ...], ...]] = None,\n)->Any:",
                        "at_line": 2061
                    },
                    {
                        "type": "function",
                        "name": "cache_miss",
                        "signature": "def cache_miss(*args, **kwargs):",
                        "at_line": 2080
                    },
                    {
                        "type": "call",
                        "name": "_PmapFastpathData",
                        "signature": "_PmapFastpathData(\n          version=1,\n          xla_executable=execute_replicated.xla_executable,\n          in_handler=in_handler,\n          out_handler=out_handler,\n          out_pytree_def=out_pytree_def,\n          input_sharding_specs=in_handler.sharding_specs,\n          input_devices=in_handler.local_devices,\n          input_indices=in_handler.input_indices,\n          out_sharding_specs=out_handler.out_specs,\n          out_indices=out_handler.out_indices,\n          out_avals=out_handler.unmapped_local_out_avals,\n      )",
                        "at_line": 2112,
                        "argument": "out_avals=..."
                    }
                ],
                "idx": 0,
                "hunk_diff": "File: jax/_src/api.py\nCode:\n             def _cpp_pmap(\n    fun: Callable,\n    axis_name: Optional[AxisName] = None,\n    *,\n    in_axes=0,\n    out_axes=0,\n    static_broadcasted_argnums: Union[int, Iterable[int]] = (),\n    devices: Optional[Sequence[xc.Device]] = None,\n    backend: Optional[str] = None,\n    axis_size: Optional[int] = None,\n    donate_argnums: Union[int, Iterable[int]] = (),\n    global_arg_shapes: Optional[Tuple[Tuple[int, ...], ...]] = None,\n)->Any:\n                 ...\n                 def cache_miss(*args, **kwargs):\n                     ...\n                     _PmapFastpathData(\n          version=1,\n          xla_executable=execute_replicated.xla_executable,\n          in_handler=in_handler,\n          out_handler=out_handler,\n          out_pytree_def=out_pytree_def,\n          input_sharding_specs=in_handler.sharding_specs,\n          input_devices=in_handler.local_devices,\n          input_indices=in_handler.input_indices,\n          out_sharding_specs=out_handler.out_specs,\n          out_indices=out_handler.out_indices,\n          out_avals=out_handler.unmapped_local_out_avals,\n      )\n                         ...\n2120 2120              input_indices=in_handler.input_indices,\n2121 2121              out_sharding_specs=out_handler.out_specs,\n2122 2122              out_indices=out_handler.out_indices,\n2123       -           out_avals=out_handler.unmapped_local_out_avals,\n     2123  +           out_avals=out_handler.out_avals,\n2124 2124          )\n2125 2125    \n2126 2126        else:\n           ...\n",
                "file_path": "jax/_src/api.py",
                "identifiers_before": [
                    "out_avals",
                    "out_handler",
                    "unmapped_local_out_avals"
                ],
                "identifiers_after": [
                    "out_avals",
                    "out_handler"
                ],
                "prefix": [
                    "          input_indices=in_handler.input_indices,\n",
                    "          out_sharding_specs=out_handler.out_specs,\n",
                    "          out_indices=out_handler.out_indices,\n"
                ],
                "suffix": [
                    "      )\n",
                    "\n",
                    "    else:\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    1
                ]
            },
            [
                "      )\n",
                "\n",
                "    else:\n",
                "      fastpath_data = None\n",
                "\n",
                "    return out, fastpath_data\n",
                "\n",
                "  cpp_mapped_f = pmap_lib.pmap(fun, cache_miss,\n",
                "                               static_broadcasted_tuple, pxla._shard_arg)\n",
                "\n",
                "  pmap_f = wraps(fun)(cpp_mapped_f)\n",
                "\n",
                "  pmap_f.lower = _pmap_lower(\n",
                "      fun, axis_name, in_axes, out_axes, static_broadcasted_tuple, devices,\n",
                "      backend, axis_size, global_arg_shapes, donate_tuple)\n",
                "\n",
                "  return pmap_f\n",
                "\n",
                "\n",
                "def _pmap_lower(fun, axis_name, in_axes, out_axes, static_broadcasted_tuple,\n",
                "                devices, backend, axis_size, global_arg_shapes, donate_tuple):\n",
                "  \"\"\"Make a ``lower`` method for pmapped functions.\"\"\"\n",
                "  # If the function we returned from ``pmap`` were a class instance,\n",
                "  # this might naturally be a method, with ``fun`` as a ``self`` and\n",
                "  # all the other arguments stored as attributes.\n",
                "  @api_boundary\n",
                "  def lower(*args, **kwargs) -> Lowered:\n",
                "    \"\"\"Lower a parallel-mapped form of this function for the given arguments.\n",
                "\n",
                "    A parallel-mapped and lowered function is staged out of Python and\n",
                "    translated to a compiler's input language, possibly in a\n",
                "    backend-dependent manner. It is ready for compilation but is not yet\n",
                "    compiled. It represents a function intended for SPMD execution on\n",
                "    multiple devices.\n",
                "\n",
                "    Returns:\n",
                "      A ``Lowered`` instance representing the post-map lowering.\n",
                "    \"\"\"\n",
                "    p = _prepare_pmap(\n",
                "        fun, in_axes, out_axes, static_broadcasted_tuple, donate_tuple,\n",
                "        global_arg_shapes, args, kwargs)\n",
                "    abstract_args = map(xla.abstractify, p.flat_args)\n",
                "    computation = pxla.lower_parallel_callable(\n",
                "        p.flat_fun, backend, axis_name,\n",
                "        axis_size=p.local_axis_size, global_axis_size=axis_size,\n",
                "        devices=None if devices is None else tuple(devices),\n",
                "        name=p.flat_fun.__name__,\n",
                "        in_axes=p.in_axes_flat,\n",
                "        out_axes_thunk=p.out_axes_thunk,\n",
                "        donated_invars=p.donated_invars,\n",
                "        global_arg_shapes=p.global_arg_shapes_flat,\n",
                "        avals=abstract_args)\n",
                "    return Lowered(computation, p.in_tree, p.out_tree(), donate_tuple)\n",
                "\n",
                "  return lower\n",
                "\n",
                "\n",
                "def mask(fun: Callable, in_shapes, out_shape=None) -> Callable:\n",
                "  _check_callable(fun)\n",
                "  unique_ids = masking.UniqueIds()\n",
                "\n",
                "  in_specs, in_shapes_tree = tree_flatten(in_shapes)\n",
                "  in_specs = map(masking.parse_spec, in_specs)\n",
                "  in_specs = map(partial(masking.remap_ids, unique_ids), in_specs)\n",
                "\n",
                "  if out_shape is not None:\n",
                "    out_specs, out_spec_tree = tree_flatten(out_shape)\n",
                "    out_specs = map(masking.parse_spec, out_specs)\n",
                "    out_specs = map(partial(masking.remap_ids, unique_ids), out_specs)\n",
                "\n",
                "  def wrapped_fun(args, logical_env):\n",
                "    args_flat, in_tree = tree_flatten(args)\n",
                "    if in_tree != in_shapes_tree:\n",
                "      raise TypeError(f\"Tree mismatch: Input {in_tree} and shape spec {in_shapes_tree}.\")\n",
                "    logical_env = {unique_ids[name] : val for name, val in logical_env.items()}\n",
                "    in_shapes = map(masking.finalize_spec, in_specs, map(np.shape, args_flat))\n",
                "    padded_env = masking.bind_shapes(in_shapes, [x.shape for x in args_flat])\n",
                "    f = lu.wrap_init(fun)\n",
                "    flat_fun, out_tree_thunk = flatten_fun_nokwargs(f, in_tree)\n",
                "    outs, out_shapes = masking.mask_fun(\n",
                "      flat_fun, logical_env, padded_env, args_flat, in_shapes)\n",
                "    out_tree = out_tree_thunk()\n",
                "\n",
                "    if out_shape is None:\n",
                "      def logical_shape(poly_shape, padded_val):\n",
                "        shape = masking.eval_poly_shape(poly_shape, logical_env)\n",
                "        return ShapeDtypeStruct(shape, core.get_aval(padded_val).dtype)\n",
                "      out_logicals = map(logical_shape, out_shapes, outs)\n",
                "      return tree_unflatten(out_tree, outs), tree_unflatten(out_tree, out_logicals)\n",
                "    else:\n",
                "      masking.check_shapes(out_specs, out_spec_tree, list(out_shapes), out_tree)\n",
                "      def padded_spec(shape_spec):\n",
                "        return tuple(dim if dim is masking._monomorphic_dim else\n",
                "                     masking.eval_poly(dim, padded_env) for dim in shape_spec)\n",
                "      masking.check_shapes(map(padded_spec, out_specs), out_spec_tree,\n",
                "                           map(np.shape, outs), out_tree, \"Padded output\")\n",
                "      return tree_unflatten(out_tree, outs)\n",
                "  return wrapped_fun\n",
                "\n",
                "@curry\n",
                "def shapecheck(in_shapes, out_shape, fun: Callable):\n",
                "  _check_callable(fun)\n",
                "  in_shapes, in_tree = tree_flatten(in_shapes)\n",
                "  in_shapes = map(masking.parse_spec, in_shapes)\n",
                "  out_specs, out_spec_tree = tree_flatten(out_shape)\n",
                "  out_specs = map(masking.parse_spec, out_specs)\n",
                "  flat_fun, out_tree_thunk = flatten_fun_nokwargs(lu.wrap_init(fun), in_tree)\n",
                "  avals = map(partial(ShapedArray, dtype=np.float32), in_shapes)\n",
                "  out_shapes = [o.shape for o in pe.abstract_eval_fun(flat_fun.call_wrapped, *avals)]\n",
                "  masking.check_shapes(map(tuple, out_specs), out_spec_tree,\n",
                "                       map(tuple, out_shapes), out_tree_thunk())\n",
                "  return fun\n",
                "\n",
                "def jvp(\n",
                "    fun: Callable, primals, tangents, has_aux: bool = False\n",
                ") -> Tuple[Any, ...]:\n",
                "  \"\"\"Computes a (forward-mode) Jacobian-vector product of ``fun``.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be differentiated. Its arguments should be arrays, scalars,\n",
                "      or standard Python containers of arrays or scalars. It should return an\n",
                "      array, scalar, or standard Python container of arrays or scalars.\n",
                "    primals: The primal values at which the Jacobian of ``fun`` should be\n",
                "      evaluated. Should be either a tuple or a list of arguments,\n",
                "      and its length should be equal to the number of positional parameters of\n",
                "      ``fun``.\n",
                "    tangents: The tangent vector for which the Jacobian-vector product should be\n",
                "      evaluated. Should be either a tuple or a list of tangents, with the same\n",
                "      tree structure and array shapes as ``primals``.\n",
                "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
                "     first element is considered the output of the mathematical function to be\n",
                "     differentiated and the second element is auxiliary data. Default False.\n",
                "\n",
                "  Returns:\n",
                "    If ``has_aux`` is ``False``, returns a ``(primals_out, tangents_out)`` pair,\n",
                "    where ``primals_out`` is ``fun(*primals)``,\n",
                "    and ``tangents_out`` is the Jacobian-vector product of\n",
                "    ``function`` evaluated at ``primals`` with ``tangents``. The\n",
                "    ``tangents_out`` value has the same Python tree structure and shapes as\n",
                "    ``primals_out``. If ``has_aux`` is ``True``, returns a\n",
                "    ``(primals_out, tangents_out, aux)`` tuple where ``aux``\n",
                "    is the auxiliary data returned by ``fun``.\n",
                "\n",
                "  For example:\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> y, v = jax.jvp(jax.numpy.sin, (0.1,), (0.2,))\n",
                "  >>> print(y)\n",
                "  0.09983342\n",
                "  >>> print(v)\n",
                "  0.19900084\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "  return _jvp(lu.wrap_init(fun), primals, tangents, has_aux=has_aux)\n",
                "\n",
                "def _jvp(fun: lu.WrappedFun, primals, tangents, has_aux=False):\n",
                "  \"\"\"Variant of jvp() that takes an lu.WrappedFun.\"\"\"\n",
                "  if (not isinstance(primals, (tuple, list)) or\n",
                "      not isinstance(tangents, (tuple, list))):\n",
                "    raise TypeError(\"primal and tangent arguments to jax.jvp must be tuples or lists; \"\n",
                "                    f\"found {type(primals).__name__} and {type(tangents).__name__}.\")\n",
                "\n",
                "  ps_flat, tree_def = tree_flatten(primals)\n",
                "  ts_flat, tree_def_2 = tree_flatten(tangents)\n",
                "  if tree_def != tree_def_2:\n",
                "    raise TypeError(\"primal and tangent arguments to jax.jvp must have the same tree \"\n",
                "                    f\"structure; primals have tree structure {tree_def} whereas tangents have \"\n",
                "                    f\"tree structure {tree_def_2}.\")\n",
                "  for p, t in safe_zip(ps_flat, ts_flat):\n",
                "    if core.primal_dtype_to_tangent_dtype(_dtype(p)) != _dtype(t):\n",
                "      raise TypeError(\"primal and tangent arguments to jax.jvp do not match; \"\n",
                "                      \"dtypes must be equal, or in case of int/bool primal dtype \"\n",
                "                      \"the tangent dtype must be float0.\"\n",
                "                      f\"Got primal dtype {_dtype(p)} and so expected tangent dtype \"\n",
                "                      f\"{core.primal_dtype_to_tangent_dtype(_dtype(p))}, but got \"\n",
                "                      f\"tangent dtype {_dtype(t)} instead.\")\n",
                "    if np.shape(p) != np.shape(t):\n",
                "      raise ValueError(\"jvp called with different primal and tangent shapes;\"\n",
                "                       f\"Got primal shape {np.shape(p)} and tangent shape as {np.shape(t)}\")\n",
                "\n",
                "  if not has_aux:\n",
                "    flat_fun, out_tree = flatten_fun_nokwargs(fun, tree_def)\n",
                "    out_primals, out_tangents = ad.jvp(flat_fun).call_wrapped(ps_flat, ts_flat)\n",
                "    out_tree = out_tree()\n",
                "    return (tree_unflatten(out_tree, out_primals),\n",
                "            tree_unflatten(out_tree, out_tangents))\n",
                "  else:\n",
                "    flat_fun, out_aux_trees = flatten_fun_nokwargs2(fun, tree_def)\n",
                "    jvp_fun, aux = ad.jvp(flat_fun, has_aux=True)\n",
                "    out_primals, out_tangents = jvp_fun.call_wrapped(ps_flat, ts_flat)\n",
                "    out_tree, aux_tree = out_aux_trees()\n",
                "    return (tree_unflatten(out_tree, out_primals),\n",
                "            tree_unflatten(out_tree, out_tangents),\n",
                "            tree_unflatten(aux_tree, aux()))\n",
                "\n",
                "def linearize(fun: Callable, *primals) -> Tuple[Any, Callable]:\n",
                "  \"\"\"Produces a linear approximation to ``fun`` using :py:func:`jvp` and partial eval.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be differentiated. Its arguments should be arrays, scalars,\n",
                "      or standard Python containers of arrays or scalars. It should return an\n",
                "      array, scalar, or standard python container of arrays or scalars.\n",
                "    primals: The primal values at which the Jacobian of ``fun`` should be\n",
                "      evaluated. Should be a tuple of arrays, scalar, or standard Python\n",
                "      container thereof. The length of the tuple is equal to the number of\n",
                "      positional parameters of ``fun``.\n",
                "\n",
                "  Returns:\n",
                "    A pair where the first element is the value of ``f(*primals)`` and the\n",
                "    second element is a function that evaluates the (forward-mode)\n",
                "    Jacobian-vector product of ``fun`` evaluated at ``primals`` without re-doing\n",
                "    the linearization work.\n",
                "\n",
                "  In terms of values computed, :py:func:`linearize` behaves much like a curried\n",
                "  :py:func:`jvp`, where these two code blocks compute the same values::\n",
                "\n",
                "    y, out_tangent = jax.jvp(f, (x,), (in_tangent,))\n",
                "\n",
                "    y, f_jvp = jax.linearize(f, x)\n",
                "    out_tangent = f_jvp(in_tangent)\n",
                "\n",
                "  However, the difference is that :py:func:`linearize` uses partial evaluation\n",
                "  so that the function ``f`` is not re-linearized on calls to ``f_jvp``. In\n",
                "  general that means the memory usage scales with the size of the computation,\n",
                "  much like in reverse-mode. (Indeed, :py:func:`linearize` has a similar\n",
                "  signature to :py:func:`vjp`!)\n",
                "\n",
                "  This function is mainly useful if you want to apply ``f_jvp`` multiple times,\n",
                "  i.e. to evaluate a pushforward for many different input tangent vectors at the\n",
                "  same linearization point. Moreover if all the input tangent vectors are known\n",
                "  at once, it can be more efficient to vectorize using :py:func:`vmap`, as in::\n",
                "\n",
                "    pushfwd = partial(jvp, f, (x,))\n",
                "    y, out_tangents = vmap(pushfwd, out_axes=(None, 0))((in_tangents,))\n",
                "\n",
                "  By using :py:func:`vmap` and :py:func:`jvp` together like this we avoid the stored-linearization\n",
                "  memory cost that scales with the depth of the computation, which is incurred\n",
                "  by both :py:func:`linearize` and :py:func:`vjp`.\n",
                "\n",
                "  Here's a more complete example of using :py:func:`linearize`:\n",
                "\n",
                "  >>> import jax\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>>\n",
                "  >>> def f(x): return 3. * jnp.sin(x) + jnp.cos(x / 2.)\n",
                "  ...\n",
                "  >>> jax.jvp(f, (2.,), (3.,))\n",
                "  (DeviceArray(3.26819, dtype=float32, weak_type=True), DeviceArray(-5.00753, dtype=float32, weak_type=True))\n",
                "  >>> y, f_jvp = jax.linearize(f, 2.)\n",
                "  >>> print(y)\n",
                "  3.2681944\n",
                "  >>> print(f_jvp(3.))\n",
                "  -5.007528\n",
                "  >>> print(f_jvp(4.))\n",
                "  -6.676704\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "  f = lu.wrap_init(fun)\n",
                "  primals_flat, in_tree = tree_flatten((primals, {}))\n",
                "  jaxtree_fun, out_tree = flatten_fun(f, in_tree)\n",
                "  out_primals, out_pvals, jaxpr, consts = ad.linearize(jaxtree_fun, *primals_flat)\n",
                "  out_tree = out_tree()\n",
                "  out_primal_py = tree_unflatten(out_tree, out_primals)\n",
                "  primal_avals = list(map(core.get_aval, primals_flat))\n",
                "  # Ensure that lifted_jvp is a PyTree\n",
                "  lifted_jvp = Partial(partial(_lift_linearized, jaxpr, primal_avals,\n",
                "                               (in_tree, out_tree), out_pvals), consts)\n",
                "  return out_primal_py, lifted_jvp\n",
                "\n",
                "def _lift_linearized(jaxpr, primal_avals, io_tree, out_pvals, consts, *py_args):\n",
                "  def fun(*tangents):\n",
                "    tangent_avals = list(map(core.get_aval, tangents))\n",
                "    for primal_aval, tangent_aval in zip(primal_avals, tangent_avals):\n",
                "      if not core.typecompat(primal_aval.at_least_vspace(), tangent_aval):\n",
                "        raise ValueError(\"linearized function called on tangent values inconsistent with \"\n",
                "                         \"the original primal values: \"\n",
                "                         f\"got {tangent_aval} for primal aval {primal_aval}\")\n",
                "    tangents_out = eval_jaxpr(jaxpr, consts, *tangents)\n",
                "    return tuple(map(lambda out_pv, tan_out: out_pv.merge_with_known(tan_out),\n",
                "                     out_pvals, tangents_out))\n",
                "\n",
                "  return apply_flat_fun(fun, io_tree, *py_args)\n",
                "\n",
                "def _vjp_pullback_wrapper(cotangent_dtypes, cotangent_shapes,\n",
                "                          io_tree, fun, py_args):\n",
                "  in_tree_expected, out_tree = io_tree\n",
                "  args, in_tree = tree_flatten(py_args)\n",
                "  if in_tree != in_tree_expected:\n",
                "    raise TypeError(f\"Tree structure of cotangent input {in_tree}, does not match structure of \"\n",
                "                    f\"primal output {in_tree_expected}.\")\n",
                "  for arg, ct_dtype, ct_shape in safe_zip(args, cotangent_dtypes, cotangent_shapes):\n",
                "    expected_tangent_dtype = core.primal_dtype_to_tangent_dtype(_dtype(arg))\n",
                "    if expected_tangent_dtype != ct_dtype:\n",
                "      raise TypeError(\n",
                "          f\"Type of cotangent input to vjp pullback function ({ct_dtype}) is not \"\n",
                "          f\"the expected tangent type ({expected_tangent_dtype}) of corresponding primal output \"\n",
                "          f\"with dtype {_dtype(arg)}.\")\n",
                "    if np.shape(arg) != ct_shape:\n",
                "      raise ValueError(\n",
                "          f\"Shape of cotangent input to vjp pullback function {np.shape(arg)} \"\n",
                "          \"must be the same as the shape of corresponding primal input \"\n",
                "          f\"{ct_shape}.\")\n",
                "  ans = fun(*args)\n",
                "  return tree_unflatten(out_tree, ans)\n",
                "\n",
                "\n",
                "if sys.version_info >= (3, 8):\n",
                "  from typing import Literal\n",
                "\n",
                "  @overload  # type: ignore\n",
                "  def vjp(fun: Callable[..., T],\n",
                "          *primals: Any,\n",
                "          has_aux: Literal[False] = False,\n",
                "          reduce_axes: Sequence[AxisName] = ()) -> Tuple[T, Callable]:\n",
                "    ...\n",
                "\n",
                "  @overload\n",
                "  def vjp(fun: Callable[..., Tuple[T, U]], *primals: Any,\n",
                "          has_aux: Literal[True],\n",
                "          reduce_axes: Sequence[AxisName] = ()) -> Tuple[T, Callable, U]:\n",
                "    ...\n",
                "else:\n",
                "\n",
                "  @overload  # type: ignore\n",
                "  def vjp(fun: Callable[..., T], *primals: Any) -> Tuple[T, Callable]:\n",
                "    ...\n",
                "\n",
                "  @overload\n",
                "  def vjp(\n",
                "      fun: Callable[..., Any], *primals: Any,\n",
                "      has_aux: bool,\n",
                "      reduce_axes: Sequence[AxisName] = ()\n",
                "  ) -> Union[Tuple[Any, Callable], Tuple[Any, Callable, Any]]:\n",
                "    ...\n",
                "\n",
                "\n",
                "def vjp(  # type: ignore\n",
                "    fun: Callable, *primals, has_aux: bool = False, reduce_axes=()\n",
                ") -> Union[Tuple[Any, Callable], Tuple[Any, Callable, Any]]:\n",
                "  \"\"\"Compute a (reverse-mode) vector-Jacobian product of ``fun``.\n",
                "\n",
                "  :py:func:`grad` is implemented as a special case of :py:func:`vjp`.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be differentiated. Its arguments should be arrays, scalars,\n",
                "      or standard Python containers of arrays or scalars. It should return an\n",
                "      array, scalar, or standard Python container of arrays or scalars.\n",
                "    primals: A sequence of primal values at which the Jacobian of ``fun``\n",
                "      should be evaluated. The length of ``primals`` should be equal to the\n",
                "      number of positional parameters to ``fun``. Each primal value should be a\n",
                "      tuple of arrays, scalar, or standard Python containers thereof.\n",
                "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
                "     first element is considered the output of the mathematical function to be\n",
                "     differentiated and the second element is auxiliary data. Default False.\n",
                "    reduce_axes: Optional, tuple of axis names. If an axis is listed here, and\n",
                "      ``fun`` implicitly broadcasts a value over that axis, the backward pass\n",
                "      will perform a ``psum`` of the corresponding gradient. Otherwise, the\n",
                "      VJP will be per-example over named axes. For example, if ``'batch'``\n",
                "      is a named batch axis, ``vjp(f, *args, reduce_axes=('batch',))`` will\n",
                "      create a VJP function that sums over the batch while ``vjp(f, *args)``\n",
                "      will create a per-example VJP.\n",
                "\n",
                "  Returns:\n",
                "    If ``has_aux`` is ``False``, returns a ``(primals_out, vjpfun)`` pair, where\n",
                "    ``primals_out`` is ``fun(*primals)``.\n",
                "    ``vjpfun`` is a function from a cotangent vector with the same shape as\n",
                "    ``primals_out`` to a tuple of cotangent vectors with the same shape as\n",
                "    ``primals``, representing the vector-Jacobian product of ``fun`` evaluated at\n",
                "    ``primals``. If ``has_aux`` is ``True``, returns a\n",
                "    ``(primals_out, vjpfun, aux)`` tuple where ``aux`` is the auxiliary data\n",
                "    returned by ``fun``.\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> def f(x, y):\n",
                "  ...   return jax.numpy.sin(x), jax.numpy.cos(y)\n",
                "  ...\n",
                "  >>> primals, f_vjp = jax.vjp(f, 0.5, 1.0)\n",
                "  >>> xbar, ybar = f_vjp((-0.7, 0.3))\n",
                "  >>> print(xbar)\n",
                "  -0.61430776\n",
                "  >>> print(ybar)\n",
                "  -0.2524413\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "  reduce_axes = _ensure_str_tuple(reduce_axes)\n",
                "  return _vjp(\n",
                "      lu.wrap_init(fun), *primals, has_aux=has_aux, reduce_axes=reduce_axes)\n",
                "\n",
                "def _vjp(fun: lu.WrappedFun, *primals, has_aux=False, reduce_axes=()):\n",
                "  \"\"\"Variant of vjp() that takes an lu.WrappedFun.\"\"\"\n",
                "  primals_flat, in_tree = tree_flatten(primals)\n",
                "  for arg in primals_flat: _check_arg(arg)\n",
                "  if not has_aux:\n",
                "    flat_fun, out_tree = flatten_fun_nokwargs(fun, in_tree)\n",
                "    out_primal, out_vjp = ad.vjp(\n",
                "        flat_fun, primals_flat, reduce_axes=reduce_axes)\n",
                "    out_tree = out_tree()\n",
                "  else:\n",
                "    flat_fun, out_aux_trees = flatten_fun_nokwargs2(fun, in_tree)\n",
                "    out_primal, out_vjp, aux = ad.vjp(\n",
                "        flat_fun, primals_flat, has_aux=True, reduce_axes=reduce_axes)\n",
                "    out_tree, aux_tree = out_aux_trees()\n",
                "  out_primal_py = tree_unflatten(out_tree, out_primal)\n",
                "  ct_dtypes = [core.primal_dtype_to_tangent_dtype(_dtype(x)) for x in out_primal]\n",
                "  ct_shapes = [np.shape(x) for x in out_primal]\n",
                "  # Ensure that vjp_py is a PyTree so that we can pass it from the forward to the\n",
                "  # backward pass in a custom VJP.\n",
                "  vjp_py = Partial(partial(_vjp_pullback_wrapper,\n",
                "                           ct_dtypes, ct_shapes,\n",
                "                           (out_tree, in_tree)),\n",
                "                   out_vjp)\n",
                "  if not has_aux:\n",
                "    return out_primal_py, vjp_py\n",
                "  else:\n",
                "    return out_primal_py, vjp_py, tree_unflatten(aux_tree, aux)\n",
                "\n",
                "\n",
                "def linear_transpose(fun: Callable, *primals, reduce_axes=()) -> Callable:\n",
                "  \"\"\"Transpose a function that is promised to be linear.\n",
                "\n",
                "  For linear functions, this transformation is equivalent to ``vjp``, but\n",
                "  avoids the overhead of computing the forward pass.\n",
                "\n",
                "  The outputs of the transposed function will always have the exact same dtypes\n",
                "  as ``primals``, even if some values are truncated (e.g., from complex to\n",
                "  float, or from float64 to float32). To avoid truncation, use dtypes in\n",
                "  ``primals`` that match the full range of desired outputs from the transposed\n",
                "  function. Integer dtypes are not supported.\n",
                "\n",
                "  Args:\n",
                "    fun: the linear function to be transposed.\n",
                "    *primals: a positional argument tuple of arrays, scalars, or (nested)\n",
                "      standard Python containers (tuples, lists, dicts, namedtuples, i.e.,\n",
                "      pytrees) of those types used for evaluating the shape/dtype of\n",
                "      ``fun(*primals)``. These arguments may be real scalars/ndarrays, but that\n",
                "      is not required: only the ``shape`` and ``dtype`` attributes are accessed.\n",
                "      See below for an example. (Note that the duck-typed objects cannot be\n",
                "      namedtuples because those are treated as standard Python containers.)\n",
                "    reduce_axes: Optional, tuple of axis names. If an axis is listed here, and\n",
                "      ``fun`` implicitly broadcasts a value over that axis, the backward pass\n",
                "      will perform a ``psum`` of the corresponding cotangent. Otherwise, the\n",
                "      transposed function will be per-example over named axes. For example, if\n",
                "      ``'batch'`` is a named batch axis, ``linear_transpose(f, *args,\n",
                "      reduce_axes=('batch',))`` will create a transpose function that sums over\n",
                "      the batch while ``linear_transpose(f, args)`` will create a per-example\n",
                "      transpose.\n",
                "\n",
                "  Returns:\n",
                "    A callable that calculates the transpose of ``fun``. Valid input into this\n",
                "    function must have the same shape/dtypes/structure as the result of\n",
                "    ``fun(*primals)``. Output will be a tuple, with the same\n",
                "    shape/dtypes/structure as ``primals``.\n",
                "\n",
                "  >>> import jax\n",
                "  >>> import types\n",
                "  >>>\n",
                "  >>> f = lambda x, y: 0.5 * x - 0.5 * y\n",
                "  >>> scalar = types.SimpleNamespace(shape=(), dtype=np.dtype(np.float32))\n",
                "  >>> f_transpose = jax.linear_transpose(f, scalar, scalar)\n",
                "  >>> f_transpose(1.0)\n",
                "  (DeviceArray(0.5, dtype=float32), DeviceArray(-0.5, dtype=float32))\n",
                "  \"\"\"\n",
                "  reduce_axes = _ensure_str_tuple(reduce_axes)\n",
                "  primals_flat, in_tree = tree_flatten(primals)\n",
                "  flat_fun, out_tree = flatten_fun_nokwargs(lu.wrap_init(fun), in_tree)\n",
                "  in_avals = map(shaped_abstractify, primals_flat)\n",
                "  in_dtypes = map(dtypes.dtype, in_avals)\n",
                "\n",
                "  in_pvals = map(pe.PartialVal.unknown, in_avals)\n",
                "  jaxpr, out_pvals, consts = pe.trace_to_jaxpr(flat_fun, in_pvals,\n",
                "                                               instantiate=True)\n",
                "  out_avals, _ = unzip2(out_pvals)\n",
                "  out_dtypes = map(dtypes.dtype, out_avals)\n",
                "  if not (all(dtypes.issubdtype(d, np.inexact) for d in in_dtypes + out_dtypes)\n",
                "          or all(dtypes.issubdtype(d, np.integer)\n",
                "                 for d in in_dtypes + out_dtypes)):\n",
                "    raise TypeError(\"linear_transpose only supports [float or complex] -> \"\n",
                "                    \"[float or complex], and integer -> integer functions, \"\n",
                "                    f\"but got {in_dtypes} -> {out_dtypes}.\")\n",
                "\n",
                "  def transposed_fun(consts, out_cotangent):\n",
                "    out_cotangents, out_tree2 = tree_flatten(out_cotangent)\n",
                "    if out_tree() != out_tree2:\n",
                "      raise TypeError(\"cotangent tree does not match function output, \"\n",
                "                      f\"expected {out_tree()} but got {out_tree2}\")\n",
                "    if not all(map(core.typecheck, out_avals, out_cotangents)):\n",
                "      raise TypeError(\"cotangent type does not match function output, \"\n",
                "                      f\"expected {out_avals} but got {out_cotangents}\")\n",
                "    dummies = [ad.UndefinedPrimal(a) for a in in_avals]\n",
                "    in_cotangents = map(\n",
                "        ad.instantiate_zeros,\n",
                "        ad.backward_pass(jaxpr, reduce_axes, True, consts, dummies, out_cotangents))\n",
                "    return tree_unflatten(in_tree, in_cotangents)\n",
                "\n",
                "  # Ensure that transposed_fun is a PyTree\n",
                "  return Partial(transposed_fun, consts)\n",
                "\n",
                "\n",
                "def make_jaxpr(fun: Callable,\n",
                "               static_argnums: Union[int, Iterable[int]] = (),\n",
                "               axis_env: Optional[Sequence[Tuple[AxisName, int]]] = None,\n",
                "               return_shape: bool = False,\n",
                "               abstracted_axes: Optional[Any] = None,\n",
                "               ) -> Callable[..., core.ClosedJaxpr]:\n",
                "  \"\"\"Creates a function that produces its jaxpr given example args.\n",
                "\n",
                "  Args:\n",
                "    fun: The function whose ``jaxpr`` is to be computed. Its positional\n",
                "      arguments and return value should be arrays, scalars, or standard Python\n",
                "      containers (tuple/list/dict) thereof.\n",
                "    static_argnums: See the :py:func:`jax.jit` docstring.\n",
                "    axis_env: Optional, a sequence of pairs where the first element is an axis\n",
                "      name and the second element is a positive integer representing the size of\n",
                "      the mapped axis with that name. This parameter is useful when lowering\n",
                "      functions that involve parallel communication collectives, and it\n",
                "      specifies the axis name/size environment that would be set up by\n",
                "      applications of :py:func:`jax.pmap`.\n",
                "    return_shape: Optional boolean, defaults to ``False``. If ``True``, the\n",
                "      wrapped function returns a pair where the first element is the XLA\n",
                "      computation and the second element is a pytree with the same structure as\n",
                "      the output of ``fun`` and where the leaves are objects with ``shape``,\n",
                "      ``dtype``, and ``named_shape`` attributes representing the corresponding\n",
                "      types of the output leaves.\n",
                "\n",
                "  Returns:\n",
                "    A wrapped version of ``fun`` that when applied to example arguments returns\n",
                "    a ``ClosedJaxpr`` representation of ``fun`` on those arguments. If the\n",
                "    argument ``return_shape`` is ``True``, then the returned function instead\n",
                "    returns a pair where the first element is the ``ClosedJaxpr``\n",
                "    representation of ``fun`` and the second element is a pytree representing\n",
                "    the structure, shape, dtypes, and named shapes of the output of ``fun``.\n",
                "\n",
                "  A ``jaxpr`` is JAX's intermediate representation for program traces. The\n",
                "  ``jaxpr`` language is based on the simply-typed first-order lambda calculus\n",
                "  with let-bindings. :py:func:`make_jaxpr` adapts a function to return its\n",
                "  ``jaxpr``, which we can inspect to understand what JAX is doing internally.\n",
                "  The ``jaxpr`` returned is a trace of ``fun`` abstracted to\n",
                "  :py:class:`ShapedArray` level. Other levels of abstraction exist internally.\n",
                "\n",
                "  We do not describe the semantics of the ``jaxpr`` language in detail here, but\n",
                "  instead give a few examples.\n",
                "\n",
                "  >>> import jax\n",
                "  >>>\n",
                "  >>> def f(x): return jax.numpy.sin(jax.numpy.cos(x))\n",
                "  >>> print(f(3.0))\n",
                "  -0.83602\n",
                "  >>> jax.make_jaxpr(f)(3.0)\n",
                "  { lambda ; a:f32[]. let b:f32[] = cos a; c:f32[] = sin b in (c,) }\n",
                "  >>> jax.make_jaxpr(jax.grad(f))(3.0)\n",
                "  { lambda ; a:f32[]. let\n",
                "      b:f32[] = cos a\n",
                "      c:f32[] = sin a\n",
                "      _:f32[] = sin b\n",
                "      d:f32[] = cos b\n",
                "      e:f32[] = mul 1.0 d\n",
                "      f:f32[] = neg e\n",
                "      g:f32[] = mul f c\n",
                "    in (g,) }\n",
                "  \"\"\"\n",
                "  _check_callable(fun)\n",
                "  static_argnums = _ensure_index_tuple(static_argnums)\n",
                "\n",
                "  def abstractify(args, kwargs):\n",
                "    flat_args, in_tree = tree_flatten((args, kwargs))\n",
                "    if abstracted_axes is None:\n",
                "      return map(shaped_abstractify, flat_args), in_tree, [True] * len(flat_args)\n",
                "    else:\n",
                "      if kwargs: raise NotImplementedError\n",
                "      ax_leaf = lambda l: (isinstance(l, dict) and all_leaves(l.values()) or\n",
                "                           isinstance(l, tuple) and all_leaves(l))\n",
                "      axes_specs = broadcast_prefix(abstracted_axes, args, ax_leaf)\n",
                "      sizes: Dict[Hashable, int] = {}\n",
                "      env: Dict[Hashable, core.AbstractValue] = {}\n",
                "      def make_aval(arg, spec):\n",
                "        if isinstance(spec, tuple):\n",
                "            spec = dict(zip(range(len(arg.shape)), spec))\n",
                "        if not spec: return shaped_abstractify(arg)\n",
                "        assert all(arg.shape[i] == sizes.setdefault(name, arg.shape[i])\n",
                "                   for i, name in spec.items())\n",
                "        shape = [env.setdefault(spec[i], ShapedArray((), dtypes.dtype('int32')))\n",
                "                 if i in spec else d for i, d in enumerate(arg.shape)]\n",
                "        return core.DShapedArray(tuple(shape), arg.dtype, False)\n",
                "      in_avals = map(make_aval, flat_args, axes_specs)\n",
                "      keep_inputs = [False] * len(env) + [True] * len(flat_args)\n",
                "      return [*env.values(), *in_avals], in_tree, keep_inputs\n",
                "\n",
                "  @wraps(fun)\n",
                "  @api_boundary\n",
                "  def make_jaxpr_f(*args, **kwargs):\n",
                "    f = lu.wrap_init(fun)\n",
                "    if static_argnums:\n",
                "      dyn_argnums = [i for i in range(len(args)) if i not in static_argnums]\n",
                "      f, args = argnums_partial(f, dyn_argnums, args)\n",
                "    in_avals, in_tree, keep_inputs = abstractify(args, kwargs)\n",
                "    f, out_tree = flatten_fun(f, in_tree)\n",
                "    with ExitStack() as stack:\n",
                "      for axis_name, size in axis_env or []:\n",
                "        stack.enter_context(core.extend_axis_env(axis_name, size, None))\n",
                "      jaxpr, out_avals, consts = pe.trace_to_jaxpr_dynamic(\n",
                "          f, in_avals, keep_inputs=keep_inputs)\n",
                "    closed_jaxpr = core.ClosedJaxpr(jaxpr, consts)\n",
                "    if return_shape:\n",
                "      out_shapes_flat = [\n",
                "          ShapeDtypeStruct(a.shape, a.dtype, a.named_shape) for a in out_avals]\n",
                "      return closed_jaxpr, tree_unflatten(out_tree(), out_shapes_flat)\n",
                "    return closed_jaxpr\n",
                "\n",
                "  make_jaxpr_f.__name__ = f\"make_jaxpr({make_jaxpr.__name__})\"\n",
                "  return make_jaxpr_f\n",
                "\n",
                "\n",
                "def device_put(x, device: Optional[xc.Device] = None):\n",
                "  \"\"\"Transfers ``x`` to ``device``.\n",
                "\n",
                "  Args:\n",
                "    x: An array, scalar, or (nested) standard Python container thereof.\n",
                "    device: The (optional) :py:class:`Device` to which ``x`` should be\n",
                "      transferred. If given, then the result is committed to the device.\n",
                "\n",
                "  If the ``device`` parameter is ``None``, then this operation behaves like the\n",
                "  identity function if the operand is on any device already, otherwise it\n",
                "  transfers the data to the default device, uncommitted.\n",
                "\n",
                "  For more details on data placement see the\n",
                "  :ref:`FAQ on data placement <faq-data-placement>`.\n",
                "\n",
                "  Returns:\n",
                "    A copy of ``x`` that resides on ``device``.\n",
                "  \"\"\"\n",
                "  with config_explicit_device_put_scope():\n",
                "    return tree_map(lambda y: dispatch.device_put_p.bind(y, device=device), x)\n",
                "\n",
                "\n",
                "def device_put_sharded(shards: Sequence[Any], devices: Sequence[xc.Device]):\n",
                "  \"\"\"Transfer array shards to specified devices and form ShardedDeviceArray(s).\n",
                "\n",
                "  Args:\n",
                "    shards: A sequence of arrays, scalars, or (nested) standard Python\n",
                "      containers thereof representing the shards to be stacked together to form\n",
                "      the output. The length of ``shards`` must equal the length of ``devices``.\n",
                "    devices: A sequence of :py:class:`Device` instances representing the devices\n",
                "      to which corresponding shards in ``shards`` will be transferred.\n",
                "\n",
                "  Returns:\n",
                "    A ShardedDeviceArray or (nested) Python container thereof representing the\n",
                "    elements of ``shards`` stacked together, with each shard backed by physical\n",
                "    device memory specified by the corresponding entry in ``devices``.\n",
                "\n",
                "  Examples:\n",
                "    Passing a list of arrays for ``shards`` results in a sharded array\n",
                "    containing a stacked version of the inputs:\n",
                "\n",
                "    >>> import jax\n",
                "    >>> devices = jax.local_devices()\n",
                "    >>> x = [jax.numpy.ones(5) for device in devices]\n",
                "    >>> y = jax.device_put_sharded(x, devices)\n",
                "    >>> np.allclose(y, jax.numpy.stack(x))\n",
                "    True\n",
                "\n",
                "    Passing a list of nested container objects with arrays at the leaves for\n",
                "    ``shards`` corresponds to stacking the shards at each leaf. This requires\n",
                "    all entries in the list to have the same tree structure:\n",
                "\n",
                "    >>> x = [(i, jax.numpy.arange(i, i + 4)) for i in range(len(devices))]\n",
                "    >>> y = jax.device_put_sharded(x, devices)\n",
                "    >>> type(y)\n",
                "    <class 'tuple'>\n",
                "    >>> y0 = jax.device_put_sharded([a for a, b in x], devices)\n",
                "    >>> y1 = jax.device_put_sharded([b for a, b in x], devices)\n",
                "    >>> np.allclose(y[0], y0)\n",
                "    True\n",
                "    >>> np.allclose(y[1], y1)\n",
                "    True\n",
                "\n",
                "  See Also:\n",
                "    - device_put\n",
                "    - device_put_replicated\n",
                "  \"\"\"\n",
                "  # TODO(jakevdp): provide a default for devices that considers both local\n",
                "  # devices and pods\n",
                "  if not isinstance(shards, Sequence):\n",
                "    raise ValueError(\"device_put_sharded `shards` input must be a sequence; \"\n",
                "                     f\"got {type(shards)}\")\n",
                "  if not len(shards) == len(devices):\n",
                "    raise ValueError(f\"len(shards) = {len(shards)} must equal \"\n",
                "                     f\"len(devices) = {len(devices)}.\")\n",
                "\n",
                "  def _device_put_sharded(*xs):\n",
                "    avals = [core.raise_to_shaped(core.get_aval(x)) for x in xs]\n",
                "    if not all(a1 == a2 for a1, a2 in zip(avals[:-1], avals[1:])):\n",
                "      a1, a2 = next((a1, a2) for a1, a2 in zip(avals[:-1], avals[1:])\n",
                "                    if a1 != a2)\n",
                "      raise ValueError(\"the shards passed to device_put_sharded must have \"\n",
                "                       f\"consistent shape and dtype, but got {a1} and {a2}.\")\n",
                "    stacked_aval = avals[0].update(shape=(len(devices),) + avals[0].shape)\n",
                "    buffers = [buf for x, d in zip(xs, devices)\n",
                "               for buf in dispatch.device_put(x, d)]\n",
                "    return pxla.make_sharded_device_array(stacked_aval, None, buffers)\n",
                "\n",
                "  with config_explicit_device_put_scope():\n",
                "    return tree_multimap(_device_put_sharded, *shards)\n",
                "\n",
                "\n",
                "def device_put_replicated(x: Any, devices: Sequence[xc.Device]):\n",
                "  \"\"\"Transfer array(s) to each specified device and form ShardedDeviceArray(s).\n",
                "\n",
                "  Args:\n",
                "    x: an array, scalar, or (nested) standard Python container thereof\n",
                "      representing the array to be replicated to form the output.\n",
                "    devices: A sequence of :py:class:`Device` instances representing the devices\n",
                "      to which ``x`` will be transferred.\n",
                "\n",
                "  Returns:\n",
                "    A ShardedDeviceArray or (nested) Python container thereof representing the\n",
                "    value of ``x`` broadcasted along a new leading axis of size\n",
                "    ``len(devices)``, with each slice along that new leading axis backed by\n",
                "    memory on the device specified by the corresponding entry in ``devices``.\n",
                "\n",
                "  Examples:\n",
                "    Passing an array:\n",
                "\n",
                "    >>> import jax\n",
                "    >>> devices = jax.local_devices()\n",
                "    >>> x = jax.numpy.array([1., 2., 3.])\n",
                "    >>> y = jax.device_put_replicated(x, devices)\n",
                "    >>> np.allclose(y, jax.numpy.stack([x for _ in devices]))\n",
                "    True\n",
                "\n",
                "  See Also:\n",
                "    - device_put\n",
                "    - device_put_sharded\n",
                "  \"\"\"\n",
                "  if not isinstance(devices, Sequence) or not devices:\n",
                "    raise ValueError(\"`devices` argument to `device_put_replicated must be \"\n",
                "                     \"a non-empty sequence.\")\n",
                "  def _device_put_replicated(x):\n",
                "    aval = core.unmapped_aval(len(devices), core.no_axis_name, 0,\n",
                "                              core.raise_to_shaped(core.get_aval(x)))\n",
                "    assert (isinstance(aval, core.ShapedArray) and\n",
                "            len(xla.aval_to_xla_shapes(aval)) == 1)\n",
                "    buf, = dispatch.device_put(x, devices[0])\n",
                "    rest_bufs = [buf.copy_to_device(d) for d in devices[1:]]\n",
                "    return pxla.make_sharded_device_array(aval, None, [buf, *rest_bufs])\n",
                "\n",
                "  with config_explicit_device_put_scope():\n",
                "    return tree_map(_device_put_replicated, x)\n",
                "\n",
                "\n",
                "# TODO(mattjj): consider revising\n",
                "def _device_get(x):\n",
                "  if isinstance(x, core.Tracer):\n",
                "    return x\n",
                "  try:\n",
                "    copy = x.copy\n",
                "  except AttributeError:\n",
                "    return x\n",
                "  else:\n",
                "    return copy()\n",
                "\n",
                "def device_get(x: Any):\n",
                "  \"\"\"Transfer ``x`` to host.\n",
                "\n",
                "  If ``x`` is a pytree, then the individual buffers are copied in parallel.\n",
                "\n",
                "  Args:\n",
                "    x: An array, scalar, DeviceArray or (nested) standard Python container thereof\n",
                "      representing the array to be transferred to host.\n",
                "\n",
                "  Returns:\n",
                "    An array or (nested) Python container thereof representing the\n",
                "    value of ``x``.\n",
                "\n",
                "  Examples:\n",
                "    Passing a DeviceArray:\n",
                "\n",
                "    >>> import jax\n",
                "    >>> x = jax.numpy.array([1., 2., 3.])\n",
                "    >>> jax.device_get(x)\n",
                "    array([1., 2., 3.], dtype=float32)\n",
                "\n",
                "    Passing a scalar (has no effect):\n",
                "\n",
                "    >>> jax.device_get(1)\n",
                "    1\n",
                "\n",
                "  See Also:\n",
                "    - device_put\n",
                "    - device_put_sharded\n",
                "    - device_put_replicated\n",
                "  \"\"\"\n",
                "  with config_explicit_device_get_scope():\n",
                "    for y in tree_leaves(x):\n",
                "      try:\n",
                "        y.copy_to_host_async()\n",
                "      except AttributeError:\n",
                "        pass\n",
                "    return tree_map(_device_get, x)\n",
                "\n",
                "def _check_arg(arg):\n",
                "  if not (isinstance(arg, core.Tracer) or _valid_jaxtype(arg)):\n",
                "    raise TypeError(f\"Argument '{arg}' of type {type(arg)} is not a valid JAX type.\")\n",
                "\n",
                "# TODO(mattjj,necula): this duplicates code in core.valid_jaxtype, but one\n",
                "# internal user relies on it for duck-typing. must fix downstream user!\n",
                "def _valid_jaxtype(arg):\n",
                "  try:\n",
                "    xla.abstractify(arg)  # faster than core.get_aval\n",
                "  except TypeError:\n",
                "    return False\n",
                "  else:\n",
                "    return True\n",
                "\n",
                "\n",
                "class ShapeDtypeStruct:\n",
                "  __slots__ = [\"shape\", \"dtype\", \"named_shape\"]\n",
                "  def __init__(self, shape, dtype, named_shape=None):\n",
                "    self.shape = shape\n",
                "    self.dtype = np.dtype(dtype)\n",
                "    self.named_shape = {} if named_shape is None else dict(named_shape)\n",
                "\n",
                "  size = property(lambda self: prod(self.shape))\n",
                "  ndim = property(lambda self: len(self.shape))\n",
                "\n",
                "  def __len__(self):\n",
                "    try:\n",
                "      return self.shape[0]\n",
                "    except IndexError as e:\n",
                "      raise TypeError(\"len() of unsized object\") from e # same as numpy error\n",
                "\n",
                "  def __repr__(self):\n",
                "    ns = f\", named_shape={self.named_shape}\" if self.named_shape else \"\"\n",
                "    return f\"{type(self).__name__}(shape={self.shape}, dtype={self.dtype.name}{ns})\"\n",
                "\n",
                "  __str__ = __repr__\n",
                "\n",
                "  def __eq__(self, other):\n",
                "    if not isinstance(other, ShapeDtypeStruct):\n",
                "      return False\n",
                "    else:\n",
                "      return (other.shape, other.dtype, other.named_shape) == (\n",
                "          self.shape, self.dtype, self.named_shape)\n",
                "\n",
                "  def __hash__(self):\n",
                "    # TODO(frostig): avoid the conversion from dict by addressing\n",
                "    # https://github.com/google/jax/issues/8182\n",
                "    named = frozenset(self.named_shape.items())\n",
                "    return hash((self.shape, self.dtype, named))\n",
                "\n",
                "def eval_shape(fun: Callable, *args, **kwargs):\n",
                "  \"\"\"Compute the shape/dtype of ``fun`` without any FLOPs.\n",
                "\n",
                "  This utility function is useful for performing shape inference. Its\n",
                "  input/output behavior is defined by::\n",
                "\n",
                "    def eval_shape(fun, *args, **kwargs):\n",
                "      out = fun(*args, **kwargs)\n",
                "      return jax.tree_util.tree_map(shape_dtype_struct, out)\n",
                "\n",
                "    def shape_dtype_struct(x):\n",
                "      return ShapeDtypeStruct(x.shape, x.dtype)\n",
                "\n",
                "    class ShapeDtypeStruct:\n",
                "      __slots__ = [\"shape\", \"dtype\"]\n",
                "      def __init__(self, shape, dtype):\n",
                "        self.shape = shape\n",
                "        self.dtype = dtype\n",
                "\n",
                "  In particular, the output is a pytree of objects that have ``shape`` and\n",
                "  ``dtype`` attributes, but nothing else about them is guaranteed by the API.\n",
                "\n",
                "  But instead of applying ``fun`` directly, which might be expensive, it uses\n",
                "  JAX's abstract interpretation machinery to evaluate the shapes without doing\n",
                "  any FLOPs.\n",
                "\n",
                "  Using :py:func:`eval_shape` can also catch shape errors, and will raise same\n",
                "  shape errors as evaluating ``fun(*args, **kwargs)``.\n",
                "\n",
                "  Args:\n",
                "    fun: The function whose output shape should be evaluated.\n",
                "    *args: a positional argument tuple of arrays, scalars, or (nested) standard\n",
                "      Python containers (tuples, lists, dicts, namedtuples, i.e. pytrees) of\n",
                "      those types. Since only the ``shape`` and ``dtype`` attributes are\n",
                "      accessed, only values that duck-type arrays are required, rather than real\n",
                "      ndarrays. The duck-typed objects cannot be namedtuples because those are\n",
                "      treated as standard Python containers. See the example below.\n",
                "    **kwargs: a keyword argument dict of arrays, scalars, or (nested) standard\n",
                "      Python containers (pytrees) of those types. As in ``args``, array values\n",
                "      need only be duck-typed to have ``shape`` and ``dtype`` attributes.\n",
                "\n",
                "  For example:\n",
                "\n",
                "  >>> import jax\n",
                "  >>> import jax.numpy as jnp\n",
                "  >>>\n",
                "  >>> f = lambda A, x: jnp.tanh(jnp.dot(A, x))\n",
                "  >>> class MyArgArray(object):\n",
                "  ...   def __init__(self, shape, dtype):\n",
                "  ...     self.shape = shape\n",
                "  ...     self.dtype = jnp.dtype(dtype)\n",
                "  ...\n",
                "  >>> A = MyArgArray((2000, 3000), jnp.float32)\n",
                "  >>> x = MyArgArray((3000, 1000), jnp.float32)\n",
                "  >>> out = jax.eval_shape(f, A, x)  # no FLOPs performed\n",
                "  >>> print(out.shape)\n",
                "  (2000, 1000)\n",
                "  >>> print(out.dtype)\n",
                "  float32\n",
                "  \"\"\"\n",
                "  args_flat, in_tree = tree_flatten((args, kwargs))\n",
                "  wrapped_fun, out_tree = flatten_fun(lu.wrap_init(fun), in_tree)\n",
                "  debug_info = pe.debug_info(fun, in_tree, True, \"eval_shape\")\n",
                "  out = pe.abstract_eval_fun(wrapped_fun.call_wrapped,\n",
                "                             *map(shaped_abstractify, args_flat),\n",
                "                             debug_info=debug_info)\n",
                "  out = [ShapeDtypeStruct(x.shape, x.dtype, x.named_shape) for x in out]\n",
                "  return tree_unflatten(out_tree(), out)\n",
                "\n",
                "\n",
                "def checkpoint(fun: Callable, concrete: bool = False, prevent_cse: bool = True,\n",
                "               policy: Optional[Callable[..., bool]] = None,\n",
                "               ) -> Callable:\n",
                "  \"\"\"Make ``fun`` recompute internal linearization points when differentiated.\n",
                "\n",
                "  The :func:`jax.checkpoint` decorator, aliased to ``jax.remat``, provides a\n",
                "  way to trade off computation time and memory cost in the context of automatic\n",
                "  differentiation, especially with reverse-mode autodiff like :func:`jax.grad`\n",
                "  and :func:`jax.vjp` but also with :func:`jax.linearize`.\n",
                "\n",
                "  When differentiating a function in reverse-mode, by default all the\n",
                "  linearization points (e.g. inputs to elementwise nonlinear primitive\n",
                "  operations) are stored when evaluating the forward pass so that they can be\n",
                "  reused on the backward pass. This evaluation strategy can lead to a high\n",
                "  memory cost, or even to poor performance on hardware accelerators where memory\n",
                "  access is much more expensive than FLOPs.\n",
                "\n",
                "  An alternative evaluation strategy is for some of the linearization points to\n",
                "  be recomputed (i.e. rematerialized) rather than stored. This approach can\n",
                "  reduce memory usage at the cost of increased computation.\n",
                "\n",
                "  This function decorator produces a new version of ``fun`` which follows\n",
                "  the rematerialization strategy rather than the default store-everything\n",
                "  strategy. That is, it returns a new version of ``fun`` which, when\n",
                "  differentiated, doesn't store any of its intermediate linearization points.\n",
                "  Instead, these linearization points are recomputed from the function's saved\n",
                "  inputs.\n",
                "\n",
                "  See the examples below.\n",
                "\n",
                "  Args:\n",
                "    fun: Function for which the autodiff evaluation strategy is to be changed\n",
                "      from the default of storing all intermediate linearization points to\n",
                "      recomputing them. Its arguments and return value should be arrays,\n",
                "      scalars, or (nested) standard Python containers (tuple/list/dict) thereof.\n",
                "    concrete: Optional, boolean indicating whether ``fun`` may involve\n",
                "      value-dependent Python control flow (default False). Support for such\n",
                "      control flow is optional, and disabled by default, because in some\n",
                "      edge-case compositions with :func:`jax.jit` it can lead to some extra\n",
                "      computation.\n",
                "    prevent_cse: Optional, boolean indicating whether to prevent common\n",
                "      subexpression elimination (CSE) optimizations in the HLO generated from\n",
                "      differentiation. This CSE prevention has costs because it can foil other\n",
                "      optimizations, and because it can incur high overheads on some backends,\n",
                "      especially GPU. The default is True because otherwise, under a ``jit`` or\n",
                "      ``pmap``, CSE can defeat the purpose of this decorator. But in some\n",
                "      settings, like when used inside a ``scan``, this CSE prevention mechanism\n",
                "      is unnecessary, in which case ``prevent_cse`` can be set to False.\n",
                "    policy: This is an experimental feature and the API is likely to change.\n",
                "      Optional callable, one of the attributes of ``jax.checkpoint_policies``,\n",
                "      which takes as input a type-level specification of a first-order primitive\n",
                "      application and returns a boolean indicating whether the corresponding\n",
                "      output value(s) can be saved as a residual (or, if not, instead must be\n",
                "      recomputed in the (co)tangent computation).\n",
                "\n",
                "  Returns:\n",
                "    A function (callable) with the same input/output behavior as ``fun`` but\n",
                "    which, when differentiated using e.g. :func:`jax.grad`, :func:`jax.vjp`, or\n",
                "    :func:`jax.linearize`, recomputes rather than stores intermediate\n",
                "    linearization points, thus potentially saving memory at the cost of extra\n",
                "    computation.\n",
                "\n",
                "  Here is a simple example:\n",
                "\n",
                "  >>> import jax\n",
                "  >>> import jax.numpy as jnp\n",
                "\n",
                "  >>> @jax.checkpoint\n",
                "  ... def g(x):\n",
                "  ...   y = jnp.sin(x)\n",
                "  ...   z = jnp.sin(y)\n",
                "  ...   return z\n",
                "  ...\n",
                "  >>> jax.value_and_grad(g)(2.0)\n",
                "  (DeviceArray(0.78907233, dtype=float32, weak_type=True), DeviceArray(-0.2556391, dtype=float32, weak_type=True))\n",
                "\n",
                "  Here, the same value is produced whether or not the :func:`jax.checkpoint`\n",
                "  decorator is present. When the decorator is not present, the values\n",
                "  ``jnp.cos(2.0)`` and ``jnp.cos(jnp.sin(2.0))`` are computed on the forward\n",
                "  pass and are stored for use in the backward pass, because they are needed\n",
                "  on the backward pass and depend only on the primal inputs. When using\n",
                "  :func:`jax.checkpoint`, the forward pass will compute only the primal outputs\n",
                "  and only the primal inputs (``2.0``) will be stored for the backward pass.\n",
                "  At that time, the value ``jnp.sin(2.0)`` is recomputed, along with the values\n",
                "  ``jnp.cos(2.0)`` and ``jnp.cos(jnp.sin(2.0))``.\n",
                "\n",
                "  While ``jax.checkpoint`` controls what values are stored from the forward-pass\n",
                "  to be used on the backward pass, the total amount of memory required to\n",
                "  evaluate a function or its VJP depends on many additional internal details of\n",
                "  that function. Those details include which numerical primitives are used,\n",
                "  how they're composed, where jit and control flow primitives like scan\n",
                "  are used, and other factors.\n",
                "\n",
                "  The :func:`jax.checkpoint` decorator can be applied recursively to express\n",
                "  sophisticated autodiff rematerialization strategies. For example:\n",
                "\n",
                "  >>> def recursive_checkpoint(funs):\n",
                "  ...   if len(funs) == 1:\n",
                "  ...     return funs[0]\n",
                "  ...   elif len(funs) == 2:\n",
                "  ...     f1, f2 = funs\n",
                "  ...     return lambda x: f1(f2(x))\n",
                "  ...   else:\n",
                "  ...     f1 = recursive_checkpoint(funs[:len(funs)//2])\n",
                "  ...     f2 = recursive_checkpoint(funs[len(funs)//2:])\n",
                "  ...     return lambda x: f1(jax.checkpoint(f2)(x))\n",
                "  ...\n",
                "  \"\"\"\n",
                "  @wraps(fun)\n",
                "  @api_boundary\n",
                "  def remat_f(*args, **kwargs):\n",
                "    args_flat, in_tree = tree_flatten((args, kwargs))\n",
                "    flat_fun, out_tree = flatten_fun(lu.wrap_init(fun), in_tree)\n",
                "    out_flat = pe.remat_call(flat_fun, *args_flat, name=flat_fun.__name__,\n",
                "                             concrete=concrete, prevent_cse=prevent_cse,\n",
                "                             differentiated=False,\n",
                "                             policy=policy)\n",
                "    return tree_unflatten(out_tree(), out_flat)\n",
                "  return remat_f\n",
                "remat = checkpoint  # type: ignore\n",
                "\n",
                "def named_call(\n",
                "    fun: Callable[..., Any],\n",
                "    *,\n",
                "    name: Optional[str] = None,\n",
                ") -> Callable[..., Any]:\n",
                "  \"\"\"Adds a user specified name to a function when staging out JAX computations.\n",
                "\n",
                "  When staging out computations for just-in-time compilation to XLA (or other\n",
                "  backends such as TensorFlow) JAX runs your Python program but by default does\n",
                "  not preserve any of the function names or other metadata associated with it.\n",
                "  This can make debugging the staged out (and/or compiled) representation of\n",
                "  your program complicated because there is limited context information for each\n",
                "  operation being executed.\n",
                "\n",
                "  `named_call` tells JAX to stage the given function out as a subcomputation\n",
                "  with a specific name. When the staged out program is compiled with XLA these\n",
                "  named subcomputations are preserved and show up in debugging utilities like\n",
                "  the TensorFlow Profiler in TensorBoard. Names are also preserved when staging\n",
                "  out JAX programs to TensorFlow using :func:`experimental.jax2tf.convert`.\n",
                "\n",
                "  Args:\n",
                "    fun: Function to be wrapped. This can be any Callable.\n",
                "    name: Optional. The prefix to use to name all sub computations created\n",
                "      within the name scope. Use the fun.__name__ if not specified.\n",
                "\n",
                "  Returns:\n",
                "    A version of `fun` that is wrapped in a name_scope.\n",
                "  \"\"\"\n",
                "  if name is None:\n",
                "    name = fun.__name__\n",
                "\n",
                "  _, in_tree = tree_flatten(())\n",
                "\n",
                "  if config.jax_experimental_name_stack:\n",
                "    return source_info_util.extend_name_stack(name)(fun)\n",
                "\n",
                "  @functools.wraps(fun)\n",
                "  def named_call_f(*args, **kwargs):\n",
                "    lu_f = lu.wrap_init(lambda: fun(*args, **kwargs))\n",
                "    flat_f, out_tree = flatten_fun_nokwargs(lu_f, in_tree)\n",
                "    out_flat = core.named_call_p.bind(flat_f, name=name)\n",
                "    return tree_unflatten(out_tree(), out_flat)\n",
                "\n",
                "  return named_call_f\n",
                "\n",
                "def invertible(fun: Callable) -> Callable:\n",
                "  \"\"\"Asserts that the decorated function is invertible.\n",
                "\n",
                "  Applying reverse-mode AD to a decorated function will use a more memory efficient\n",
                "  procedure than usual, which will reconstruct the necessary intermediate values\n",
                "  by inverting the function. Note that this might degrade the numerical accuracy of\n",
                "  obtained gradients if the inverse is unstable.\n",
                "\n",
                "  Args:\n",
                "    fun: The function assumed to be invertible.\n",
                "  \"\"\"\n",
                "  return iad.invertible(fun)\n",
                "\n",
                "\n",
                "def block_until_ready(x):\n",
                "  \"\"\"\n",
                "  Tries to call a ``block_until_ready`` method on pytree leaves.\n",
                "\n",
                "  Args:\n",
                "    x: a pytree, usually with at least some JAX array instances at its leaves.\n",
                "\n",
                "  Returns:\n",
                "    A pytree with the same structure and values of the input, where the values\n",
                "    of all JAX array leaves are ready.\n",
                "  \"\"\"\n",
                "  def try_to_block(x):\n",
                "    try:\n",
                "      return x.block_until_ready()\n",
                "    except AttributeError:\n",
                "      return x\n",
                "  return jax.tree_util.tree_map(try_to_block, x)"
            ]
        ],
        "jax/interpreters/pxla.py": [
            [
                "# Copyright 2018 Google LLC\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     https://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "\"\"\"Implementation of pmap and related functionality.\"\"\"\n",
                "\n",
                "# A ShardingSpec describes at a high level how a logical array is sharded across\n",
                "# devices (each ShardedDeviceArray has a ShardingSpec, and ShardingSpecs also\n",
                "# describe how to shard inputs to a parallel computation). spec_to_indices()\n",
                "# encodes exactly how a given ShardingSpec is translated to device buffers, i.e.\n",
                "# how the sharded array is \"laid out\" across devices. Given a sequence of\n",
                "# devices, we shard the data across the devices in row-major order, with\n",
                "# replication treated as an extra inner dimension.\n",
                "#\n",
                "# For example, given the logical data array [1, 2, 3, 4], if we were to\n",
                "# partition this array 4 ways with a replication factor of 2, for a total of 8\n",
                "# devices, the data on each device would be: [1, 1], [2, 2], [3, 3], [4, 4].\n",
                "#\n",
                "# This encoding is assumed by various parts of the system, e.g. generating\n",
                "# replica groups for collective operations.\n",
                "\n",
                "from __future__ import annotations\n",
                "\n",
                "from contextlib import contextmanager, ContextDecorator\n",
                "from collections import defaultdict, OrderedDict\n",
                "import dataclasses\n",
                "from functools import partial\n",
                "import itertools as it\n",
                "import operator as op\n",
                "import threading\n",
                "from typing import (Any, Callable, Dict, List, NamedTuple, Optional, FrozenSet,\n",
                "                    Sequence, Set, Tuple, Type, Union, Iterable, Mapping, cast)\n",
                "import sys\n",
                "\n",
                "from absl import logging\n",
                "import numpy as np\n",
                "\n",
                "from jax._src.config import config\n",
                "from jax import core\n",
                "from jax import linear_util as lu\n",
                "from jax._src import abstract_arrays\n",
                "from jax._src.abstract_arrays import array_types\n",
                "from jax.core import ConcreteArray, ShapedArray\n",
                "from jax._src import device_array\n",
                "from jax._src import source_info_util\n",
                "from jax._src import util\n",
                "from jax._src.util import (unzip3, prod, safe_map, safe_zip,\n",
                "                           extend_name_stack, new_name_stack, wrap_name, assert_unreachable,\n",
                "                           tuple_insert, tuple_delete, distributed_debug_log)\n",
                "from jax.errors import JAXTypeError\n",
                "from jax._src import dispatch\n",
                "from jax._src import profiler\n",
                "from jax._src.lib import _xla_extension_version\n",
                "from jax._src.lib import xla_bridge as xb\n",
                "from jax._src.lib import xla_client as xc\n",
                "from jax._src.lib import pmap_lib\n",
                "from jax._src.lib.mlir import ir\n",
                "from jax._src.lib.mlir.dialects import mhlo\n",
                "from jax.tree_util import tree_flatten, tree_map\n",
                "from jax.interpreters import batching\n",
                "from jax.interpreters import mlir\n",
                "from jax.interpreters import partial_eval as pe\n",
                "from jax.interpreters import xla\n",
                "from jax.interpreters import ad\n",
                "\n",
                "# Built in Python lists don't support weak refs but subclasses of lists do.\n",
                "class WeakRefList(list):\n",
                "  pass\n",
                "\n",
                "if sys.version_info >= (3, 8):\n",
                "  from functools import cached_property as maybe_cached_property\n",
                "else:\n",
                "  maybe_cached_property = property\n",
                "\n",
                "if sys.version_info >= (3, 9):\n",
                "  OrderedDictType = OrderedDict\n",
                "else:\n",
                "  OrderedDictType = Dict\n",
                "\n",
                "xops = xc.ops\n",
                "xe = xc._xla\n",
                "\n",
                "unsafe_map, map = map, safe_map  # type: ignore\n",
                "\n",
                "Index = Union[int, slice, Tuple[Union[int, slice], ...]]\n",
                "\n",
                "NoSharding = pmap_lib.NoSharding\n",
                "Chunked = pmap_lib.Chunked\n",
                "Unstacked = pmap_lib.Unstacked\n",
                "\n",
                "ShardedAxis = pmap_lib.ShardedAxis\n",
                "Replicated = pmap_lib.Replicated\n",
                "\n",
                "_UNSHARDED_INSTANCE = NoSharding()\n",
                "AvalDimSharding = Union[Unstacked, Chunked, NoSharding]\n",
                "MeshDimAssignment = Union[ShardedAxis, Replicated]\n",
                "ShardingSpec = pmap_lib.ShardingSpec\n",
                "\n",
                "MeshAxisName = Any\n",
                "OpShardingType = Any\n",
                "\n",
                "\n",
                "def sharding_spec_mesh_shape(self):\n",
                "  sharded_axis_sizes = []\n",
                "  for sharding in self.sharding:\n",
                "    if isinstance(sharding, NoSharding):\n",
                "      continue\n",
                "    elif isinstance(sharding, Unstacked):\n",
                "      sharded_axis_sizes.append(sharding.size)\n",
                "    elif isinstance(sharding, Chunked):\n",
                "      sharded_axis_sizes.extend(sharding.chunks)\n",
                "    else:\n",
                "      assert_unreachable(sharding)\n",
                "  return tuple(sharded_axis_sizes[a.axis] if isinstance(a, ShardedAxis) else a.replicas\n",
                "               for a in self.mesh_mapping)\n",
                "\n",
                "def sharding_spec_sharding_proto(self, special_axes: Mapping[int, OpShardingType] = {}):\n",
                "  \"\"\"Converts a ShardingSpec to an OpSharding proto.\n",
                "\n",
                "  See\n",
                "  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/xla_data.proto#L601\n",
                "  for details on the OpSharding proto.\n",
                "  Unfortunately the semantics are not very well described in the proto spec, but the code here might help:\n",
                "  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/experimental/xla_sharding/xla_sharding.py\n",
                "  \"\"\"\n",
                "  mesh_shape = cast(Tuple[int, ...], self.mesh_shape)\n",
                "  mesh = np.arange(np.prod(mesh_shape)).reshape(mesh_shape)\n",
                "\n",
                "  sharded_axes = {}  # maps sharded axis identifiers to mesh axis indices to which they're mapped\n",
                "  replicated_maxes = []  # lists mesh axis identifiers to replicate over\n",
                "  for maxis, assignment in enumerate(self.mesh_mapping):\n",
                "    if isinstance(assignment, Replicated):\n",
                "      replicated_maxes.append((maxis, assignment.replicas))\n",
                "    elif isinstance(assignment, ShardedAxis):\n",
                "      sharded_axes[assignment.axis] = maxis\n",
                "    else:\n",
                "      assert_unreachable(assignment)\n",
                "\n",
                "  proto = xc.OpSharding()\n",
                "  if len(replicated_maxes) == len(self.mesh_mapping) and not special_axes:\n",
                "    proto.type = xc.OpSharding.Type.REPLICATED\n",
                "    return proto\n",
                "  else:\n",
                "    proto.type = xc.OpSharding.Type.OTHER\n",
                "\n",
                "  mesh_permutation = []\n",
                "  new_mesh_shape = []\n",
                "  next_sharded_axis = 0\n",
                "  for axis, sharding in enumerate(self.sharding):\n",
                "    if isinstance(sharding, NoSharding):\n",
                "      new_mesh_shape.append(1)  # Add a dummy mesh axis we won't be sharding over\n",
                "    elif isinstance(sharding, Chunked):\n",
                "      for nchunks in sharding.chunks:\n",
                "        maxis = sharded_axes[next_sharded_axis]\n",
                "        assert mesh_shape[maxis] == nchunks\n",
                "        mesh_permutation.append(maxis)\n",
                "        next_sharded_axis += 1\n",
                "      new_mesh_shape.append(int(np.prod(sharding.chunks)))\n",
                "    elif isinstance(sharding, Unstacked):\n",
                "      raise RuntimeError(\"Cannot convert unstacked sharding specs to XLA OpSharding\")\n",
                "    else:\n",
                "      assert_unreachable(sharding)\n",
                "\n",
                "  # Create a partial sharding proto if tensor is replicated or partitioned\n",
                "  # specially over some mesh axes.\n",
                "  if replicated_maxes:\n",
                "    last_tile_dims = []\n",
                "    axes_by_type: Dict[OpShardingType, List[MeshAxisName]] = {}\n",
                "    size_by_type: Dict[OpShardingType, int] = defaultdict(lambda: 1)\n",
                "    assert set(x[0] for x in replicated_maxes).issuperset(set(special_axes.keys()))\n",
                "    for axis, size in replicated_maxes:\n",
                "      ty = special_axes.get(axis, xc.OpSharding.Type.REPLICATED)\n",
                "      axes_by_type.setdefault(ty, []).append(axis)\n",
                "      size_by_type[ty] *= size\n",
                "    for ty, axes in sorted(axes_by_type.items(), key=lambda x: x[0].value):\n",
                "      last_tile_dims.append(ty)\n",
                "      new_mesh_shape.append(size_by_type[ty])\n",
                "      mesh_permutation.extend(axes)\n",
                "    proto.last_tile_dims = last_tile_dims\n",
                "\n",
                "  proto_mesh = mesh.transpose(mesh_permutation).reshape(new_mesh_shape)\n",
                "  proto.tile_assignment_dimensions = list(proto_mesh.shape)\n",
                "  proto.tile_assignment_devices = list(proto_mesh.flat)\n",
                "  return proto\n",
                "\n",
                "def sharding_spec_indices(self, shape: Tuple[int, ...]) -> np.ndarray:\n",
                "  \"\"\"Returns NumPy-style indices corresponding to a sharding spec.\n",
                "\n",
                "  Args:\n",
                "    shape: The shape of the logical array being sharded.\n",
                "\n",
                "  Returns:\n",
                "    An ndarray with the same shape as the logical mesh (as derived form\n",
                "    `mesh_mapping`). Each entry is a NumPy-style index selecting the subset of\n",
                "    the data array to be placed on a corresponding device. The indices can be\n",
                "    ints, slice objects with step=1, or tuples of those.\n",
                "  \"\"\"\n",
                "  assert len(shape) == len(self.sharding), (shape, self.sharding)\n",
                "\n",
                "  axis_indices: List[Sequence[Index]] = []\n",
                "  shard_indices_shape = []\n",
                "  for dim, sharding in enumerate(self.sharding):\n",
                "    axis_size = shape[dim]\n",
                "    if isinstance(sharding, NoSharding):\n",
                "      axis_indices.append([slice(None)])\n",
                "      # NOTE: We don't append unsharded dimensions to shard_indices_shape here,\n",
                "      #       because they do not appear in the mesh mapping.\n",
                "    elif isinstance(sharding, Unstacked):\n",
                "      assert axis_size == sharding.size, f'{axis_size} != {sharding.size}'\n",
                "      axis_indices.append(range(axis_size))\n",
                "      shard_indices_shape.append(axis_size)\n",
                "    elif isinstance(sharding, Chunked):\n",
                "      total_chunks = int(np.prod(sharding.chunks))\n",
                "      shard_size, ragged = divmod(axis_size, total_chunks)\n",
                "      assert not ragged, (axis_size, total_chunks, dim)\n",
                "      axis_indices.append([slice(i * shard_size, (i + 1) * shard_size)\n",
                "                           for i in range(total_chunks)])\n",
                "      shard_indices_shape.extend(sharding.chunks)\n",
                "    else:\n",
                "      assert_unreachable(sharding)\n",
                "\n",
                "  # shard_indices is an ndarray representing the sharded axes of the logical array,\n",
                "  # with each dimension having size equal to the number of shards across the corresponding\n",
                "  # logical array dimension, and each element containing the multi-dimensional index that\n",
                "  # is used to extract the corresponding shard of the logical array.\n",
                "  shard_indices = np.empty([prod(shard_indices_shape)], dtype=np.object_)\n",
                "  for i, idxs in enumerate(it.product(*axis_indices)):\n",
                "    shard_indices[i] = idxs\n",
                "  shard_indices = shard_indices.reshape(shard_indices_shape)\n",
                "\n",
                "  # Ensure that each sharded axis is used exactly once in the mesh mapping\n",
                "  num_sharded_dim = len(shard_indices_shape)\n",
                "  sharded_dim_perm = [a.axis for a in self.mesh_mapping if isinstance(a, ShardedAxis)]\n",
                "  assert (set(sharded_dim_perm) == set(range(num_sharded_dim)) and\n",
                "          len(sharded_dim_perm) == num_sharded_dim)\n",
                "  # Replicate/reorder the indices according to the mesh mapping\n",
                "  replica_sizes = tuple(a.replicas for a in self.mesh_mapping if isinstance(a, Replicated))\n",
                "  replica_dim, sharded_dim = it.count(0), iter(sharded_dim_perm)\n",
                "  perm = [next(replica_dim) if isinstance(a, Replicated) else\n",
                "          len(replica_sizes) + next(sharded_dim)\n",
                "          for a in self.mesh_mapping]\n",
                "  return (np.broadcast_to(shard_indices, replica_sizes + shard_indices.shape)\n",
                "            .transpose(perm))\n",
                "\n",
                "def sharding_spec_repr(self):\n",
                "  return f'ShardingSpec({self.sharding}, {self.mesh_mapping})'\n",
                "\n",
                "\n",
                "ShardingSpec.mesh_shape = property(sharding_spec_mesh_shape)\n",
                "ShardingSpec.sharding_proto = sharding_spec_sharding_proto\n",
                "ShardingSpec.indices = sharding_spec_indices\n",
                "# mypy raises: error: Cannot assign to a method  [assignment]\n",
                "ShardingSpec.__repr__ = sharding_spec_repr  # type: ignore\n",
                "# Do not pollute the namespace\n",
                "del sharding_spec_mesh_shape, sharding_spec_indices, sharding_spec_repr\n",
                "\n",
                "def spec_to_indices(shape: Tuple[int, ...],\n",
                "                    spec: ShardingSpec) -> Tuple[Index, ...]:\n",
                "  \"\"\"Returns numpy-style indices corresponding to a sharding spec.\n",
                "\n",
                "  Each index describes a shard of the array. The order of the indices is the\n",
                "  same as the device_buffers of a ShardedDeviceArray (i.e. the data is laid out\n",
                "  row-major).\n",
                "\n",
                "  Args:\n",
                "    shape: The shape of the logical array being sharded.\n",
                "    spec: Describes how the array is sharded and how the shards are assigned to\n",
                "      the logical mesh.\n",
                "\n",
                "  Returns:\n",
                "    A tuple of length equal to the size of the mesh (inferred as the product of\n",
                "    sharded dimension sizes and all replication factors).  Each element is an\n",
                "    int, a slice object with step=1, or a tuple thereof, to be treated as an\n",
                "    index into the full logical array.\n",
                "  \"\"\"\n",
                "  return tuple(spec.indices(shape).flat)  # type: ignore\n",
                "\n",
                "\n",
                "### util\n",
                "\n",
                "def identity(x): return x\n",
                "\n",
                "def _shard_arg(arg, devices, arg_indices):\n",
                "  \"\"\"Returns a list of size len(devices) containing per-device buffers.\n",
                "\n",
                "  For the C++ pmap path, we fallback to Python (this function) to shard\n",
                "  arguments that are not supported by the C++ `ShardArg`.\n",
                "\n",
                "  Arrgs:\n",
                "    arg: The Python argument.\n",
                "    devices: The list of devices to shard over.\n",
                "    arg_indices: A list of `len(devices)` indices to use to shard the argument.\n",
                "  \"\"\"\n",
                "  if isinstance(arg, ShardedDeviceArray) and arg_indices == arg.indices:\n",
                "    # The shard_arg_handlers allow an extensible set of types to be sharded, but\n",
                "    # inline handling for ShardedDeviceArray as a special case for performance\n",
                "    # NOTE: we compare indices instead of sharding_spec because\n",
                "    # pmap_benchmark.pmap_shard_args_benchmark indicates this is faster.\n",
                "    return [\n",
                "        buf if buf.device() == d else buf.copy_to_device(d)\n",
                "        for d, buf in zip(devices, arg.device_buffers)\n",
                "    ]\n",
                "  else:\n",
                "    arg = xla.canonicalize_dtype(arg)\n",
                "    return shard_arg_handlers[type(arg)](arg, devices, arg_indices)\n",
                "\n",
                "\n",
                "@profiler.annotate_function\n",
                "def shard_args(devices: Sequence[xb.xla_client.Device],\n",
                "               indices: Sequence[Sequence[Index]],\n",
                "               args) -> Sequence[Sequence[xb.xla_client.Buffer]]:\n",
                "  \"\"\"Shard each argument data array along its leading axis.\n",
                "\n",
                "  Args:\n",
                "    devices: sequence of Devices mapping replica index to a physical device.\n",
                "    indices: sequence of the same length as `args` describing how each arg\n",
                "      should be sharded/replicated across `devices`. Each element in `indices`\n",
                "      is the same length as `devices`.\n",
                "    args: a sequence of JaxTypes representing arguments to be sharded according\n",
                "      to `indices` and placed on `devices`.\n",
                "\n",
                "  Returns:\n",
                "    A list of length matching args, containing lists of per-device buffers\n",
                "    for each argument.\n",
                "  \"\"\"\n",
                "  return [_shard_arg(arg, devices, indices[i]) for i, arg in enumerate(args)]\n",
                "\n",
                "\n",
                "shard_arg_handlers: Dict[Any, Callable[[Any, Any, Any], Sequence[Any]]] = {}\n",
                "shard_arg_handlers[core.Unit] = \\\n",
                "    lambda x, devices, _: device_put(core.unit, devices, replicate=True)  # type: ignore[has-type]\n",
                "def _shard_array(x, devices, indices):\n",
                "  return device_put([x[i] for i in indices], devices)\n",
                "for _t in array_types:\n",
                "  shard_arg_handlers[_t] = _shard_array\n",
                "\n",
                "def _shard_device_array(x, devices, indices):\n",
                "  start_indices, limit_indices, removed_dims = unzip3(\n",
                "      _as_slice_indices(x, idx) for idx in indices)\n",
                "  shards = x._multi_slice(start_indices, limit_indices, removed_dims)\n",
                "  return device_put(shards, devices)\n",
                "for t in device_array.device_array_types:\n",
                "  shard_arg_handlers[t] = _shard_device_array\n",
                "\n",
                "\n",
                "# NOTE(skye): we could refactor to generate _multi_slice parameters directly\n",
                "# from the input ShardingSpec, rather than the indices. However, this would\n",
                "# require duplicating the ordering logic of spec_to_indices, which is more\n",
                "# subtle and more likely to change than the index logic we have to support here.\n",
                "def _as_slice_indices(arr: device_array.DeviceArrayProtocol, idx: Index) -> Tuple[\n",
                "    Tuple[int, ...], Tuple[int, ...], Tuple[int, ...]]:\n",
                "  \"\"\"Returns start_indices, limit_indices, removed_dims\"\"\"\n",
                "  start_indices = [0] * arr.ndim\n",
                "  limit_indices = list(arr.shape)\n",
                "  removed_dims = []\n",
                "\n",
                "  tuple_idx = idx if isinstance(idx, tuple) else (idx,)\n",
                "  for dim, sub_idx in enumerate(tuple_idx):\n",
                "    if isinstance(sub_idx, int):\n",
                "      start_indices[dim] = sub_idx\n",
                "      limit_indices[dim] = sub_idx + 1\n",
                "      removed_dims.append(dim)\n",
                "    elif sub_idx == slice(None):\n",
                "      continue\n",
                "    else:\n",
                "      assert isinstance(sub_idx, slice), sub_idx\n",
                "      assert isinstance(sub_idx.start, int), sub_idx\n",
                "      assert isinstance(sub_idx.stop, int), sub_idx\n",
                "      start_indices[dim] = sub_idx.start\n",
                "      limit_indices[dim] = sub_idx.stop\n",
                "\n",
                "  return tuple(start_indices), tuple(limit_indices), tuple(removed_dims) # type: ignore\n",
                "\n",
                "\n",
                "def shard_aval(size, axis: int, aval):\n",
                "  try:\n",
                "    return shard_aval_handlers[type(aval)](size, axis, aval)\n",
                "  except KeyError as err:\n",
                "    raise TypeError(f\"No shard_aval handler for type: {type(aval)}\") from err\n",
                "shard_aval_handlers: Dict[Type[core.AbstractValue], Callable[[int, int, Any], Any]] = {}\n",
                "shard_aval_handlers[core.AbstractUnit] = lambda size, axis, x: x\n",
                "def _shard_abstract_array(size, axis: int, x):\n",
                "  try:\n",
                "    if x.shape[axis] != size:\n",
                "      raise ValueError(f\"Axis size {size} does not match dimension {axis} of \"\n",
                "                       f\"shape {x.shape}\")\n",
                "  except IndexError:\n",
                "    raise ValueError(\"Cannot split a {x.dim}D value along axis {axis}\") from None\n",
                "  return x.update(shape=tuple_delete(x.shape, axis))\n",
                "shard_aval_handlers[ShapedArray] = _shard_abstract_array\n",
                "\n",
                "\"\"\"\n",
                "ArrayMapping specifies how an ndarray should map to mesh axes.\n",
                "\n",
                "Note that the ordering is crucial for the cases when this mapping is non-injective\n",
                "(i.e. when multiple mesh axes map to the same positional axis). Then, the\n",
                "order of entries of the mapping determines a major-to-minor order on mesh axes,\n",
                "according to which chunks of the value along the repeated dimension will be assigned.\n",
                "\n",
                "For example, consider a mapping {'x': 1, 'y': 1} and a mesh with shape {'x': 2, 'y': 3}.\n",
                "The second dimension of the value would get chunked into 6 pieces, and assigned to the\n",
                "mesh in a way that treats 'y' as the fastest changing (minor) dimension. In this case,\n",
                "that would mean that a flat list of chunks would get assigned to a flattened list of\n",
                "mesh devices without any modifications. If the mapping was {'y': 1, 'x': 1}, then the\n",
                "mesh devices ndarray would have to be transposed before flattening and assignment.\n",
                "\"\"\"\n",
                "ArrayMapping = OrderedDictType[MeshAxisName, int]\n",
                "\n",
                "AxisResource = Tuple[Optional[Tuple[Any, ...]], ...]\n",
                "\n",
                "def array_mapping_to_axis_resources(array_mapping: ArrayMapping) -> AxisResource:\n",
                "  if not array_mapping:\n",
                "    return tuple()\n",
                "  max_index = -1\n",
                "  reverse_map = defaultdict(list)\n",
                "  for axis, index in array_mapping.items():\n",
                "    reverse_map[index].append(axis)\n",
                "    if index > max_index:\n",
                "      max_index = index\n",
                "  return tuple(\n",
                "      tuple(reverse_map[i]) if reverse_map[i] else None for i in range(max_index + 1)\n",
                "  )\n",
                "\n",
                "def local_aval_to_result_handler(\n",
                "    aval: core.AbstractValue,\n",
                "    sharding_spec: Optional[ShardingSpec],\n",
                "    indices: Optional[Tuple[Index]],\n",
                ") -> Callable[[List[xb.xla_client.Buffer]], Any]:\n",
                "  \"\"\"Returns a function for handling the raw buffers of a single output aval.\n",
                "\n",
                "  Args:\n",
                "    aval: The local output AbstractValue.\n",
                "    sharding_spec: Indicates how the output is sharded across devices, or None\n",
                "      for non-array avals.\n",
                "    indices: The pre-computed result of spec_to_indices, or None for non-array\n",
                "      avals.\n",
                "\n",
                "  Returns:\n",
                "    A function for handling the Buffers that will eventually be produced\n",
                "    for this output. The function will return an object suitable for returning\n",
                "    to the user, e.g. a ShardedDeviceArray.\n",
                "  \"\"\"\n",
                "  try:\n",
                "    return local_result_handlers[type(aval)](aval, sharding_spec, indices)\n",
                "  except KeyError as err:\n",
                "    raise TypeError(\n",
                "        \"No pxla_result_handler for type: {}\".format(type(aval))) from err\n",
                "\n",
                "PxlaResultHandler = Callable[..., Callable[[List[xb.xla_client.Buffer]], Any]]\n",
                "local_result_handlers: Dict[Type[core.AbstractValue], PxlaResultHandler] = {}\n",
                "local_result_handlers[core.AbstractUnit] = lambda *_: lambda _: core.unit\n",
                "def sda_array_result_handler(aval: ShapedArray, sharding_spec, indices):\n",
                "  return lambda bufs: make_sharded_device_array(aval, sharding_spec, bufs,\n",
                "                                                indices)\n",
                "local_result_handlers[ShapedArray] = sda_array_result_handler\n",
                "local_result_handlers[ConcreteArray] = sda_array_result_handler\n",
                "\n",
                "\n",
                "def global_aval_to_result_handler(\n",
                "    aval: core.AbstractValue,\n",
                "    out_axis_resources: Optional[AxisResource], global_mesh,\n",
                ") -> Callable[[List[xb.xla_client.Buffer]], Any]:\n",
                "  \"\"\"Returns a function for handling the raw buffers of a single output aval.\n",
                "\n",
                "  Args:\n",
                "    aval: The global output AbstractValue.\n",
                "    out_axis_resources: A tuple specifying the sharding of outputs.\n",
                "      Used for creating GSDAs.\n",
                "    global_mesh: The global device mesh that generated this output. Used\n",
                "      for creating GSDAs.\n",
                "\n",
                "  Returns:\n",
                "    A function for handling the Buffers that will eventually be produced\n",
                "    for this output. The function will return an object suitable for returning\n",
                "    to the user, e.g. a ShardedDeviceArray.\n",
                "  \"\"\"\n",
                "  try:\n",
                "    return global_result_handlers[type(aval)](aval, out_axis_resources,\n",
                "                                              global_mesh)\n",
                "  except KeyError as err:\n",
                "    raise TypeError(\n",
                "        \"No pxla_result_handler for type: {}\".format(type(aval))) from err\n",
                "\n",
                "global_result_handlers: Dict[Type[core.AbstractValue], PxlaResultHandler] = {}\n",
                "global_result_handlers[core.AbstractUnit] = lambda *_: lambda _: core.unit\n",
                "\n",
                "### lazy device-memory persistence and result handling\n",
                "\n",
                "# TODO(jblespiau): Consider removing this option.\n",
                "_USE_CPP_SDA = True\n",
                "\n",
                "\n",
                "def make_sharded_device_array(\n",
                "    aval: ShapedArray,\n",
                "    sharding_spec: Optional[ShardingSpec],\n",
                "    # Any is for JAX extensions implementing their own buffer.\n",
                "    device_buffers: List[Union[Any, xb.xla_client.Buffer]],\n",
                "    indices: Optional[Tuple[Index, ...]] = None,\n",
                "):\n",
                "  \"\"\"Returns a ShardedDeviceArray implementation based on arguments.\n",
                "\n",
                "  Returns either a C++ SDA or a Python DeviceArray when the buffers are not\n",
                "  JAX buffers.\n",
                "\n",
                "  Args:\n",
                "    aval: The `ShapedArray` for this array.\n",
                "    sharding_spec: If `None`, assumes a pmap-style ShardedDeviceArrays over the\n",
                "      first dimension.\n",
                "    device_buffers: If a list of Jax `Buffer` objects, a C++ SDA will be\n",
                "      returned (if the version is high enough). Otherwise, a Python object will\n",
                "      be returned, for JAX extensions not implementing the C++ API.\n",
                "    indices: For caching purposes, will be computed if `None`.\n",
                "  \"\"\"\n",
                "  if sharding_spec is None:\n",
                "    sharded_aval = aval.update(shape=aval.shape[1:])\n",
                "    sharding_spec = _pmap_sharding_spec(aval.shape[0], aval.shape[0], 1, None,\n",
                "                                        sharded_aval, 0)\n",
                "\n",
                "  if indices is None:\n",
                "    indices = spec_to_indices(aval.shape, sharding_spec)\n",
                "\n",
                "  if (_USE_CPP_SDA and\n",
                "      (not device_buffers or\n",
                "       isinstance(device_buffers[0], xb.xla_client.Buffer))):\n",
                "    return pmap_lib.ShardedDeviceArray.make(\n",
                "        aval, sharding_spec, device_buffers,\n",
                "        indices, aval.weak_type)\n",
                "\n",
                "  return _ShardedDeviceArray(aval, sharding_spec, device_buffers, indices)\n",
                "\n",
                "\n",
                "if _USE_CPP_SDA:\n",
                "  ShardedDeviceArrayBase = pmap_lib.ShardedDeviceArrayBase  # type: ignore\n",
                "  # We want the C++ SDA to extend the DeviceArrayBase. We want this both to\n",
                "  # benefit from its methods, and to have isinstance(x, DeviceArray) return true\n",
                "  ShardedDeviceArrayBase.__bases__ = ((device_array.DeviceArray,) +  # type: ignore\n",
                "                                      ShardedDeviceArrayBase.__bases__)\n",
                "  _SDA_BASE_CLASS = pmap_lib.ShardedDeviceArrayBase  # type: ignore\n",
                "else:\n",
                "  _SDA_BASE_CLASS: Type[device_array.DeviceArray] = device_array.DeviceArray  # type: ignore\n",
                "\n",
                "\n",
                "class _ShardedDeviceArray(_SDA_BASE_CLASS):  # type: ignore\n",
                "  \"\"\"A ShardedDeviceArray is an ndarray sharded across devices.\n",
                "\n",
                "  The purpose of a ShardedDeviceArray is to reduce the number of transfers when\n",
                "  executing replicated computations, by allowing results to persist on the\n",
                "  devices that produced them. That way dispatching a similarly replicated\n",
                "  computation that consumes the same sharded memory layout does not incur any\n",
                "  transfers.\n",
                "\n",
                "  A ShardedDeviceArray represents one logical ndarray value, and simulates the\n",
                "  behavior of an ndarray so that it can be treated by user code as an ndarray;\n",
                "  that is, it is only an optimization to reduce transfers.\n",
                "\n",
                "  Attributes:\n",
                "    aval: A ShapedArray indicating the shape and dtype of this array.\n",
                "    sharding_spec: describes how this array is sharded across `device_buffers`.\n",
                "    device_buffers: the buffers containing the data for this array. Each buffer\n",
                "      is the same shape and on a different device. Buffers are in row-major\n",
                "      order, with replication treated as an extra innermost dimension.\n",
                "    indices: the result of spec_to_indices(sharding_spec). Can optionally be\n",
                "      precomputed for efficiency. A list the same length as\n",
                "      `device_buffers`. Each index indicates what portion of the full array is\n",
                "      stored in the corresponding device buffer, i.e. `array[indices[i]] ==\n",
                "      device_buffers[i].to_py()`.\n",
                "  \"\"\"\n",
                "  __slots__ = [\n",
                "      \"aval\", \"device_buffers\", \"sharding_spec\", \"indices\",\n",
                "      \"_one_replica_buffer_indices\", \"_npy_value\"\n",
                "  ]\n",
                "\n",
                "  def __init__(self,\n",
                "               aval: ShapedArray,\n",
                "               sharding_spec: ShardingSpec,\n",
                "               device_buffers: List[xb.xla_client.Buffer],\n",
                "               indices: Optional[Tuple[Index, ...]] = None):\n",
                "    super().__init__()\n",
                "\n",
                "    # TODO(skye): assert invariants. Keep performance in mind though.\n",
                "    if indices is None:\n",
                "      indices = spec_to_indices(aval.shape, sharding_spec)\n",
                "\n",
                "    self.aval = aval\n",
                "    self.device_buffers = device_buffers\n",
                "    self.sharding_spec = sharding_spec\n",
                "    self.indices = indices\n",
                "    self._npy_value = None\n",
                "    self._one_replica_buffer_indices = None\n",
                "    if config.jax_enable_checks:\n",
                "      assert type(aval) is ShapedArray\n",
                "\n",
                "  @property\n",
                "  def shape(self):\n",
                "    return self.aval.shape\n",
                "\n",
                "  @property\n",
                "  def dtype(self):\n",
                "    return self.aval.dtype\n",
                "\n",
                "  @property\n",
                "  def size(self):\n",
                "    return prod(self.aval.shape)\n",
                "\n",
                "  @property\n",
                "  def ndim(self):\n",
                "    return len(self.aval.shape)\n",
                "\n",
                "  def delete(self):\n",
                "    if self.device_buffers is None:\n",
                "      return\n",
                "    for buf in self.device_buffers:\n",
                "      buf.delete()\n",
                "    self.device_buffers = None\n",
                "    self._npy_value = None\n",
                "\n",
                "\n",
                "def _sda_one_replica_buffer_indices(self):\n",
                "  \"\"\"Indices of buffers containing one complete copy of the array data.\"\"\"\n",
                "  if self._one_replica_buffer_indices is None:\n",
                "    one_replica_indices = []\n",
                "    seen_index_hashes = set()\n",
                "    for i, index in enumerate(self.indices):\n",
                "      hashed_index = _hashable_index(index)\n",
                "      if hashed_index not in seen_index_hashes:\n",
                "        one_replica_indices.append(i)\n",
                "        seen_index_hashes.add(hashed_index)\n",
                "    self._one_replica_buffer_indices = one_replica_indices\n",
                "  return self._one_replica_buffer_indices\n",
                "\n",
                "\n",
                "def _sda_copy_to_host_async(self):\n",
                "  for buffer_index in self.one_replica_buffer_indices:\n",
                "    self.device_buffers[buffer_index].copy_to_host_async()\n",
                "\n",
                "\n",
                "def _sda_check_if_deleted(self):\n",
                "  if self.device_buffers is None:\n",
                "    raise ValueError(\"ShardedDeviceArray has been deleted.\")\n",
                "\n",
                "\n",
                "def _sda_block_until_ready(self):\n",
                "  self._check_if_deleted()\n",
                "  for buf in self.device_buffers:\n",
                "    buf.block_host_until_ready()\n",
                "  return self\n",
                "\n",
                "\n",
                "def _sda_value(self):\n",
                "  if self._npy_value is None:\n",
                "    self.copy_to_host_async()\n",
                "    npy_value = np.empty(self.aval.shape, self.aval.dtype)\n",
                "    for i in self.one_replica_buffer_indices:\n",
                "      npy_value[self.indices[i]] = self.device_buffers[i].to_py()\n",
                "    self._npy_value = npy_value\n",
                "  return self._npy_value\n",
                "\n",
                "\n",
                "def _sda__getitem__(self, idx):\n",
                "  self._check_if_deleted()\n",
                "  if not isinstance(idx, tuple):\n",
                "    cidx = (idx,) + (slice(None),) * (len(self.aval.shape) - 1)\n",
                "  else:\n",
                "    cidx = idx + (slice(None),) * (len(self.aval.shape) - len(idx))\n",
                "  if self._npy_value is None:\n",
                "    try:\n",
                "      buf_idx = self.indices.index(cidx)\n",
                "    except ValueError:\n",
                "      buf_idx = None\n",
                "    if buf_idx is not None:\n",
                "      buf = self.device_buffers[buf_idx]\n",
                "      aval = ShapedArray(buf.xla_shape().dimensions(), self.aval.dtype)\n",
                "      return device_array.make_device_array(aval, None, buf)\n",
                "  return super(self.__class__, self).__getitem__(idx)\n",
                "\n",
                "\n",
                "def _sda__iter__(self):\n",
                "  if self.ndim == 0:\n",
                "    raise TypeError(\"iteration over a 0-d array\")  # same as numpy error\n",
                "  else:\n",
                "    return (self[i] for i in range(self.shape[0]))\n",
                "\n",
                "def _sda__reversed__(self):\n",
                "  if self.ndim == 0:\n",
                "    raise TypeError(\"iteration over a 0-d array\")  # same as numpy error\n",
                "  else:\n",
                "    return (self[i] for i in range(self.shape[0] - 1, -1, -1))\n",
                "\n",
                "\n",
                "for sda in [_ShardedDeviceArray, pmap_lib.ShardedDeviceArray]:\n",
                "  setattr(sda, \"one_replica_buffer_indices\",\n",
                "          property(_sda_one_replica_buffer_indices))\n",
                "  setattr(sda, \"copy_to_host_async\", _sda_copy_to_host_async)\n",
                "  setattr(sda, \"_check_if_deleted\", _sda_check_if_deleted)\n",
                "  setattr(sda, \"block_until_ready\", _sda_block_until_ready)\n",
                "  setattr(sda, \"_value\", property(_sda_value))\n",
                "  setattr(sda, \"__getitem__\", _sda__getitem__)\n",
                "  setattr(sda, \"__iter__\", _sda__iter__)\n",
                "  setattr(sda, \"__reversed__\", _sda__reversed__)\n",
                "\n",
                "del (_sda_one_replica_buffer_indices, _sda_copy_to_host_async,\n",
                "     _sda_check_if_deleted, _sda_block_until_ready, _sda_value, _sda__getitem__)\n",
                "\n",
                "\n",
                "ShardedDeviceArray: Type[object]\n",
                "if _USE_CPP_SDA:\n",
                "  ShardedDeviceArray = pmap_lib.ShardedDeviceArrayBase\n",
                "else:\n",
                "  ShardedDeviceArray = _ShardedDeviceArray\n",
                "\n",
                "\n",
                "\n",
                "def _hashable_index(idx):\n",
                "  return tree_map(lambda x: (x.start, x.stop) if type(x) == slice else x,\n",
                "                  idx)\n",
                "\n",
                "# The fast path is handled directly in shard_args().\n",
                "# TODO(skye): is there a simpler way to rewrite this using sharding_spec?\n",
                "def _shard_sharded_device_array_slow_path(x, devices, indices):\n",
                "  candidates = defaultdict(list)\n",
                "  for buf, idx in safe_zip(x.device_buffers, x.indices):\n",
                "    candidates[_hashable_index(idx)].append(buf)\n",
                "\n",
                "  bufs = []\n",
                "  for idx, device in safe_zip(indices, devices):\n",
                "    # Look up all buffers that contain the correct slice of the logical array.\n",
                "    candidates_list = candidates[_hashable_index(idx)]\n",
                "    if not candidates_list:\n",
                "      # This array isn't sharded correctly. Reshard it via host roundtrip.\n",
                "      # TODO(skye): more efficient reshard?\n",
                "      return shard_arg_handlers[type(x._value)](x._value, devices, indices)\n",
                "    # Try to find a candidate buffer already on the correct device,\n",
                "    # otherwise copy one of them.\n",
                "    for buf in candidates_list:\n",
                "      if buf.device() == device:\n",
                "        bufs.append(buf)\n",
                "        break\n",
                "    else:\n",
                "      bufs.append(buf.copy_to_device(device))\n",
                "  return bufs\n",
                "\n",
                "\n",
                "def _sharded_device_array_constant_handler(c, val, canonicalize_types=True):\n",
                "  return xla.pyval_to_ir_constants(c, np.asarray(val),\n",
                "                                   canonicalize_types=canonicalize_types)\n",
                "\n",
                "\n",
                "def _sharded_device_array_mlir_constant_handler(val, canonicalize_types=True):\n",
                "  return mlir.ir_constants(np.asarray(val),\n",
                "                           canonicalize_types=canonicalize_types)\n",
                "\n",
                "def _register_handlers_for_sharded_device_array(sda):\n",
                "  shard_arg_handlers[sda] = _shard_sharded_device_array_slow_path\n",
                "  xla.register_constant_handler(sda, _sharded_device_array_constant_handler)\n",
                "  mlir.register_constant_handler(sda,\n",
                "                                 _sharded_device_array_mlir_constant_handler)\n",
                "\n",
                "  core.pytype_aval_mappings[sda] = abstract_arrays.canonical_concrete_aval\n",
                "  dispatch.device_put_handlers[sda] = dispatch._device_put_array\n",
                "  xla.pytype_aval_mappings[sda] = op.attrgetter(\"aval\")\n",
                "  xla.canonicalize_dtype_handlers[sda] = identity\n",
                "\n",
                "_register_handlers_for_sharded_device_array(_ShardedDeviceArray)\n",
                "_register_handlers_for_sharded_device_array(pmap_lib.ShardedDeviceArray)\n",
                "\n",
                "### the xla_pmap primitive and its rules are comparable to xla_call in xla.py\n",
                "\n",
                "def xla_pmap_impl(fun: lu.WrappedFun, *args,\n",
                "                  backend: Optional[str],\n",
                "                  axis_name: core.AxisName,\n",
                "                  axis_size: int,\n",
                "                  global_axis_size: Optional[int],\n",
                "                  devices: Optional[Sequence[Any]],\n",
                "                  name: str,\n",
                "                  in_axes: Sequence[Optional[int]],\n",
                "                  out_axes_thunk: Callable[[], Sequence[Optional[int]]],\n",
                "                  donated_invars: Sequence[bool],\n",
                "                  global_arg_shapes: Sequence[Optional[Tuple[int, ...]]]):\n",
                "  abstract_args = unsafe_map(xla.abstractify, args)\n",
                "  compiled_fun, fingerprint = parallel_callable(\n",
                "      fun, backend, axis_name, axis_size, global_axis_size, devices, name,\n",
                "      in_axes, out_axes_thunk, donated_invars, global_arg_shapes,\n",
                "      *abstract_args)\n",
                "\n",
                "  # Don't re-abstractify args unless logging is enabled for performance.\n",
                "  if config.jax_distributed_debug:\n",
                "    distributed_debug_log((\"Running pmapped function\", name),\n",
                "                          (\"python function\", fun.f),\n",
                "                          (\"devices\", devices),\n",
                "                          (\"abstract args\", map(xla.abstractify, args)),\n",
                "                          (\"fingerprint\", fingerprint))\n",
                "  return compiled_fun(*args)\n",
                "\n",
                "\n",
                "@lu.cache\n",
                "def parallel_callable(fun: lu.WrappedFun,\n",
                "                      backend_name: Optional[str],\n",
                "                      axis_name: core.AxisName,\n",
                "                      axis_size: int,\n",
                "                      global_axis_size: Optional[int],\n",
                "                      devices: Optional[Sequence[Any]],\n",
                "                      name: str,\n",
                "                      in_axes: Sequence[Optional[int]],\n",
                "                      out_axes_thunk: Callable[[], Sequence[Optional[int]]],\n",
                "                      donated_invars: Sequence[bool],\n",
                "                      global_arg_shapes: Sequence[Optional[Tuple[int, ...]]],\n",
                "                      *avals):\n",
                "  pmap_computation = lower_parallel_callable(\n",
                "      fun, backend_name, axis_name, axis_size, global_axis_size, devices, name,\n",
                "      in_axes, out_axes_thunk, donated_invars, global_arg_shapes, avals)\n",
                "  pmap_executable = pmap_computation.compile()\n",
                "  return WeakRefList([pmap_executable.unsafe_call, pmap_executable.fingerprint])\n",
                "\n",
                "\n",
                "@dataclasses.dataclass(frozen=True)\n",
                "class ParallelCallableInfo:\n",
                "  name: str\n",
                "  backend: xla.Backend\n",
                "  axis_name: core.AxisName\n",
                "  axis_size: int\n",
                "  global_axis_size: Optional[int]\n",
                "  devices: Optional[Sequence[xla.Device]]\n",
                "  in_axes: Iterable[Optional[int]]\n",
                "  out_axes_thunk: Callable[[], Sequence[Optional[int]]]\n",
                "  avals: Sequence[core.AbstractValue]\n",
                "\n",
                "  @maybe_cached_property\n",
                "  def local_devices(self):\n",
                "    if self.devices:\n",
                "      out = [d for d in self.devices\n",
                "             if d.process_index == xb.process_index(self.backend)]\n",
                "      assert len(out) > 0\n",
                "    else:\n",
                "      out = None  # type: ignore\n",
                "    return out\n",
                "\n",
                "  @maybe_cached_property\n",
                "  def out_axes(self):\n",
                "    return self.out_axes_thunk()\n",
                "\n",
                "\n",
                "class ShardInfo(NamedTuple):\n",
                "  sharded_avals: Sequence[core.AbstractValue]\n",
                "  out_sharded_avals: Sequence[core.AbstractValue]\n",
                "  global_sharded_avals: Sequence[core.AbstractValue]\n",
                "  num_local_shards: int\n",
                "  num_global_shards: int\n",
                "\n",
                "\n",
                "class ReplicaInfo(NamedTuple):\n",
                "  jaxpr_replicas: int\n",
                "  num_local_replicas: int\n",
                "  num_global_replicas: int\n",
                "\n",
                "\n",
                "def find_replicas(jaxpr, axis_size, global_axis_size):\n",
                "  # TODO(skyewm): replace this with a chain of pmaps and/or sharded_jits\n",
                "  jaxpr_replicas = dispatch.jaxpr_replicas(jaxpr)\n",
                "  num_local_replicas = axis_size * jaxpr_replicas\n",
                "  num_global_replicas = global_axis_size * jaxpr_replicas\n",
                "  return ReplicaInfo(jaxpr_replicas, num_local_replicas, num_global_replicas)\n",
                "\n",
                "\n",
                "def should_tuple_args(shards: ShardInfo):\n",
                "  # tuplify long arg lists for TPU\n",
                "  return len(shards.global_sharded_avals) > 100\n",
                "\n",
                "\n",
                "def stage_parallel_callable(\n",
                "    pci: ParallelCallableInfo,\n",
                "    fun: lu.WrappedFun,\n",
                "    global_arg_shapes: Sequence[Optional[Tuple[int, ...]]]):\n",
                "  sharded_avals = tuple(\n",
                "      shard_aval(pci.axis_size, axis, aval) if axis is not None else aval\n",
                "      for axis, aval in safe_zip(pci.in_axes, pci.avals))\n",
                "  if any(s is not None for s in global_arg_shapes):\n",
                "    # TODO(skye): we could take this branch unconditionally if we handled\n",
                "    # grad of global_arg_shapes correctly.\n",
                "    global_sharded_avals = [\n",
                "        aval.update(shape=shape) if shape is not None else aval\n",
                "        for shape, aval in safe_zip(global_arg_shapes, sharded_avals)]\n",
                "  else:\n",
                "    global_sharded_avals = sharded_avals  # type: ignore\n",
                "\n",
                "  with core.extend_axis_env(pci.axis_name, pci.global_axis_size, None):  # type: ignore\n",
                "    with dispatch.log_elapsed_time(f\"Finished tracing + transforming {fun.__name__} \"\n",
                "                                   \"for pmap in {elapsed_time} sec\"):\n",
                "      jaxpr, out_sharded_avals, consts = pe.trace_to_jaxpr_final(\n",
                "          fun, global_sharded_avals, pe.debug_info_final(fun, \"pmap\"))\n",
                "  jaxpr = dispatch.apply_outfeed_rewriter(jaxpr)\n",
                "\n",
                "  assert len(out_sharded_avals) == len(pci.out_axes), (\n",
                "      len(out_sharded_avals), len(pci.out_axes))\n",
                "\n",
                "  # TODO(skye,mattjj): allow more collectives on multi-host as we test them, but\n",
                "  # for now raise an error\n",
                "  if pci.devices is not None:\n",
                "    is_multi_host_pmap = len(pci.local_devices) != len(pci.devices)\n",
                "  else:\n",
                "    is_multi_host_pmap = xb.process_count(pci.backend) > 1\n",
                "  if is_multi_host_pmap:\n",
                "    check_multihost_collective_allowlist(jaxpr)\n",
                "\n",
                "  replicas = find_replicas(jaxpr, pci.axis_size, pci.global_axis_size)\n",
                "  parts = find_partitions(jaxpr)\n",
                "\n",
                "  num_local_shards = replicas.num_local_replicas * parts.local_num_partitions\n",
                "  num_global_shards = replicas.num_global_replicas * parts.num_partitions\n",
                "\n",
                "  shards = ShardInfo(\n",
                "      sharded_avals, out_sharded_avals, global_sharded_avals,\n",
                "      num_local_shards, num_global_shards)\n",
                "\n",
                "  return jaxpr, consts, replicas, parts, shards\n",
                "\n",
                "\n",
                "def _shardings_to_mlir_shardings(\n",
                "    shardings: Optional[Sequence['PartitionsOrReplicated']]\n",
                "    ) -> Optional[Sequence[Optional[xc.OpSharding]]]:\n",
                "  if shardings is None:\n",
                "    return None\n",
                "  return [xla.sharding_to_proto(s) for s in shardings]\n",
                "\n",
                "@profiler.annotate_function\n",
                "def lower_parallel_callable(\n",
                "    fun: lu.WrappedFun,\n",
                "    backend_name: Optional[str],\n",
                "    axis_name: core.AxisName,\n",
                "    axis_size: int,\n",
                "    global_axis_size: Optional[int],\n",
                "    devices: Optional[Sequence[xla.Device]],\n",
                "    name: str,\n",
                "    in_axes: Iterable[Optional[int]],\n",
                "    out_axes_thunk: Callable[[], Sequence[Optional[int]]],\n",
                "    donated_invars: Sequence[bool],\n",
                "    global_arg_shapes: Sequence[Optional[Tuple[int, ...]]],\n",
                "    avals: Sequence[core.AbstractValue]):\n",
                "  if devices is not None and len(devices) == 0:\n",
                "    raise ValueError(\"'devices' argument to pmap must be non-empty, or None.\")\n",
                "\n",
                "  # Determine global_axis_size for use in AxisEnv.\n",
                "  # TODO(mattjj,skyewm): revive this check (inner_pmap always False now)\n",
                "  # if xb.process_count() > 1 and global_axis_size is None and inner_pmap:\n",
                "  #   raise ValueError(\"'axis_size' must be specified for nested multi-host pmaps\")\n",
                "  if (xb.process_count() == 1 and global_axis_size is not None and\n",
                "      global_axis_size != axis_size):\n",
                "    raise ValueError(\n",
                "        f\"Specified axis_size {global_axis_size} doesn't match received \"\n",
                "        f\"axis_size {axis_size}.\")\n",
                "\n",
                "  if devices is not None and backend_name is None:\n",
                "    backend = xb.get_device_backend(devices[0])\n",
                "  else:\n",
                "    backend = xb.get_backend(backend_name)\n",
                "\n",
                "  must_run_on_all_devices = False\n",
                "  no_nested_sharding = False\n",
                "  if global_axis_size is None:\n",
                "    if xb.process_count(backend) == 1:\n",
                "      global_axis_size = axis_size\n",
                "    elif devices:\n",
                "      # This allows each host in a multi-host pmap to run on a different number\n",
                "      # of devices, but precludes nested sharding (i.e. inner pmaps or\n",
                "      # sharded_jits).\n",
                "      global_axis_size = len(devices)\n",
                "      no_nested_sharding = True\n",
                "    else:\n",
                "      # This assumes all hosts run on the same number of devices. We make sure\n",
                "      # this assumption is true by requiring that the pmap is run on all devices\n",
                "      # (and making the further assumption that each host has the same number of\n",
                "      # devices). Nested sharding is ok in this case.\n",
                "      global_axis_size = axis_size * xb.process_count(backend)\n",
                "      assert all(\n",
                "          len(xb.local_devices(process_index, backend)) == xb.local_device_count(backend)\n",
                "          for process_index in range(xb.process_count(backend)))\n",
                "      must_run_on_all_devices = True\n",
                "\n",
                "  pci = ParallelCallableInfo(\n",
                "      name, backend, axis_name, axis_size, global_axis_size, devices,\n",
                "      in_axes, out_axes_thunk, avals)\n",
                "  jaxpr, consts, replicas, parts, shards = stage_parallel_callable(\n",
                "      pci, fun, global_arg_shapes)\n",
                "\n",
                "  if logging.vlog_is_on(2):\n",
                "    logging.vlog(2, \"sharded_avals: %s\", shards.sharded_avals)\n",
                "    logging.vlog(2, \"global_sharded_avals: %s\", shards.global_sharded_avals)\n",
                "    logging.vlog(2, \"num_replicas: %d  num_local_replicas: %d\",\n",
                "                 replicas.num_global_replicas, replicas.num_local_replicas)\n",
                "    logging.vlog(2, \"num_partitions: %d  local_num_partitions: %d\",\n",
                "                 parts.num_partitions, parts.local_num_partitions)\n",
                "    logging.vlog(2, \"arg_parts: %s\", parts.arg_parts)\n",
                "    logging.vlog(2, \"local_arg_parts: %s\", parts.local_arg_parts)\n",
                "    logging.vlog(2, \"out_parts: %s\", parts.out_parts)\n",
                "    logging.vlog(2, \"local_out_parts: %s\", parts.local_out_parts)\n",
                "    logging.vlog(2, \"devices: %s\", devices)\n",
                "    logging.vlog(2, \"local_devices: %s\", pci.local_devices)\n",
                "\n",
                "  if (xb.process_count(backend) > 1 and must_run_on_all_devices and\n",
                "      shards.num_local_shards != xb.local_device_count(backend)):\n",
                "    if shards.num_local_shards == axis_size:\n",
                "      raise ValueError(\n",
                "         f\"On multi-host platforms, the input to pmapped functions must have \"\n",
                "         f\"leading axis size equal to the number of local devices if no \"\n",
                "         f\"`devices` argument is specified. Got axis_size={axis_size}, \"\n",
                "         f\"num_local_devices={xb.local_device_count(backend)}\")\n",
                "    else:\n",
                "      raise ValueError(\n",
                "        f\"On multi-host platforms, pmapped functions must run across all \"\n",
                "        f\"devices, i.e. num_replicas * num_partitions should equal the \"\n",
                "        f\"number of local devices. Got \"\n",
                "        f\"num_replicas={replicas.num_local_replicas}, \"\n",
                "        f\"num_partitions={parts.num_partitions}, and \"\n",
                "        f\"num_local_devices={xb.local_device_count(backend)}\")\n",
                "\n",
                "  if no_nested_sharding and (\n",
                "      replicas.jaxpr_replicas > 1 or parts.num_partitions > 1):\n",
                "    raise ValueError(\n",
                "      f\"On multi-host platforms, pmapped functions that both have `devices` \"\n",
                "      f\"specified and contain an inner_pmap or sharded_jit must specify an \"\n",
                "      f\"`axis_size` (or remove the `devices` argument). Got nested_replicas=\"\n",
                "      f\"{replicas.jaxpr_replicas} and nested_partitions={parts.num_partitions}\")\n",
                "\n",
                "  log_priority = logging.WARNING if config.jax_log_compiles else logging.DEBUG\n",
                "  logging.log(log_priority,\n",
                "              \"Compiling %s (%d) for %d devices with args %s. (num_replicas=%d\"\n",
                "              \" num_partitions=%d)\", fun.__name__, id(fun),\n",
                "              shards.num_global_shards, avals, replicas.num_global_replicas,\n",
                "              parts.num_partitions)\n",
                "\n",
                "  axis_env = xla.AxisEnv(\n",
                "      replicas.num_global_replicas, (axis_name,), (global_axis_size,))\n",
                "  name_stack = new_name_stack(wrap_name(name, 'pmap'))\n",
                "  closed_jaxpr = core.ClosedJaxpr(jaxpr, consts)\n",
                "  replicated_args = [axis is None for axis in in_axes]\n",
                "  module: Union[str, xc.XlaComputation]\n",
                "  tuple_args = should_tuple_args(shards)\n",
                "  module_name = f\"pmap_{fun.__name__}\"\n",
                "  with maybe_extend_axis_env(axis_name, global_axis_size, None):  # type: ignore\n",
                "    if config.jax_enable_mlir:\n",
                "      module = mlir.lower_jaxpr_to_module(\n",
                "          module_name, closed_jaxpr, backend.platform, mlir.ReplicaAxisContext(axis_env),\n",
                "          name_stack, donated_invars, replicated_args=replicated_args,\n",
                "          arg_shardings=_shardings_to_mlir_shardings(parts.arg_parts),\n",
                "          result_shardings=_shardings_to_mlir_shardings(parts.out_parts))\n",
                "    else:\n",
                "      module = xla.lower_jaxpr_to_xla_module(\n",
                "          module_name, closed_jaxpr, backend.platform, axis_env,\n",
                "          name_stack, tuple_args, donated_invars, replicated_args,\n",
                "          parts.arg_parts, parts.out_parts)\n",
                "  return PmapComputation(module, pci=pci, replicas=replicas, parts=parts,\n",
                "                         shards=shards, tuple_args=tuple_args)\n",
                "\n",
                "\n",
                "class PmapComputation:\n",
                "  _hlo: Union[ir.Module, xc.XlaComputation]\n",
                "  def __init__(self, hlo: Union[ir.Module, xc.XlaComputation], **compile_args):\n",
                "    self._executable = None\n",
                "    self._hlo = hlo\n",
                "    self.compile_args = compile_args\n",
                "\n",
                "  def hlo(self):\n",
                "    # this is a method for api consistency with dispatch.XlaComputation\n",
                "    if isinstance(self._hlo, xc.XlaComputation):\n",
                "      return self._hlo\n",
                "    else:\n",
                "      return xe.mlir.mlir_module_to_xla_computation(\n",
                "          mlir.module_to_string(self._hlo),\n",
                "          use_tuple_args=self.compile_args[\"tuple_args\"])\n",
                "\n",
                "  def mhlo(self) -> ir.Module:\n",
                "    if isinstance(self._hlo, xc.XlaComputation):\n",
                "      module_str = xe.mlir.xla_computation_to_mlir_module(self._hlo)\n",
                "      with mlir.make_ir_context():\n",
                "        return ir.Module.parse(module_str)\n",
                "    return self._hlo\n",
                "\n",
                "  @profiler.annotate_function\n",
                "  def compile(self):\n",
                "    if self._executable is None:\n",
                "      self._executable = PmapExecutable.from_hlo(self._hlo, **self.compile_args)\n",
                "    return self._executable\n",
                "\n",
                "\n",
                "class PmapExecutable:\n",
                "  __slots__ = ['xla_executable', 'unsafe_call', 'fingerprint', 'in_avals']\n",
                "\n",
                "  def __init__(self, xla_executable, unsafe_call, fingerprint, in_avals):\n",
                "    self.xla_executable = xla_executable\n",
                "    self.unsafe_call = unsafe_call\n",
                "    self.fingerprint = fingerprint\n",
                "    self.in_avals = in_avals\n",
                "\n",
                "  @staticmethod\n",
                "  def from_hlo(xla_computation,\n",
                "               pci: ParallelCallableInfo,\n",
                "               replicas: ReplicaInfo,\n",
                "               parts: 'PartitionInfo',\n",
                "               shards: ShardInfo,\n",
                "               tuple_args: bool):\n",
                "    devices = pci.devices\n",
                "    if devices is None:\n",
                "      if shards.num_global_shards > xb.device_count(pci.backend):\n",
                "        msg = (\"compiling computation that requires {} logical devices, but only {} XLA \"\n",
                "               \"devices are available (num_replicas={}, num_partitions={})\")\n",
                "        raise ValueError(msg.format(shards.num_global_shards,\n",
                "                                    xb.device_count(pci.backend),\n",
                "                                    replicas.num_global_replicas,\n",
                "                                    parts.num_partitions))\n",
                "      # On a single host, we use the platform's default device assignment to\n",
                "      # potentially take advantage of device locality. On multiple hosts, the\n",
                "      # default device assignment may interleave different hosts' replicas,\n",
                "      # violating pmap's semantics where data is sharded across replicas in\n",
                "      # row-major order. Instead, manually create a device assignment that ensures\n",
                "      # each host is responsible for a continguous set of replicas.\n",
                "      if shards.num_global_shards > shards.num_local_shards:\n",
                "        # TODO(skye): use a locality-aware assignment that satisfies the above\n",
                "        # constraint.\n",
                "        devices = [d for process_index in range(xb.process_count(pci.backend))\n",
                "                  for d in xb.local_devices(process_index, pci.backend)]\n",
                "      else:\n",
                "        devices = xb.get_backend(pci.backend).get_default_device_assignment(\n",
                "            replicas.num_global_replicas, parts.num_partitions)\n",
                "    else:\n",
                "      if shards.num_local_shards != len(pci.local_devices):\n",
                "        local_devices_str = \", \".join(map(str, pci.local_devices))\n",
                "        if shards.num_local_shards == pci.axis_size:\n",
                "          raise ValueError(\n",
                "              f\"Leading axis size of input to pmapped function must equal the \"\n",
                "              f\"number of local devices passed to pmap. Got axis_size=\"\n",
                "              f\"{pci.axis_size}, num_local_devices={len(pci.local_devices)}.\\n\"\n",
                "              f\"(Local devices available to pmap: {local_devices_str})\")\n",
                "        else:\n",
                "          raise ValueError(\n",
                "              f\"pmapped function requires {shards.num_local_shards} local \"\n",
                "              f\"devices to run due to nested pmapped or other parallel \"\n",
                "              f\"functions, but only {len(pci.local_devices)} are available.\\n\"\n",
                "              f\"(outer axis size: {pci.axis_size}, local devices available to \"\n",
                "              f\"pmap: {local_devices_str})\")\n",
                "      if shards.num_global_shards != len(devices):\n",
                "        raise ValueError(\"compiling computation that creates %s shards, \"\n",
                "                        \"but %s devices were specified\" %\n",
                "                        (shards.num_global_shards, len(devices)))\n",
                "\n",
                "    # 'devices' may be 1D or 2D at this point (e.g.\n",
                "    # get_default_device_assignment() returns 2D assignment, caller may have\n",
                "    # provided 1D list of devices).\n",
                "    # Convert to 2D in case it's 1D and we have > 1 partitions.\n",
                "    device_assignment = np.array(devices).reshape(\n",
                "        (replicas.num_global_replicas, parts.num_partitions))\n",
                "    # TODO(b/162356737): Enabling SPMD partitioning causes issues with some\n",
                "    # non-partitioned workloads, so disable unless needed.\n",
                "    use_spmd_partitioning = parts.num_partitions > 1\n",
                "    compile_options = xb.get_compile_options(\n",
                "        num_replicas=replicas.num_global_replicas,\n",
                "        num_partitions=parts.num_partitions,\n",
                "        device_assignment=device_assignment,\n",
                "        use_spmd_partitioning=use_spmd_partitioning,\n",
                "    )\n",
                "    compile_options.parameter_is_tupled_arguments = tuple_args\n",
                "\n",
                "    local_arg_parts_ = parts.local_arg_parts or [None] * len(pci.avals)\n",
                "    input_sharding_specs = [\n",
                "        _pmap_sharding_spec(replicas.num_local_replicas, pci.axis_size,\n",
                "                            parts.local_num_partitions, arg_parts, aval, in_axis)\n",
                "        if aval is not core.abstract_unit else None\n",
                "        for aval, arg_parts, in_axis in safe_zip(\n",
                "            shards.sharded_avals, local_arg_parts_, pci.in_axes)]\n",
                "    input_indices = [spec_to_indices(aval.shape, spec)\n",
                "                    if spec is not None else None\n",
                "                    for aval, spec in safe_zip(pci.avals, input_sharding_specs)]\n",
                "    nouts = len(shards.out_sharded_avals)\n",
                "\n",
                "    out_parts, local_out_parts = parts.out_parts, parts.local_out_parts\n",
                "    if parts.out_parts is None:\n",
                "      out_parts = (None,) * nouts\n",
                "    if parts.local_out_parts is None:\n",
                "      local_out_parts = (None,) * nouts\n",
                "\n",
                "    local_out_avals = [\n",
                "        get_local_aval(aval, parts, lparts)\n",
                "        for aval, parts, lparts\n",
                "        in safe_zip(shards.out_sharded_avals, out_parts, local_out_parts)]\n",
                "    local_unmapped_avals = [\n",
                "        core.unmapped_aval(pci.axis_size, pci.axis_name, out_axis, aval)\n",
                "        if out_axis is not None else aval\n",
                "        for aval, out_axis in safe_zip(local_out_avals, pci.out_axes)]\n",
                "\n",
                "    out_specs = [\n",
                "        _pmap_sharding_spec(replicas.num_local_replicas, pci.axis_size,\n",
                "                            parts.local_num_partitions, out_parts, aval, out_axis)\n",
                "        if aval is not core.abstract_unit else None\n",
                "        for out_parts, aval, out_axis in safe_zip(\n",
                "            local_out_parts, local_out_avals, pci.out_axes)]\n",
                "    handle_outs = local_avals_to_results_handler(out_specs, local_unmapped_avals)\n",
                "\n",
                "    if hasattr(pci.backend, \"compile_replicated\"):\n",
                "      execute_fun = pci.backend.compile_replicated(\n",
                "          xla_computation, compile_options, input_indices, input_sharding_specs,\n",
                "          handle_outs)\n",
                "      # TODO(frostig): need `compile_replicated` to give us the XLA executable\n",
                "      return PmapExecutable(None, execute_fun, None, pci.avals)\n",
                "\n",
                "    with dispatch.log_elapsed_time(\n",
                "        f\"Finished XLA compilation of {pci.name} in {{elapsed_time}} sec\"):\n",
                "      compiled = dispatch.compile_or_get_cached(\n",
                "          pci.backend, xla_computation, compile_options)\n",
                "    handle_args = InputsHandler(\n",
                "        compiled.local_devices(), input_sharding_specs, input_indices)\n",
                "    execute_fun = ExecuteReplicated(compiled, pci.backend, handle_args, handle_outs)\n",
                "    fingerprint = getattr(compiled, \"fingerprint\", None)\n",
                "\n",
                "    return PmapExecutable(compiled, execute_fun, fingerprint, pci.avals)\n",
                "\n",
                "  @profiler.annotate_function\n",
                "  def call(self, *args):\n",
                "    # TODO(frostig): do we need to check sharding and sharded avals?\n",
                "    arg_avals = map(xla.abstractify, args)\n",
                "    dispatch.check_arg_avals_for_call(self.in_avals, arg_avals)\n",
                "    return self.unsafe_call(*args)\n",
                "\n",
                "\n",
                "multi_host_supported_collectives: Set[core.Primitive] = set()\n",
                "\n",
                "\n",
                "def check_multihost_collective_allowlist(jaxpr):\n",
                "  used_collectives = set(xla.jaxpr_collectives(jaxpr))\n",
                "  if not used_collectives.issubset(multi_host_supported_collectives):\n",
                "    bad_collectives = used_collectives - multi_host_supported_collectives\n",
                "    msg = \"using collectives that aren't supported for multi-host: {}\"\n",
                "    raise TypeError(msg.format(\", \".join(map(str, bad_collectives))))\n",
                "\n",
                "\n",
                "PartitionsOrReplicated = Optional[Tuple[int, ...]]\n",
                "\n",
                "class PartitionInfo(NamedTuple):\n",
                "  arg_parts: Optional[Tuple[PartitionsOrReplicated, ...]]\n",
                "  out_parts: Optional[Tuple[PartitionsOrReplicated, ...]]\n",
                "  num_partitions: int\n",
                "  local_arg_parts: Optional[Tuple[PartitionsOrReplicated, ...]]\n",
                "  local_out_parts: Optional[Tuple[PartitionsOrReplicated, ...]]\n",
                "  local_num_partitions: Optional[int]\n",
                "\n",
                "def _find_partitions(jaxpr):\n",
                "  \"\"\"Returns (in_partitions, out_partitions, num_partitions, local_in_parts,\n",
                "              local_out_parts, local_num_partitions).\n",
                "  \"\"\"\n",
                "  for eqn in jaxpr.eqns:\n",
                "    if eqn.primitive.name == \"sharded_call\":\n",
                "      if len(jaxpr.eqns) > 1:\n",
                "        raise NotImplementedError(\n",
                "            \"pmap of sharded_jit + non-sharded operations not yet implemented.\")\n",
                "      num_partitions = reconcile_num_partitions(eqn.params[\"call_jaxpr\"],\n",
                "                                                eqn.params[\"nparts\"])\n",
                "      return (eqn.params[\"in_parts\"],\n",
                "              eqn.params[\"out_parts_thunk\"](),\n",
                "              num_partitions,\n",
                "              eqn.params[\"local_in_parts\"],\n",
                "              eqn.params[\"local_out_parts_thunk\"](),\n",
                "              eqn.params[\"local_nparts\"])\n",
                "  return None, None, 1, None, None, None\n",
                "\n",
                "def find_partitions(jaxpr) -> PartitionInfo:\n",
                "  (arg_parts, out_parts, num_partitions, local_arg_parts, local_out_parts,\n",
                "   local_num_partitions) = _find_partitions(jaxpr)\n",
                "\n",
                "  if local_num_partitions is None:\n",
                "    local_num_partitions = num_partitions\n",
                "  if local_arg_parts is None:\n",
                "    local_arg_parts = arg_parts\n",
                "  if local_out_parts is None:\n",
                "    local_out_parts = out_parts\n",
                "\n",
                "  return PartitionInfo(arg_parts, out_parts, num_partitions,\n",
                "                       local_arg_parts, local_out_parts, local_num_partitions)\n",
                "\n",
                "\n",
                "def reconcile_num_partitions(jaxpr, outer_num_parts: Optional[int]):\n",
                "  \"\"\"Returns the total number of partitions to use.\n",
                "\n",
                "  Validates that any inner partitioning matches outer_num_parts if provided, and\n",
                "  returns the number of partitions to use based on outer_num_parts and any inner\n",
                "  partitioning.\n",
                "  \"\"\"\n",
                "  inner_num_parts = _inner_partitions(jaxpr, outer_num_parts)\n",
                "  if outer_num_parts is None and inner_num_parts is None:\n",
                "    # No partitions specified anywhere, everything is replicated.\n",
                "    return 1\n",
                "  if outer_num_parts is None:\n",
                "    return inner_num_parts\n",
                "  return outer_num_parts\n",
                "\n",
                "\n",
                "def _inner_partitions(jaxpr, expected_num_parts: Optional[int]):\n",
                "  \"\"\"Returns the total number of partitions from PartitionSpecs inside `jaxpr`.\n",
                "\n",
                "  Also validates that this number matches `expected_num_parts` if provided.\n",
                "  \"\"\"\n",
                "  for eqn in jaxpr.eqns:\n",
                "    if eqn.primitive.name in [\"sharding_constraint\", \"infeed\"]:\n",
                "      parts = eqn.params[\"partitions\"]\n",
                "      nparts = get_num_partitions(parts)\n",
                "      if expected_num_parts is None:\n",
                "        expected_num_parts = nparts\n",
                "      elif nparts is not None and nparts != expected_num_parts:\n",
                "        # TODO(skye): raise this error as we trace the jaxpr\n",
                "        raise ValueError(\n",
                "            f\"with_sharding_constraint with partitions={parts} \"\n",
                "            f\"(total partitions: {nparts}) doesn't match expected number of \"\n",
                "            f\"partitions: {expected_num_parts}. If these partitions look \"\n",
                "            f\"right, check outer sharded_jit and/or other \"\n",
                "            f\"with_sharding_constraint calls.\")\n",
                "    else:\n",
                "      for subjaxpr in core.jaxprs_in_params(eqn.params):\n",
                "        expected_num_parts = _inner_partitions(subjaxpr, expected_num_parts)\n",
                "  return expected_num_parts\n",
                "\n",
                "\n",
                "def get_num_partitions(*partitions):\n",
                "  partition_specs = tree_flatten(partitions)[0]\n",
                "  if len(partition_specs) == 0:\n",
                "    # Everything is specified as replicated (all Nones).\n",
                "    return None\n",
                "  num_partitions_set = {np.prod(spec) for spec in partition_specs}\n",
                "  if len(num_partitions_set) > 1:\n",
                "    raise ValueError(\n",
                "        f\"All partition specs must use the same number of total partitions, \"\n",
                "        f\"got {partitions}, with distinct number of partitions \"\n",
                "        f\"{num_partitions_set} (the total number of partitions is the product \"\n",
                "        f\"of a partition spec)\")\n",
                "  assert len(num_partitions_set) == 1\n",
                "  return num_partitions_set.pop()\n",
                "\n",
                "\n",
                "def get_global_aval(local_aval, global_parts: PartitionsOrReplicated,\n",
                "                    local_parts: PartitionsOrReplicated):\n",
                "  if local_aval is core.abstract_unit:\n",
                "    return local_aval\n",
                "  if global_parts is None:\n",
                "    return local_aval\n",
                "  assert local_parts is not None\n",
                "  global_shape = [dim * _safe_div(ngparts, nlparts)\n",
                "                  for dim, ngparts, nlparts\n",
                "                  in safe_zip(local_aval.shape, global_parts, local_parts)]\n",
                "  return local_aval.update(shape=global_shape)\n",
                "\n",
                "\n",
                "def get_local_aval(global_aval, global_parts: PartitionsOrReplicated,\n",
                "                   local_parts: PartitionsOrReplicated):\n",
                "  if global_aval is core.abstract_unit:\n",
                "    return global_aval\n",
                "  if global_parts is None:\n",
                "    return global_aval\n",
                "  assert local_parts is not None\n",
                "  local_shape = [_safe_div(dim, _safe_div(ngparts, nlparts))\n",
                "                 for dim, ngparts, nlparts\n",
                "                 in safe_zip(global_aval.shape, global_parts, local_parts)]\n",
                "  return global_aval.update(shape=local_shape)\n",
                "\n",
                "\n",
                "def _safe_div(x, y):\n",
                "  result, ragged = divmod(x, y)\n",
                "  assert not ragged, f\"{x} % {y} != 0\"\n",
                "  return result\n",
                "\n",
                "\n",
                "class InputsHandler:\n",
                "  __slots__ = (\"handler\", \"local_devices\", \"sharding_specs\", \"input_indices\")\n",
                "\n",
                "  def __init__(self, local_devices, sharding_specs, input_indices):\n",
                "    self.handler = partial(shard_args, local_devices, input_indices)\n",
                "    self.local_devices = local_devices\n",
                "    self.sharding_specs = sharding_specs\n",
                "    self.input_indices = input_indices\n",
                "\n",
                "  def __call__(self, input_buffers):\n",
                "    return self.handler(input_buffers)\n",
                "\n",
                "  def __str__(self):\n",
                "    return (\"InputsHandler(\\n\"\n",
                "            f\"local_devices={self.local_devices},\\n\"\n",
                "            f\"sharding_specs={self.sharding_specs},\\n\"\n",
                "            f\"input_indices={self.input_indices})\")\n",
                "\n",
                "\n",
                "class ResultsHandler:\n"
            ],
            {
                "type": "replace",
                "before": [
                    "  __slots__ = (\"handlers\", \"out_specs\", \"out_indices\", \"unmapped_local_out_avals\")\n"
                ],
                "after": [
                    "  __slots__ = (\"handlers\", \"out_specs\", \"out_indices\", \"out_avals\")\n"
                ],
                "parent_version_range": {
                    "start": 1394,
                    "end": 1395
                },
                "child_version_range": {
                    "start": 1394,
                    "end": 1395
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "ResultsHandler",
                        "signature": "class ResultsHandler:",
                        "at_line": 1393
                    }
                ],
                "idx": 1,
                "hunk_diff": "File: jax/interpreters/pxla.py\nCode:\n1391 1391    \n1392 1392    \n1393 1393    class ResultsHandler:\n1394       -   __slots__ = (\"handlers\", \"out_specs\", \"out_indices\", \"unmapped_local_out_avals\")\n     1394  +   __slots__ = (\"handlers\", \"out_specs\", \"out_indices\", \"out_avals\")\n1395 1395    \n           ...\n",
                "file_path": "jax/interpreters/pxla.py",
                "identifiers_before": [
                    "__slots__"
                ],
                "identifiers_after": [
                    "__slots__"
                ],
                "prefix": [
                    "\n",
                    "\n",
                    "class ResultsHandler:\n"
                ],
                "suffix": [
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    0
                ]
            },
            [
                "\n"
            ],
            {
                "type": "replace",
                "before": [
                    "  def __init__(self, handlers, out_specs, out_indices, unmapped_local_out_avals):\n"
                ],
                "after": [
                    "  def __init__(self, handlers, out_specs, out_indices, out_avals):\n",
                    "    self.handlers = handlers\n"
                ],
                "parent_version_range": {
                    "start": 1396,
                    "end": 1397
                },
                "child_version_range": {
                    "start": 1396,
                    "end": 1398
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "ResultsHandler",
                        "signature": "class ResultsHandler:",
                        "at_line": 1393
                    },
                    {
                        "type": "function",
                        "name": "__init__",
                        "signature": "def __init__(self, handlers, out_specs, out_indices, unmapped_local_out_avals):",
                        "at_line": 1396
                    }
                ],
                "idx": 2,
                "hunk_diff": "File: jax/interpreters/pxla.py\nCode:\n             class ResultsHandler:\n                 ...\n1395 1395    \n1396       -   def __init__(self, handlers, out_specs, out_indices, unmapped_local_out_avals):\n     1396  +   def __init__(self, handlers, out_specs, out_indices, out_avals):\n     1397  +     self.handlers = handlers\n1397 1398        self.out_specs = out_specs\n1398 1399        self.out_indices = out_indices\n           ...\n",
                "file_path": "jax/interpreters/pxla.py",
                "identifiers_before": [
                    "__init__",
                    "handlers",
                    "out_indices",
                    "out_specs",
                    "self",
                    "unmapped_local_out_avals"
                ],
                "identifiers_after": [
                    "__init__",
                    "handlers",
                    "out_avals",
                    "out_indices",
                    "out_specs",
                    "self"
                ],
                "prefix": [
                    "\n"
                ],
                "suffix": [
                    "    self.out_specs = out_specs\n",
                    "    self.out_indices = out_indices\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "self",
                            "position": {
                                "start": {
                                    "line": 1396,
                                    "column": 15
                                },
                                "end": {
                                    "line": 1396,
                                    "column": 19
                                }
                            },
                            "type": "identifier",
                            "kind": "parameter",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "self",
                            "position": {
                                "start": {
                                    "line": 1396,
                                    "column": 15
                                },
                                "end": {
                                    "line": 1396,
                                    "column": 19
                                }
                            },
                            "type": "identifier",
                            "kind": "parameter",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "handlers",
                            "position": {
                                "start": {
                                    "line": 1396,
                                    "column": 21
                                },
                                "end": {
                                    "line": 1396,
                                    "column": 29
                                }
                            },
                            "type": "identifier",
                            "kind": "parameter",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "unmapped_local_out_avals",
                            "position": {
                                "start": {
                                    "line": 1396,
                                    "column": 55
                                },
                                "end": {
                                    "line": 1396,
                                    "column": 79
                                }
                            },
                            "type": "identifier",
                            "kind": "parameter",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_callee": [],
                "head_dependency_caller": [
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "self",
                            "position": {
                                "start": {
                                    "line": 1396,
                                    "column": 15
                                },
                                "end": {
                                    "line": 1396,
                                    "column": 19
                                }
                            },
                            "type": "identifier",
                            "kind": "parameter",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "out_avals",
                            "position": {
                                "start": {
                                    "line": 1396,
                                    "column": 55
                                },
                                "end": {
                                    "line": 1396,
                                    "column": 64
                                }
                            },
                            "type": "identifier",
                            "kind": "parameter",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    }
                ],
                "other_clones": []
            },
            [
                "    self.out_specs = out_specs\n",
                "    self.out_indices = out_indices\n"
            ],
            {
                "type": "replace",
                "before": [
                    "    self.handlers = handlers\n",
                    "    self.unmapped_local_out_avals = unmapped_local_out_avals\n"
                ],
                "after": [
                    "    self.out_avals = out_avals\n"
                ],
                "parent_version_range": {
                    "start": 1399,
                    "end": 1401
                },
                "child_version_range": {
                    "start": 1400,
                    "end": 1401
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "ResultsHandler",
                        "signature": "class ResultsHandler:",
                        "at_line": 1393
                    },
                    {
                        "type": "function",
                        "name": "__init__",
                        "signature": "def __init__(self, handlers, out_specs, out_indices, unmapped_local_out_avals):",
                        "at_line": 1396
                    }
                ],
                "idx": 3,
                "hunk_diff": "File: jax/interpreters/pxla.py\nCode:\n             class ResultsHandler:\n                 ...\n                 def __init__(self, handlers, out_specs, out_indices, unmapped_local_out_avals):\n                     ...\n1397 1398        self.out_specs = out_specs\n1398 1399        self.out_indices = out_indices\n1399       -     self.handlers = handlers\n1400       -     self.unmapped_local_out_avals = unmapped_local_out_avals\n     1400  +     self.out_avals = out_avals\n1401 1401    \n1402 1402      def __call__(self, out_bufs):\n1403 1403        return [h(bufs) for h, bufs in safe_zip(self.handlers, out_bufs)]\n           ...\n",
                "file_path": "jax/interpreters/pxla.py",
                "identifiers_before": [
                    "handlers",
                    "self",
                    "unmapped_local_out_avals"
                ],
                "identifiers_after": [
                    "out_avals",
                    "self"
                ],
                "prefix": [
                    "    self.out_specs = out_specs\n",
                    "    self.out_indices = out_indices\n"
                ],
                "suffix": [
                    "\n",
                    "  def __call__(self, out_bufs):\n",
                    "    return [h(bufs) for h, bufs in safe_zip(self.handlers, out_bufs)]\n"
                ],
                "base_dependency_callee": [
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "self",
                            "position": {
                                "start": {
                                    "line": 1399,
                                    "column": 4
                                },
                                "end": {
                                    "line": 1399,
                                    "column": 8
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "self",
                            "position": {
                                "start": {
                                    "line": 1400,
                                    "column": 4
                                },
                                "end": {
                                    "line": 1400,
                                    "column": 8
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "handlers",
                            "position": {
                                "start": {
                                    "line": 1399,
                                    "column": 20
                                },
                                "end": {
                                    "line": 1399,
                                    "column": 28
                                }
                            },
                            "type": "identifier",
                            "kind": "variable",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "unmapped_local_out_avals",
                            "position": {
                                "start": {
                                    "line": 1400,
                                    "column": 36
                                },
                                "end": {
                                    "line": 1400,
                                    "column": 60
                                }
                            },
                            "type": "identifier",
                            "kind": "variable",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    }
                ],
                "base_dependency_caller": [],
                "head_dependency_callee": [
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "self",
                            "position": {
                                "start": {
                                    "line": 1400,
                                    "column": 4
                                },
                                "end": {
                                    "line": 1400,
                                    "column": 8
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "out_avals",
                            "position": {
                                "start": {
                                    "line": 1400,
                                    "column": 21
                                },
                                "end": {
                                    "line": 1400,
                                    "column": 30
                                }
                            },
                            "type": "identifier",
                            "kind": "variable",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "\n",
                "  def __call__(self, out_bufs):\n",
                "    return [h(bufs) for h, bufs in safe_zip(self.handlers, out_bufs)]\n",
                "\n",
                "\n",
                "def local_avals_to_results_handler(\n",
                "    local_out_specs: Sequence[Optional[ShardingSpec]],\n",
                "    unmapped_local_out_avals: Sequence[Optional[ShapedArray]]):\n",
                "  out_indices = [spec_to_indices(aval.shape, spec)\n",
                "                 if aval is not core.abstract_unit else None\n",
                "                 for aval, spec in safe_zip(unmapped_local_out_avals, local_out_specs)]  # pytype: disable=attribute-error\n",
                "  handlers = [\n",
                "      local_aval_to_result_handler(aval, spec, idcs)\n",
                "      for aval, spec, idcs in safe_zip(unmapped_local_out_avals, local_out_specs, out_indices)\n",
                "  ]\n",
                "  return ResultsHandler(handlers, local_out_specs, out_indices, unmapped_local_out_avals)\n",
                "\n",
                "\n",
                "def global_avals_to_results_handler(global_out_avals: Sequence[ShapedArray],\n",
                "                                    out_axes: Sequence[ArrayMapping],\n",
                "                                    global_mesh):\n",
                "  if config.jax_parallel_functions_output_gda:\n",
                "    global_sharding_spec = mesh_sharding_specs(global_mesh.shape, global_mesh.axis_names)\n",
                "    global_out_specs = [global_sharding_spec(aval, oa)\n",
                "                        for aval, oa in safe_zip(global_out_avals, out_axes)]\n"
            ],
            {
                "type": "replace",
                "before": [
                    "    out_indices = [spec_to_indices(aval.shape, spec)\n"
                ],
                "after": [
                    "    global_out_indices = [spec_to_indices(aval.shape, spec)\n"
                ],
                "parent_version_range": {
                    "start": 1426,
                    "end": 1427
                },
                "child_version_range": {
                    "start": 1426,
                    "end": 1427
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if config.jax_parallel_functions_output_gda:",
                        "start_line": 1422,
                        "end_line": 1442
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "global_avals_to_results_handler",
                        "signature": "def global_avals_to_results_handler(global_out_avals: Sequence[ShapedArray],\n                                    out_axes: Sequence[ArrayMapping],\n                                    global_mesh):",
                        "at_line": 1419
                    }
                ],
                "idx": 4,
                "hunk_diff": "File: jax/interpreters/pxla.py\nCode:\n             def global_avals_to_results_handler(global_out_avals: Sequence[ShapedArray],\n                                    out_axes: Sequence[ArrayMapping],\n                                    global_mesh):\n                 ...\n1423 1423        global_sharding_spec = mesh_sharding_specs(global_mesh.shape, global_mesh.axis_names)\n1424 1424        global_out_specs = [global_sharding_spec(aval, oa)\n1425 1425                            for aval, oa in safe_zip(global_out_avals, out_axes)]\n1426       -     out_indices = [spec_to_indices(aval.shape, spec)\n     1426  +     global_out_indices = [spec_to_indices(aval.shape, spec)\n1427 1427                       if aval is not core.abstract_unit else None\n1428 1428                       for aval, spec in safe_zip(global_out_avals, global_out_specs)]\n1429 1429        out_axis_resources = [array_mapping_to_axis_resources(o) for o in out_axes]\n           ...\n",
                "file_path": "jax/interpreters/pxla.py",
                "identifiers_before": [
                    "aval",
                    "out_indices",
                    "shape",
                    "spec",
                    "spec_to_indices"
                ],
                "identifiers_after": [
                    "aval",
                    "global_out_indices",
                    "shape",
                    "spec",
                    "spec_to_indices"
                ],
                "prefix": [
                    "    global_sharding_spec = mesh_sharding_specs(global_mesh.shape, global_mesh.axis_names)\n",
                    "    global_out_specs = [global_sharding_spec(aval, oa)\n",
                    "                        for aval, oa in safe_zip(global_out_avals, out_axes)]\n"
                ],
                "suffix": [
                    "                   if aval is not core.abstract_unit else None\n",
                    "                   for aval, spec in safe_zip(global_out_avals, global_out_specs)]\n",
                    "    out_axis_resources = [array_mapping_to_axis_resources(o) for o in out_axes]\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [
                    {
                        "to_hunk_idx": 5,
                        "detail": {
                            "identifier": "out_indices",
                            "position": {
                                "start": {
                                    "line": 1426,
                                    "column": 4
                                },
                                "end": {
                                    "line": 1426,
                                    "column": 15
                                }
                            },
                            "type": "identifier",
                            "kind": "variable",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_callee": [],
                "head_dependency_caller": [
                    {
                        "to_hunk_idx": 5,
                        "detail": {
                            "identifier": "global_out_indices",
                            "position": {
                                "start": {
                                    "line": 1426,
                                    "column": 4
                                },
                                "end": {
                                    "line": 1426,
                                    "column": 22
                                }
                            },
                            "type": "identifier",
                            "kind": "variable",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    }
                ],
                "other_clones": [
                    5
                ]
            },
            [
                "                   if aval is not core.abstract_unit else None\n",
                "                   for aval, spec in safe_zip(global_out_avals, global_out_specs)]\n",
                "    out_axis_resources = [array_mapping_to_axis_resources(o) for o in out_axes]\n",
                "    handlers = [\n",
                "        global_aval_to_result_handler(global_aval, out_axis, global_mesh)\n",
                "        for global_aval, out_axis in safe_zip(global_out_avals, out_axis_resources)\n",
                "    ]\n"
            ],
            {
                "type": "replace",
                "before": [
                    "    return ResultsHandler(handlers, global_out_specs, out_indices, global_out_avals)\n"
                ],
                "after": [
                    "    return ResultsHandler(handlers, global_out_specs, global_out_indices,\n",
                    "                          global_out_avals)\n"
                ],
                "parent_version_range": {
                    "start": 1434,
                    "end": 1435
                },
                "child_version_range": {
                    "start": 1434,
                    "end": 1436
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if config.jax_parallel_functions_output_gda:",
                        "start_line": 1422,
                        "end_line": 1442
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "global_avals_to_results_handler",
                        "signature": "def global_avals_to_results_handler(global_out_avals: Sequence[ShapedArray],\n                                    out_axes: Sequence[ArrayMapping],\n                                    global_mesh):",
                        "at_line": 1419
                    }
                ],
                "idx": 5,
                "hunk_diff": "File: jax/interpreters/pxla.py\nCode:\n             def global_avals_to_results_handler(global_out_avals: Sequence[ShapedArray],\n                                    out_axes: Sequence[ArrayMapping],\n                                    global_mesh):\n                 ...\n1431 1431            global_aval_to_result_handler(global_aval, out_axis, global_mesh)\n1432 1432            for global_aval, out_axis in safe_zip(global_out_avals, out_axis_resources)\n1433 1433        ]\n1434       -     return ResultsHandler(handlers, global_out_specs, out_indices, global_out_avals)\n     1434  +     return ResultsHandler(handlers, global_out_specs, global_out_indices,\n     1435  +                           global_out_avals)\n1435 1436      else:\n1436 1437        local_sharding_spec = mesh_sharding_specs(global_mesh.local_mesh.shape, global_mesh.axis_names)\n1437 1438        local_out_untiled_avals = [global_mesh._global_to_local(axis, aval)\n           ...\n",
                "file_path": "jax/interpreters/pxla.py",
                "identifiers_before": [
                    "ResultsHandler",
                    "global_out_avals",
                    "global_out_specs",
                    "handlers",
                    "out_indices"
                ],
                "identifiers_after": [
                    "ResultsHandler",
                    "global_out_avals",
                    "global_out_indices",
                    "global_out_specs",
                    "handlers"
                ],
                "prefix": [
                    "        global_aval_to_result_handler(global_aval, out_axis, global_mesh)\n",
                    "        for global_aval, out_axis in safe_zip(global_out_avals, out_axis_resources)\n",
                    "    ]\n"
                ],
                "suffix": [
                    "  else:\n",
                    "    local_sharding_spec = mesh_sharding_specs(global_mesh.local_mesh.shape, global_mesh.axis_names)\n",
                    "    local_out_untiled_avals = [global_mesh._global_to_local(axis, aval)\n"
                ],
                "base_dependency_callee": [
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "out_indices",
                            "position": {
                                "start": {
                                    "line": 1434,
                                    "column": 54
                                },
                                "end": {
                                    "line": 1434,
                                    "column": 65
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 5,
                            "dependency_checked": true
                        }
                    }
                ],
                "base_dependency_caller": [],
                "head_dependency_callee": [
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "global_out_indices",
                            "position": {
                                "start": {
                                    "line": 1434,
                                    "column": 54
                                },
                                "end": {
                                    "line": 1434,
                                    "column": 72
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/jax/jax/interpreters/pxla.py",
                            "hunk_idx": 5,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_caller": [],
                "other_clones": [
                    4
                ]
            },
            [
                "  else:\n",
                "    local_sharding_spec = mesh_sharding_specs(global_mesh.local_mesh.shape, global_mesh.axis_names)\n",
                "    local_out_untiled_avals = [global_mesh._global_to_local(axis, aval)\n",
                "                               for axis, aval in safe_zip(out_axes, global_out_avals)]\n",
                "    local_out_specs = [local_sharding_spec(aval, oa)\n",
                "                       for aval, oa in safe_zip(local_out_untiled_avals, out_axes)]\n",
                "    return local_avals_to_results_handler(\n",
                "        local_out_specs, local_out_untiled_avals)\n",
                "\n",
                "\n",
                "@profiler.annotate_function\n",
                "def replicate(val, axis_size, nrep, devices=None, backend=None, in_axis=0):\n",
                "  \"\"\"Replicates ``val`` across multiple devices.\n",
                "\n",
                "  Args:\n",
                "    val: the value to be replicated.\n",
                "    axis_size: the length of the output, i.e. the logical number of replicas to\n",
                "    create. Usually equal to `nrep`, but in the case of nested pmaps, `nrep` may\n",
                "    be a multiple of `axis_size`.\n",
                "    nrep: the number of replicas to create. If ``devices`` is set, must be equal\n",
                "      to ``len(devices)``.\n",
                "    devices: the devices to replicate across. If None, ``nrep`` will be used to\n",
                "      generate a default device assignment.\n",
                "    backend: string specifying which backend to use.\n",
                "    in_axis: axis along which the value is to be replciated.\n",
                "\n",
                "  Returns:\n",
                "    A ShardedDeviceArray of length `axis_size` where each shard is equal to\n",
                "    ``val``.\n",
                "  \"\"\"\n",
                "  device_count = (len(devices) if devices else xb.local_device_count(backend))\n",
                "  if nrep > device_count:\n",
                "    msg = (\"Cannot replicate across %d replicas because only %d local devices \"\n",
                "           \"are available.\" % (nrep, device_count))\n",
                "    if devices:\n",
                "      msg += (\" (local devices = %s)\"\n",
                "              % \", \".join(map(str, devices)) if devices else str(None))\n",
                "    raise ValueError(msg)\n",
                "\n",
                "  if devices is None:\n",
                "    assert nrep is not None\n",
                "    # TODO(skye): use different device assignment on multihost\n",
                "    devices = xb.get_backend(backend).get_default_device_assignment(nrep)\n",
                "  assert nrep == len(devices)\n",
                "\n",
                "  aval = xla.abstractify(val)  # type: ShapedArray\n",
                "  if in_axis is not None:\n",
                "    replicated_aval = aval.update(shape=(axis_size,) + aval.shape)\n",
                "  else:\n",
                "    replicated_aval = aval\n",
                "  # TODO(skye): figure out how partitioning should work here\n",
                "  sharding_spec = _pmap_sharding_spec(nrep, axis_size, 1, None, aval, in_axis)\n",
                "  device_buffers = device_put(val, devices, replicate=True)\n",
                "  return make_sharded_device_array(replicated_aval, sharding_spec,\n",
                "                                   device_buffers)\n",
                "\n",
                "\n",
                "def _pmap_sharding_spec(nrep, axis_size, npart, parts, sharded_aval,\n",
                "                        map_axis: Optional[int]) -> ShardingSpec:\n",
                "  \"\"\"Sharding spec for arguments or results of a pmap.\n",
                "  Args:\n",
                "    nrep: number of local XLA replicas (product of local axis sizes)\n",
                "    axis_size: local axis size for outer pmap\n",
                "    npart: total number of XLA partitions (required by sharded_jit calls)\n",
                "    parts: the partitioning of the value or None\n",
                "    sharded_aval: the aval of the value inside the outer pmap, an instance of\n",
                "      a ShapedArray.\n",
                "    map_axis: the axis along which the value is mapped in the outer pmap\n",
                "  Returns:\n",
                "    A ShardingSpec.\n",
                "  \"\"\"\n",
                "  assert isinstance(sharded_aval, ShapedArray), sharded_aval\n",
                "  replication_factor, ragged = divmod(nrep, axis_size)\n",
                "  assert not ragged\n",
                "  # get the sharding spec from inner sharded_jits as if we weren't in a pmap\n",
                "  pspec = partitioned_sharding_spec(npart, parts, sharded_aval)\n",
                "  maybe_replicate = () if replication_factor == 1 else (Replicated(replication_factor),)\n",
                "  if map_axis is not None:\n",
                "    sharded_in_axis = sum(not isinstance(s, NoSharding) for s in pspec.sharding[:map_axis])\n",
                "    def shift_sharded_axis(a: MeshDimAssignment):\n",
                "      if isinstance(a, ShardedAxis) and a.axis >= sharded_in_axis:\n",
                "        return ShardedAxis(a.axis + 1)\n",
                "      return a\n",
                "    # replication_factor represents the product of inner pmaps, so it goes\n",
                "    # after the outer pmapped axis at index 0\n",
                "    return ShardingSpec(\n",
                "      sharding=tuple_insert(pspec.sharding, map_axis, Unstacked(axis_size)),\n",
                "      mesh_mapping=it.chain([ShardedAxis(sharded_in_axis)],\n",
                "                            maybe_replicate,\n",
                "                            map(shift_sharded_axis, pspec.mesh_mapping)))\n",
                "  else:\n",
                "    return ShardingSpec(\n",
                "      sharding=pspec.sharding,\n",
                "      mesh_mapping=(Replicated(axis_size),) + maybe_replicate + pspec.mesh_mapping)\n",
                "\n",
                "def partitioned_sharding_spec(num_partitions: int,\n",
                "                              partitions: Optional[Sequence[int]],\n",
                "                              aval) -> ShardingSpec:\n",
                "  if partitions is None:\n",
                "    maybe_replicate = () if num_partitions == 1 else (Replicated(num_partitions),)\n",
                "    return ShardingSpec(\n",
                "        sharding=[_UNSHARDED_INSTANCE] * len(aval.shape),\n",
                "        mesh_mapping=maybe_replicate)\n",
                "  else:\n",
                "    assert len(partitions) == len(aval.shape)\n",
                "    return ShardingSpec(\n",
                "        # Chunked expects a list of integers\n",
                "        sharding=map(Chunked, [[x] for x in partitions]),\n",
                "        mesh_mapping=map(ShardedAxis, range(len(partitions))))\n",
                "\n",
                "\n",
                "class ExecuteReplicated:\n",
                "  \"\"\"The logic to shard inputs, execute a replicated model, returning outputs.\"\"\"\n",
                "  __slots__ = ['xla_executable', 'backend', 'in_handler', 'out_handler']\n",
                "\n",
                "  def __init__(self, xla_executable, backend, in_handler: InputsHandler,\n",
                "               out_handler: ResultsHandler):\n",
                "    self.xla_executable = xla_executable\n",
                "    self.backend = backend\n",
                "    self.in_handler = in_handler\n",
                "    self.out_handler = out_handler\n",
                "\n",
                "  @profiler.annotate_function\n",
                "  def __call__(self, *args):\n",
                "    input_bufs = self.in_handler(args)\n",
                "    out_bufs = self.xla_executable.execute_sharded_on_local_devices(input_bufs)\n",
                "    if dispatch.needs_check_special():\n",
                "      for bufs in out_bufs:\n",
                "        dispatch.check_special(\"parallel computation\", bufs)\n",
                "    return self.out_handler(out_bufs)\n",
                "\n",
                "\n",
                "xla_pmap_p = core.MapPrimitive('xla_pmap')\n",
                "xla_pmap = xla_pmap_p.bind\n",
                "xla_pmap_p.def_impl(xla_pmap_impl)\n",
                "\n",
                "# Set param update handlers to update `donated_invars` just like xla_call_p\n",
                "pe.call_param_updaters[xla_pmap_p] = pe.call_param_updaters[xla.xla_call_p]\n",
                "pe.partial_eval_jaxpr_custom_rules[xla_pmap_p] = \\\n",
                "    partial(pe.partial_eval_jaxpr_custom_rule_not_implemented, 'pmap')\n",
                "ad.call_param_updaters[xla_pmap_p] = ad.call_param_updaters[xla.xla_call_p]\n",
                "ad.call_transpose_param_updaters[xla_pmap_p] = \\\n",
                "    ad.call_transpose_param_updaters[xla.xla_call_p]\n",
                "\n",
                "def _pmap_translation_rule(ctx, avals_in, avals_out, *in_nodes,\n",
                "                           axis_name, axis_size,\n",
                "                           global_axis_size, devices, name,\n",
                "                           call_jaxpr, backend=None, in_axes, out_axes,\n",
                "                           donated_invars, global_arg_shapes):\n",
                "  del donated_invars  # Unused.\n",
                "  xla.check_backend_matches(backend, ctx.platform)\n",
                "  # We in-line here rather than generating a Call HLO as in the xla_call\n",
                "  # translation rule just because the extra tuple stuff is a pain.\n",
                "  if ctx.axis_env.names and devices is not None:\n",
                "    raise ValueError(\"Nested pmap with explicit devices argument.\")\n",
                "  if global_axis_size is None:\n",
                "    global_axis_size = axis_size\n",
                "  new_env = xla.extend_axis_env(ctx.axis_env, axis_name, global_axis_size)\n",
                "  # Shard the in_nodes that are mapped\n",
                "  in_avals = [v.aval for v in call_jaxpr.invars]\n",
                "  in_nodes_sharded = (\n",
                "      _xla_shard(ctx.builder, aval, new_env, in_node, in_axis)\n",
                "      if in_axis is not None else in_node\n",
                "      for aval, in_node, in_axis in safe_zip(in_avals, in_nodes, in_axes))\n",
                "\n",
                "  with maybe_extend_axis_env(axis_name, global_axis_size, None):  # type: ignore\n",
                "    sub_ctx = ctx.replace(\n",
                "        axis_env=new_env,\n",
                "        name_stack=extend_name_stack(ctx.name_stack, wrap_name(name, 'pmap')))\n",
                "    sharded_outs = xla.jaxpr_subcomp(sub_ctx, call_jaxpr, (), *in_nodes_sharded)\n",
                "  out_avals = [v.aval for v in call_jaxpr.outvars]\n",
                "  outs = [_xla_unshard(ctx.builder, aval, new_env, out_axis, shard,\n",
                "                       backend=backend)\n",
                "          for aval, out_axis, shard in safe_zip(out_avals, out_axes, sharded_outs)]\n",
                "  return outs\n",
                "\n",
                "xla.register_translation(xla_pmap_p, _pmap_translation_rule)\n",
                "ad.primitive_transposes[xla_pmap_p] = partial(ad.map_transpose, xla_pmap_p)\n",
                "\n",
                "def _xla_shard(c, aval, axis_env, x, in_axis):\n",
                "  if aval is core.abstract_unit:\n",
                "    return x\n",
                "  elif aval is core.abstract_token:\n",
                "    return x\n",
                "  elif isinstance(aval, ShapedArray):\n",
                "    dims = list(c.get_shape(x).dimensions())\n",
                "    zero = xops.Constant(c, np.zeros((), dtype=np.uint32))\n",
                "    idxs = [zero] * (len(dims) - 1)\n",
                "    idxs.insert(in_axis, _unravel_index(c, axis_env))\n",
                "    dims_unsqueezed = dims.copy()\n",
                "    dims_unsqueezed[in_axis] = 1\n",
                "    dims_squeezed = dims.copy()\n",
                "    dims_squeezed.pop(in_axis)\n",
                "    return xops.Reshape(xops.DynamicSlice(x, idxs, dims_unsqueezed), dims_squeezed)\n",
                "  else:\n",
                "    raise TypeError((aval, c.get_shape(x)))\n",
                "\n",
                "# TODO(b/110096942): more efficient gather\n",
                "def _xla_unshard(c, aval, axis_env, out_axis, x, backend):\n",
                "  if aval is core.abstract_unit:\n",
                "    return x\n",
                "  elif aval is core.abstract_token:\n",
                "    return x\n",
                "  elif isinstance(aval, ShapedArray):\n",
                "    # TODO(mattjj): remove this logic when AllReduce PRED supported on CPU / GPU\n",
                "    convert_bool = (np.issubdtype(aval.dtype, np.bool_)\n",
                "                    and xb.get_backend(backend).platform in ('cpu', 'gpu'))\n",
                "    if convert_bool:\n",
                "      x = xops.ConvertElementType(\n",
                "          x, xla.dtype_to_primitive_type(np.dtype(np.float32)))\n",
                "\n",
                "    xla_shape = c.get_shape(x)\n",
                "    dims = list(xla_shape.dimensions())\n",
                "    padded = xops.Broadcast(\n",
                "        xops.Constant(c, np.array(0, xla_shape.numpy_dtype())),\n",
                "        [axis_env.sizes[-1]] + dims)\n",
                "    zero = xops.Constant(c, np.zeros((), dtype=np.uint32))\n",
                "    idxs = [_unravel_index(c, axis_env)] + [zero] * len(dims)\n",
                "    padded = xops.DynamicUpdateSlice(padded, xops.Reshape(x, [1] + dims), idxs)\n",
                "    replica_groups_protos = xc.make_replica_groups(\n",
                "      xla.axis_groups(axis_env, axis_env.names[-1]))\n",
                "    out = xops.CrossReplicaSum(padded, replica_groups_protos)\n",
                "    if out_axis != 0:\n",
                "      # TODO(apaszke,mattjj): Change the indices to DynamicUpdateSlice instead\n",
                "      perm = list(range(1, len(dims)))\n",
                "      perm.insert(out_axis, 0)\n",
                "      out = xops.Transpose(out, perm)\n",
                "\n",
                "    # TODO(mattjj): remove this logic when AllReduce PRED supported on CPU / GPU\n",
                "    if convert_bool:\n",
                "      nonzero = xops.Ne(out, xops.Constant(c, np.array(0, dtype=np.float32)))\n",
                "      out = xops.ConvertElementType(\n",
                "          nonzero, xla.dtype_to_primitive_type(np.dtype(np.bool_)))\n",
                "    return out\n",
                "  else:\n",
                "    raise TypeError((aval, c.get_shape(x)))\n",
                "\n",
                "def _unravel_index(c, axis_env):\n",
                "  div = xops.Constant(c, np.array(axis_env.nreps // prod(axis_env.sizes),\n",
                "                                  np.uint32))\n",
                "  mod = xops.Constant(c, np.array(axis_env.sizes[-1], np.uint32))\n",
                "  return xops.Rem(xops.Div(xops.ReplicaId(c), div), mod)\n",
                "\n",
                "\n",
                "\n",
                "def _unravel_index_mhlo(axis_env):\n",
                "  div = mlir.ir_constant(\n",
                "      np.array(axis_env.nreps // util.prod(axis_env.sizes), np.uint32))\n",
                "  mod = mlir.ir_constant(np.array(axis_env.sizes[-1], np.uint32))\n",
                "  return mhlo.RemOp(\n",
                "      mhlo.DivOp(mhlo.ReplicaIdOp().result, div).result, mod).result\n",
                "\n",
                "def _mhlo_shard(aval, axis_env, xs, in_axis):\n",
                "  if aval is core.abstract_unit:\n",
                "    return xs\n",
                "  elif aval is core.abstract_token:\n",
                "    return xs\n",
                "  elif isinstance(aval, core.ShapedArray):\n",
                "    x, = xs\n",
                "    dims = list(aval.shape)\n",
                "    zero = mlir.ir_constant(np.zeros((), dtype=np.uint32))\n",
                "    idxs = [zero] * len(dims)\n",
                "    idxs.insert(in_axis, _unravel_index_mhlo(axis_env))\n",
                "    dims_unsqueezed = dims.copy()\n",
                "    dims_unsqueezed.insert(in_axis, 1)\n",
                "    return [\n",
                "      mhlo.ReshapeOp(\n",
                "        mlir.aval_to_ir_type(aval),\n",
                "        mhlo.DynamicSliceOp(\n",
                "            mlir.aval_to_ir_type(aval.update(shape=dims_unsqueezed)),\n",
                "            x, idxs, mlir.dense_int_elements(dims_unsqueezed)).result\n",
                "      ).result\n",
                "    ]\n",
                "  else:\n",
                "    raise TypeError(aval)\n",
                "\n",
                "# TODO(b/110096942): more efficient gather\n",
                "def _mhlo_unshard(aval, axis_env, out_axis, xs, platform):\n",
                "  if aval is core.abstract_unit:\n",
                "    return xs\n",
                "  elif aval is core.abstract_token:\n",
                "    return xs\n",
                "  elif isinstance(aval, core.ShapedArray):\n",
                "    x, = xs\n",
                "    # TODO(mattjj): remove this logic when AllReduce PRED supported on CPU / GPU\n",
                "    convert_bool = (np.issubdtype(aval.dtype, np.bool_)\n",
                "                    and platform in ('cpu', 'gpu'))\n",
                "    if convert_bool:\n",
                "      aval = aval.update(dtype=np.dtype(np.float32))\n",
                "      x = mhlo.ConvertOp(mlir.aval_to_ir_type(aval), x).result\n",
                "\n",
                "    dims = list(aval.shape)\n",
                "    padded_aval = aval.update(shape=[axis_env.sizes[-1]] + dims)\n",
                "    padded = mlir.full_like_aval(0, padded_aval)\n",
                "    zero = mlir.ir_constant(np.zeros((), dtype=np.uint32))\n",
                "    idxs = [_unravel_index_mhlo(axis_env)] + [zero] * len(dims)\n",
                "    padded = mhlo.DynamicUpdateSliceOp(\n",
                "        padded.type,\n",
                "        padded,\n",
                "        mhlo.BroadcastOp(mlir.aval_to_ir_type(aval.update(shape=[1] + dims)), x,\n",
                "                         mlir.dense_int_elements([1])).result,\n",
                "        idxs).result\n",
                "    replica_groups = mlir.dense_int_elements(\n",
                "      xla.axis_groups(axis_env, axis_env.names[-1]))\n",
                "    out = mhlo.CrossReplicaSumOp(padded, replica_groups).result\n",
                "    if out_axis != 0:\n",
                "      # TODO(apaszke,mattjj): Change the indices to DynamicUpdateSlice instead\n",
                "      perm = list(range(1, len(dims)))\n",
                "      perm.insert(out_axis, 0)\n",
                "      transposed_dims = list(dims)\n",
                "      transposed_dims.insert(out_axis, axis_env.sizes[-1])\n",
                "      aval = aval.update(shape=transposed_dims)\n",
                "      if _xla_extension_version < 49:\n",
                "        out = mhlo.TransposeOp(\n",
                "            mlir.aval_to_ir_type(aval), out,\n",
                "            mlir.dense_int_elements(perm)).result\n",
                "      else:\n",
                "        out = mhlo.TransposeOp(out, mlir.dense_int_elements(perm)).result\n",
                "\n",
                "    # TODO(mattjj): remove this logic when AllReduce PRED supported on CPU / GPU\n",
                "    if convert_bool:\n",
                "      float_zero = mlir.full_like_aval(0, padded_aval)\n",
                "      out = mhlo.CompareOp(\n",
                "          mlir.aval_to_ir_type(padded_aval.update(dtype=np.dtype(np.bool_))),\n",
                "          out, float_zero, ir.StringAttr.get(\"NE\"),\n",
                "          ir.StringAttr.get(\"FLOAT\")).result\n",
                "    return out\n",
                "  else:\n",
                "    raise TypeError(aval)\n",
                "\n",
                "\n",
                "def _pmap_lowering(ctx, *in_nodes, axis_name,\n",
                "                   axis_size, global_axis_size, devices, name,\n",
                "                   call_jaxpr, backend=None, in_axes, out_axes,\n",
                "                   donated_invars, global_arg_shapes):\n",
                "  del donated_invars  # Unused.\n",
                "  xla.check_backend_matches(backend, ctx.module_context.platform)\n",
                "  # We in-line here rather than generating a Call HLO as in the xla_call\n",
                "  # translation rule just because the extra tuple stuff is a pain.\n",
                "  if ctx.module_context.axis_env.names and devices is not None:\n",
                "    raise ValueError(\"Nested pmap with explicit devices argument.\")\n",
                "  if global_axis_size is None:\n",
                "    global_axis_size = axis_size\n",
                "  new_env = xla.extend_axis_env(ctx.module_context.axis_env, axis_name,\n",
                "                                global_axis_size)\n",
                "  # Shard the in_nodes that are mapped\n",
                "  in_avals = [v.aval for v in call_jaxpr.invars]\n",
                "  in_nodes_sharded = (\n",
                "    _mhlo_shard(aval, new_env, mlir.wrap_singleton_ir_values(in_node), in_axis)\n",
                "    if in_axis is not None else mlir.wrap_singleton_ir_values(in_node)\n",
                "    for aval, in_node, in_axis in zip(in_avals, in_nodes, in_axes))\n",
                "\n",
                "  with maybe_extend_axis_env(axis_name, global_axis_size, None):  # type: ignore\n",
                "    sub_ctx = ctx.module_context.replace(\n",
                "        axis_context=mlir.ReplicaAxisContext(new_env),\n",
                "        name_stack=xla.extend_name_stack(ctx.module_context.name_stack,\n",
                "                                         util.wrap_name(name, 'pmap')))\n",
                "    sharded_outs = mlir.jaxpr_subcomp(sub_ctx, call_jaxpr, (),\n",
                "                                      *in_nodes_sharded)\n",
                "  out_avals = [v.aval for v in call_jaxpr.outvars]\n",
                "  outs = [_mhlo_unshard(aval, new_env, out_axis, shard,\n",
                "                        platform=ctx.module_context.platform)\n",
                "          for aval, out_axis, shard in zip(out_avals, out_axes, sharded_outs)]\n",
                "  return outs\n",
                "\n",
                "mlir.register_lowering(xla_pmap_p, _pmap_lowering)\n",
                "\n",
                "\n",
                "# ------------------- xmap -------------------\n",
                "\n",
                "class Mesh(ContextDecorator):\n",
                "  devices: np.ndarray\n",
                "  axis_names: Tuple[MeshAxisName, ...]\n",
                "\n",
                "  def __init__(self, devices: np.ndarray, axis_names: Sequence[MeshAxisName]):\n",
                "    assert devices.ndim == len(axis_names)\n",
                "    # TODO: Make sure that devices are unique? At least with the quick and\n",
                "    #       dirty check that the array size is not larger than the number of\n",
                "    #       available devices?\n",
                "    self.devices = devices.copy()\n",
                "    self.devices.flags.writeable = False\n",
                "    self.axis_names = tuple(axis_names)\n",
                "\n",
                "  def __eq__(self, other):\n",
                "    if not isinstance(other, Mesh):\n",
                "      return False\n",
                "    return (self.axis_names == other.axis_names and\n",
                "            np.array_equal(self.devices, other.devices))\n",
                "\n",
                "  def __hash__(self):\n",
                "    if not hasattr(self, '_hash'):\n",
                "      self._hash = hash(\n",
                "          (self.axis_names, tuple(self.devices.flat), self.devices.shape))\n",
                "    return self._hash\n",
                "\n",
                "  def __setattr__(self, name, value):\n",
                "    if hasattr(self, name):\n",
                "      raise RuntimeError(\"Cannot reassign attributes of immutable mesh objects\")\n",
                "    super().__setattr__(name, value)\n",
                "\n",
                "  def __enter__(self):\n",
                "    new_env = _old_env.stack[-1].with_mesh(self)\n",
                "    _old_env.stack.append(new_env)\n",
                "    thread_resources.env = new_env\n",
                "    return self\n",
                "\n",
                "  def __exit__(self, exc_type, exc_value, traceback):\n",
                "    _old_env.stack.pop()\n",
                "    thread_resources.env = _old_env.stack[-1]\n",
                "    return False\n",
                "\n",
                "  @property\n",
                "  def shape(self):\n",
                "    return OrderedDict((name, size) for name, size in safe_zip(self.axis_names, self.devices.shape))\n",
                "\n",
                "  @property\n",
                "  def size(self):\n",
                "    return np.prod(list(self.shape.values()))\n",
                "\n",
                "  @property\n",
                "  def empty(self):\n",
                "    return self.devices.ndim == 0\n",
                "\n",
                "  @property\n",
                "  def is_multi_process(self):\n",
                "    return self.devices.size != len(self.local_devices)\n",
                "\n",
                "  @maybe_cached_property\n",
                "  def local_mesh(self):\n",
                "    return self._local_mesh(xb.process_index())\n",
                "\n",
                "  def _local_mesh(self, process_index):\n",
                "    if self.empty:\n",
                "      return self\n",
                "    is_local_device = np.vectorize(\n",
                "        lambda d: d.process_index == process_index, otypes=[bool])(self.devices)\n",
                "    subcube_indices = []\n",
                "    # We take the smallest slice of each dimension that doesn't skip any local device.\n",
                "    for axis in range(self.devices.ndim):\n",
                "      other_axes = tuple_delete(tuple(range(self.devices.ndim)), axis)\n",
                "      # NOTE: This re-reduces over many axes multiple times, so we could definitely\n",
                "      #       optimize it, but I hope it won't be a bottleneck anytime soon.\n",
                "      local_slices = is_local_device.any(other_axes, keepdims=False)\n",
                "      nonzero_indices = np.flatnonzero(local_slices)\n",
                "      start, end = int(np.min(nonzero_indices)), int(np.max(nonzero_indices))\n",
                "      subcube_indices.append(slice(start, end + 1))\n",
                "    subcube_indices = tuple(subcube_indices)\n",
                "    # We only end up with all conditions being true if the local devices formed a\n",
                "    # subcube of the full array. This is because we were biased towards taking a\n",
                "    # \"hull\" spanned by the devices, and in case the local devices don't form a\n",
                "    # subcube that hull will contain non-local devices.\n",
                "    if not is_local_device[subcube_indices].all():\n",
                "      raise ValueError(\n",
                "          \"When passing non-GlobalDeviceArray inputs to pjit or xmap, devices \"\n",
                "          \"connected to a single host must form a contiguous subcube of the \"\n",
                "          \"global device mesh\")\n",
                "    return Mesh(self.devices[subcube_indices], self.axis_names)\n",
                "\n",
                "  @property\n",
                "  def device_ids(self):\n",
                "    assert not self.empty\n",
                "    return np.vectorize(lambda d: d.id, otypes=[int])(self.devices)\n",
                "\n",
                "  def __repr__(self):\n",
                "    if self.empty:\n",
                "      return \"Mesh([], ())\"\n",
                "    return f\"Mesh({self.device_ids!r}, {self.axis_names!r})\"\n",
                "\n",
                "  @maybe_cached_property\n",
                "  def local_devices(self):\n",
                "    process_index = xb.process_index()\n",
                "    return [d for d in self.devices.flat if d.process_index == process_index]\n",
                "\n",
                "  def _local_to_global(self, axes: ArrayMapping, aval):\n",
                "    return untile_aval_nd(self.shape, axes,\n",
                "                          tile_aval_nd(self.local_mesh.shape, axes, aval))\n",
                "\n",
                "  def _global_to_local(self, axes: ArrayMapping, aval):\n",
                "    return untile_aval_nd(self.local_mesh.shape, axes,\n",
                "                          tile_aval_nd(self.shape, axes, aval))\n",
                "\n",
                "\n",
                "ResourceAxisName = core.AxisName\n",
                "\n",
                "class _Loop(NamedTuple):\n",
                "  name: ResourceAxisName\n",
                "  length: int\n",
                "\n",
                "\n",
                "def show_axes(axes):\n",
                "  return \", \".join(sorted([f\"`{a}`\" for a in axes]))\n",
                "\n",
                "\n",
                "class ResourceEnv(NamedTuple):\n",
                "  physical_mesh: Mesh\n",
                "  loops: Tuple[_Loop, ...]\n",
                "\n",
                "  def with_mesh(self, mesh: Mesh):\n",
                "    overlap = set(mesh.axis_names) & (self.resource_axes - set(self.physical_mesh.axis_names))\n",
                "    if overlap:\n",
                "      raise ValueError(f\"Cannot update the mesh of the current resource \"\n",
                "                       f\"environment. The new mesh shadows already defined axes \"\n",
                "                       f\"{show_axes(overlap)}\")\n",
                "    return self._replace(physical_mesh=mesh)\n",
                "\n",
                "  def with_extra_loop(self, loop: _Loop):\n",
                "    if loop.name in self.resource_axes:\n",
                "      raise ValueError(f\"Cannot extend the resource environment with loop named \"\n",
                "                       f\"`{loop.name}`. An axis of this name is already defined!\")\n",
                "    return self._replace(loops=self.loops + (loop,))\n",
                "\n",
                "  @property\n",
                "  def physical_resource_axes(self) -> Set[ResourceAxisName]:\n",
                "    return set(self.physical_mesh.axis_names)\n",
                "\n",
                "  @property\n",
                "  def loop_resource_axes(self) -> Set[ResourceAxisName]:\n",
                "    return set(loop.name for loop in self.loops)\n",
                "\n",
                "  @property\n",
                "  def resource_axes(self) -> Set[ResourceAxisName]:\n",
                "    return self.physical_resource_axes | self.loop_resource_axes\n",
                "\n",
                "  @property\n",
                "  def shape(self):\n",
                "    shape = self.physical_mesh.shape\n",
                "    shape.update(self.loops)\n",
                "    return shape\n",
                "\n",
                "  @property\n",
                "  def local_shape(self):\n",
                "    shape = self.physical_mesh.local_mesh.shape\n",
                "    shape.update(self.loops)\n",
                "    return shape\n",
                "\n",
                "  def __repr__(self):\n",
                "    return f\"ResourceEnv({self.physical_mesh!r}, {self.loops!r})\"\n",
                "\n",
                "EMPTY_ENV = ResourceEnv(Mesh(np.empty((), dtype=object), ()), ())\n",
                "\n",
                "class _ThreadResourcesLocalState(threading.local):\n",
                "\n",
                "  def __init__(self):\n",
                "    self.env = EMPTY_ENV\n",
                "\n",
                "thread_resources = _ThreadResourcesLocalState()\n",
                "\n",
                "# TODO(yashkatariya): Merge this into `_ThreadResourcesLocalState` by\n",
                "# maintaining a stack there and pointing `self.env` to `self.stack[-1]`.\n",
                "# Do this after the old `mesh` context manager is deprecated.\n",
                "class _ThreadLocalOldEnv(threading.local):\n",
                "  def __init__(self):\n",
                "    self.stack = [EMPTY_ENV]\n",
                "\n",
                "_old_env = _ThreadLocalOldEnv()\n",
                "\n",
                "\n",
                "def tile_aval_nd(axis_sizes, in_axes: ArrayMapping, aval):\n",
                "  if aval is core.abstract_unit:\n",
                "    return aval\n",
                "  assert isinstance(aval, ShapedArray)\n",
                "  shape = list(aval.shape)\n",
                "  named_shape = dict(aval.named_shape)\n",
                "  for name, axis in in_axes.items():\n",
                "    assert shape[axis] % axis_sizes[name] == 0\n",
                "    assert name not in named_shape\n",
                "    named_shape[name] = axis_sizes[name]\n",
                "    shape[axis] //= axis_sizes[name]\n",
                "  return aval.update(shape=tuple(shape), named_shape=named_shape)\n",
                "\n",
                "def untile_aval_nd(axis_sizes, out_axes: ArrayMapping, aval):\n",
                "  if aval is core.abstract_unit:\n",
                "    return aval\n",
                "  assert isinstance(aval, ShapedArray)\n",
                "  shape = list(aval.shape)\n",
                "  named_shape = dict(aval.named_shape)\n",
                "  for name, axis in out_axes.items():\n",
                "    shape[axis] *= axis_sizes[name]\n",
                "    named_shape.pop(name, None)  # The name might be missing --- it's a broadcast.\n",
                "  return aval.update(shape=tuple(shape), named_shape=named_shape)\n",
                "\n",
                "\n",
                "class SPMDBatchTrace(batching.BatchTrace):\n",
                "  def get_axis_primitive_batcher(self, primitive, frame):\n",
                "    if primitive in spmd_primitive_batchers:\n",
                "      return partial(spmd_primitive_batchers[primitive],\n",
                "          frame.size, frame.name, frame.main_trace.trace_type)\n",
                "    return super().get_axis_primitive_batcher(primitive, frame)\n",
                "\n",
                "\n",
                "spmd_primitive_batchers: Dict[core.Primitive, Callable] = {}\n",
                "\n",
                "\n",
                "def vtile_by_mesh(fun: lu.WrappedFun,\n",
                "                  mesh: Mesh,\n",
                "                  in_axes: Sequence[ArrayMapping],\n",
                "                  out_axes: Sequence[ArrayMapping]):\n",
                "  # We vectorize in reversed order, because vmap is often biased towards\n",
                "  # moving the batch axis to the front, and this way of stacking transforms\n",
                "  # will order the batch axes according to the mesh axis order.\n",
                "  # Not strictly necessary, but seems nicer than reversing it?\n",
                "  for name, size in reversed(mesh.shape.items()):\n",
                "    fun = batching.vtile(fun,\n",
                "                         tuple(a.get(name, None) for a in in_axes),\n",
                "                         tuple(a.get(name, None) for a in out_axes),\n",
                "                         tile_size=size,\n",
                "                         axis_name=name,\n",
                "                         main_type=SPMDBatchTrace)\n",
                "  return fun\n",
                "\n",
                "full_to_shard_p = core.Primitive('full_to_shard')\n",
                "\n",
                "@full_to_shard_p.def_abstract_eval\n",
                "def _full_to_shard_abstract_eval(x, axes, mesh, **_):\n",
                "  # TODO: Assert x is a global aval! Or ideally check that it's global in dims from axes!\n",
                "  return tile_aval_nd(mesh.shape, axes, x)\n",
                "\n",
                "def _manual_proto(aval: core.ShapedArray, manual_axes_set: FrozenSet[MeshAxisName], mesh: Mesh):\n",
                "  \"\"\"Create an OpSharding proto that declares all mesh axes from `axes` as manual\n",
                "  and all others as replicated.\n",
                "  \"\"\"\n",
                "  named_mesh_shape = mesh.shape\n",
                "  mesh_shape = list(named_mesh_shape.values())\n",
                "  axis_order = {axis: i for i, axis in enumerate(mesh.axis_names)}\n",
                "\n",
                "  manual_axes = list(sorted(manual_axes_set, key=str))\n",
                "  replicated_axes = list(axis for axis in mesh.axis_names if axis not in manual_axes_set)\n",
                "\n",
                "  tad_perm = ([axis_order[a] for a in replicated_axes] +\n",
                "              [axis_order[a] for a in manual_axes])\n",
                "  tad_shape = [1] * aval.ndim\n",
                "  tad_shape.append(int(np.prod([named_mesh_shape[a] for a in replicated_axes], dtype=int)))\n",
                "  tad_shape.append(int(np.prod([named_mesh_shape[a] for a in manual_axes], dtype=int)))\n",
                "\n",
                "  raw_mesh = np.arange(np.prod(mesh_shape)).reshape(mesh_shape)\n",
                "  proto = xc.OpSharding()\n",
                "  proto.type = xc.OpSharding.Type.OTHER\n",
                "  proto.tile_assignment_dimensions = tad_shape\n",
                "  proto.tile_assignment_devices = list(raw_mesh.transpose(tad_perm).reshape(tad_shape).flat)\n",
                "  proto.last_tile_dims = [xc.OpSharding.Type.REPLICATED, xc.OpSharding.Type.MANUAL]\n",
                "  return proto\n",
                "\n",
                "@partial(mlir.register_lowering, full_to_shard_p)\n",
                "def _full_to_shard_lowering(ctx, x, *, axes: ArrayMapping, mesh: Mesh, manual_axes: FrozenSet[MeshAxisName]):\n",
                "  # TODO: Can we short-circuit for replicated values? Probably not.\n",
                "  aval_in, = ctx.avals_in\n",
                "  aval_out, = ctx.avals_out\n",
                "  sharding_proto = mesh_sharding_specs(mesh.shape, mesh.axis_names)(aval_in, axes).sharding_proto()\n",
                "  unspecified_dims = set(range(aval_in.ndim)) - set(axes.values())\n",
                "  sx = mlir.wrap_with_sharding_op(x, sharding_proto, unspecified_dims=unspecified_dims)\n",
                "  manual_proto = _manual_proto(aval_in, manual_axes, mesh)\n",
                "  result_type, = mlir.aval_to_ir_types(aval_out)\n",
                "  return mlir.wrap_with_full_to_shard_op(result_type, sx, manual_proto, unspecified_dims=unspecified_dims),\n",
                "\n",
                "shard_to_full_p = core.Primitive('shard_to_full')\n",
                "\n",
                "@shard_to_full_p.def_abstract_eval\n",
                "def _shard_to_full_abstract_eval(x, axes, mesh, **_):\n",
                "  # TODO: Assert x is a global aval! Or ideally check that it's global in dims from axes!\n",
                "  return untile_aval_nd(mesh.shape, axes, x)\n",
                "\n",
                "@partial(mlir.register_lowering, shard_to_full_p)\n",
                "def _shard_to_full_lowering(ctx, x, *, axes: ArrayMapping, mesh: Mesh, manual_axes: FrozenSet[MeshAxisName]):\n",
                "  aval_in, = ctx.avals_in\n",
                "  aval_out, = ctx.avals_out\n",
                "  manual_proto = _manual_proto(aval_in, manual_axes, mesh)\n",
                "  result_type, = mlir.aval_to_ir_types(aval_out)\n",
                "  unspecified_dims = set(range(aval_in.ndim)) - set(axes.values())\n",
                "  sx = mlir.wrap_with_sharding_op(x, manual_proto, unspecified_dims=unspecified_dims)\n",
                "  sharding_proto = mesh_sharding_specs(mesh.shape, mesh.axis_names)(aval_out, axes).sharding_proto()\n",
                "  return mlir.wrap_with_shard_to_full_op(result_type, sx, sharding_proto, unspecified_dims),\n",
                "\n",
                "@lu.transformation\n",
                "def vtile_manual(manual_axes: FrozenSet[MeshAxisName],\n",
                "                 mesh: Mesh,\n",
                "                 in_axes: Sequence[ArrayMapping],\n",
                "                 out_axes: Sequence[ArrayMapping],\n",
                "                 *args):\n",
                "  tiled_args = [full_to_shard_p.bind(arg, axes=axes, mesh=mesh, manual_axes=manual_axes)\n",
                "                for arg, axes in zip(args, in_axes)]\n",
                "  tiled_outs = yield tiled_args, {}\n",
                "  outs = [shard_to_full_p.bind(out, axes=axes, mesh=mesh, manual_axes=manual_axes)\n",
                "          for out, axes in zip(tiled_outs, out_axes)]\n",
                "  yield outs\n",
                "\n",
                "\n",
                "@dataclasses.dataclass(frozen=True)\n",
                "class TileVectorize:\n",
                "  pass\n",
                "\n",
                "@dataclasses.dataclass(frozen=True)\n",
                "class TileManual:\n",
                "  manual_axes: FrozenSet[MeshAxisName]\n",
                "\n",
                "TilingMethod = Union[TileVectorize, TileManual]\n",
                "\n",
                "\n",
                "@profiler.annotate_function\n",
                "def lower_mesh_computation(\n",
                "    fun: lu.WrappedFun,\n",
                "    api_name: str,\n",
                "    fun_name: str,\n",
                "    mesh: Mesh,\n",
                "    in_axes: Sequence[ArrayMapping],\n",
                "    out_axes: Union[Sequence[ArrayMapping], Callable[[], Sequence[ArrayMapping]]],\n",
                "    donated_invars: Sequence[bool],\n",
                "    spmd_lowering: bool,\n",
                "    global_in_avals: Sequence[core.ShapedArray],\n",
                "    tiling_method: Optional[TilingMethod],\n",
                "    in_is_gda: Sequence[bool]):\n",
                "  assert not mesh.empty\n",
                "  backend = xb.get_device_backend(mesh.devices.flat[0])\n",
                "  name_stack = new_name_stack(wrap_name(fun_name, api_name))\n",
                "\n",
                "  global_axis_sizes = mesh.shape\n",
                "\n",
                "  log_priority = logging.WARNING if config.jax_log_compiles else logging.DEBUG\n",
                "  logging.log(log_priority,\n",
                "              \"Compiling %s (%d) for %s mesh with global shapes and types %s. \"\n",
                "              \"Argument mapping: %s.\",\n",
                "              getattr(fun, '__name__', '<unnamed function>'), id(fun),\n",
                "              tuple(global_axis_sizes.items()), global_in_avals,\n",
                "              in_axes)\n",
                "\n",
                "  # 1. Trace to jaxpr and preprocess/verify it\n",
                "  in_tiled_avals = [tile_aval_nd(global_axis_sizes, aval_in_axes, aval)\n",
                "                    for aval, aval_in_axes in safe_zip(global_in_avals, in_axes)]\n",
                "  if spmd_lowering:\n",
                "    # TODO: Consider handling xmap's 'vectorize' in here. We can vmap once instead of vtile twice!\n",
                "    if tiling_method is not None:\n",
                "      if isinstance(tiling_method, TileVectorize):\n",
                "        tiling_transform = vtile_by_mesh\n",
                "      elif isinstance(tiling_method, TileManual):\n",
                "        tiling_transform = lambda f, *args: vtile_manual(f, tiling_method.manual_axes, *args)  # type: ignore\n",
                "      else:\n",
                "        raise NotImplementedError(f\"Unrecognized tiling method: {tiling_method}\")\n",
                "      assert not callable(out_axes)\n",
                "      fun = tiling_transform(fun, mesh, in_axes, out_axes)\n",
                "    in_jaxpr_avals = global_in_avals\n",
                "  else:\n",
                "    assert isinstance(tiling_method, TileVectorize)\n",
                "    in_jaxpr_avals = in_tiled_avals\n",
                "  with core.extend_axis_env_nd(mesh.shape.items()):\n",
                "    with dispatch.log_elapsed_time(f\"Finished tracing + transforming {name_stack} \"\n",
                "                                   \"in {elapsed_time} sec\"):\n",
                "      jaxpr, out_jaxpr_avals, consts = pe.trace_to_jaxpr_final(fun, in_jaxpr_avals)\n",
                "  if callable(out_axes):\n",
                "    out_axes = out_axes()\n",
                "  assert len(out_axes) == len(out_jaxpr_avals)\n",
                "  if spmd_lowering:\n",
                "    global_out_avals = out_jaxpr_avals\n",
                "  else:\n",
                "    global_out_avals = [untile_aval_nd(global_axis_sizes, aval_out_axes, aval)\n",
                "                        for aval, aval_out_axes in safe_zip(out_jaxpr_avals, out_axes)]\n",
                "  _sanitize_mesh_jaxpr(jaxpr)\n",
                "  if mesh.is_multi_process:\n",
                "    check_multihost_collective_allowlist(jaxpr)\n",
                "  jaxpr = dispatch.apply_outfeed_rewriter(jaxpr)\n",
                "\n",
                "  # 3. Build up the HLO\n",
                "  tuple_args = len(in_jaxpr_avals) > 100  # pass long arg lists as tuple for TPU\n",
                "  in_partitions: Optional[List[Optional[xc.OpSharding]]]\n",
                "  out_partitions: Optional[List[Optional[xc.OpSharding]]]\n",
                "  axis_ctx: mlir.AxisContext\n",
                "  if spmd_lowering:\n",
                "    replicated_args = [False] * len(in_jaxpr_avals)\n",
                "    global_sharding_spec = mesh_sharding_specs(global_axis_sizes, mesh.axis_names)\n",
                "    in_partitions = [global_sharding_spec(aval, aval_in_axes).sharding_proto()\n",
                "                     if aval is not core.abstract_unit else None\n",
                "                     for aval, aval_in_axes in safe_zip(global_in_avals, in_axes)]\n",
                "    out_partitions = [global_sharding_spec(aval, aval_out_axes).sharding_proto()\n",
                "                      for aval, aval_out_axes in safe_zip(global_out_avals, out_axes)]\n",
                "    out_partitions_t = xla.tuple_sharding_proto(out_partitions)\n",
                "    partitions_proto = True\n",
                "    axis_ctx = mlir.SPMDAxisContext(mesh)\n",
                "    axis_env = axis_ctx.axis_env\n",
                "  else:\n",
                "    replicated_args = [not axis for axis in in_axes]\n",
                "    in_partitions = None\n",
                "    out_partitions = None\n",
                "    out_partitions_t = None\n",
                "    partitions_proto = False\n",
                "    axis_env = xla.AxisEnv(nreps=mesh.size,\n",
                "                           names=tuple(global_axis_sizes.keys()),\n",
                "                           sizes=tuple(global_axis_sizes.values()))\n",
                "    axis_ctx = mlir.ReplicaAxisContext(axis_env)\n",
                "  closed_jaxpr = core.ClosedJaxpr(jaxpr, consts)\n",
                "  module: Union[str, xc.XlaComputation]\n",
                "  module_name = f\"{api_name}_{fun_name}\"\n",
                "  with core.extend_axis_env_nd(mesh.shape.items()):\n",
                "    if config.jax_enable_mlir:\n",
                "      module = mlir.lower_jaxpr_to_module(\n",
                "          module_name, closed_jaxpr, backend.platform, axis_ctx, name_stack,\n",
                "          donated_invars, replicated_args=replicated_args,\n",
                "          arg_shardings=in_partitions, result_shardings=out_partitions)\n",
                "    else:\n",
                "      module = xla.lower_jaxpr_to_xla_module(\n",
                "          module_name, closed_jaxpr, backend.platform, axis_env,\n",
                "          name_stack, tuple_args, donated_invars, replicated_args,\n",
                "          in_partitions, out_partitions_t,\n",
                "          partitions_are_protos=partitions_proto)\n",
                "\n",
                "  return MeshComputation(\n",
                "      str(name_stack), module, donated_invars, mesh=mesh, global_in_avals=global_in_avals,\n",
                "      global_out_avals=global_out_avals, in_axes=in_axes, out_axes=out_axes,\n",
                "      spmd_lowering=spmd_lowering, tuple_args=tuple_args, in_is_gda=in_is_gda)\n",
                "\n",
                "\n",
                "class MeshComputation:\n",
                "  _hlo: Union[ir.Module, xc.XlaComputation]\n",
                "  _executable: Optional['MeshExecutable']\n",
                "\n",
                "  def __init__(self, name: str, hlo: Union[ir.Module, xc.XlaComputation],\n",
                "               donated_invars: Sequence[bool], **compile_args):\n",
                "    self._name = name\n",
                "    self._hlo = hlo\n",
                "    self._donated_invars = donated_invars\n",
                "    self.compile_args = compile_args\n",
                "    self._executable = None\n",
                "\n",
                "  def hlo(self):\n",
                "    # this is a method for api consistency with dispatch.XlaComputation\n",
                "    if isinstance(self._hlo, xc.XlaComputation):\n",
                "      return self._hlo\n",
                "    return xe.mlir.mlir_module_to_xla_computation(\n",
                "        mlir.module_to_string(self._hlo),\n",
                "        use_tuple_args=self.compile_args[\"tuple_args\"])\n",
                "\n",
                "  def mhlo(self) -> str:\n",
                "    if isinstance(self._hlo, xc.XlaComputation):\n",
                "      module_str = xe.mlir.xla_computation_to_mlir_module(self._hlo)\n",
                "      with mlir.make_ir_context():\n",
                "        return ir.Module.parse(module_str)\n",
                "    return self._hlo\n",
                "\n",
                "  def compile(self,\n",
                "              _allow_propagation_to_outputs : bool = False,\n",
                "              _allow_compile_replicated : bool = True) -> 'MeshExecutable':\n",
                "    if self._executable is None:\n",
                "      self._executable = MeshExecutable.from_hlo(\n",
                "          self._name, self._hlo, **self.compile_args,\n",
                "          _allow_propagation_to_outputs=_allow_propagation_to_outputs,\n",
                "          _allow_compile_replicated=_allow_compile_replicated)  # type: ignore\n",
                "    return self._executable\n",
                "\n",
                "\n",
                "def _get_input_metadata(global_in_avals, global_mesh, in_axes, in_is_gda):\n",
                "  input_specs, input_indices, input_avals = [], [], []\n",
                "  num_local_devices = len(global_mesh.local_devices)\n",
                "  for gaval, axis, is_gda in safe_zip(global_in_avals, in_axes, in_is_gda):\n",
                "    # TODO(yashkatariya): Don't calculate input_indices and input_specs for GDA\n",
                "    # as GDA doesn't need it.\n",
                "    if is_gda or not axis:\n",
                "      aval = gaval\n",
                "      mesh = global_mesh\n",
                "    else:\n",
                "      aval = global_mesh._global_to_local(axis, gaval)\n",
                "      mesh = global_mesh.local_mesh\n",
                "\n",
                "    spec = (mesh_sharding_specs(mesh.shape, mesh.axis_names)(aval, axis)\n",
                "            if aval is not core.abstract_unit else None)\n",
                "    # We special case this logic to support fully replicated non-GDA values\n",
                "    # with non-contiguous submeshes\n",
                "    if not axis and not is_gda:\n",
                "      index = tuple((slice(None),) * aval.ndim for _ in range(num_local_devices))\n",
                "    else:\n",
                "      index = spec_to_indices(aval.shape, spec) if spec is not None else None\n",
                "    input_specs.append(spec)\n",
                "    input_indices.append(index)\n",
                "    input_avals.append(aval)\n",
                "  return input_specs, input_indices, input_avals\n",
                "\n",
                "\n",
                "class MeshExecutable:\n",
                "  __slots__ = ['xla_executable', 'unsafe_call', '_input_avals']\n",
                "\n",
                "  def __init__(self, xla_executable, unsafe_call, input_avals):\n",
                "    self.xla_executable = xla_executable\n",
                "    self.unsafe_call = unsafe_call\n",
                "    # input_avals is a list of global and local avals. Aval is global if input\n",
                "    # is a GDA else local.\n",
                "    self._input_avals = input_avals\n",
                "\n",
                "  @staticmethod\n",
                "  def from_hlo(name: str,\n",
                "               computation: Union[ir.Module, xc.XlaComputation],\n",
                "               mesh: Mesh,\n",
                "               global_in_avals: Sequence[ShapedArray],\n",
                "               global_out_avals: Sequence[ShapedArray],\n",
                "               in_axes: Sequence[ArrayMapping],\n",
                "               out_axes: Sequence[ArrayMapping],\n",
                "               spmd_lowering: bool, tuple_args: bool,\n",
                "               in_is_gda: Sequence[bool],\n",
                "               _allow_propagation_to_outputs: bool,\n",
                "               _allow_compile_replicated: bool) -> 'MeshExecutable':\n",
                "    assert not mesh.empty\n",
                "    backend = xb.get_device_backend(mesh.devices.flat[0])\n",
                "\n",
                "    if spmd_lowering:\n",
                "      num_replicas, num_partitions = 1, mesh.size\n",
                "    else:\n",
                "      num_replicas, num_partitions = mesh.size, 1\n",
                "    device_assignment = mesh.devices.reshape((num_replicas, num_partitions))\n",
                "    compile_options = xb.get_compile_options(\n",
                "        num_replicas=num_replicas,\n",
                "        num_partitions=num_partitions,\n",
                "        device_assignment=device_assignment,\n",
                "        use_spmd_partitioning=spmd_lowering,\n",
                "    )\n",
                "    compile_options.parameter_is_tupled_arguments = tuple_args\n",
                "    compile_options.executable_build_options.allow_spmd_sharding_propagation_to_output = \\\n",
                "        _allow_propagation_to_outputs\n",
                "\n",
                "    input_specs, input_indices, input_avals = _get_input_metadata(\n",
                "        global_in_avals, mesh, in_axes, in_is_gda)\n",
                "    # Calculate local information here instead of calculating it in\n",
                "    # `avals_to_results_handler` because pmap also uses this function.\n",
                "    handle_outs = global_avals_to_results_handler(global_out_avals, out_axes, mesh)\n",
                "\n",
                "    if _allow_compile_replicated and hasattr(backend, \"compile_replicated\"):\n",
                "      unsafe_call = backend.compile_replicated(\n",
                "          computation, compile_options,\n",
                "          input_indices, input_specs,\n",
                "          handle_outs)\n",
                "      xla_executable = None\n",
                "    else:\n",
                "      with dispatch.log_elapsed_time(f\"Finished XLA compilation of {name} \"\n",
                "                                     \"in {elapsed_time} sec\"):\n",
                "        xla_executable = dispatch.compile_or_get_cached(backend, computation, compile_options)\n",
                "      handle_args = InputsHandler(xla_executable.local_devices(), input_specs, input_indices)\n",
                "      unsafe_call = ExecuteReplicated(xla_executable, backend, handle_args, handle_outs)\n",
                "\n",
                "    return MeshExecutable(xla_executable, unsafe_call, input_avals)\n",
                "\n",
                "  def call(self, *args):\n",
                "    # TODO(yashkatariya): Add a AOT lowering test where GDA is an input.\n",
                "    arg_avals = map(xla.abstractify, args)\n",
                "    ref_avals = self._input_avals\n",
                "    dispatch.check_arg_avals_for_call(ref_avals, arg_avals)\n",
                "    return self.unsafe_call(*args)\n",
                "\n",
                "\n",
                "_forbidden_primitives = {\n",
                "  'xla_pmap': 'pmap',\n",
                "  'sharded_call': 'sharded_jit',\n",
                "}\n",
                "def _sanitize_mesh_jaxpr(jaxpr):\n",
                "  if isinstance(jaxpr, core.ClosedJaxpr):\n",
                "    jaxpr = jaxpr.jaxpr\n",
                "  for eqn in jaxpr.eqns:\n",
                "    if eqn.primitive.name in _forbidden_primitives:\n",
                "      raise RuntimeError(f\"Nesting {_forbidden_primitives[eqn.primitive.name]} \"\n",
                "                         f\"inside xmaps not supported!\")\n",
                "    core.traverse_jaxpr_params(_sanitize_mesh_jaxpr, eqn.params)\n",
                "\n",
                "\n",
                "custom_resource_typing_rules: Dict[core.Primitive, Callable] = {}\n",
                "\n",
                "def resource_typecheck(jaxpr, resource_env, axis_resources, what_jaxpr_thunk):\n",
                "  if isinstance(jaxpr, core.ClosedJaxpr):\n",
                "    jaxpr = jaxpr.jaxpr\n",
                "  def _check_aval(aval, what_thunk):\n",
                "    if not hasattr(aval, 'named_shape'):\n",
                "      return\n",
                "    resource_to_axis = {}\n",
                "    for axis in aval.named_shape:\n",
                "      for resource in axis_resources[axis]:\n",
                "        if resource in resource_to_axis:\n",
                "          other_axis = resource_to_axis[resource]\n",
                "          axis, other_axis = sorted([str(axis), str(other_axis)])\n",
                "          raise JAXTypeError(\n",
                "              f\"Axes `{axis}` and `{other_axis}` are both mapped to the \"\n",
                "              f\"resource `{resource}`, but they coincide in the named_shape \"\n",
                "              f\"of {what_thunk()}\")\n",
                "        resource_to_axis[resource] = axis\n",
                "\n",
                "  what_thunk = lambda: (f\"an input to {what_jaxpr_thunk()}\")\n",
                "  for v in jaxpr.constvars:\n",
                "    _check_aval(v.aval, what_thunk)\n",
                "  for v in jaxpr.invars:\n",
                "    _check_aval(v.aval, what_thunk)\n",
                "  what_thunk = lambda: (f\"a value returned from a primitive {eqn.primitive} created \"\n",
                "                        f\"at {source_info_util.summarize(eqn.source_info)}\")\n",
                "  rec_what_jaxpr_thunk = lambda: (f\"a primitive {eqn.primitive} created at\"\n",
                "                                  f\"{source_info_util.summarize(eqn.source_info)}\")\n",
                "  for eqn in jaxpr.eqns:\n",
                "    typing_rule = custom_resource_typing_rules.get(eqn.primitive, None)\n",
                "    if typing_rule:\n",
                "      typing_rule([v.aval for v in eqn.invars], eqn.params, eqn.source_info,\n",
                "                  resource_env, axis_resources)\n",
                "    else:\n",
                "      core.traverse_jaxpr_params(partial(resource_typecheck,\n",
                "                                         resource_env=resource_env,\n",
                "                                         axis_resources=axis_resources,\n",
                "                                         what_jaxpr_thunk=rec_what_jaxpr_thunk),\n",
                "                                 eqn.params)\n",
                "    for v in eqn.outvars:\n",
                "      _check_aval(v.aval, what_thunk)\n",
                "\n",
                "\n",
                "def mesh_sharding_specs(axis_sizes, axis_names, allow_uneven_axes=False):\n",
                "  mesh_axis_pos = {name: i for i, name in enumerate(axis_names)}\n",
                "  # NOTE: This takes in the non-sharded avals!\n",
                "  def mk_sharding_spec(aval, aval_axes):\n",
                "    mesh_mapping = [Replicated(axis_size) for axis_size in axis_sizes.values()]\n",
                "    if aval is core.abstract_token:\n",
                "      assert not aval_axes\n",
                "      return ShardingSpec([], mesh_mapping)\n",
                "    sharding = [_UNSHARDED_INSTANCE] * len(aval.shape)\n",
                "    next_sharded_axis = 0\n",
                "    aval_shape = list(aval.shape)\n",
                "    # NOTE: sorted is stable, which is important when multiple resources\n",
                "    #       map to the same axis.\n",
                "    for name, axis in sorted(aval_axes.items(), key=lambda x: x[1]):\n",
                "      if not allow_uneven_axes:\n",
                "        assert aval_shape[axis] % axis_sizes[name] == 0, (axis_sizes[name], aval.shape[axis])\n",
                "      aval_shape[axis] //= axis_sizes[name]\n",
                "      chunked = sharding[axis]\n",
                "      if isinstance(chunked, NoSharding):\n",
                "        chunked = Chunked([])\n",
                "      sharding[axis] = Chunked(list(chunked.chunks) + [axis_sizes[name]])\n",
                "      assert isinstance(mesh_mapping[mesh_axis_pos[name]], Replicated), \\\n",
                "          \"Value mapped to the same mesh axis twice\"\n",
                "      mesh_mapping[mesh_axis_pos[name]] = ShardedAxis(next_sharded_axis)\n",
                "      next_sharded_axis += 1\n",
                "    return ShardingSpec(sharding, mesh_mapping)\n",
                "  return mk_sharding_spec\n",
                "\n",
                "\n",
                "@contextmanager\n",
                "def maybe_extend_axis_env(*args, **kwargs):\n",
                "  with core.extend_axis_env(*args, **kwargs):\n",
                "    yield\n",
                "\n",
                "class DynamicAxisEnvFrame(object):\n",
                "  __slots__ = [\"name\", \"pmap_trace\", \"hard_size\"]\n",
                "  def __init__(self, name, pmap_trace, hard_size):\n",
                "    self.name = name\n",
                "    self.pmap_trace = pmap_trace\n",
                "    self.hard_size = hard_size\n",
                "\n",
                "class DynamicAxisEnv(list):\n",
                "  def __contains__(self, axis_name):\n",
                "    return axis_name in (frame.name for frame in self)\n",
                "\n",
                "  def __getitem__(self, axis_name):\n",
                "    if axis_name not in self:\n",
                "      raise NameError(\"unbound axis name: {}\".format(axis_name))\n",
                "    for frame in reversed(self):\n",
                "      if frame.name == axis_name:\n",
                "        return frame\n",
                "\n",
                "    raise AssertionError\n",
                "\n",
                "  @property\n",
                "  def sizes(self):\n",
                "    return tuple(frame.hard_size for frame in self)\n",
                "\n",
                "  @property\n",
                "  def nreps(self):\n",
                "    return prod(frame.hard_size for frame in self)\n",
                "\n",
                "class _ThreadLocalState(threading.local):\n",
                "  def __init__(self):\n",
                "    self.dynamic_axis_env = DynamicAxisEnv()\n",
                "\n",
                "_thread_local_state = _ThreadLocalState()\n",
                "\n",
                "def device_put(x, devices: Sequence[xb.xla_client.Device], replicate: bool=False) -> List[xb.xla_client.Buffer]:\n",
                "  \"\"\"Call device_put on a sequence of devices and return a flat sequence of buffers.\"\"\"\n",
                "  if replicate:\n",
                "    return list(it.chain.from_iterable(dispatch.device_put(x, device) for device in devices))\n",
                "  else:\n",
                "    return list(it.chain.from_iterable(dispatch.device_put(val, device) for val, device in safe_zip(x, devices)))"
            ]
        ]
    },
    "partial_orders": [
        {
            "edit_hunk_pair": [
                0,
                1
            ],
            "edit_order": "bi-directional",
            "reason": "declare and use"
        },
        {
            "edit_hunk_pair": [
                0,
                2
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        },
        {
            "edit_hunk_pair": [
                0,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "implement and use"
        },
        {
            "edit_hunk_pair": [
                1,
                2
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                1,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                1,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "declare and use"
        },
        {
            "edit_hunk_pair": [
                2,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        },
        {
            "edit_hunk_pair": [
                2,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        },
        {
            "edit_hunk_pair": [
                3,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "implement and use"
        },
        {
            "edit_hunk_pair": [
                4,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        }
    ]
}