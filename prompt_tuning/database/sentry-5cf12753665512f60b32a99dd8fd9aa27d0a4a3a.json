{
    "language": "python",
    "commit_url": "https://github.com/getsentry/sentry/commit/5cf12753665512f60b32a99dd8fd9aa27d0a4a3a",
    "commit_message": "ref(locks): Make the post_process locks backend configurable (#36328)",
    "commit_snapshots": {
        "src/sentry/conf/server.py": [
            [
                "\"\"\"\n",
                "These settings act as the default (base) settings for the Sentry-provided web-server\n",
                "\"\"\"\n",
                "\n",
                "import os\n",
                "import os.path\n",
                "import platform\n",
                "import re\n",
                "import socket\n",
                "import sys\n",
                "import tempfile\n",
                "from datetime import timedelta\n",
                "from urllib.parse import urlparse\n",
                "\n",
                "import sentry\n",
                "from sentry.utils.celery import crontab_with_minute_jitter\n",
                "from sentry.utils.types import type_from_value\n",
                "\n",
                "\n",
                "def gettext_noop(s):\n",
                "    return s\n",
                "\n",
                "\n",
                "socket.setdefaulttimeout(5)\n",
                "\n",
                "\n",
                "def env(key, default=\"\", type=None):\n",
                "    \"\"\"\n",
                "    Extract an environment variable for use in configuration\n",
                "\n",
                "    :param key: The environment variable to be extracted.\n",
                "    :param default: The value to be returned if `key` is not found.\n",
                "    :param type: The type of the returned object (defaults to the type of `default`).\n",
                "    :return: The environment variable if it exists, else `default`.\n",
                "    \"\"\"\n",
                "\n",
                "    # First check an internal cache, so we can `pop` multiple times\n",
                "    # without actually losing the value.\n",
                "    try:\n",
                "        rv = env._cache[key]\n",
                "    except KeyError:\n",
                "        if \"SENTRY_RUNNING_UWSGI\" in os.environ:\n",
                "            # We do this so when the process forks off into uwsgi\n",
                "            # we want to actually be popping off values. This is so that\n",
                "            # at runtime, the variables aren't actually available.\n",
                "            fn = os.environ.pop\n",
                "        else:\n",
                "            fn = os.environ.__getitem__\n",
                "\n",
                "        try:\n",
                "            rv = fn(key)\n",
                "            env._cache[key] = rv\n",
                "        except KeyError:\n",
                "            rv = default\n",
                "\n",
                "    if type is None:\n",
                "        type = type_from_value(default)\n",
                "\n",
                "    return type(rv)\n",
                "\n",
                "\n",
                "env._cache = {}\n",
                "\n",
                "ENVIRONMENT = os.environ.get(\"SENTRY_ENVIRONMENT\", \"production\")\n",
                "\n",
                "IS_DEV = ENVIRONMENT == \"development\"\n",
                "\n",
                "DEBUG = IS_DEV\n",
                "\n",
                "ADMIN_ENABLED = DEBUG\n",
                "\n",
                "ADMINS = ()\n",
                "\n",
                "# Hosts that are considered in the same network (including VPNs).\n",
                "INTERNAL_IPS = ()\n",
                "\n",
                "# List of IP subnets which should not be accessible\n",
                "SENTRY_DISALLOWED_IPS = ()\n",
                "\n",
                "# When resolving DNS for external sources (source map fetching, webhooks, etc),\n",
                "# ensure that domains are fully resolved first to avoid poking internal\n",
                "# search domains.\n",
                "SENTRY_ENSURE_FQDN = False\n",
                "\n",
                "# Hosts that are allowed to use system token authentication.\n",
                "# http://en.wikipedia.org/wiki/Reserved_IP_addresses\n",
                "INTERNAL_SYSTEM_IPS = (\n",
                "    \"0.0.0.0/8\",\n",
                "    \"10.0.0.0/8\",\n",
                "    \"100.64.0.0/10\",\n",
                "    \"127.0.0.0/8\",\n",
                "    \"169.254.0.0/16\",\n",
                "    \"172.16.0.0/12\",\n",
                "    \"192.0.0.0/29\",\n",
                "    \"192.0.2.0/24\",\n",
                "    \"192.88.99.0/24\",\n",
                "    \"192.168.0.0/16\",\n",
                "    \"198.18.0.0/15\",\n",
                "    \"198.51.100.0/24\",\n",
                "    \"224.0.0.0/4\",\n",
                "    \"240.0.0.0/4\",\n",
                "    \"255.255.255.255/32\",\n",
                ")\n",
                "\n",
                "MANAGERS = ADMINS\n",
                "\n",
                "APPEND_SLASH = True\n",
                "\n",
                "PROJECT_ROOT = os.path.normpath(os.path.join(os.path.dirname(__file__), os.pardir))\n",
                "\n",
                "# XXX(dcramer): handle case when we've installed from source vs just running\n",
                "# this straight out of the repository\n",
                "if \"site-packages\" in __file__:\n",
                "    NODE_MODULES_ROOT = os.path.join(PROJECT_ROOT, \"node_modules\")\n",
                "else:\n",
                "    NODE_MODULES_ROOT = os.path.join(PROJECT_ROOT, os.pardir, os.pardir, \"node_modules\")\n",
                "\n",
                "NODE_MODULES_ROOT = os.path.normpath(NODE_MODULES_ROOT)\n",
                "\n",
                "DEVSERVICES_CONFIG_DIR = os.path.normpath(\n",
                "    os.path.join(PROJECT_ROOT, os.pardir, os.pardir, \"config\")\n",
                ")\n",
                "\n",
                "SENTRY_DISTRIBUTED_CLICKHOUSE_TABLES = False\n",
                "\n",
                "RELAY_CONFIG_DIR = os.path.join(DEVSERVICES_CONFIG_DIR, \"relay\")\n",
                "\n",
                "SYMBOLICATOR_CONFIG_DIR = os.path.join(DEVSERVICES_CONFIG_DIR, \"symbolicator\")\n",
                "\n",
                "# XXX(epurkhiser): The generated chartucterie config.js file will be stored\n",
                "# here. This directory may not exist until that file is generated.\n",
                "CHARTCUTERIE_CONFIG_DIR = os.path.join(DEVSERVICES_CONFIG_DIR, \"chartcuterie\")\n",
                "\n",
                "CDC_CONFIG_DIR = os.path.join(DEVSERVICES_CONFIG_DIR, \"cdc\")\n",
                "\n",
                "sys.path.insert(0, os.path.normpath(os.path.join(PROJECT_ROOT, os.pardir)))\n",
                "\n",
                "DATABASES = {\n",
                "    \"default\": {\n",
                "        \"ENGINE\": \"sentry.db.postgres\",\n",
                "        \"NAME\": \"sentry\",\n",
                "        \"USER\": \"postgres\",\n",
                "        \"PASSWORD\": \"\",\n",
                "        \"HOST\": \"127.0.0.1\",\n",
                "        \"PORT\": \"\",\n",
                "        \"AUTOCOMMIT\": True,\n",
                "        \"ATOMIC_REQUESTS\": False,\n",
                "    }\n",
                "}\n",
                "\n",
                "if \"DATABASE_URL\" in os.environ:\n",
                "    url = urlparse(os.environ[\"DATABASE_URL\"])\n",
                "\n",
                "    # Ensure default database exists.\n",
                "    DATABASES[\"default\"] = DATABASES.get(\"default\", {})\n",
                "\n",
                "    # Update with environment configuration.\n",
                "    DATABASES[\"default\"].update(\n",
                "        {\n",
                "            \"NAME\": url.path[1:],\n",
                "            \"USER\": url.username,\n",
                "            \"PASSWORD\": url.password,\n",
                "            \"HOST\": url.hostname,\n",
                "            \"PORT\": url.port,\n",
                "        }\n",
                "    )\n",
                "    if url.scheme == \"postgres\":\n",
                "        DATABASES[\"default\"][\"ENGINE\"] = \"sentry.db.postgres\"\n",
                "\n",
                "# This should always be UTC.\n",
                "TIME_ZONE = \"UTC\"\n",
                "\n",
                "# Language code for this installation. All choices can be found here:\n",
                "# http://www.i18nguy.com/unicode/language-identifiers.html\n",
                "LANGUAGE_CODE = \"en-us\"\n",
                "\n",
                "LANGUAGES = (\n",
                "    (\"af\", gettext_noop(\"Afrikaans\")),\n",
                "    (\"ar\", gettext_noop(\"Arabic\")),\n",
                "    (\"az\", gettext_noop(\"Azerbaijani\")),\n",
                "    (\"bg\", gettext_noop(\"Bulgarian\")),\n",
                "    (\"be\", gettext_noop(\"Belarusian\")),\n",
                "    (\"bn\", gettext_noop(\"Bengali\")),\n",
                "    (\"br\", gettext_noop(\"Breton\")),\n",
                "    (\"bs\", gettext_noop(\"Bosnian\")),\n",
                "    (\"ca\", gettext_noop(\"Catalan\")),\n",
                "    (\"cs\", gettext_noop(\"Czech\")),\n",
                "    (\"cy\", gettext_noop(\"Welsh\")),\n",
                "    (\"da\", gettext_noop(\"Danish\")),\n",
                "    (\"de\", gettext_noop(\"German\")),\n",
                "    (\"el\", gettext_noop(\"Greek\")),\n",
                "    (\"en\", gettext_noop(\"English\")),\n",
                "    (\"eo\", gettext_noop(\"Esperanto\")),\n",
                "    (\"es\", gettext_noop(\"Spanish\")),\n",
                "    (\"et\", gettext_noop(\"Estonian\")),\n",
                "    (\"eu\", gettext_noop(\"Basque\")),\n",
                "    (\"fa\", gettext_noop(\"Persian\")),\n",
                "    (\"fi\", gettext_noop(\"Finnish\")),\n",
                "    (\"fr\", gettext_noop(\"French\")),\n",
                "    (\"ga\", gettext_noop(\"Irish\")),\n",
                "    (\"gl\", gettext_noop(\"Galician\")),\n",
                "    (\"he\", gettext_noop(\"Hebrew\")),\n",
                "    (\"hi\", gettext_noop(\"Hindi\")),\n",
                "    (\"hr\", gettext_noop(\"Croatian\")),\n",
                "    (\"hu\", gettext_noop(\"Hungarian\")),\n",
                "    (\"ia\", gettext_noop(\"Interlingua\")),\n",
                "    (\"id\", gettext_noop(\"Indonesian\")),\n",
                "    (\"is\", gettext_noop(\"Icelandic\")),\n",
                "    (\"it\", gettext_noop(\"Italian\")),\n",
                "    (\"ja\", gettext_noop(\"Japanese\")),\n",
                "    (\"ka\", gettext_noop(\"Georgian\")),\n",
                "    (\"kk\", gettext_noop(\"Kazakh\")),\n",
                "    (\"km\", gettext_noop(\"Khmer\")),\n",
                "    (\"kn\", gettext_noop(\"Kannada\")),\n",
                "    (\"ko\", gettext_noop(\"Korean\")),\n",
                "    (\"lb\", gettext_noop(\"Luxembourgish\")),\n",
                "    (\"lt\", gettext_noop(\"Lithuanian\")),\n",
                "    (\"lv\", gettext_noop(\"Latvian\")),\n",
                "    (\"mk\", gettext_noop(\"Macedonian\")),\n",
                "    (\"ml\", gettext_noop(\"Malayalam\")),\n",
                "    (\"mn\", gettext_noop(\"Mongolian\")),\n",
                "    (\"my\", gettext_noop(\"Burmese\")),\n",
                "    (\"nb\", gettext_noop(\"Norwegian Bokmal\")),\n",
                "    (\"ne\", gettext_noop(\"Nepali\")),\n",
                "    (\"nl\", gettext_noop(\"Dutch\")),\n",
                "    (\"nn\", gettext_noop(\"Norwegian Nynorsk\")),\n",
                "    (\"os\", gettext_noop(\"Ossetic\")),\n",
                "    (\"pa\", gettext_noop(\"Punjabi\")),\n",
                "    (\"pl\", gettext_noop(\"Polish\")),\n",
                "    (\"pt\", gettext_noop(\"Portuguese\")),\n",
                "    (\"pt-br\", gettext_noop(\"Brazilian Portuguese\")),\n",
                "    (\"ro\", gettext_noop(\"Romanian\")),\n",
                "    (\"ru\", gettext_noop(\"Russian\")),\n",
                "    (\"sk\", gettext_noop(\"Slovak\")),\n",
                "    (\"sl\", gettext_noop(\"Slovenian\")),\n",
                "    (\"sq\", gettext_noop(\"Albanian\")),\n",
                "    (\"sr\", gettext_noop(\"Serbian\")),\n",
                "    (\"sv-se\", gettext_noop(\"Swedish\")),\n",
                "    (\"sw\", gettext_noop(\"Swahili\")),\n",
                "    (\"ta\", gettext_noop(\"Tamil\")),\n",
                "    (\"te\", gettext_noop(\"Telugu\")),\n",
                "    (\"th\", gettext_noop(\"Thai\")),\n",
                "    (\"tr\", gettext_noop(\"Turkish\")),\n",
                "    (\"tt\", gettext_noop(\"Tatar\")),\n",
                "    (\"udm\", gettext_noop(\"Udmurt\")),\n",
                "    (\"uk\", gettext_noop(\"Ukrainian\")),\n",
                "    (\"ur\", gettext_noop(\"Urdu\")),\n",
                "    (\"vi\", gettext_noop(\"Vietnamese\")),\n",
                "    (\"zh-cn\", gettext_noop(\"Simplified Chinese\")),\n",
                "    (\"zh-tw\", gettext_noop(\"Traditional Chinese\")),\n",
                ")\n",
                "\n",
                "from .locale import CATALOGS\n",
                "\n",
                "LANGUAGES = tuple((code, name) for code, name in LANGUAGES if code in CATALOGS)\n",
                "\n",
                "SUPPORTED_LANGUAGES = frozenset(CATALOGS)\n",
                "\n",
                "SITE_ID = 1\n",
                "\n",
                "# If you set this to False, Django will make some optimizations so as not\n",
                "# to load the internationalization machinery.\n",
                "USE_I18N = True\n",
                "\n",
                "# If you set this to False, Django will not format dates, numbers and\n",
                "# calendars according to the current locale\n",
                "USE_L10N = True\n",
                "\n",
                "USE_TZ = True\n",
                "\n",
                "# CAVEAT: If you're adding a middleware that modifies a response's content,\n",
                "# and appears before CommonMiddleware, you must either reorder your middleware\n",
                "# so that responses aren't modified after Content-Length is set, or have the\n",
                "# response modifying middleware reset the Content-Length header.\n",
                "# This is because CommonMiddleware Sets the Content-Length header for non-streaming responses.\n",
                "MIDDLEWARE = (\n",
                "    \"sentry.middleware.health.HealthCheck\",\n",
                "    \"sentry.middleware.security.SecurityHeadersMiddleware\",\n",
                "    \"sentry.middleware.env.SentryEnvMiddleware\",\n",
                "    \"sentry.middleware.proxy.SetRemoteAddrFromForwardedFor\",\n",
                "    \"sentry.middleware.stats.RequestTimingMiddleware\",\n",
                "    \"sentry.middleware.access_log.access_log_middleware\",\n",
                "    \"sentry.middleware.stats.ResponseCodeMiddleware\",\n",
                "    \"sentry.middleware.subdomain.SubdomainMiddleware\",\n",
                "    \"django.middleware.common.CommonMiddleware\",\n",
                "    \"django.contrib.sessions.middleware.SessionMiddleware\",\n",
                "    \"django.middleware.csrf.CsrfViewMiddleware\",\n",
                "    \"sentry.middleware.auth.AuthenticationMiddleware\",\n",
                "    \"sentry.middleware.user.UserActiveMiddleware\",\n",
                "    \"sentry.middleware.sudo.SudoMiddleware\",\n",
                "    \"sentry.middleware.superuser.SuperuserMiddleware\",\n",
                "    \"sentry.middleware.locale.SentryLocaleMiddleware\",\n",
                "    \"sentry.middleware.ratelimit.RatelimitMiddleware\",\n",
                "    \"django.contrib.messages.middleware.MessageMiddleware\",\n",
                ")\n",
                "\n",
                "ROOT_URLCONF = \"sentry.conf.urls\"\n",
                "\n",
                "# TODO(joshuarli): Django 1.10 introduced this option, which restricts the size of a\n",
                "# request body. We have some middleware in sentry.middleware.proxy that sets the\n",
                "# Content Length to max uint32 in certain cases related to minidump.\n",
                "# Once relay's fully rolled out, that can be deleted.\n",
                "# Until then, the safest and easiest thing to do is to disable this check\n",
                "# to leave things the way they were with Django <1.9.\n",
                "DATA_UPLOAD_MAX_MEMORY_SIZE = None\n",
                "\n",
                "TEMPLATES = [\n",
                "    {\n",
                "        \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n",
                "        \"DIRS\": [os.path.join(PROJECT_ROOT, \"templates\")],\n",
                "        \"APP_DIRS\": True,\n",
                "        \"OPTIONS\": {\n",
                "            \"context_processors\": [\n",
                "                \"django.contrib.auth.context_processors.auth\",\n",
                "                \"django.contrib.messages.context_processors.messages\",\n",
                "                \"django.template.context_processors.csrf\",\n",
                "                \"django.template.context_processors.request\",\n",
                "            ]\n",
                "        },\n",
                "    }\n",
                "]\n",
                "\n",
                "INSTALLED_APPS = (\n",
                "    \"django.contrib.admin\",\n",
                "    \"django.contrib.auth\",\n",
                "    \"django.contrib.contenttypes\",\n",
                "    \"django.contrib.messages\",\n",
                "    \"django.contrib.sessions\",\n",
                "    \"django.contrib.sites\",\n",
                "    \"drf_spectacular\",\n",
                "    \"crispy_forms\",\n",
                "    \"rest_framework\",\n",
                "    \"sentry\",\n",
                "    \"sentry.analytics\",\n",
                "    \"sentry.incidents.apps.Config\",\n",
                "    \"sentry.discover\",\n",
                "    \"sentry.analytics.events\",\n",
                "    \"sentry.nodestore\",\n",
                "    \"sentry.release_health\",\n",
                "    \"sentry.search\",\n",
                "    \"sentry.sentry_metrics.indexer\",\n",
                "    \"sentry.snuba\",\n",
                "    \"sentry.lang.java.apps.Config\",\n",
                "    \"sentry.lang.javascript.apps.Config\",\n",
                "    \"sentry.lang.native.apps.Config\",\n",
                "    \"sentry.plugins.sentry_interface_types.apps.Config\",\n",
                "    \"sentry.plugins.sentry_urls.apps.Config\",\n",
                "    \"sentry.plugins.sentry_useragents.apps.Config\",\n",
                "    \"sentry.plugins.sentry_webhooks.apps.Config\",\n",
                "    \"social_auth\",\n",
                "    \"sudo\",\n",
                "    \"sentry.eventstream\",\n",
                "    \"sentry.auth.providers.google.apps.Config\",\n",
                "    \"django.contrib.staticfiles\",\n",
                ")\n",
                "\n",
                "# Silence internal hints from Django's system checks\n",
                "SILENCED_SYSTEM_CHECKS = (\n",
                "    # Django recommends to use OneToOneField over ForeignKey(unique=True)\n",
                "    # however this changes application behavior in ways that break association\n",
                "    # loading\n",
                "    \"fields.W342\",\n",
                "    # We have a \"catch-all\" react_page_view that we only want to match on URLs\n",
                "    # ending with a `/` to allow APPEND_SLASHES to kick in for the ones lacking\n",
                "    # the trailing slash. This confuses the warning as the regex is `/$` which\n",
                "    # looks like it starts with a slash but it doesn't.\n",
                "    \"urls.W002\",\n",
                "    # Our own AuthenticationMiddleware suffices as a replacement for\n",
                "    # django.contrib.auth.middleware.AuthenticationMiddleware; both add the\n",
                "    # authenticated user to the HttpRequest which is what's needed here.\n",
                "    \"admin.E408\",\n",
                "    # This is fixed in Django@7c08f26bf0439c1ed593b51b51ad847f7e262bc1.\n",
                "    # It's not our problem; refer to Django issue 32260.\n",
                "    \"urls.E007\",\n",
                ")\n",
                "\n",
                "STATIC_ROOT = os.path.realpath(os.path.join(PROJECT_ROOT, \"static\"))\n",
                "STATIC_URL = \"/_static/{version}/\"\n",
                "# webpack assets live at a different URL that is unversioned\n",
                "# as we configure webpack to include file content based hash in the filename\n",
                "STATIC_FRONTEND_APP_URL = \"/_static/dist/\"\n",
                "\n",
                "# The webpack output directory\n",
                "STATICFILES_DIRS = [\n",
                "    os.path.join(STATIC_ROOT, \"sentry\", \"dist\"),\n",
                "]\n",
                "\n",
                "# various middleware will use this to identify resources which should not access\n",
                "# cookies\n",
                "ANONYMOUS_STATIC_PREFIXES = (\n",
                "    \"/_static/\",\n",
                "    \"/avatar/\",\n",
                "    \"/organization-avatar/\",\n",
                "    \"/team-avatar/\",\n",
                "    \"/project-avatar/\",\n",
                "    \"/js-sdk-loader/\",\n",
                ")\n",
                "\n",
                "STATICFILES_FINDERS = (\n",
                "    \"django.contrib.staticfiles.finders.FileSystemFinder\",\n",
                "    \"django.contrib.staticfiles.finders.AppDirectoriesFinder\",\n",
                ")\n",
                "\n",
                "ASSET_VERSION = 0\n",
                "\n",
                "# setup a default media root to somewhere useless\n",
                "MEDIA_ROOT = \"/tmp/sentry-files\"\n",
                "MEDIA_URL = \"_media/\"\n",
                "\n",
                "LOCALE_PATHS = (os.path.join(PROJECT_ROOT, \"locale\"),)\n",
                "\n",
                "CSRF_FAILURE_VIEW = \"sentry.web.frontend.csrf_failure.view\"\n",
                "CSRF_COOKIE_NAME = \"sc\"\n",
                "\n",
                "# Auth configuration\n",
                "\n",
                "from django.urls import reverse_lazy\n",
                "\n",
                "LOGIN_REDIRECT_URL = reverse_lazy(\"sentry-login-redirect\")\n",
                "LOGIN_URL = reverse_lazy(\"sentry-login\")\n",
                "\n",
                "AUTHENTICATION_BACKENDS = (\n",
                "    \"sentry.utils.auth.EmailAuthBackend\",\n",
                "    # The following authentication backends are used by social auth only.\n",
                "    # We don't use them for user authentication.\n",
                "    \"social_auth.backends.asana.AsanaBackend\",\n",
                "    \"social_auth.backends.github.GithubBackend\",\n",
                "    \"social_auth.backends.bitbucket.BitbucketBackend\",\n",
                "    \"social_auth.backends.visualstudio.VisualStudioBackend\",\n",
                ")\n",
                "\n",
                "AUTH_PASSWORD_VALIDATORS = [\n",
                "    {\n",
                "        \"NAME\": \"sentry.auth.password_validation.MinimumLengthValidator\",\n",
                "        \"OPTIONS\": {\"min_length\": 6},\n",
                "    },\n",
                "    {\n",
                "        \"NAME\": \"sentry.auth.password_validation.MaximumLengthValidator\",\n",
                "        \"OPTIONS\": {\"max_length\": 256},\n",
                "    },\n",
                "]\n",
                "\n",
                "SOCIAL_AUTH_USER_MODEL = AUTH_USER_MODEL = \"sentry.User\"\n",
                "\n",
                "SESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n",
                "SESSION_COOKIE_NAME = \"sentrysid\"\n",
                "\n",
                "# setting SESSION_COOKIE_SAMESITE to None below for now because\n",
                "# Django's default in 2.1 now `Lax`.\n",
                "# this breaks certain IDP flows where we need cookies sent to us on a redirected POST\n",
                "# request, and `Lax` doesnt permit this.\n",
                "# See here: https://docs.djangoproject.com/en/2.1/ref/settings/#session-cookie-samesite\n",
                "SESSION_COOKIE_SAMESITE = None\n",
                "\n",
                "BITBUCKET_CONSUMER_KEY = \"\"\n",
                "BITBUCKET_CONSUMER_SECRET = \"\"\n",
                "\n",
                "ASANA_CLIENT_ID = \"\"\n",
                "ASANA_CLIENT_SECRET = \"\"\n",
                "\n",
                "VISUALSTUDIO_APP_ID = \"\"\n",
                "VISUALSTUDIO_APP_SECRET = \"\"\n",
                "VISUALSTUDIO_CLIENT_SECRET = \"\"\n",
                "VISUALSTUDIO_SCOPES = [\"vso.work_write\", \"vso.project\", \"vso.code\", \"vso.release\"]\n",
                "\n",
                "SOCIAL_AUTH_PIPELINE = (\n",
                "    \"social_auth.backends.pipeline.user.get_username\",\n",
                "    \"social_auth.backends.pipeline.social.social_auth_user\",\n",
                "    \"social_auth.backends.pipeline.associate.associate_by_email\",\n",
                "    \"social_auth.backends.pipeline.misc.save_status_to_session\",\n",
                "    \"social_auth.backends.pipeline.social.associate_user\",\n",
                "    \"social_auth.backends.pipeline.social.load_extra_data\",\n",
                "    \"social_auth.backends.pipeline.user.update_user_details\",\n",
                "    \"social_auth.backends.pipeline.misc.save_status_to_session\",\n",
                ")\n",
                "SOCIAL_AUTH_REVOKE_TOKENS_ON_DISCONNECT = True\n",
                "SOCIAL_AUTH_LOGIN_REDIRECT_URL = \"/account/settings/identities/\"\n",
                "SOCIAL_AUTH_ASSOCIATE_ERROR_URL = SOCIAL_AUTH_LOGIN_REDIRECT_URL\n",
                "\n",
                "INITIAL_CUSTOM_USER_MIGRATION = \"0108_fix_user\"\n",
                "\n",
                "# Auth engines and the settings required for them to be listed\n",
                "AUTH_PROVIDERS = {\n",
                "    \"github\": (\"GITHUB_APP_ID\", \"GITHUB_API_SECRET\"),\n",
                "    \"bitbucket\": (\"BITBUCKET_CONSUMER_KEY\", \"BITBUCKET_CONSUMER_SECRET\"),\n",
                "    \"asana\": (\"ASANA_CLIENT_ID\", \"ASANA_CLIENT_SECRET\"),\n",
                "    \"visualstudio\": (\n",
                "        \"VISUALSTUDIO_APP_ID\",\n",
                "        \"VISUALSTUDIO_APP_SECRET\",\n",
                "        \"VISUALSTUDIO_CLIENT_SECRET\",\n",
                "    ),\n",
                "}\n",
                "\n",
                "AUTH_PROVIDER_LABELS = {\n",
                "    \"github\": \"GitHub\",\n",
                "    \"bitbucket\": \"Bitbucket\",\n",
                "    \"asana\": \"Asana\",\n",
                "    \"visualstudio\": \"Visual Studio\",\n",
                "}\n",
                "\n",
                "import random\n",
                "\n",
                "\n",
                "def SOCIAL_AUTH_DEFAULT_USERNAME():\n",
                "    return random.choice([\"Darth Vader\", \"Obi-Wan Kenobi\", \"R2-D2\", \"C-3PO\", \"Yoda\"])\n",
                "\n",
                "\n",
                "SOCIAL_AUTH_PROTECTED_USER_FIELDS = [\"email\"]\n",
                "SOCIAL_AUTH_FORCE_POST_DISCONNECT = True\n",
                "\n",
                "# Queue configuration\n",
                "from kombu import Exchange, Queue\n",
                "\n",
                "BROKER_URL = \"redis://127.0.0.1:6379\"\n",
                "BROKER_TRANSPORT_OPTIONS = {}\n",
                "\n",
                "# Ensure workers run async by default\n",
                "# in Development you might want them to run in-process\n",
                "# though it would cause timeouts/recursions in some cases\n",
                "CELERY_ALWAYS_EAGER = False\n",
                "\n",
                "# Complain about bad use of pickle.  See sentry.celery.SentryTask.apply_async for how\n",
                "# this works.\n",
                "CELERY_COMPLAIN_ABOUT_BAD_USE_OF_PICKLE = False\n",
                "\n",
                "# We use the old task protocol because during benchmarking we noticed that it's faster\n",
                "# than the new protocol. If we ever need to bump this it should be fine, there were no\n",
                "# compatibility issues, just need to run benchmarks and do some tests to make sure\n",
                "# things run ok.\n",
                "CELERY_TASK_PROTOCOL = 1\n",
                "CELERY_EAGER_PROPAGATES_EXCEPTIONS = True\n",
                "CELERY_IGNORE_RESULT = True\n",
                "CELERY_SEND_EVENTS = False\n",
                "CELERY_RESULT_BACKEND = None\n",
                "CELERY_TASK_RESULT_EXPIRES = 1\n",
                "CELERY_DISABLE_RATE_LIMITS = True\n",
                "CELERY_DEFAULT_QUEUE = \"default\"\n",
                "CELERY_DEFAULT_EXCHANGE = \"default\"\n",
                "CELERY_DEFAULT_EXCHANGE_TYPE = \"direct\"\n",
                "CELERY_DEFAULT_ROUTING_KEY = \"default\"\n",
                "CELERY_CREATE_MISSING_QUEUES = True\n",
                "CELERY_REDIRECT_STDOUTS = False\n",
                "CELERYD_HIJACK_ROOT_LOGGER = False\n",
                "CELERY_TASK_SERIALIZER = \"pickle\"\n",
                "CELERY_RESULT_SERIALIZER = \"pickle\"\n",
                "CELERY_ACCEPT_CONTENT = {\"pickle\"}\n",
                "CELERY_IMPORTS = (\n",
                "    \"sentry.data_export.tasks\",\n",
                "    \"sentry.discover.tasks\",\n",
                "    \"sentry.incidents.tasks\",\n",
                "    \"sentry.sentry_metrics.indexer.tasks\",\n",
                "    \"sentry.snuba.tasks\",\n",
                "    \"sentry.tasks.app_store_connect\",\n",
                "    \"sentry.tasks.assemble\",\n",
                "    \"sentry.tasks.auth\",\n",
                "    \"sentry.tasks.auto_remove_inbox\",\n",
                "    \"sentry.tasks.auto_resolve_issues\",\n",
                "    \"sentry.tasks.beacon\",\n",
                "    \"sentry.tasks.check_auth\",\n",
                "    \"sentry.tasks.check_monitors\",\n",
                "    \"sentry.tasks.clear_expired_snoozes\",\n",
                "    \"sentry.tasks.codeowners.code_owners_auto_sync\",\n",
                "    \"sentry.tasks.codeowners.update_code_owners_schema\",\n",
                "    \"sentry.tasks.collect_project_platforms\",\n",
                "    \"sentry.tasks.commits\",\n",
                "    \"sentry.tasks.deletion\",\n",
                "    \"sentry.tasks.digests\",\n",
                "    \"sentry.tasks.email\",\n",
                "    \"sentry.tasks.files\",\n",
                "    \"sentry.tasks.groupowner\",\n",
                "    \"sentry.tasks.integrations\",\n",
                "    \"sentry.tasks.low_priority_symbolication\",\n",
                "    \"sentry.tasks.merge\",\n",
                "    \"sentry.tasks.options\",\n",
                "    \"sentry.tasks.ping\",\n",
                "    \"sentry.tasks.post_process\",\n",
                "    \"sentry.tasks.process_buffer\",\n",
                "    \"sentry.tasks.relay\",\n",
                "    \"sentry.tasks.release_registry\",\n",
                "    \"sentry.tasks.reports\",\n",
                "    \"sentry.tasks.reprocessing\",\n",
                "    \"sentry.tasks.reprocessing2\",\n",
                "    \"sentry.tasks.scheduler\",\n",
                "    \"sentry.tasks.sentry_apps\",\n",
                "    \"sentry.tasks.servicehooks\",\n",
                "    \"sentry.tasks.store\",\n",
                "    \"sentry.tasks.symbolication\",\n",
                "    \"sentry.tasks.unmerge\",\n",
                "    \"sentry.tasks.update_user_reports\",\n",
                "    \"sentry.tasks.user_report\",\n",
                "    \"sentry.profiles.task\",\n",
                "    \"sentry.release_health.duplex\",\n",
                "    \"sentry.release_health.tasks\",\n",
                ")\n",
                "CELERY_QUEUES = [\n",
                "    Queue(\"activity.notify\", routing_key=\"activity.notify\"),\n",
                "    Queue(\"alerts\", routing_key=\"alerts\"),\n",
                "    Queue(\"app_platform\", routing_key=\"app_platform\"),\n",
                "    Queue(\"appstoreconnect\", routing_key=\"sentry.tasks.app_store_connect.#\"),\n",
                "    Queue(\"assemble\", routing_key=\"assemble\"),\n",
                "    Queue(\"auth\", routing_key=\"auth\"),\n",
                "    Queue(\"buffers.process_pending\", routing_key=\"buffers.process_pending\"),\n",
                "    Queue(\"buffers.incr\", routing_key=\"buffers.incr\"),\n",
                "    Queue(\"cleanup\", routing_key=\"cleanup\"),\n",
                "    Queue(\"code_owners\", routing_key=\"code_owners\"),\n",
                "    Queue(\"commits\", routing_key=\"commits\"),\n",
                "    Queue(\"data_export\", routing_key=\"data_export\"),\n",
                "    Queue(\"default\", routing_key=\"default\"),\n",
                "    Queue(\"digests.delivery\", routing_key=\"digests.delivery\"),\n",
                "    Queue(\"digests.scheduling\", routing_key=\"digests.scheduling\"),\n",
                "    Queue(\"email\", routing_key=\"email\"),\n",
                "    Queue(\"events.preprocess_event\", routing_key=\"events.preprocess_event\"),\n",
                "    Queue(\"events.process_event\", routing_key=\"events.process_event\"),\n",
                "    Queue(\"events.reprocess_events\", routing_key=\"events.reprocess_events\"),\n",
                "    Queue(\n",
                "        \"events.reprocessing.preprocess_event\", routing_key=\"events.reprocessing.preprocess_event\"\n",
                "    ),\n",
                "    Queue(\"events.reprocessing.process_event\", routing_key=\"events.reprocessing.process_event\"),\n",
                "    Queue(\n",
                "        \"events.reprocessing.symbolicate_event\", routing_key=\"events.reprocessing.symbolicate_event\"\n",
                "    ),\n",
                "    Queue(\n",
                "        \"events.reprocessing.symbolicate_event_low_priority\",\n",
                "        routing_key=\"events.reprocessing.symbolicate_event_low_priority\",\n",
                "    ),\n",
                "    Queue(\"events.save_event\", routing_key=\"events.save_event\"),\n",
                "    Queue(\"events.save_event_transaction\", routing_key=\"events.save_event_transaction\"),\n",
                "    Queue(\"events.save_event_attachments\", routing_key=\"events.save_event_attachments\"),\n",
                "    Queue(\"events.symbolicate_event\", routing_key=\"events.symbolicate_event\"),\n",
                "    Queue(\n",
                "        \"events.symbolicate_event_low_priority\", routing_key=\"events.symbolicate_event_low_priority\"\n",
                "    ),\n",
                "    Queue(\"files.delete\", routing_key=\"files.delete\"),\n",
                "    Queue(\n",
                "        \"group_owners.process_suspect_commits\", routing_key=\"group_owners.process_suspect_commits\"\n",
                "    ),\n",
                "    Queue(\n",
                "        \"releasemonitor\",\n",
                "        routing_key=\"releasemonitor\",\n",
                "    ),\n",
                "    Queue(\"incidents\", routing_key=\"incidents\"),\n",
                "    Queue(\"incident_snapshots\", routing_key=\"incident_snapshots\"),\n",
                "    Queue(\"incidents\", routing_key=\"incidents\"),\n",
                "    Queue(\"integrations\", routing_key=\"integrations\"),\n",
                "    Queue(\"merge\", routing_key=\"merge\"),\n",
                "    Queue(\"options\", routing_key=\"options\"),\n",
                "    Queue(\"relay_config\", routing_key=\"relay_config\"),\n",
                "    Queue(\"relay_config_bulk\", routing_key=\"relay_config_bulk\"),\n",
                "    Queue(\"reports.deliver\", routing_key=\"reports.deliver\"),\n",
                "    Queue(\"reports.prepare\", routing_key=\"reports.prepare\"),\n",
                "    Queue(\"search\", routing_key=\"search\"),\n",
                "    Queue(\"sentry_metrics.indexer\", routing_key=\"sentry_metrics.indexer\"),\n",
                "    Queue(\"similarity.index\", routing_key=\"similarity.index\"),\n",
                "    Queue(\"sleep\", routing_key=\"sleep\"),\n",
                "    Queue(\"stats\", routing_key=\"stats\"),\n",
                "    Queue(\"subscriptions\", routing_key=\"subscriptions\"),\n",
                "    Queue(\n",
                "        \"symbolications.compute_low_priority_projects\",\n",
                "        routing_key=\"symbolications.compute_low_priority_projects\",\n",
                "    ),\n",
                "    Queue(\"unmerge\", routing_key=\"unmerge\"),\n",
                "    Queue(\"update\", routing_key=\"update\"),\n",
                "    Queue(\"profiles.process\", routing_key=\"profiles.process\"),\n",
                "    Queue(\"release_health.duplex\", routing_key=\"release_health.duplex\"),\n",
                "]\n",
                "\n",
                "for queue in CELERY_QUEUES:\n",
                "    queue.durable = False\n",
                "\n",
                "CELERY_ROUTES = (\"sentry.queue.routers.SplitQueueRouter\",)\n",
                "\n",
                "\n",
                "def create_partitioned_queues(name):\n",
                "    exchange = Exchange(name, type=\"direct\")\n",
                "    for num in range(1):\n",
                "        CELERY_QUEUES.append(Queue(f\"{name}-{num}\", exchange=exchange))\n",
                "\n",
                "\n",
                "create_partitioned_queues(\"counters\")\n",
                "create_partitioned_queues(\"triggers\")\n",
                "\n",
                "from celery.schedules import crontab\n",
                "\n",
                "# XXX: Make sure to register the monitor_id for each job in `SENTRY_CELERYBEAT_MONITORS`!\n",
                "CELERYBEAT_SCHEDULE_FILENAME = os.path.join(tempfile.gettempdir(), \"sentry-celerybeat\")\n",
                "CELERYBEAT_SCHEDULE = {\n",
                "    \"check-auth\": {\n",
                "        \"task\": \"sentry.tasks.check_auth\",\n",
                "        \"schedule\": timedelta(minutes=1),\n",
                "        \"options\": {\"expires\": 60, \"queue\": \"auth\"},\n",
                "    },\n",
                "    \"enqueue-scheduled-jobs\": {\n",
                "        \"task\": \"sentry.tasks.enqueue_scheduled_jobs\",\n",
                "        \"schedule\": timedelta(minutes=1),\n",
                "        \"options\": {\"expires\": 60},\n",
                "    },\n",
                "    \"send-beacon\": {\n",
                "        \"task\": \"sentry.tasks.send_beacon\",\n",
                "        \"schedule\": timedelta(hours=1),\n",
                "        \"options\": {\"expires\": 3600},\n",
                "    },\n",
                "    \"send-ping\": {\n",
                "        \"task\": \"sentry.tasks.send_ping\",\n",
                "        \"schedule\": timedelta(minutes=1),\n",
                "        \"options\": {\"expires\": 60},\n",
                "    },\n",
                "    \"flush-buffers\": {\n",
                "        \"task\": \"sentry.tasks.process_buffer.process_pending\",\n",
                "        \"schedule\": timedelta(seconds=10),\n",
                "        \"options\": {\"expires\": 10, \"queue\": \"buffers.process_pending\"},\n",
                "    },\n",
                "    \"sync-options\": {\n",
                "        \"task\": \"sentry.tasks.options.sync_options\",\n",
                "        \"schedule\": timedelta(seconds=10),\n",
                "        \"options\": {\"expires\": 10, \"queue\": \"options\"},\n",
                "    },\n",
                "    \"schedule-digests\": {\n",
                "        \"task\": \"sentry.tasks.digests.schedule_digests\",\n",
                "        \"schedule\": timedelta(seconds=30),\n",
                "        \"options\": {\"expires\": 30},\n",
                "    },\n",
                "    \"check-monitors\": {\n",
                "        \"task\": \"sentry.tasks.check_monitors\",\n",
                "        \"schedule\": timedelta(minutes=1),\n",
                "        \"options\": {\"expires\": 60},\n",
                "    },\n",
                "    \"clear-expired-snoozes\": {\n",
                "        \"task\": \"sentry.tasks.clear_expired_snoozes\",\n",
                "        \"schedule\": timedelta(minutes=5),\n",
                "        \"options\": {\"expires\": 300},\n",
                "    },\n",
                "    \"clear-expired-raw-events\": {\n",
                "        \"task\": \"sentry.tasks.clear_expired_raw_events\",\n",
                "        \"schedule\": timedelta(minutes=15),\n",
                "        \"options\": {\"expires\": 300},\n",
                "    },\n",
                "    \"collect-project-platforms\": {\n",
                "        \"task\": \"sentry.tasks.collect_project_platforms\",\n",
                "        \"schedule\": crontab_with_minute_jitter(hour=3),\n",
                "        \"options\": {\"expires\": 3600 * 24},\n",
                "    },\n",
                "    \"update-user-reports\": {\n",
                "        \"task\": \"sentry.tasks.update_user_reports\",\n",
                "        \"schedule\": timedelta(minutes=15),\n",
                "        \"options\": {\"expires\": 300},\n",
                "    },\n",
                "    \"schedule-auto-resolution\": {\n",
                "        \"task\": \"sentry.tasks.schedule_auto_resolution\",\n",
                "        \"schedule\": timedelta(minutes=15),\n",
                "        \"options\": {\"expires\": 60 * 25},\n",
                "    },\n",
                "    \"auto-remove-inbox\": {\n",
                "        \"task\": \"sentry.tasks.auto_remove_inbox\",\n",
                "        \"schedule\": timedelta(minutes=15),\n",
                "        \"options\": {\"expires\": 60 * 25},\n",
                "    },\n",
                "    \"schedule-deletions\": {\n",
                "        \"task\": \"sentry.tasks.deletion.run_scheduled_deletions\",\n",
                "        \"schedule\": timedelta(minutes=15),\n",
                "        \"options\": {\"expires\": 60 * 25},\n",
                "    },\n",
                "    \"reattempt-deletions\": {\n",
                "        \"task\": \"sentry.tasks.deletion.reattempt_deletions\",\n",
                "        \"schedule\": crontab(hour=10, minute=0),  # 03:00 PDT, 07:00 EDT, 10:00 UTC\n",
                "        \"options\": {\"expires\": 60 * 25},\n",
                "    },\n",
                "    \"schedule-weekly-organization-reports\": {\n",
                "        \"task\": \"sentry.tasks.reports.prepare_reports\",\n",
                "        \"schedule\": crontab(\n",
                "            minute=0, hour=12, day_of_week=\"monday\"  # 05:00 PDT, 09:00 EDT, 12:00 UTC\n",
                "        ),\n",
                "        \"options\": {\"expires\": 60 * 60 * 3},\n",
                "    },\n",
                "    \"schedule-verify-weekly-organization-reports\": {\n",
                "        \"task\": \"sentry.tasks.reports.verify_prepare_reports\",\n",
                "        \"schedule\": crontab(\n",
                "            minute=0, hour=12, day_of_week=\"tuesday\"  # 05:00 PDT, 09:00 EDT, 12:00 UTC\n",
                "        ),\n",
                "        \"options\": {\"expires\": 60 * 60},\n",
                "    },\n",
                "    \"schedule-vsts-integration-subscription-check\": {\n",
                "        \"task\": \"sentry.tasks.integrations.kickoff_vsts_subscription_check\",\n",
                "        \"schedule\": crontab_with_minute_jitter(hour=\"*/6\"),\n",
                "        \"options\": {\"expires\": 60 * 25},\n",
                "    },\n",
                "    \"monitor-release-adoption\": {\n",
                "        \"task\": \"sentry.release_health.tasks.monitor_release_adoption\",\n",
                "        \"schedule\": crontab(minute=0),\n",
                "        \"options\": {\"expires\": 3600, \"queue\": \"releasemonitor\"},\n",
                "    },\n",
                "    \"fetch-release-registry-data\": {\n",
                "        \"task\": \"sentry.tasks.release_registry.fetch_release_registry_data\",\n",
                "        \"schedule\": timedelta(minutes=5),\n",
                "        \"options\": {\"expires\": 3600},\n",
                "    },\n",
                "    \"fetch-appstore-builds\": {\n",
                "        \"task\": \"sentry.tasks.app_store_connect.refresh_all_builds\",\n",
                "        \"schedule\": timedelta(hours=1),\n",
                "        \"options\": {\"expires\": 3600},\n",
                "    },\n",
                "    \"snuba-subscription-checker\": {\n",
                "        \"task\": \"sentry.snuba.tasks.subscription_checker\",\n",
                "        \"schedule\": timedelta(minutes=20),\n",
                "        \"options\": {\"expires\": 20 * 60},\n",
                "    },\n",
                "}\n",
                "\n",
                "BGTASKS = {\n",
                "    \"sentry.bgtasks.clean_dsymcache:clean_dsymcache\": {\"interval\": 5 * 60, \"roles\": [\"worker\"]},\n",
                "    \"sentry.bgtasks.clean_releasefilecache:clean_releasefilecache\": {\n",
                "        \"interval\": 5 * 60,\n",
                "        \"roles\": [\"worker\"],\n",
                "    },\n",
                "}\n",
                "\n",
                "# Sentry logs to two major places: stdout, and it's internal project.\n",
                "# To disable logging to the internal project, add a logger who's only\n",
                "# handler is 'console' and disable propagating upwards.\n",
                "# Additionally, Sentry has the ability to override logger levels by\n",
                "# providing the cli with -l/--loglevel or the SENTRY_LOG_LEVEL env var.\n",
                "# The loggers that it overrides are root and any in LOGGING.overridable.\n",
                "# Be very careful with this in a production system, because the celery\n",
                "# logger can be extremely verbose when given INFO or DEBUG.\n",
                "LOGGING = {\n",
                "    \"default_level\": \"INFO\",\n",
                "    \"version\": 1,\n",
                "    \"disable_existing_loggers\": True,\n",
                "    \"handlers\": {\n",
                "        \"null\": {\"class\": \"logging.NullHandler\"},\n",
                "        \"console\": {\"class\": \"sentry.logging.handlers.StructLogHandler\"},\n",
                "        \"internal\": {\"level\": \"ERROR\", \"class\": \"sentry_sdk.integrations.logging.EventHandler\"},\n",
                "        \"metrics\": {\n",
                "            \"level\": \"WARNING\",\n",
                "            \"filters\": [\"important_django_request\"],\n",
                "            \"class\": \"sentry.logging.handlers.MetricsLogHandler\",\n",
                "        },\n",
                "        \"django_internal\": {\n",
                "            \"level\": \"WARNING\",\n",
                "            \"filters\": [\"important_django_request\"],\n",
                "            \"class\": \"sentry_sdk.integrations.logging.EventHandler\",\n",
                "        },\n",
                "    },\n",
                "    \"filters\": {\n",
                "        \"important_django_request\": {\n",
                "            \"()\": \"sentry.logging.handlers.MessageContainsFilter\",\n",
                "            \"contains\": [\"CSRF\"],\n",
                "        }\n",
                "    },\n",
                "    \"root\": {\"level\": \"NOTSET\", \"handlers\": [\"console\", \"internal\"]},\n",
                "    # LOGGING.overridable is a list of loggers including root that will change\n",
                "    # based on the overridden level defined above.\n",
                "    \"overridable\": [\"celery\", \"sentry\"],\n",
                "    \"loggers\": {\n",
                "        \"celery\": {\"level\": \"WARNING\"},\n",
                "        \"sentry\": {\"level\": \"INFO\"},\n",
                "        \"sentry_plugins\": {\"level\": \"INFO\"},\n",
                "        \"sentry.files\": {\"level\": \"WARNING\"},\n",
                "        \"sentry.minidumps\": {\"handlers\": [\"internal\"], \"propagate\": False},\n",
                "        \"sentry.reprocessing\": {\"handlers\": [\"internal\"], \"propagate\": False},\n",
                "        \"sentry.interfaces\": {\"handlers\": [\"internal\"], \"propagate\": False},\n",
                "        # This only needs to go to Sentry for now.\n",
                "        \"sentry.similarity\": {\"handlers\": [\"internal\"], \"propagate\": False},\n",
                "        \"sentry.errors\": {\"handlers\": [\"console\"], \"propagate\": False},\n",
                "        \"sentry_sdk.errors\": {\"handlers\": [\"console\"], \"level\": \"INFO\", \"propagate\": False},\n",
                "        \"sentry.rules\": {\"handlers\": [\"console\"], \"propagate\": False},\n",
                "        \"multiprocessing\": {\n",
                "            \"handlers\": [\"console\"],\n",
                "            # https://github.com/celery/celery/commit/597a6b1f3359065ff6dbabce7237f86b866313df\n",
                "            # This commit has not been rolled into any release and leads to a\n",
                "            # large amount of errors when working with postgres.\n",
                "            \"level\": \"CRITICAL\",\n",
                "            \"propagate\": False,\n",
                "        },\n",
                "        \"celery.worker.job\": {\"handlers\": [\"console\"], \"propagate\": False},\n",
                "        \"static_compiler\": {\"level\": \"INFO\"},\n",
                "        \"django.request\": {\n",
                "            \"level\": \"WARNING\",\n",
                "            \"handlers\": [\"console\", \"metrics\", \"django_internal\"],\n",
                "            \"propagate\": False,\n",
                "        },\n",
                "        \"toronado\": {\"level\": \"ERROR\", \"handlers\": [\"null\"], \"propagate\": False},\n",
                "        \"urllib3.connectionpool\": {\"level\": \"ERROR\", \"handlers\": [\"console\"], \"propagate\": False},\n",
                "        \"boto3\": {\"level\": \"WARNING\", \"handlers\": [\"console\"], \"propagate\": False},\n",
                "        \"botocore\": {\"level\": \"WARNING\", \"handlers\": [\"console\"], \"propagate\": False},\n",
                "    },\n",
                "}\n",
                "\n",
                "# django-rest-framework\n",
                "\n",
                "REST_FRAMEWORK = {\n",
                "    \"DEFAULT_RENDERER_CLASSES\": [\"rest_framework.renderers.JSONRenderer\"],\n",
                "    \"DEFAULT_PARSER_CLASSES\": [\n",
                "        \"rest_framework.parsers.JSONParser\",\n",
                "        \"rest_framework.parsers.MultiPartParser\",\n",
                "        \"rest_framework.parsers.FormParser\",\n",
                "    ],\n",
                "    \"TEST_REQUEST_DEFAULT_FORMAT\": \"json\",\n",
                "    \"DEFAULT_PERMISSION_CLASSES\": (\"sentry.api.permissions.NoPermission\",),\n",
                "    \"EXCEPTION_HANDLER\": \"sentry.api.handlers.custom_exception_handler\",\n",
                "    \"DEFAULT_SCHEMA_CLASS\": \"drf_spectacular.openapi.AutoSchema\",\n",
                "}\n",
                "\n",
                "\n",
                "if os.environ.get(\"OPENAPIGENERATE\", False):\n",
                "    OLD_OPENAPI_JSON_PATH = \"tests/apidocs/openapi-deprecated.json\"\n",
                "    from sentry.apidocs.build import OPENAPI_TAGS, get_old_json_paths\n",
                "\n",
                "    SPECTACULAR_SETTINGS = {\n",
                "        \"PREPROCESSING_HOOKS\": [\"sentry.apidocs.hooks.custom_preprocessing_hook\"],\n",
                "        \"POSTPROCESSING_HOOKS\": [\"sentry.apidocs.hooks.custom_postprocessing_hook\"],\n",
                "        \"DISABLE_ERRORS_AND_WARNINGS\": False,\n",
                "        \"COMPONENT_SPLIT_REQUEST\": False,\n",
                "        \"COMPONENT_SPLIT_PATCH\": False,\n",
                "        \"AUTHENTICATION_WHITELIST\": [\"sentry.api.authentication.TokenAuthentication\"],\n",
                "        \"TAGS\": OPENAPI_TAGS,\n",
                "        \"TITLE\": \"API Reference\",\n",
                "        \"DESCRIPTION\": \"Sentry Public API\",\n",
                "        \"TOS\": \"http://sentry.io/terms/\",\n",
                "        \"CONTACT\": {\"email\": \"partners@sentry.io\"},\n",
                "        \"LICENSE\": {\"name\": \"Apache 2.0\", \"url\": \"http://www.apache.org/licenses/LICENSE-2.0.html\"},\n",
                "        \"VERSION\": \"v0\",\n",
                "        \"SERVERS\": [{\"url\": \"https://sentry.io/\"}],\n",
                "        \"PARSER_WHITELIST\": [\"rest_framework.parsers.JSONParser\"],\n",
                "        \"APPEND_PATHS\": get_old_json_paths(OLD_OPENAPI_JSON_PATH),\n",
                "        \"SORT_OPERATION_PARAMETERS\": False,\n",
                "    }\n",
                "\n",
                "CRISPY_TEMPLATE_PACK = \"bootstrap3\"\n",
                "# Sentry and internal client configuration\n",
                "\n",
                "SENTRY_FEATURES = {\n",
                "    # Enables user registration.\n",
                "    \"auth:register\": True,\n",
                "    # Workflow 2.0 Experimental ReleaseMembers who opt-in to get notified as a release committer\n",
                "    \"organizations:active-release-notification-opt-in\": False,\n",
                "    # Enable advanced search features, like negation and wildcard matching.\n",
                "    \"organizations:advanced-search\": True,\n",
                "    # Use metrics as the dataset for crash free metric alerts\n",
                "    \"organizations:alert-crash-free-metrics\": False,\n",
                "    # Workflow 2.0 notifications following a release\n",
                "    \"organizations:alert-release-notification-workflow\": False,\n",
                "    # Alert wizard redesign version 3\n",
                "    \"organizations:alert-wizard-v3\": True,\n",
                "    \"organizations:api-keys\": False,\n",
                "    # Enable multiple Apple app-store-connect sources per project.\n",
                "    \"organizations:app-store-connect-multiple\": False,\n",
                "    # Enable the linked event feature in the issue details breadcrumb.\n",
                "    \"organizations:breadcrumb-linked-event\": False,\n",
                "    # Enable change alerts for an org\n",
                "    \"organizations:change-alerts\": True,\n",
                "    # Enable alerting based on crash free sessions/users\n",
                "    \"organizations:crash-rate-alerts\": True,\n",
                "    # Enable creating organizations within sentry (if SENTRY_SINGLE_ORGANIZATION\n",
                "    # is not enabled).\n",
                "    \"organizations:create\": True,\n",
                "    # Enable the 'discover' interface.\n",
                "    \"organizations:discover\": False,\n",
                "    # Enables events endpoint usage on discover and dashboards frontend\n",
                "    \"organizations:discover-frontend-use-events-endpoint\": True,\n",
                "    # Enables events endpoint usage on performance frontend\n",
                "    \"organizations:performance-frontend-use-events-endpoint\": True,\n",
                "    # Enables events endpoint rate limit\n",
                "    \"organizations:discover-events-rate-limit\": False,\n",
                "    # Enable duplicating alert rules.\n",
                "    \"organizations:duplicate-alert-rule\": True,\n",
                "    # Enable attaching arbitrary files to events.\n",
                "    \"organizations:event-attachments\": True,\n",
                "    # Enable Filters & Sampling in the project settings\n",
                "    \"organizations:filters-and-sampling\": False,\n",
                "    # Allow organizations to configure all symbol sources.\n",
                "    \"organizations:symbol-sources\": True,\n",
                "    # Allow organizations to configure custom external symbol sources.\n",
                "    \"organizations:custom-symbol-sources\": True,\n",
                "    # Enable discover 2 basic functions\n",
                "    \"organizations:discover-basic\": True,\n",
                "    # Enable discover 2 custom queries and saved queries\n",
                "    \"organizations:discover-query\": True,\n",
                "    # Allows an org to have a larger set of project ownership rules per project\n",
                "    \"organizations:higher-ownership-limit\": False,\n",
                "    # Enable Performance view\n",
                "    \"organizations:performance-view\": True,\n",
                "    # Enable profiling\n",
                "    \"organizations:profiling\": False,\n",
                "    # Enable multi project selection\n",
                "    \"organizations:global-views\": False,\n",
                "    # Enable experimental new version of Merged Issues where sub-hashes are shown\n",
                "    \"organizations:grouping-tree-ui\": False,\n",
                "    # Enable experimental new version of stacktrace component where additional\n",
                "    # data related to grouping is shown on each frame\n",
                "    \"organizations:grouping-stacktrace-ui\": False,\n",
                "    # Enable tweaks to group title in relation to hierarchical\n",
                "    # grouping.\n",
                "    \"organizations:grouping-title-ui\": False,\n",
                "    # Lets organizations manage grouping configs\n",
                "    \"organizations:set-grouping-config\": False,\n",
                "    # Lets organizations set a custom title through fingerprinting\n",
                "    \"organizations:custom-event-title\": True,\n",
                "    # Enable rule page.\n",
                "    \"organizations:rule-page\": False,\n",
                "    # Enable incidents feature\n",
                "    \"organizations:incidents\": False,\n",
                "    # Enable having the issue ID in the breadcrumbs on Issue Details\n",
                "    \"organizations:issue-id-breadcrumbs\": False,\n",
                "    # Flags for enabling CdcEventsDatasetSnubaSearchBackend in sentry.io. No effect in open-source\n",
                "    # sentry at the moment.\n",
                "    \"organizations:issue-search-use-cdc-primary\": False,\n",
                "    \"organizations:issue-search-use-cdc-secondary\": False,\n",
                "    # Enable metrics feature on the backend\n",
                "    \"organizations:metrics\": False,\n",
                "    # Enable metric alert charts in email/slack\n",
                "    \"organizations:metric-alert-chartcuterie\": False,\n",
                "    # Enable the new widget builder experience on Dashboards\n",
                "    \"organizations:new-widget-builder-experience\": False,\n",
                "    # Enable the new widget builder experience \"design\" on Dashboards\n",
                "    \"organizations:new-widget-builder-experience-design\": False,\n",
                "    # Enable access to the Add to Dashboard modal for metrics work\n",
                "    \"organizations:new-widget-builder-experience-modal-access\": False,\n",
                "    # Automatically extract metrics during ingestion.\n",
                "    #\n",
                "    # XXX(ja): DO NOT ENABLE UNTIL THIS NOTICE IS GONE. Relay experiences\n",
                "    # gradual slowdown when this is enabled for too many projects.\n",
                "    \"organizations:metrics-extraction\": False,\n",
                "    # Enable switch metrics button on Performance, allowing switch to unsampled transaction metrics\n",
                "    \"organizations:metrics-performance-ui\": False,\n",
                "    # True if release-health related queries should be run against both\n",
                "    # backends (sessions and metrics dataset)\n",
                "    \"organizations:release-health-check-metrics\": False,\n",
                "    # True if differences between the metrics and sessions backend should be reported\n",
                "    \"organizations:release-health-check-metrics-report\": False,\n",
                "    # True if the metrics data should be returned as API response (if possible with current data)\n",
                "    \"organizations:release-health-return-metrics\": False,\n",
                "    # Enable threshold period in metric alert rule builder\n",
                "    \"organizations:metric-alert-threshold-period\": False,\n",
                "    # Enable integration functionality to create and link groups to issues on\n",
                "    # external services.\n",
                "    \"organizations:integrations-issue-basic\": True,\n",
                "    # Enable interface functionality to synchronize groups between sentry and\n",
                "    # issues on external services.\n",
                "    \"organizations:integrations-issue-sync\": True,\n",
                "    # Enable interface functionality to receive event hooks.\n",
                "    \"organizations:integrations-event-hooks\": True,\n",
                "    # Enable integration functionality to work with alert rules\n",
                "    \"organizations:integrations-alert-rule\": True,\n",
                "    # Enable integration functionality to work with alert rules (specifically chat integrations)\n",
                "    \"organizations:integrations-chat-unfurl\": True,\n",
                "    # Enable integration functionality to work with alert rules (specifically incident\n",
                "    # management integrations)\n",
                "    \"organizations:integrations-incident-management\": True,\n",
                "    # Allow orgs to automatically create Tickets in Issue Alerts\n",
                "    \"organizations:integrations-ticket-rules\": True,\n",
                "    # Allow orgs to use the stacktrace linking feature\n",
                "    \"organizations:integrations-stacktrace-link\": False,\n",
                "    # Allow orgs to install a custom source code management integration\n",
                "    \"organizations:integrations-custom-scm\": False,\n",
                "    # Limit project events endpoint to only query back a certain number of days\n",
                "    \"organizations:project-event-date-limit\": False,\n",
                "    # Enable data forwarding functionality for organizations.\n",
                "    \"organizations:data-forwarding\": True,\n",
                "    # Enable react-grid-layout dashboards\n",
                "    \"organizations:dashboard-grid-layout\": False,\n",
                "    # Enable readonly dashboards\n",
                "    \"organizations:dashboards-basic\": True,\n",
                "    # Enable custom editable dashboards\n",
                "    \"organizations:dashboards-edit\": True,\n",
                "    # Enable dashboard widget library\n",
                "    \"organizations:widget-library\": False,\n",
                "    # Enable metrics enhanced performance in dashboards\n",
                "    \"organizations:dashboards-mep\": False,\n",
                "    # Enable release health widgets in dashboards\n",
                "    \"organizations:dashboards-releases\": False,\n",
                "    # Enable top level query filters in dashboards\n",
                "    \"organizations:dashboards-top-level-filter\": False,\n",
                "    # Enables usage of custom measurements in dashboard widgets\n",
                "    \"organizations:dashboard-custom-measurement-widgets\": False,\n",
                "    # Enable widget viewer modal in dashboards\n",
                "    \"organizations:widget-viewer-modal\": False,\n",
                "    # Enable minimap in the widget viewer modal in dashboards\n",
                "    \"organizations:widget-viewer-modal-minimap\": False,\n",
                "    # Enable experimental performance improvements.\n",
                "    \"organizations:enterprise-perf\": False,\n",
                "    # Enable the API to importing CODEOWNERS for a project\n",
                "    \"organizations:integrations-codeowners\": False,\n",
                "    # Enable inviting members to organizations.\n",
                "    \"organizations:invite-members\": True,\n",
                "    # Enable rate limits for inviting members.\n",
                "    \"organizations:invite-members-rate-limits\": True,\n",
                "    # Enable removing issue from issue list if action taken.\n",
                "    \"organizations:issue-list-removal-action\": False,\n",
                "    # Prefix host with organization ID when giving users DSNs (can be\n",
                "    # customized with SENTRY_ORG_SUBDOMAIN_TEMPLATE)\n",
                "    \"organizations:org-subdomains\": False,\n",
                "    # Enable views for ops breakdown\n",
                "    \"organizations:performance-ops-breakdown\": False,\n",
                "    # Enable interpolation of null data points in charts instead of zerofilling in performance\n",
                "    \"organizations:performance-chart-interpolation\": False,\n",
                "    # Enable views for suspect tags\n",
                "    \"organizations:performance-suspect-spans-view\": False,\n",
                "    # Enable views for anomaly detection\n",
                "    \"organizations:performance-anomaly-detection-ui\": False,\n",
                "    # Enable histogram view in span details\n",
                "    \"organizations:performance-span-histogram-view\": False,\n",
                "    # Enable autogrouping of sibling spans\n",
                "    \"organizations:performance-autogroup-sibling-spans\": False,\n",
                "    # Enable performance on-boarding checklist\n",
                "    \"organizations:performance-onboarding-checklist\": False,\n",
                "    # Enable automatic horizontal scrolling on the span tree\n",
                "    \"organizations:performance-span-tree-autoscroll\": False,\n",
                "    # Enable transaction name only search\n",
                "    \"organizations:performance-transaction-name-only-search\": False,\n",
                "    # Enable performance issue view\n",
                "    \"organizations:performance-extraneous-spans-poc\": False,\n",
                "    # Enable the new Related Events feature\n",
                "    \"organizations:related-events\": False,\n",
                "    # Enable usage of external relays, for use with Relay. See\n",
                "    # https://github.com/getsentry/relay.\n",
                "    \"organizations:relay\": True,\n",
                "    # Enable experimental session replay features\n",
                "    \"organizations:session-replay\": False,\n",
                "    # Enable Session Stats down to a minute resolution\n",
                "    \"organizations:minute-resolution-sessions\": True,\n",
                "    # Notify all project members when fallthrough is disabled, instead of just the auto-assignee\n",
                "    \"organizations:notification-all-recipients\": False,\n",
                "    # Enable the new native stack trace design\n",
                "    \"organizations:native-stack-trace-v2\": False,\n",
                "    # Enable version 2 of reprocessing (completely distinct from v1)\n",
                "    \"organizations:reprocessing-v2\": False,\n",
                "    # Enable the UI for the overage alert settings\n",
                "    \"organizations:slack-overage-notifications\": False,\n",
                "    # Enable basic SSO functionality, providing configurable single sign on\n",
                "    # using services like GitHub / Google. This is *not* the same as the signup\n",
                "    # and login with Github / Azure DevOps that sentry.io provides.\n",
                "    \"organizations:sso-basic\": True,\n",
                "    # Enable SAML2 based SSO functionality. getsentry/sentry-auth-saml2 plugin\n",
                "    # must be installed to use this functionality.\n",
                "    \"organizations:sso-saml2\": True,\n",
                "    # Enable new server-side sampling UI in the project settings\n",
                "    \"organizations:server-side-sampling\": False,\n",
                "    # Enable the new images loaded design and features\n",
                "    \"organizations:images-loaded-v2\": True,\n",
                "    # Enable the mobile screenshots feature\n",
                "    \"organizations:mobile-screenshots\": False,\n",
                "    # Enable the release details performance section\n",
                "    \"organizations:release-comparison-performance\": False,\n",
                "    # Enable team insights page\n",
                "    \"organizations:team-insights\": True,\n",
                "    # Enable setting team-level roles and receiving permissions from them\n",
                "    \"organizations:team-roles\": False,\n",
                "    # Adds additional filters and a new section to issue alert rules.\n",
                "    \"projects:alert-filters\": True,\n",
                "    # Enable functionality to specify custom inbound filters on events.\n",
                "    \"projects:custom-inbound-filters\": False,\n",
                "    # Enable data forwarding functionality for projects.\n",
                "    \"projects:data-forwarding\": True,\n",
                "    # Enable functionality to discard groups.\n",
                "    \"projects:discard-groups\": False,\n",
                "    # DEPRECATED: pending removal\n",
                "    \"projects:dsym\": False,\n",
                "    # Enable selection of members, teams or code owners as email targets for issue alerts.\n",
                "    \"projects:issue-alerts-targeting\": True,\n",
                "    # Enable functionality for attaching  minidumps to events and displaying\n",
                "    # then in the group UI.\n",
                "    \"projects:minidump\": True,\n",
                "    # Enable ingestion for suspect spans\n",
                "    \"projects:performance-suspect-spans-ingestion\": False,\n",
                "    # Enable functionality for project plugins.\n",
                "    \"projects:plugins\": True,\n",
                "    # Enable alternative version of group creation that is supposed to be less racy.\n",
                "    \"projects:race-free-group-creation\": True,\n",
                "    # Enable functionality for rate-limiting events on projects.\n",
                "    \"projects:rate-limits\": True,\n",
                "    # Enable functionality to trigger service hooks upon event ingestion.\n",
                "    \"projects:servicehooks\": False,\n",
                "    # Use Kafka (instead of Celery) for ingestion pipeline.\n",
                "    \"projects:kafka-ingest\": False,\n",
                "    # Automatically opt IN users to receiving Slack notifications.\n",
                "    \"users:notification-slack-automatic\": False,\n",
                "    # Don't add feature defaults down here! Please add them in their associated\n",
                "    # group sorted alphabetically.\n",
                "}\n",
                "\n",
                "# Default time zone for localization in the UI.\n",
                "# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name\n",
                "SENTRY_DEFAULT_TIME_ZONE = \"UTC\"\n",
                "\n",
                "SENTRY_DEFAULT_LANGUAGE = \"en\"\n",
                "\n",
                "# Enable the Sentry Debugger (Beta)\n",
                "SENTRY_DEBUGGER = None\n",
                "\n",
                "SENTRY_IGNORE_EXCEPTIONS = (\"OperationalError\",)\n",
                "\n",
                "# Should we send the beacon to the upstream server?\n",
                "SENTRY_BEACON = True\n",
                "\n",
                "# Allow access to Sentry without authentication.\n",
                "SENTRY_PUBLIC = False\n",
                "\n",
                "# Instruct Sentry that this install intends to be run by a single organization\n",
                "# and thus various UI optimizations should be enabled.\n",
                "SENTRY_SINGLE_ORGANIZATION = False\n",
                "\n",
                "# Login url (defaults to LOGIN_URL)\n",
                "SENTRY_LOGIN_URL = None\n",
                "\n",
                "# Default project ID (for internal errors)\n",
                "SENTRY_PROJECT = 1\n",
                "SENTRY_PROJECT_KEY = None\n",
                "\n",
                "# Default organization to represent the Internal Sentry project.\n",
                "# Used as a default when in SINGLE_ORGANIZATION mode.\n",
                "SENTRY_ORGANIZATION = None\n",
                "\n",
                "# Project ID for recording frontend (javascript) exceptions\n",
                "SENTRY_FRONTEND_PROJECT = None\n",
                "# DSN for the frontend to use explicitly, which takes priority\n",
                "# over SENTRY_FRONTEND_PROJECT or SENTRY_PROJECT\n",
                "SENTRY_FRONTEND_DSN = None\n",
                "# DSN for tracking all client HTTP requests (which can be noisy) [experimental]\n",
                "SENTRY_FRONTEND_REQUESTS_DSN = None\n",
                "\n",
                "# Configuration for JavaScript's whitelistUrls - defaults to ALLOWED_HOSTS\n",
                "SENTRY_FRONTEND_WHITELIST_URLS = None\n",
                "\n",
                "# ----\n",
                "# APM config\n",
                "# ----\n",
                "\n",
                "# sample rate for transactions initiated from the frontend\n",
                "SENTRY_FRONTEND_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for transactions in the backend\n",
                "SENTRY_BACKEND_APM_SAMPLING = 0\n",
                "\n",
                "# Sample rate for symbolicate_event task transactions\n",
                "SENTRY_SYMBOLICATE_EVENT_APM_SAMPLING = 0\n",
                "\n",
                "# Sample rate for the process_event task transactions\n",
                "SENTRY_PROCESS_EVENT_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for the relay projectconfig endpoint\n",
                "SENTRY_RELAY_ENDPOINT_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for relay's cache invalidation task\n",
                "SENTRY_RELAY_TASK_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for ingest consumer processing functions\n",
                "SENTRY_INGEST_CONSUMER_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for Apple App Store Connect tasks transactions\n",
                "SENTRY_APPCONNECT_APM_SAMPLING = SENTRY_BACKEND_APM_SAMPLING\n",
                "\n",
                "# sample rate for suspect commits task\n",
                "SENTRY_SUSPECT_COMMITS_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for post_process_group task\n",
                "SENTRY_POST_PROCESS_GROUP_APM_SAMPLING = 0\n",
                "\n",
                "# sample rate for all reprocessing tasks (except for the per-event ones)\n",
                "SENTRY_REPROCESSING_APM_SAMPLING = 0\n",
                "\n",
                "# ----\n",
                "# end APM config\n",
                "# ----\n",
                "\n",
                "# DSN to use for Sentry monitors\n",
                "SENTRY_MONITOR_DSN = None\n",
                "SENTRY_MONITOR_API_ROOT = None\n",
                "SENTRY_CELERYBEAT_MONITORS = {\n",
                "    # 'scheduled-name': 'monitor_guid',\n",
                "}\n",
                "\n",
                "# Web Service\n",
                "SENTRY_WEB_HOST = \"127.0.0.1\"\n",
                "SENTRY_WEB_PORT = 9000\n",
                "SENTRY_WEB_OPTIONS = {}\n",
                "\n",
                "# SMTP Service\n",
                "SENTRY_SMTP_HOST = \"127.0.0.1\"\n",
                "SENTRY_SMTP_PORT = 1025\n",
                "\n",
                "SENTRY_INTERFACES = {\n",
                "    \"csp\": \"sentry.interfaces.security.Csp\",\n",
                "    \"hpkp\": \"sentry.interfaces.security.Hpkp\",\n",
                "    \"expectct\": \"sentry.interfaces.security.ExpectCT\",\n",
                "    \"expectstaple\": \"sentry.interfaces.security.ExpectStaple\",\n",
                "    \"exception\": \"sentry.interfaces.exception.Exception\",\n",
                "    \"logentry\": \"sentry.interfaces.message.Message\",\n",
                "    \"request\": \"sentry.interfaces.http.Http\",\n",
                "    \"sdk\": \"sentry.interfaces.sdk.Sdk\",\n",
                "    \"stacktrace\": \"sentry.interfaces.stacktrace.Stacktrace\",\n",
                "    \"template\": \"sentry.interfaces.template.Template\",\n",
                "    \"user\": \"sentry.interfaces.user.User\",\n",
                "    \"breadcrumbs\": \"sentry.interfaces.breadcrumbs.Breadcrumbs\",\n",
                "    \"contexts\": \"sentry.interfaces.contexts.Contexts\",\n",
                "    \"threads\": \"sentry.interfaces.threads.Threads\",\n",
                "    \"debug_meta\": \"sentry.interfaces.debug_meta.DebugMeta\",\n",
                "    \"spans\": \"sentry.interfaces.spans.Spans\",\n",
                "}\n",
                "PREFER_CANONICAL_LEGACY_KEYS = False\n",
                "\n",
                "SENTRY_EMAIL_BACKEND_ALIASES = {\n",
                "    \"smtp\": \"django.core.mail.backends.smtp.EmailBackend\",\n",
                "    \"dummy\": \"django.core.mail.backends.dummy.EmailBackend\",\n",
                "    \"console\": \"django.core.mail.backends.console.EmailBackend\",\n",
                "    \"preview\": \"sentry.utils.email.PreviewBackend\",\n",
                "}\n",
                "\n",
                "SENTRY_FILESTORE_ALIASES = {\n",
                "    \"filesystem\": \"django.core.files.storage.FileSystemStorage\",\n",
                "    \"s3\": \"sentry.filestore.s3.S3Boto3Storage\",\n",
                "    \"gcs\": \"sentry.filestore.gcs.GoogleCloudStorage\",\n",
                "}\n",
                "\n",
                "SENTRY_ANALYTICS_ALIASES = {\n",
                "    \"noop\": \"sentry.analytics.Analytics\",\n",
                "    \"pubsub\": \"sentry.analytics.pubsub.PubSubAnalytics\",\n",
                "}\n",
                "\n",
                "# set of backends that do not support needing SMTP mail.* settings\n",
                "# This list is a bit fragile and hardcoded, but it's unlikely that\n",
                "# a user will be using a different backend that also mandates SMTP\n",
                "# credentials.\n",
                "SENTRY_SMTP_DISABLED_BACKENDS = frozenset(\n",
                "    (\n",
                "        \"django.core.mail.backends.dummy.EmailBackend\",\n",
                "        \"django.core.mail.backends.console.EmailBackend\",\n",
                "        \"django.core.mail.backends.locmem.EmailBackend\",\n",
                "        \"django.core.mail.backends.filebased.EmailBackend\",\n",
                "        \"sentry.utils.email.PreviewBackend\",\n",
                "    )\n",
                ")\n",
                "\n",
                "# Should users without superuser permissions be allowed to\n",
                "# make projects public\n",
                "SENTRY_ALLOW_PUBLIC_PROJECTS = True\n",
                "\n",
                "# Will an invite be sent when a member is added to an organization?\n",
                "SENTRY_ENABLE_INVITES = True\n",
                "\n",
                "# Origins allowed for session-based API access (via the Access-Control-Allow-Origin header)\n",
                "SENTRY_ALLOW_ORIGIN = None\n",
                "\n",
                "# Buffer backend\n",
                "SENTRY_BUFFER = \"sentry.buffer.Buffer\"\n",
                "SENTRY_BUFFER_OPTIONS = {}\n",
                "\n",
                "# Cache backend\n",
                "# XXX: We explicitly require the cache to be configured as its not optional\n",
                "# and causes serious confusion with the default django cache\n",
                "SENTRY_CACHE = None\n",
                "SENTRY_CACHE_OPTIONS = {}\n",
                "\n",
                "# Attachment blob cache backend\n",
                "SENTRY_ATTACHMENTS = \"sentry.attachments.default.DefaultAttachmentCache\"\n",
                "SENTRY_ATTACHMENTS_OPTIONS = {}\n",
                "\n",
                "# Events blobs processing backend\n",
                "SENTRY_EVENT_PROCESSING_STORE = \"sentry.eventstore.processing.default.DefaultEventProcessingStore\"\n",
                "SENTRY_EVENT_PROCESSING_STORE_OPTIONS = {}\n",
                "\n",
                "# The internal Django cache is still used in many places\n",
                "# TODO(dcramer): convert uses over to Sentry's backend\n",
                "CACHES = {\"default\": {\"BACKEND\": \"django.core.cache.backends.dummy.DummyCache\"}}\n",
                "\n",
                "# The cache version affects both Django's internal cache (at runtime) as well\n",
                "# as Sentry's cache. This automatically overrides VERSION on the default\n",
                "# CACHES backend.\n",
                "CACHE_VERSION = 1\n",
                "\n",
                "# Digests backend\n",
                "SENTRY_DIGESTS = \"sentry.digests.backends.dummy.DummyBackend\"\n",
                "SENTRY_DIGESTS_OPTIONS = {}\n",
                "\n",
                "# Quota backend\n",
                "SENTRY_QUOTAS = \"sentry.quotas.Quota\"\n",
                "SENTRY_QUOTA_OPTIONS = {}\n",
                "\n",
                "# Cache for Relay project configs\n",
                "SENTRY_RELAY_PROJECTCONFIG_CACHE = \"sentry.relay.projectconfig_cache.redis.RedisProjectConfigCache\"\n",
                "SENTRY_RELAY_PROJECTCONFIG_CACHE_OPTIONS = {}\n",
                "\n",
                "# Which cache to use for debouncing cache updates to the projectconfig cache\n",
                "SENTRY_RELAY_PROJECTCONFIG_DEBOUNCE_CACHE = (\n",
                "    \"sentry.relay.projectconfig_debounce_cache.base.ProjectConfigDebounceCache\"\n",
                ")\n",
                "SENTRY_RELAY_PROJECTCONFIG_DEBOUNCE_CACHE_OPTIONS = {}\n",
                "\n",
                "# Rate limiting backend\n",
                "SENTRY_RATELIMITER = \"sentry.ratelimits.base.RateLimiter\"\n",
                "SENTRY_RATELIMITER_ENABLED = False\n",
                "SENTRY_RATELIMITER_OPTIONS = {}\n",
                "SENTRY_RATELIMITER_DEFAULT = 999\n",
                "SENTRY_CONCURRENT_RATE_LIMIT_DEFAULT = 999\n",
                "ENFORCE_CONCURRENT_RATE_LIMITS = False\n",
                "\n",
                "# Rate Limit Group Category Defaults\n",
                "SENTRY_CONCURRENT_RATE_LIMIT_GROUP_CLI = 999\n",
                "SENTRY_RATELIMITER_GROUP_CLI = 999\n",
                "\n",
                "# The default value for project-level quotas\n",
                "SENTRY_DEFAULT_MAX_EVENTS_PER_MINUTE = \"90%\"\n",
                "\n",
                "# Snuba configuration\n",
                "SENTRY_SNUBA = os.environ.get(\"SNUBA\", \"http://127.0.0.1:1218\")\n",
                "SENTRY_SNUBA_TIMEOUT = 30\n",
                "SENTRY_SNUBA_CACHE_TTL_SECONDS = 60\n",
                "\n",
                "# Node storage backend\n",
                "SENTRY_NODESTORE = \"sentry.nodestore.django.DjangoNodeStorage\"\n",
                "SENTRY_NODESTORE_OPTIONS = {}\n",
                "\n",
                "# Tag storage backend\n",
                "SENTRY_TAGSTORE = os.environ.get(\"SENTRY_TAGSTORE\", \"sentry.tagstore.snuba.SnubaTagStorage\")\n",
                "SENTRY_TAGSTORE_OPTIONS = {}\n",
                "\n",
                "# Search backend\n",
                "SENTRY_SEARCH = os.environ.get(\n",
                "    \"SENTRY_SEARCH\", \"sentry.search.snuba.EventsDatasetSnubaSearchBackend\"\n",
                ")\n",
                "SENTRY_SEARCH_OPTIONS = {}\n",
                "# SENTRY_SEARCH_OPTIONS = {\n",
                "#     'urls': ['http://127.0.0.1:9200/'],\n",
                "#     'timeout': 5,\n",
                "# }\n",
                "\n",
                "# Time-series storage backend\n",
                "SENTRY_TSDB = \"sentry.tsdb.dummy.DummyTSDB\"\n",
                "SENTRY_TSDB_OPTIONS = {}\n",
                "\n",
                "SENTRY_NEWSLETTER = \"sentry.newsletter.base.Newsletter\"\n",
                "SENTRY_NEWSLETTER_OPTIONS = {}\n",
                "\n",
                "SENTRY_EVENTSTREAM = \"sentry.eventstream.snuba.SnubaEventStream\"\n",
                "SENTRY_EVENTSTREAM_OPTIONS = {}\n",
                "\n",
                "# rollups must be ordered from highest granularity to lowest\n",
                "SENTRY_TSDB_ROLLUPS = (\n",
                "    # (time in seconds, samples to keep)\n",
                "    (10, 360),  # 60 minutes at 10 seconds\n",
                "    (3600, 24 * 7),  # 7 days at 1 hour\n",
                "    (3600 * 24, 90),  # 90 days at 1 day\n",
                ")\n",
                "\n",
                "# Internal metrics\n",
                "SENTRY_METRICS_BACKEND = \"sentry.metrics.dummy.DummyMetricsBackend\"\n",
                "SENTRY_METRICS_OPTIONS = {}\n",
                "SENTRY_METRICS_SAMPLE_RATE = 1.0\n",
                "SENTRY_METRICS_PREFIX = \"sentry.\"\n",
                "SENTRY_METRICS_SKIP_INTERNAL_PREFIXES = []  # Order this by most frequent prefixes.\n",
                "\n",
                "# Metrics product\n",
                "SENTRY_METRICS_INDEXER = \"sentry.sentry_metrics.indexer.postgres_v2.StaticStringsIndexerDecorator\"\n",
                "SENTRY_METRICS_INDEXER_OPTIONS = {}\n",
                "SENTRY_METRICS_INDEXER_CACHE_TTL = 3600 * 2\n",
                "\n",
                "# Release Health\n",
                "SENTRY_RELEASE_HEALTH = \"sentry.release_health.sessions.SessionsReleaseHealthBackend\"\n",
                "SENTRY_RELEASE_HEALTH_OPTIONS = {}\n",
                "\n",
                "# Release Monitor\n",
                "SENTRY_RELEASE_MONITOR = (\n",
                "    \"sentry.release_health.release_monitor.sessions.SessionReleaseMonitorBackend\"\n",
                ")\n",
                "SENTRY_RELEASE_MONITOR_OPTIONS = {}\n",
                "\n",
                "\n",
                "# Render charts on the backend. This uses the Chartcuterie external service.\n",
                "SENTRY_CHART_RENDERER = \"sentry.charts.chartcuterie.Chartcuterie\"\n",
                "SENTRY_CHART_RENDERER_OPTIONS = {}\n",
                "\n",
                "# URI Prefixes for generating DSN URLs\n",
                "# (Defaults to URL_PREFIX by default)\n",
                "SENTRY_ENDPOINT = None\n",
                "SENTRY_PUBLIC_ENDPOINT = None\n",
                "\n",
                "# Hostname prefix to add for organizations that are opted into the\n",
                "# `organizations:org-subdomains` feature.\n",
                "SENTRY_ORG_SUBDOMAIN_TEMPLATE = \"o{organization_id}.ingest\"\n",
                "\n",
                "# Prevent variables (e.g. context locals, http data, etc) from exceeding this\n",
                "# size in characters\n",
                "SENTRY_MAX_VARIABLE_SIZE = 512\n",
                "\n",
                "# Prevent variables within extra context from exceeding this size in\n",
                "# characters\n",
                "SENTRY_MAX_EXTRA_VARIABLE_SIZE = 4096 * 4  # 16kb\n",
                "\n",
                "# For changing the amount of data seen in Http Response Body part.\n",
                "SENTRY_MAX_HTTP_BODY_SIZE = 4096 * 4  # 16kb\n",
                "\n",
                "# For various attributes we don't limit the entire attribute on size, but the\n",
                "# individual item. In those cases we also want to limit the maximum number of\n",
                "# keys\n",
                "SENTRY_MAX_DICTIONARY_ITEMS = 50\n",
                "\n",
                "SENTRY_MAX_MESSAGE_LENGTH = 1024 * 8\n",
                "\n",
                "# Gravatar service base url\n",
                "SENTRY_GRAVATAR_BASE_URL = \"https://secure.gravatar.com\"\n",
                "\n",
                "# Timeout (in seconds) for fetching remote source files (e.g. JS)\n",
                "SENTRY_SOURCE_FETCH_TIMEOUT = 5\n",
                "\n",
                "# Timeout (in seconds) for socket operations when fetching remote source files\n",
                "SENTRY_SOURCE_FETCH_SOCKET_TIMEOUT = 2\n",
                "\n",
                "# Maximum content length for source files before we abort fetching\n",
                "SENTRY_SOURCE_FETCH_MAX_SIZE = 40 * 1024 * 1024\n",
                "\n",
                "# Maximum content length for cache value.  Currently used only to avoid\n",
                "# pointless compression of sourcemaps and other release files because we\n",
                "# silently fail to cache the compressed result anyway.  Defaults to None which\n",
                "# disables the check and allows different backends for unlimited payload.\n",
                "# e.g. memcached defaults to 1MB  = 1024 * 1024\n",
                "SENTRY_CACHE_MAX_VALUE_SIZE = None\n",
                "\n",
                "# Fields which managed users cannot change via Sentry UI. Username and password\n",
                "# cannot be changed by managed users. Optionally include 'email' and\n",
                "# 'name' in SENTRY_MANAGED_USER_FIELDS.\n",
                "SENTRY_MANAGED_USER_FIELDS = ()\n",
                "\n",
                "SENTRY_SCOPES = {\n",
                "    \"org:read\",\n",
                "    \"org:write\",\n",
                "    \"org:admin\",\n",
                "    \"org:integrations\",\n",
                "    \"member:read\",\n",
                "    \"member:write\",\n",
                "    \"member:admin\",\n",
                "    \"team:read\",\n",
                "    \"team:write\",\n",
                "    \"team:admin\",\n",
                "    \"project:read\",\n",
                "    \"project:write\",\n",
                "    \"project:admin\",\n",
                "    \"project:releases\",\n",
                "    \"event:read\",\n",
                "    \"event:write\",\n",
                "    \"event:admin\",\n",
                "    \"alerts:write\",\n",
                "    \"alerts:read\",\n",
                "}\n",
                "\n",
                "SENTRY_SCOPE_SETS = (\n",
                "    (\n",
                "        (\"org:admin\", \"Read, write, and admin access to organization details.\"),\n",
                "        (\"org:write\", \"Read and write access to organization details.\"),\n",
                "        (\"org:read\", \"Read access to organization details.\"),\n",
                "    ),\n",
                "    ((\"org:integrations\", \"Read, write, and admin access to organization integrations.\"),),\n",
                "    (\n",
                "        (\"member:admin\", \"Read, write, and admin access to organization members.\"),\n",
                "        (\"member:write\", \"Read and write access to organization members.\"),\n",
                "        (\"member:read\", \"Read access to organization members.\"),\n",
                "    ),\n",
                "    (\n",
                "        (\"team:admin\", \"Read, write, and admin access to teams.\"),\n",
                "        (\"team:write\", \"Read and write access to teams.\"),\n",
                "        (\"team:read\", \"Read access to teams.\"),\n",
                "    ),\n",
                "    (\n",
                "        (\"project:admin\", \"Read, write, and admin access to projects.\"),\n",
                "        (\"project:write\", \"Read and write access to projects.\"),\n",
                "        (\"project:read\", \"Read access to projects.\"),\n",
                "    ),\n",
                "    ((\"project:releases\", \"Read, write, and admin access to project releases.\"),),\n",
                "    (\n",
                "        (\"event:admin\", \"Read, write, and admin access to events.\"),\n",
                "        (\"event:write\", \"Read and write access to events.\"),\n",
                "        (\"event:read\", \"Read access to events.\"),\n",
                "    ),\n",
                "    (\n",
                "        (\"alerts:write\", \"Read and write alerts\"),\n",
                "        (\"alerts:read\", \"Read alerts\"),\n",
                "    ),\n",
                ")\n",
                "\n",
                "SENTRY_DEFAULT_ROLE = \"member\"\n",
                "\n",
                "# Roles are ordered, which represents a sort-of hierarchy, as well as how\n",
                "# they're presented in the UI. This is primarily important in that a member\n",
                "# that is earlier in the chain cannot manage the settings of a member later\n",
                "# in the chain (they still require the appropriate scope).\n",
                "SENTRY_ROLES = (\n",
                "    {\n",
                "        \"id\": \"member\",\n",
                "        \"name\": \"Member\",\n",
                "        \"desc\": \"Members can view and act on events, as well as view most other data within the organization.\",\n",
                "        \"scopes\": {\n",
                "            \"event:read\",\n",
                "            \"event:write\",\n",
                "            \"event:admin\",\n",
                "            \"project:releases\",\n",
                "            \"project:read\",\n",
                "            \"org:read\",\n",
                "            \"member:read\",\n",
                "            \"team:read\",\n",
                "            \"alerts:read\",\n",
                "            \"alerts:write\",\n",
                "        },\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"admin\",\n",
                "        \"name\": \"Admin\",\n",
                "        \"desc\": (\n",
                "            \"\"\"\n",
                "            Admin privileges on any teams of which they're a member. They can\n",
                "            create new teams and projects, as well as remove teams and projects\n",
                "            on which they already hold membership (or all teams, if open\n",
                "            membership is enabled). Additionally, they can manage memberships of\n",
                "            teams that they are members of. They cannot invite members to the\n",
                "            organization.\n",
                "            \"\"\"\n",
                "        ),\n",
                "        \"scopes\": {\n",
                "            \"event:read\",\n",
                "            \"event:write\",\n",
                "            \"event:admin\",\n",
                "            \"org:read\",\n",
                "            \"member:read\",\n",
                "            \"project:read\",\n",
                "            \"project:write\",\n",
                "            \"project:admin\",\n",
                "            \"project:releases\",\n",
                "            \"team:read\",\n",
                "            \"team:write\",\n",
                "            \"team:admin\",\n",
                "            \"org:integrations\",\n",
                "            \"alerts:read\",\n",
                "            \"alerts:write\",\n",
                "        },\n",
                "        \"is_retired\": True,\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"manager\",\n",
                "        \"name\": \"Manager\",\n",
                "        \"desc\": \"Gains admin access on all teams as well as the ability to add and remove members.\",\n",
                "        \"is_global\": True,\n",
                "        \"scopes\": {\n",
                "            \"event:read\",\n",
                "            \"event:write\",\n",
                "            \"event:admin\",\n",
                "            \"member:read\",\n",
                "            \"member:write\",\n",
                "            \"member:admin\",\n",
                "            \"project:read\",\n",
                "            \"project:write\",\n",
                "            \"project:admin\",\n",
                "            \"project:releases\",\n",
                "            \"team:read\",\n",
                "            \"team:write\",\n",
                "            \"team:admin\",\n",
                "            \"org:read\",\n",
                "            \"org:write\",\n",
                "            \"org:integrations\",\n",
                "            \"alerts:read\",\n",
                "            \"alerts:write\",\n",
                "        },\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"owner\",\n",
                "        \"name\": \"Owner\",\n",
                "        \"desc\": (\n",
                "            \"\"\"\n",
                "            Unrestricted access to the organization, its data, and its settings.\n",
                "            Can add, modify, and delete projects and members, as well as make\n",
                "            billing and plan changes.\n",
                "            \"\"\"\n",
                "        ),\n",
                "        \"is_global\": True,\n",
                "        \"scopes\": {\n",
                "            \"org:read\",\n",
                "            \"org:write\",\n",
                "            \"org:admin\",\n",
                "            \"org:integrations\",\n",
                "            \"member:read\",\n",
                "            \"member:write\",\n",
                "            \"member:admin\",\n",
                "            \"team:read\",\n",
                "            \"team:write\",\n",
                "            \"team:admin\",\n",
                "            \"project:read\",\n",
                "            \"project:write\",\n",
                "            \"project:admin\",\n",
                "            \"project:releases\",\n",
                "            \"event:read\",\n",
                "            \"event:write\",\n",
                "            \"event:admin\",\n",
                "            \"alerts:read\",\n",
                "            \"alerts:write\",\n",
                "        },\n",
                "    },\n",
                ")\n",
                "\n",
                "SENTRY_TEAM_ROLES = (\n",
                "    {\n",
                "        \"id\": \"contributor\",\n",
                "        \"name\": \"Contributor\",\n",
                "        \"desc\": \"Contributors can view and act on events, as well as view most other data within the team's projects.\",\n",
                "        \"scopes\": {\n",
                "            \"event:read\",\n",
                "            \"event:write\",\n",
                "            \"event:admin\",\n",
                "            \"project:releases\",\n",
                "            \"project:read\",\n",
                "            \"org:read\",\n",
                "            \"member:read\",\n",
                "            \"team:read\",\n",
                "            \"alerts:read\",\n",
                "            \"alerts:write\",\n",
                "        },\n",
                "    },\n",
                "    {\n",
                "        \"id\": \"admin\",\n",
                "        \"name\": \"Team Admin\",\n",
                "        \"desc\": (\n",
                "            # TODO: Editing pass\n",
                "            \"\"\"\n",
                "            Admin privileges on the team. They can create and remove projects,\n",
                "            and can manage the team's memberships. They cannot invite members to\n",
                "            the organization.\n",
                "            \"\"\"\n",
                "        ),\n",
                "        \"scopes\": {\n",
                "            \"event:read\",\n",
                "            \"event:write\",\n",
                "            \"event:admin\",\n",
                "            \"org:read\",\n",
                "            \"member:read\",\n",
                "            \"project:read\",\n",
                "            \"project:write\",\n",
                "            \"project:admin\",\n",
                "            \"project:releases\",\n",
                "            \"team:read\",\n",
                "            \"team:write\",\n",
                "            \"team:admin\",\n",
                "            \"org:integrations\",\n",
                "            \"alerts:read\",\n",
                "            \"alerts:write\",\n",
                "        },\n",
                "        \"is_minimum_role_for\": \"admin\",\n",
                "    },\n",
                ")\n",
                "\n",
                "# See sentry/options/__init__.py for more information\n",
                "SENTRY_OPTIONS = {}\n",
                "SENTRY_DEFAULT_OPTIONS = {}\n",
                "\n",
                "# You should not change this setting after your database has been created\n",
                "# unless you have altered all schemas first\n",
                "SENTRY_USE_BIG_INTS = False\n",
                "\n",
                "# Delay (in ms) to induce on API responses\n",
                "#\n",
                "# Simulates a small amount of lag which helps uncover more obvious race\n",
                "# conditions in UI interactions. It's also needed to test (or implement) any\n",
                "# kind of loading scenarios. Without this we will just implicitly lower the\n",
                "# overall quality of software we ship because we will not experience it in the\n",
                "# same way we would in production.\n",
                "#\n",
                "# See discussion on https://github.com/getsentry/sentry/pull/20187\n",
                "SENTRY_API_RESPONSE_DELAY = 150 if IS_DEV else None\n",
                "\n",
                "# Watchers for various application purposes (such as compiling static media)\n",
                "# XXX(dcramer): this doesn't work outside of a source distribution as the\n",
                "# webpack.config.js is not part of Sentry's datafiles\n",
                "SENTRY_WATCHERS = (\n",
                "    (\n",
                "        \"webpack\",\n",
                "        [\n",
                "            os.path.join(NODE_MODULES_ROOT, \".bin\", \"webpack\"),\n",
                "            \"serve\",\n",
                "            \"--color\",\n",
                "            \"--output-pathinfo=true\",\n",
                "            \"--config={}\".format(\n",
                "                os.path.normpath(\n",
                "                    os.path.join(PROJECT_ROOT, os.pardir, os.pardir, \"webpack.config.ts\")\n",
                "                )\n",
                "            ),\n",
                "        ],\n",
                "    ),\n",
                ")\n",
                "\n",
                "# Controls whether devserver spins up Relay, Kafka, and several ingest worker jobs to direct store traffic\n",
                "# through the Relay ingestion pipeline. Without, ingestion is completely disabled. Use `bin/load-mocks` to\n",
                "# generate fake data for local testing. You can also manually enable relay with the `--ingest` flag to `devserver`.\n",
                "# XXX: This is disabled by default as typical development workflows do not require end-to-end services running\n",
                "# and disabling optional services reduces resource consumption and complexity\n",
                "SENTRY_USE_RELAY = False\n",
                "SENTRY_RELAY_PORT = 7899\n",
                "\n",
                "# Controls whether we'll run the snuba subscription processor. If enabled, we'll run\n",
                "# it as a worker, and devservices will run Kafka.\n",
                "SENTRY_DEV_PROCESS_SUBSCRIPTIONS = False\n",
                "\n",
                "# The chunk size for attachments in blob store. Should be a power of two.\n",
                "SENTRY_ATTACHMENT_BLOB_SIZE = 8 * 1024 * 1024  # 8MB\n",
                "\n",
                "# The chunk size for files in the chunk upload. This is used for native debug\n",
                "# files and source maps, and directly translates to the chunk size in blob\n",
                "# store. MUST be a power of two.\n",
                "SENTRY_CHUNK_UPLOAD_BLOB_SIZE = 8 * 1024 * 1024  # 8MB\n",
                "\n",
                "# This flag tell DEVSERVICES to start the ingest-metrics-consumer in order to work on\n",
                "# metrics in the development environment. Note: this is \"metrics\" the product\n",
                "SENTRY_USE_METRICS_DEV = False\n",
                "\n",
                "# This flags activates the Change Data Capture backend in the development environment\n",
                "SENTRY_USE_CDC_DEV = False\n",
                "\n",
                "# This flag activates profiling backend in the development environment\n",
                "SENTRY_USE_PROFILING = False\n",
                "\n",
                "# SENTRY_DEVSERVICES = {\n",
                "#     \"service-name\": lambda settings, options: (\n",
                "#         {\n",
                "#             \"image\": \"image-name:version\",\n",
                "#             # optional ports to expose\n",
                "#             \"ports\": {\"internal-port/tcp\": external-port},\n",
                "#             # optional command\n",
                "#             \"command\": [\"exit 1\"],\n",
                "#             optional mapping of volumes\n",
                "#             \"volumes\": {\"volume-name\": {\"bind\": \"/path/in/container\"}},\n",
                "#             # optional statement to test if service should run\n",
                "#             \"only_if\": lambda settings, options: True,\n",
                "#             # optional environment variables\n",
                "#             \"environment\": {\n",
                "#                 \"ENV_VAR\": \"1\",\n",
                "#             }\n",
                "#         }\n",
                "#     )\n",
                "# }\n",
                "\n",
                "\n",
                "def build_cdc_postgres_init_db_volume(settings):\n",
                "    return (\n",
                "        {\n",
                "            os.path.join(settings.CDC_CONFIG_DIR, \"init_hba.sh\"): {\n",
                "                \"bind\": \"/docker-entrypoint-initdb.d/init_hba.sh\"\n",
                "            }\n",
                "        }\n",
                "        if settings.SENTRY_USE_CDC_DEV\n",
                "        else {}\n",
                "    )\n",
                "\n",
                "\n",
                "# platform.processor() changed at some point between these:\n",
                "# 11.2.3: arm\n",
                "# 12.3.1: arm64\n",
                "APPLE_ARM64 = sys.platform == \"darwin\" and platform.processor() in {\"arm\", \"arm64\"}\n",
                "\n",
                "SENTRY_DEVSERVICES = {\n",
                "    \"redis\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"redis:5.0-alpine\",\n",
                "            \"ports\": {\"6379/tcp\": 6379},\n",
                "            \"command\": [\n",
                "                \"redis-server\",\n",
                "                \"--appendonly\",\n",
                "                \"yes\",\n",
                "                \"--save\",\n",
                "                \"60\",\n",
                "                \"20\",\n",
                "                \"--auto-aof-rewrite-percentage\",\n",
                "                \"100\",\n",
                "                \"--auto-aof-rewrite-min-size\",\n",
                "                \"64mb\",\n",
                "            ],\n",
                "            \"volumes\": {\"redis\": {\"bind\": \"/data\"}},\n",
                "        }\n",
                "    ),\n",
                "    \"postgres\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": f\"postgres:{os.getenv('PG_VERSION') or '9.6'}-alpine\",\n",
                "            \"pull\": True,\n",
                "            \"ports\": {\"5432/tcp\": 5432},\n",
                "            \"environment\": {\"POSTGRES_DB\": \"sentry\", \"POSTGRES_HOST_AUTH_METHOD\": \"trust\"},\n",
                "            \"volumes\": {\n",
                "                \"postgres\": {\"bind\": \"/var/lib/postgresql/data\"},\n",
                "                \"wal2json\": {\"bind\": \"/wal2json\"},\n",
                "                settings.CDC_CONFIG_DIR: {\"bind\": \"/cdc\"},\n",
                "                **build_cdc_postgres_init_db_volume(settings),\n",
                "            },\n",
                "            \"command\": [\n",
                "                \"postgres\",\n",
                "                \"-c\",\n",
                "                \"wal_level=logical\",\n",
                "                \"-c\",\n",
                "                \"max_replication_slots=1\",\n",
                "                \"-c\",\n",
                "                \"max_wal_senders=1\",\n",
                "            ],\n",
                "            \"entrypoint\": \"/cdc/postgres-entrypoint.sh\" if settings.SENTRY_USE_CDC_DEV else None,\n",
                "        }\n",
                "    ),\n",
                "    \"zookeeper\": lambda settings, options: (\n",
                "        {\n",
                "            # On Apple arm64, we upgrade to version 6.x to allow zookeeper to run properly on Apple's arm64\n",
                "            # See details https://github.com/confluentinc/kafka-images/issues/80#issuecomment-855511438\n",
                "            \"image\": \"confluentinc/cp-zookeeper:6.2.0\",\n",
                "            \"environment\": {\"ZOOKEEPER_CLIENT_PORT\": \"2181\"},\n",
                "            \"volumes\": {\"zookeeper_6\": {\"bind\": \"/var/lib/zookeeper/data\"}},\n",
                "            \"only_if\": \"kafka\" in settings.SENTRY_EVENTSTREAM or settings.SENTRY_USE_RELAY,\n",
                "        }\n",
                "    ),\n",
                "    \"kafka\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"confluentinc/cp-kafka:6.2.0\",\n",
                "            \"ports\": {\"9092/tcp\": 9092},\n",
                "            \"environment\": {\n",
                "                \"KAFKA_ZOOKEEPER_CONNECT\": \"{containers[zookeeper][name]}:2181\",\n",
                "                \"KAFKA_LISTENERS\": \"INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092\",\n",
                "                \"KAFKA_ADVERTISED_LISTENERS\": \"INTERNAL://{containers[kafka][name]}:9093,EXTERNAL://{containers[kafka]\"\n",
                "                \"[ports][9092/tcp][0]}:{containers[kafka][ports][9092/tcp][1]}\",\n",
                "                \"KAFKA_LISTENER_SECURITY_PROTOCOL_MAP\": \"INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT\",\n",
                "                \"KAFKA_INTER_BROKER_LISTENER_NAME\": \"INTERNAL\",\n",
                "                \"KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR\": \"1\",\n",
                "                \"KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS\": \"1\",\n",
                "                \"KAFKA_LOG_RETENTION_HOURS\": \"24\",\n",
                "                \"KAFKA_MESSAGE_MAX_BYTES\": \"50000000\",\n",
                "                \"KAFKA_MAX_REQUEST_SIZE\": \"50000000\",\n",
                "            },\n",
                "            \"volumes\": {\"kafka_6\": {\"bind\": \"/var/lib/kafka/data\"}},\n",
                "            \"only_if\": \"kafka\" in settings.SENTRY_EVENTSTREAM\n",
                "            or settings.SENTRY_USE_RELAY\n",
                "            or settings.SENTRY_DEV_PROCESS_SUBSCRIPTIONS,\n",
                "        }\n",
                "    ),\n",
                "    \"clickhouse\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"yandex/clickhouse-server:20.3.9.70\" if not APPLE_ARM64\n",
                "            # altinity provides clickhouse support to other companies\n",
                "            # Official support: https://github.com/ClickHouse/ClickHouse/issues/22222\n",
                "            # This image is build with this script https://gist.github.com/filimonov/5f9732909ff66d5d0a65b8283382590d\n",
                "            else \"altinity/clickhouse-server:21.6.1.6734-testing-arm\",\n",
                "            \"pull\": True,\n",
                "            \"ports\": {\"9000/tcp\": 9000, \"9009/tcp\": 9009, \"8123/tcp\": 8123},\n",
                "            \"ulimits\": [{\"name\": \"nofile\", \"soft\": 262144, \"hard\": 262144}],\n",
                "            # The arm image does not properly load the MAX_MEMORY_USAGE_RATIO\n",
                "            # from the environment in loc_config.xml, thus, hard-coding it there\n",
                "            \"volumes\": {\n",
                "                \"clickhouse_dist\"\n",
                "                if settings.SENTRY_DISTRIBUTED_CLICKHOUSE_TABLES\n",
                "                else \"clickhouse\": {\"bind\": \"/var/lib/clickhouse\"},\n",
                "                os.path.join(\n",
                "                    settings.DEVSERVICES_CONFIG_DIR,\n",
                "                    \"clickhouse\",\n",
                "                    \"dist_config.xml\"\n",
                "                    if settings.SENTRY_DISTRIBUTED_CLICKHOUSE_TABLES\n",
                "                    else \"loc_config.xml\",\n",
                "                ): {\"bind\": \"/etc/clickhouse-server/config.d/sentry.xml\"},\n",
                "            },\n",
                "        }\n",
                "    ),\n",
                "    \"snuba\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"getsentry/snuba:nightly\" if not APPLE_ARM64\n",
                "            # We cross-build arm64 images on GH's Apple Intel runners\n",
                "            else \"ghcr.io/getsentry/snuba-arm64-dev:latest\",\n",
                "            \"pull\": True,\n",
                "            \"ports\": {\"1218/tcp\": 1218},\n",
                "            \"command\": [\"devserver\"],\n",
                "            \"environment\": {\n",
                "                \"PYTHONUNBUFFERED\": \"1\",\n",
                "                \"SNUBA_SETTINGS\": \"docker\",\n",
                "                \"DEBUG\": \"1\",\n",
                "                \"CLICKHOUSE_HOST\": \"{containers[clickhouse][name]}\",\n",
                "                \"CLICKHOUSE_PORT\": \"9000\",\n",
                "                \"CLICKHOUSE_HTTP_PORT\": \"8123\",\n",
                "                \"DEFAULT_BROKERS\": \"{containers[kafka][name]}:9093\",\n",
                "                \"REDIS_HOST\": \"{containers[redis][name]}\",\n",
                "                \"REDIS_PORT\": \"6379\",\n",
                "                \"REDIS_DB\": \"1\",\n",
                "                \"ENABLE_SENTRY_METRICS_DEV\": \"1\" if settings.SENTRY_USE_METRICS_DEV else \"\",\n",
                "                \"ENABLE_PROFILES_CONSUMER\": \"1\" if settings.SENTRY_USE_PROFILING else \"\",\n",
                "            },\n",
                "            \"only_if\": \"snuba\" in settings.SENTRY_EVENTSTREAM\n",
                "            or \"kafka\" in settings.SENTRY_EVENTSTREAM,\n",
                "        }\n",
                "    ),\n",
                "    \"bigtable\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"us.gcr.io/sentryio/cbtemulator:23c02d92c7a1747068eb1fc57dddbad23907d614\",\n",
                "            \"ports\": {\"8086/tcp\": 8086},\n",
                "            # NEED_BIGTABLE is set by CI so we don't have to pass\n",
                "            # --skip-only-if when compiling which services to run.\n",
                "            \"only_if\": os.environ.get(\"NEED_BIGTABLE\", False)\n",
                "            or \"bigtable\" in settings.SENTRY_NODESTORE,\n",
                "        }\n",
                "    ),\n",
                "    \"memcached\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"memcached:1.5-alpine\",\n",
                "            \"ports\": {\"11211/tcp\": 11211},\n",
                "            \"only_if\": \"memcached\" in settings.CACHES.get(\"default\", {}).get(\"BACKEND\"),\n",
                "        }\n",
                "    ),\n",
                "    \"symbolicator\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"us.gcr.io/sentryio/symbolicator:nightly\",\n",
                "            \"pull\": True,\n",
                "            \"ports\": {\"3021/tcp\": 3021},\n",
                "            \"volumes\": {settings.SYMBOLICATOR_CONFIG_DIR: {\"bind\": \"/etc/symbolicator\"}},\n",
                "            \"command\": [\"run\", \"--config\", \"/etc/symbolicator/config.yml\"],\n",
                "            \"only_if\": options.get(\"symbolicator.enabled\"),\n",
                "        }\n",
                "    ),\n",
                "    \"relay\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"us.gcr.io/sentryio/relay:nightly\",\n",
                "            \"pull\": True,\n",
                "            \"ports\": {\"7899/tcp\": settings.SENTRY_RELAY_PORT},\n",
                "            \"volumes\": {settings.RELAY_CONFIG_DIR: {\"bind\": \"/etc/relay\"}},\n",
                "            \"command\": [\"run\", \"--config\", \"/etc/relay\"],\n",
                "            \"only_if\": bool(os.environ.get(\"SENTRY_USE_RELAY\", settings.SENTRY_USE_RELAY)),\n",
                "            \"with_devserver\": True,\n",
                "        }\n",
                "    ),\n",
                "    \"chartcuterie\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"us.gcr.io/sentryio/chartcuterie:latest\",\n",
                "            \"pull\": True,\n",
                "            \"volumes\": {settings.CHARTCUTERIE_CONFIG_DIR: {\"bind\": \"/etc/chartcuterie\"}},\n",
                "            \"environment\": {\n",
                "                \"CHARTCUTERIE_CONFIG\": \"/etc/chartcuterie/config.js\",\n",
                "                \"CHARTCUTERIE_CONFIG_POLLING\": \"true\",\n",
                "            },\n",
                "            \"ports\": {\"9090/tcp\": 7901},\n",
                "            # NEED_CHARTCUTERIE is set by CI so we don't have to pass --skip-only-if when compiling which services to run.\n",
                "            \"only_if\": os.environ.get(\"NEED_CHARTCUTERIE\", False)\n",
                "            or options.get(\"chart-rendering.enabled\"),\n",
                "        }\n",
                "    ),\n",
                "    \"cdc\": lambda settings, options: (\n",
                "        {\n",
                "            \"image\": \"getsentry/cdc:nightly\",\n",
                "            \"pull\": True,\n",
                "            \"only_if\": settings.SENTRY_USE_CDC_DEV,\n",
                "            \"command\": [\"cdc\", \"-c\", \"/etc/cdc/configuration.yaml\", \"producer\"],\n",
                "            \"volumes\": {settings.CDC_CONFIG_DIR: {\"bind\": \"/etc/cdc\"}},\n",
                "        }\n",
                "    ),\n",
                "}\n",
                "\n",
                "# Max file size for serialized file uploads in API\n",
                "SENTRY_MAX_SERIALIZED_FILE_SIZE = 5000000\n",
                "\n",
                "# Max file size for avatar photo uploads\n",
                "SENTRY_MAX_AVATAR_SIZE = 5000000\n",
                "\n",
                "# The maximum age of raw events before they are deleted\n",
                "SENTRY_RAW_EVENT_MAX_AGE_DAYS = 10\n",
                "\n",
                "# statuspage.io support\n",
                "STATUS_PAGE_ID = None\n",
                "STATUS_PAGE_API_HOST = \"statuspage.io\"\n",
                "\n",
                "SENTRY_SELF_HOSTED = True\n",
                "\n",
                "# Whether we should look at X-Forwarded-For header or not\n",
                "# when checking REMOTE_ADDR ip addresses\n",
                "SENTRY_USE_X_FORWARDED_FOR = True\n",
                "\n",
                "SENTRY_DEFAULT_INTEGRATIONS = (\n",
                "    \"sentry.integrations.bitbucket.BitbucketIntegrationProvider\",\n",
                "    \"sentry.integrations.bitbucket_server.BitbucketServerIntegrationProvider\",\n",
                "    \"sentry.integrations.slack.SlackIntegrationProvider\",\n",
                "    \"sentry.integrations.github.GitHubIntegrationProvider\",\n",
                "    \"sentry.integrations.github_enterprise.GitHubEnterpriseIntegrationProvider\",\n",
                "    \"sentry.integrations.gitlab.GitlabIntegrationProvider\",\n",
                "    \"sentry.integrations.jira.JiraIntegrationProvider\",\n",
                "    \"sentry.integrations.jira_server.JiraServerIntegrationProvider\",\n",
                "    \"sentry.integrations.vsts.VstsIntegrationProvider\",\n",
                "    \"sentry.integrations.vsts_extension.VstsExtensionIntegrationProvider\",\n",
                "    \"sentry.integrations.pagerduty.integration.PagerDutyIntegrationProvider\",\n",
                "    \"sentry.integrations.vercel.VercelIntegrationProvider\",\n",
                "    \"sentry.integrations.msteams.MsTeamsIntegrationProvider\",\n",
                "    \"sentry.integrations.aws_lambda.AwsLambdaIntegrationProvider\",\n",
                "    \"sentry.integrations.custom_scm.CustomSCMIntegrationProvider\",\n",
                ")\n",
                "\n",
                "\n",
                "SENTRY_SDK_CONFIG = {\n",
                "    \"release\": sentry.__semantic_version__,\n",
                "    \"environment\": ENVIRONMENT,\n",
                "    \"in_app_include\": [\"sentry\", \"sentry_plugins\"],\n",
                "    \"debug\": True,\n",
                "    \"send_default_pii\": True,\n",
                "    \"auto_enabling_integrations\": False,\n",
                "}\n",
                "\n",
                "# Callable to bind additional context for the Sentry SDK\n",
                "#\n",
                "# def get_org_context(scope, organization, **kwargs):\n",
                "#    scope.set_tag('organization.cool', '1')\n",
                "#\n",
                "# SENTRY_ORGANIZATION_CONTEXT_HELPER = get_org_context\n",
                "SENTRY_ORGANIZATION_CONTEXT_HELPER = None\n",
                "\n",
                "# Config options that are explicitly disabled from Django\n",
                "DEAD = object()\n",
                "\n",
                "# This will eventually get set from values in SENTRY_OPTIONS during\n",
                "# sentry.runner.initializer:bootstrap_options\n",
                "SECRET_KEY = DEAD\n",
                "EMAIL_BACKEND = DEAD\n",
                "EMAIL_HOST = DEAD\n",
                "EMAIL_PORT = DEAD\n",
                "EMAIL_HOST_USER = DEAD\n",
                "EMAIL_HOST_PASSWORD = DEAD\n",
                "EMAIL_USE_TLS = DEAD\n",
                "EMAIL_USE_SSL = DEAD\n",
                "SERVER_EMAIL = DEAD\n",
                "EMAIL_SUBJECT_PREFIX = DEAD\n",
                "\n",
                "# Shared btw Auth Provider and Social Auth Plugin\n",
                "GITHUB_APP_ID = DEAD\n",
                "GITHUB_API_SECRET = DEAD\n",
                "\n",
                "# Used by Auth Provider\n",
                "GITHUB_REQUIRE_VERIFIED_EMAIL = DEAD\n",
                "GITHUB_API_DOMAIN = DEAD\n",
                "GITHUB_BASE_DOMAIN = DEAD\n",
                "\n",
                "# Used by Social Auth Plugin\n",
                "GITHUB_EXTENDED_PERMISSIONS = DEAD\n",
                "GITHUB_ORGANIZATION = DEAD\n",
                "\n",
                "\n",
                "SUDO_URL = \"sentry-sudo\"\n",
                "\n",
                "# Endpoint to https://github.com/getsentry/sentry-release-registry, used for\n",
                "# alerting the user on outdated SDKs.\n",
                "SENTRY_RELEASE_REGISTRY_BASEURL = None\n",
                "\n",
                "# Hardcoded SDK versions for SDKs that do not have an entry in the release\n",
                "# registry.\n",
                "SDK_VERSIONS = {\n",
                "    \"raven-js\": \"3.21.0\",\n",
                "    \"raven-node\": \"2.3.0\",\n",
                "    \"raven-python\": \"6.10.0\",\n",
                "    \"raven-ruby\": \"2.7.1\",\n",
                "    \"sentry-cocoa\": \"3.11.1\",\n",
                "    \"sentry-java\": \"1.6.4\",\n",
                "    \"sentry-laravel\": \"1.0.2\",\n",
                "    \"sentry-php\": \"2.0.1\",\n",
                "}\n",
                "\n",
                "# Some of the migration links below are not ideal, but that is all migration documentation we currently have and can provide at this point\n",
                "SDK_URLS = {\n",
                "    \"sentry-java\": \"https://docs.sentry.io/platforms/java/legacy/migration/\",\n",
                "    \"@sentry/browser\": \"https://github.com/getsentry/sentry-javascript/blob/master/MIGRATION.md#migrating-from-raven-js-to-sentrybrowser\",\n",
                "    \"sentry-cocoa\": \"https://docs.sentry.io/platforms/apple/migration/\",\n",
                "    \"sentry-php\": \"https://docs.sentry.io/platforms/php/\",\n",
                "    \"sentry-python\": \"https://docs.sentry.io/platforms/python/migration/\",\n",
                "    \"sentry-ruby\": \"https://docs.sentry.io/platforms/ruby/migration/\",\n",
                "    \"sentry-dotnet\": \"https://docs.sentry.io/platforms/dotnet/migration/#migrating-from-sharpraven-to-sentry-sdk\",\n",
                "    \"sentry-go\": \"https://docs.sentry.io/platforms/go/migration/\",\n",
                "}\n",
                "\n",
                "DEPRECATED_SDKS = {\n",
                "    # sdk name => new sdk name\n",
                "    \"raven-java\": \"sentry-java\",\n",
                "    \"raven-java:android\": \"sentry-java\",\n",
                "    \"raven-java:log4j\": \"sentry-java\",\n",
                "    \"raven-java:log4j2\": \"sentry-java\",\n",
                "    \"raven-java:logback\": \"sentry-java\",\n",
                "    \"raven-js\": \"@sentry/browser\",\n",
                "    \"raven-node\": \"@sentry/browser\",\n",
                "    \"raven-objc\": \"sentry-cocoa\",\n",
                "    \"raven-php\": \"sentry-php\",\n",
                "    \"raven-python\": \"sentry-python\",\n",
                "    \"raven-ruby\": \"sentry-ruby\",\n",
                "    \"raven-swift\": \"sentry-cocoa\",\n",
                "    \"raven-csharp\": \"sentry-dotnet\",\n",
                "    \"raven-go\": \"sentry-go\",\n",
                "    \"sentry-android\": \"sentry-java\",\n",
                "    \"sentry-swift\": \"sentry-cocoa\",\n",
                "    \"SharpRaven\": \"sentry-dotnet\",\n",
                "    # The Ruby SDK used to go by the name 'sentry-raven'...\n",
                "    \"sentry-raven\": \"sentry-ruby\",\n",
                "}\n",
                "\n",
                "TERMS_URL = None\n",
                "PRIVACY_URL = None\n",
                "\n",
                "# Internal sources for debug information files\n",
                "#\n",
                "# There are two special values in there: \"microsoft\" and \"ios\".  These are\n",
                "# added by default to any project created.  The \"ios\" source is currently\n",
                "# not enabled in the open source build of sentry because it points to a\n",
                "# sentry internal repository and it's unclear if these can be\n",
                "# redistributed under the Apple EULA.  If however someone configures their\n",
                "# own iOS source and name it 'ios' it will be enabled by default for all\n",
                "# projects.\n",
                "SENTRY_BUILTIN_SOURCES = {\n",
                "    \"microsoft\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:microsoft\",\n",
                "        \"name\": \"Microsoft\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"https://msdl.microsoft.com/download/symbols/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"citrix\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:citrix\",\n",
                "        \"name\": \"Citrix\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"http://ctxsym.citrix.com/symbols/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"intel\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:intel\",\n",
                "        \"name\": \"Intel\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"https://software.intel.com/sites/downloads/symbols/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"amd\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:amd\",\n",
                "        \"name\": \"AMD\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"https://download.amd.com/dir/bin/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"nvidia\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:nvidia\",\n",
                "        \"name\": \"NVIDIA\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"https://driver-symbols.nvidia.com/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"chromium\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:chromium\",\n",
                "        \"name\": \"Chromium\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"https://chromium-browser-symsrv.commondatastorage.googleapis.com/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"unity\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:unity\",\n",
                "        \"name\": \"Unity\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"pe\"]},\n",
                "        \"url\": \"http://symbolserver.unity3d.com/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"mozilla\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:mozilla\",\n",
                "        \"name\": \"Mozilla\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"url\": \"https://symbols.mozilla.org/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"autodesk\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:autodesk\",\n",
                "        \"name\": \"Autodesk\",\n",
                "        \"layout\": {\"type\": \"symstore\"},\n",
                "        \"url\": \"http://symbols.autodesk.com/\",\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "    \"electron\": {\n",
                "        \"type\": \"http\",\n",
                "        \"id\": \"sentry:electron\",\n",
                "        \"name\": \"Electron\",\n",
                "        \"layout\": {\"type\": \"native\"},\n",
                "        \"url\": \"https://symbols.electronjs.org/\",\n",
                "        \"filters\": {\"filetypes\": [\"pdb\", \"breakpad\", \"sourcebundle\"]},\n",
                "        \"is_public\": True,\n",
                "    },\n",
                "}\n",
                "\n",
                "# Relay\n",
                "# List of PKs explicitly allowed by Sentry.  All relays here are always\n",
                "# registered as internal relays.\n",
                "# DEPRECATED !!! (18.May.2021) This entry has been deprecated in favour of\n",
                "# ~/.sentry/conf.yml (relay.static_auth)\n",
                "SENTRY_RELAY_WHITELIST_PK = [\n",
                "    # NOTE (RaduW) This is the relay key for the relay instance used by devservices.\n",
                "    # This should NOT be part of any production environment.\n",
                "    # This key should match the key in /sentry/config/relay/credentials.json\n",
                "    \"SMSesqan65THCV6M4qs4kBzPai60LzuDn-xNsvYpuP8\"\n",
                "]\n",
                "\n",
                "# When open registration is not permitted then only relays in the\n",
                "# list of explicitly allowed relays can register.\n",
                "SENTRY_RELAY_OPEN_REGISTRATION = True\n",
                "\n",
                "# GeoIP\n",
                "# Used for looking up IP addresses.\n",
                "# For example /usr/local/share/GeoIP/GeoIPCity.mmdb\n",
                "GEOIP_PATH_MMDB = None\n",
                "\n",
                "# CDN\n",
                "# If this is an absolute url like e.g.: https://js.sentry-cdn.com/\n",
                "# the full url will look like this: https://js.sentry-cdn.com/<public_key>.min.js\n",
                "# otherwise django reverse url lookup will be used.\n",
                "JS_SDK_LOADER_CDN_URL = \"\"\n",
                "# Version of the SDK - Used in header Surrogate-Key sdk/JS_SDK_LOADER_SDK_VERSION\n",
                "JS_SDK_LOADER_SDK_VERSION = \"\"\n",
                "# This should be the url pointing to the JS SDK. It may contain up to two \"%s\".\n",
                "# The first \"%s\" will be replaced with the SDK version, the second one is used\n",
                "# to inject a bundle modifier in the JS SDK CDN loader. e.g:\n",
                "# - 'https://browser.sentry-cdn.com/%s/bundle%s.min.js' will become\n",
                "# 'https://browser.sentry-cdn.com/7.0.0/bundle.es5.min.js'\n",
                "# - 'https://browser.sentry-cdn.com/%s/bundle.min.js' will become\n",
                "# 'https://browser.sentry-cdn.com/7.0.0/bundle.min.js'\n",
                "# - 'https://browser.sentry-cdn.com/6.19.7/bundle.min.js' will stay the same.\n",
                "JS_SDK_LOADER_DEFAULT_SDK_URL = \"\"\n",
                "\n",
                "# block domains which are generally used by spammers -- keep this configurable\n",
                "# in case a self-hosted install wants to allow it\n",
                "INVALID_EMAIL_ADDRESS_PATTERN = re.compile(r\"\\@qq\\.com$\", re.I)\n",
                "\n",
                "# This is customizable for sentry.io, but generally should only be additive\n",
                "# (currently the values not used anymore so this is more for documentation purposes)\n",
                "SENTRY_USER_PERMISSIONS = (\"broadcasts.admin\", \"users.admin\")\n",
                "\n",
                "KAFKA_CLUSTERS = {\n",
                "    \"default\": {\n",
                "        \"common\": {\"bootstrap.servers\": \"127.0.0.1:9092\"},\n",
                "        \"producers\": {\n",
                "            \"compression.type\": \"lz4\",\n",
                "            \"message.max.bytes\": 50000000,  # 50MB, default is 1MB\n",
                "        },\n",
                "        \"consumers\": {},\n",
                "    }\n",
                "}\n",
                "\n",
                "# These constants define kafka topic names, as well as keys into `KAFKA_TOPICS`\n",
                "# which contains cluster mappings for these topics. Follow these steps to\n",
                "# override a kafka topic name:\n",
                "#\n",
                "#  1. Change the value of the `KAFKA_*` constant (e.g. KAFKA_EVENTS).\n",
                "#  2. For changes in override files, such as `sentry.conf.py` or in getsentry's\n",
                "#     `prod.py`, also override the entirety of `KAFKA_TOPICS` to ensure the keys\n",
                "#     pick up the change.\n",
                "\n",
                "KAFKA_EVENTS = \"events\"\n",
                "# TODO: KAFKA_TRANSACTIONS is temporarily mapped to \"events\" since events\n",
                "# transactions curently share a Kafka topic. Once we are ready with the code\n",
                "# changes to support different topic, switch this to \"transactions\" to start\n",
                "# producing to the new topic.\n",
                "KAFKA_TRANSACTIONS = \"events\"\n",
                "KAFKA_OUTCOMES = \"outcomes\"\n",
                "KAFKA_OUTCOMES_BILLING = \"outcomes-billing\"\n",
                "KAFKA_EVENTS_SUBSCRIPTIONS_RESULTS = \"events-subscription-results\"\n",
                "KAFKA_TRANSACTIONS_SUBSCRIPTIONS_RESULTS = \"transactions-subscription-results\"\n",
                "KAFKA_SESSIONS_SUBSCRIPTIONS_RESULTS = \"sessions-subscription-results\"\n",
                "KAFKA_METRICS_SUBSCRIPTIONS_RESULTS = \"metrics-subscription-results\"\n",
                "KAFKA_INGEST_EVENTS = \"ingest-events\"\n",
                "KAFKA_INGEST_ATTACHMENTS = \"ingest-attachments\"\n",
                "KAFKA_INGEST_TRANSACTIONS = \"ingest-transactions\"\n",
                "KAFKA_INGEST_METRICS = \"ingest-metrics\"\n",
                "KAFKA_SNUBA_METRICS = \"snuba-metrics\"\n",
                "KAFKA_PROFILES = \"profiles\"\n",
                "KAFKA_INGEST_PERFORMANCE_METRICS = \"ingest-performance-metrics\"\n",
                "KAFKA_SNUBA_GENERIC_METRICS = \"snuba-generic-metrics\"\n",
                "\n",
                "KAFKA_SUBSCRIPTION_RESULT_TOPICS = {\n",
                "    \"events\": KAFKA_EVENTS_SUBSCRIPTIONS_RESULTS,\n",
                "    \"transactions\": KAFKA_TRANSACTIONS_SUBSCRIPTIONS_RESULTS,\n",
                "    \"sessions\": KAFKA_SESSIONS_SUBSCRIPTIONS_RESULTS,\n",
                "    \"metrics\": KAFKA_METRICS_SUBSCRIPTIONS_RESULTS,\n",
                "}\n",
                "\n",
                "# Cluster configuration for each Kafka topic by name.\n",
                "KAFKA_TOPICS = {\n",
                "    KAFKA_EVENTS: {\"cluster\": \"default\"},\n",
                "    KAFKA_TRANSACTIONS: {\"cluster\": \"default\"},\n",
                "    KAFKA_OUTCOMES: {\"cluster\": \"default\"},\n",
                "    # When OUTCOMES_BILLING is None, it inherits from OUTCOMES and does not\n",
                "    # create a separate producer. Check ``track_outcome`` for details.\n",
                "    KAFKA_OUTCOMES_BILLING: None,\n",
                "    KAFKA_EVENTS_SUBSCRIPTIONS_RESULTS: {\"cluster\": \"default\"},\n",
                "    KAFKA_TRANSACTIONS_SUBSCRIPTIONS_RESULTS: {\"cluster\": \"default\"},\n",
                "    KAFKA_SESSIONS_SUBSCRIPTIONS_RESULTS: {\"cluster\": \"default\"},\n",
                "    KAFKA_METRICS_SUBSCRIPTIONS_RESULTS: {\"cluster\": \"default\"},\n",
                "    # Topic for receiving simple events (error events without attachments) from Relay\n",
                "    KAFKA_INGEST_EVENTS: {\"cluster\": \"default\"},\n",
                "    # Topic for receiving 'complex' events (error events with attachments) from Relay\n",
                "    KAFKA_INGEST_ATTACHMENTS: {\"cluster\": \"default\"},\n",
                "    # Topic for receiving transaction events (APM events) from Relay\n",
                "    KAFKA_INGEST_TRANSACTIONS: {\"cluster\": \"default\"},\n",
                "    # Topic for receiving metrics from Relay\n",
                "    KAFKA_INGEST_METRICS: {\"cluster\": \"default\"},\n",
                "    # Topic for indexer translated metrics\n",
                "    KAFKA_SNUBA_METRICS: {\"cluster\": \"default\"},\n",
                "    # Topic for receiving profiles from Relay\n",
                "    KAFKA_PROFILES: {\"cluster\": \"default\"},\n",
                "    KAFKA_INGEST_PERFORMANCE_METRICS: {\"cluster\": \"default\"},\n",
                "    KAFKA_SNUBA_GENERIC_METRICS: {\"cluster\": \"default\"},\n",
                "}\n",
                "\n",
                "\n",
                "# If True, consumers will create the topics if they don't exist\n",
                "KAFKA_CONSUMER_AUTO_CREATE_TOPICS = True\n",
                "\n",
                "# For Jira, only approved apps can use the access_email_addresses scope\n",
                "# This scope allows Sentry to use the email endpoint (https://developer.atlassian.com/cloud/jira/platform/rest/v3/#api-rest-api-3-user-email-get)\n",
                "# We use the email with Jira 2-way sync in order to match the user\n",
                "JIRA_USE_EMAIL_SCOPE = False\n",
                "\n",
                "\"\"\"\n",
                "Fields are:\n",
                " - south_app_name: Which app to apply the conversion to\n",
                " - south_migration: The south migration to map to the new name. If None, then always\n",
                "   apply\n",
                " - django_app_name: The new app name to apply the conversion to\n",
                " - django_migration: Which django migration to 'fake' as run.\n",
                " - south_migration_required: Whether the south migration is required to proceed.\n",
                " - south_migration_required_error: Error message explaining what is going wrong.\n",
                "\"\"\"\n",
                "SOUTH_MIGRATION_CONVERSIONS = (\n",
                "    (\n",
                "        \"sentry\",\n",
                "        \"0472_auto__add_field_sentryapp_author\",\n",
                "        \"sentry\",\n",
                "        \"0001_initial\",\n",
                "        True,\n",
                "        \"Please upgrade to Sentry 9.1.2 before upgrading to any later versions.\",\n",
                "    ),\n",
                "    (\n",
                "        \"sentry\",\n",
                "        \"0516_auto__del_grouptagvalue__del_unique_grouptagvalue_group_id_key_value__\",\n",
                "        \"sentry\",\n",
                "        \"0002_912_to_recent\",\n",
                "        False,\n",
                "        \"\",\n",
                "    ),\n",
                "    (\n",
                "        \"sentry\",\n",
                "        \"0518_auto__chg_field_sentryappwebhookerror_response_code\",\n",
                "        \"sentry\",\n",
                "        \"0003_auto_20191022_0122\",\n",
                "        False,\n",
                "        \"\",\n",
                "    ),\n",
                "    (\"sentry.nodestore\", \"0001_initial\", \"nodestore\", \"0001_initial\", False, None),\n",
                "    (\"nodestore\", \"0001_initial\", \"nodestore\", \"0001_initial\", False, None),\n",
                "    (\n",
                "        \"social_auth\",\n",
                "        \"0004_auto__del_unique_usersocialauth_provider_uid__add_unique_usersocialaut\",\n",
                "        \"social_auth\",\n",
                "        \"0001_initial\",\n",
                "        True,\n",
                "        \"Please upgrade to Sentry 9.1.2 before upgrading to any later versions.\",\n",
                "    ),\n",
                ")\n",
                "\n",
                "# Whether to use Django migrations to create the database, or just build it based off\n",
                "# of models, similar to how syncdb used to work. The former is more correct, the latter\n",
                "# is much faster.\n",
                "MIGRATIONS_TEST_MIGRATE = os.environ.get(\"MIGRATIONS_TEST_MIGRATE\", \"0\") == \"1\"\n",
                "# Specifies the list of django apps to include in the lockfile. If Falsey then include\n",
                "# all apps with migrations\n",
                "MIGRATIONS_LOCKFILE_APP_WHITELIST = (\n",
                "    \"nodestore\",\n",
                "    \"sentry\",\n",
                "    \"social_auth\",\n",
                ")\n",
                "# Where to write the lockfile to.\n",
                "MIGRATIONS_LOCKFILE_PATH = os.path.join(PROJECT_ROOT, os.path.pardir, os.path.pardir)\n",
                "\n",
                "# Log error and abort processing (without dropping event) when process_event is\n",
                "# taking more than n seconds to process event\n",
                "SYMBOLICATOR_PROCESS_EVENT_HARD_TIMEOUT = 600\n",
                "\n",
                "# Log warning when process_event is taking more than n seconds to process event\n",
                "SYMBOLICATOR_PROCESS_EVENT_WARN_TIMEOUT = 120\n",
                "\n",
                "# Block symbolicate_event for this many seconds to wait for a initial response\n",
                "# from symbolicator after the task submission.\n",
                "SYMBOLICATOR_POLL_TIMEOUT = 10\n",
                "\n",
                "# When retrying symbolication requests or querying for the result this set the\n",
                "# max number of second to wait between subsequent attempts.\n",
                "SYMBOLICATOR_MAX_RETRY_AFTER = 5\n",
                "\n",
                "SENTRY_REQUEST_METRIC_ALLOWED_PATHS = (\n",
                "    \"sentry.web.api\",\n",
                "    \"sentry.web.frontend\",\n",
                "    \"sentry.api.endpoints\",\n",
                "    \"sentry.data_export.endpoints\",\n",
                "    \"sentry.discover.endpoints\",\n",
                "    \"sentry.incidents.endpoints\",\n",
                ")\n",
                "SENTRY_MAIL_ADAPTER_BACKEND = \"sentry.mail.adapter.MailAdapter\"\n",
                "\n",
                "# Project ID used by synthetic monitoring\n",
                "# Synthetic monitoring recurringly send events, prepared with specific\n",
                "# attributes, which can be identified through the whole processing pipeline and\n",
                "# observed mainly for producing stable metrics.\n",
                "SENTRY_SYNTHETIC_MONITORING_PROJECT_ID = None\n",
                "\n",
                "# Similarity cluster to use\n",
                "# Similarity-v1: uses hardcoded set of event properties for diffing\n",
                "SENTRY_SIMILARITY_INDEX_REDIS_CLUSTER = \"default\"\n",
                "# Similarity-v2: uses grouping components for diffing (None = fallback to setting for v1)\n",
                "SENTRY_SIMILARITY2_INDEX_REDIS_CLUSTER = None\n",
                "\n",
                "# The grouping strategy to use for driving similarity-v2. You can add multiple\n",
                "# strategies here to index them all. This is useful for transitioning a\n",
                "# similarity dataset to newer grouping configurations.\n",
                "#\n",
                "# The dictionary value represents the redis prefix to use.\n",
                "#\n",
                "# Check out `test_similarity_config_migration` to understand the procedure and risks.\n",
                "SENTRY_SIMILARITY_GROUPING_CONFIGURATIONS_TO_INDEX = {\n",
                "    \"similarity:2020-07-23\": \"a\",\n",
                "}\n",
                "\n",
                "SENTRY_USE_UWSGI = True\n",
                "\n",
                "# When copying attachments for to-be-reprocessed events into processing store,\n",
                "# how large is an individual file chunk? Each chunk is stored as Redis key.\n",
                "SENTRY_REPROCESSING_ATTACHMENT_CHUNK_SIZE = 2**20\n",
                "\n",
                "# Which cluster is used to store auxiliary data for reprocessing. Note that\n",
                "# this cluster is not used to store attachments etc, that still happens on\n",
                "# rc-processing. This is just for buffering up event IDs and storing a counter\n",
                "# for synchronization/progress report.\n",
                "SENTRY_REPROCESSING_SYNC_REDIS_CLUSTER = \"default\"\n",
                "\n",
                "# How long can reprocessing take before we start deleting its Redis keys?\n",
                "SENTRY_REPROCESSING_SYNC_TTL = 3600 * 24\n",
                "\n",
                "# How many events to query for at once while paginating through an entire\n",
                "# issue. Note that this needs to be kept in sync with the time-limits on\n",
                "# `sentry.tasks.reprocessing2.reprocess_group`. That task is responsible for\n",
                "# copying attachments from filestore into redis and can easily take a couple of\n",
                "# seconds per event. Better play it safe!\n",
                "SENTRY_REPROCESSING_PAGE_SIZE = 10\n",
                "\n",
                "# How many event IDs to buffer up in Redis before sending them to Snuba. This\n",
                "# is about \"remaining events\" exclusively.\n",
                "SENTRY_REPROCESSING_REMAINING_EVENTS_BUF_SIZE = 500\n",
                "\n",
                "# Which backend to use for RealtimeMetricsStore.\n",
                "#\n",
                "# Currently, only redis is supported.\n",
                "SENTRY_REALTIME_METRICS_BACKEND = (\n",
                "    \"sentry.processing.realtime_metrics.dummy.DummyRealtimeMetricsStore\"\n",
                ")\n",
                "SENTRY_REALTIME_METRICS_OPTIONS = {\n",
                "    # The redis cluster used for the realtime store redis backend.\n",
                "    \"cluster\": \"default\",\n",
                "    # The bucket size of the event counter.\n",
                "    #\n",
                "    # The size (in seconds) of the buckets that events are sorted into.\n",
                "    \"counter_bucket_size\": 10,\n",
                "    # Number of seconds to keep symbolicate_event rates per project.\n",
                "    #\n",
                "    # symbolicate_event tasks report the rates of events per project to redis\n",
                "    # so that projects that exceed a reasonable rate can be sent to the low\n",
                "    # priority queue. This setting determines how long we keep these rates\n",
                "    # around.\n",
                "    #\n",
                "    # The LPQ selection is computed using the rate of the most recent events covered by this\n",
                "    # time window.  See sentry.tasks.low_priority_symbolication.excessive_event_rate for the\n",
                "    # exact implementation.\n",
                "    \"counter_time_window\": 10 * 60,\n",
                "    # The bucket size of the processing duration histogram.\n",
                "    #\n",
                "    # The size (in seconds) of the buckets that events are sorted into.\n",
                "    \"duration_bucket_size\": 10,\n",
                "    # Number of seconds to keep symbolicate_event durations per project.\n",
                "    #\n",
                "    # symbolicate_event tasks report the processing durations of events per project to redis\n",
                "    # so that projects that exceed a reasonable duration can be sent to the low\n",
                "    # priority queue. This setting determines how long we keep these duration values\n",
                "    # around.\n",
                "    #\n",
                "    # The LPQ selection is computed using the durations of the most recent events covered by\n",
                "    # this time window.  See\n",
                "    # sentry.tasks.low_priority_symbolication.excessive_event_duration for the exact\n",
                "    # implementation.\n",
                "    \"duration_time_window\": 3 * 60,\n",
                "    # Number of seconds to wait after a project is made eligible or ineligible for the LPQ\n",
                "    # before its eligibility can be changed again.\n",
                "    #\n",
                "    # This backoff is only applied to automatic changes to project eligibility, and has zero effect\n",
                "    # on any manually-triggered changes to a project's presence in the LPQ.\n",
                "    \"backoff_timer\": 5 * 60,\n",
                "}\n",
                "\n",
                "# XXX(meredith): Temporary metrics indexer\n",
                "SENTRY_METRICS_INDEXER_REDIS_CLUSTER = \"default\"\n",
                "\n",
                "# Timeout for the project counter statement execution.\n",
                "# In case of contention on the project counter, prevent workers saturation with\n",
                "# save_event tasks from single project.\n",
                "# Value is in milliseconds. Set to `None` to disable.\n",
                "SENTRY_PROJECT_COUNTER_STATEMENT_TIMEOUT = 1000\n",
                "\n",
                "# Implemented in getsentry to run additional devserver workers.\n",
                "SENTRY_EXTRA_WORKERS = None\n",
                "\n",
                "SAMPLED_DEFAULT_RATE = 1.0\n",
                "\n",
                "# A set of extra URLs to sample\n",
                "ADDITIONAL_SAMPLED_URLS = {}\n",
                "\n",
                "# A set of extra tasks to sample\n",
                "ADDITIONAL_SAMPLED_TASKS = {}\n",
                "\n",
                "# This controls whether Sentry is run in a demo mode.\n",
                "# Enabling this will allow users to create accounts without an email or password.\n",
                "DEMO_MODE = False\n",
                "\n",
                "# all demo orgs are owned by the user with this email\n",
                "DEMO_ORG_OWNER_EMAIL = None\n",
                "\n",
                "# parameters that determine how demo events are generated\n",
                "DEMO_DATA_GEN_PARAMS = {}\n",
                "\n",
                "# parameters for an org when quickly generating them synchronously\n",
                "DEMO_DATA_QUICK_GEN_PARAMS = {}\n",
                "\n",
                "# adds an extra JS to HTML template\n",
                "INJECTED_SCRIPT_ASSETS = []\n",
                "\n",
                "# Sentry post process forwarder use batching consumer\n",
                "SENTRY_POST_PROCESS_FORWARDER_BATCHING = True\n",
                "\n",
                "# Whether badly behaving projects will be automatically\n",
                "# sent to the low priority queue\n",
                "SENTRY_ENABLE_AUTO_LOW_PRIORITY_QUEUE = False\n",
                "\n",
                "# Zero Downtime Migrations settings as defined at\n",
                "# https://github.com/tbicr/django-pg-zero-downtime-migrations#settings\n",
                "ZERO_DOWNTIME_MIGRATIONS_RAISE_FOR_UNSAFE = True\n",
                "ZERO_DOWNTIME_MIGRATIONS_LOCK_TIMEOUT = None\n",
                "ZERO_DOWNTIME_MIGRATIONS_STATEMENT_TIMEOUT = None\n",
                "# Note: The docs have this backwards. We set this to False here so that we always add check\n",
                "# constraints instead of setting the column to not null.\n",
                "ZERO_DOWNTIME_MIGRATIONS_USE_NOT_NULL = False\n",
                "\n",
                "ANOMALY_DETECTION_URL = \"127.0.0.1:9091\"\n",
                "ANOMALY_DETECTION_TIMEOUT = 30\n",
                "\n",
                "# This is the URL to the profiling service\n",
                "SENTRY_PROFILING_SERVICE_URL = \"http://localhost:8085\"\n",
                "\n",
                "SENTRY_ISSUE_ALERT_HISTORY = \"sentry.rules.history.backends.postgres.PostgresRuleHistoryBackend\"\n",
                "SENTRY_ISSUE_ALERT_HISTORY_OPTIONS = {}\n",
                "\n",
                "# This is useful for testing SSO expiry flows\n",
                "SENTRY_SSO_EXPIRY_SECONDS = os.environ.get(\"SENTRY_SSO_EXPIRY_SECONDS\", None)\n",
                "\n",
                "# Set to an iterable of strings matching services so only logs from those services show up\n",
                "# eg. DEVSERVER_LOGS_ALLOWLIST = {\"server\", \"webpack\", \"worker\"}\n",
                "DEVSERVER_LOGS_ALLOWLIST = None\n",
                "\n",
                "LOG_API_ACCESS = not IS_DEV or os.environ.get(\"SENTRY_LOG_API_ACCESS\")\n",
                "\n",
                "VALIDATE_SUPERUSER_ACCESS_CATEGORY_AND_REASON = True\n",
                "\n",
                "# determines if we enable analytics or not\n",
                "ENABLE_ANALYTICS = False\n",
                "\n",
                "MAX_ISSUE_ALERTS_PER_PROJECT = 100\n",
                "MAX_QUERY_SUBSCRIPTIONS_PER_ORG = 1000\n",
                "\n",
                "MAX_REDIS_SNOWFLAKE_RETRY_COUNTER = 5\n",
                "\n",
                "SNOWFLAKE_VERSION_ID = 1\n",
                "SNOWFLAKE_REGION_ID = 0\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "\n",
                    "\n",
                    "SENTRY_POST_PROCESS_LOCKS_BACKEND_OPTIONS = {\n",
                    "    \"path\": \"sentry.utils.locking.backends.redis.RedisLockBackend\",\n",
                    "    \"options\": {\"cluster\": \"default\"},\n",
                    "}"
                ],
                "parent_version_range": {
                    "start": 2682,
                    "end": 2682
                },
                "child_version_range": {
                    "start": 2682,
                    "end": 2688
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 0,
                "hunk_diff": "File: src/sentry/conf/server.py\nCode:\n  ...\n2679 2679    \n2680 2680    SNOWFLAKE_VERSION_ID = 1\n2681 2681    SNOWFLAKE_REGION_ID = 0\n     2682  + \n     2683  + \n     2684  + SENTRY_POST_PROCESS_LOCKS_BACKEND_OPTIONS = {\n     2685  +     \"path\": \"sentry.utils.locking.backends.redis.RedisLockBackend\",\n     2686  +     \"options\": {\"cluster\": \"default\"},\n     2687  + }\n           ...\n",
                "file_path": "src/sentry/conf/server.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "SENTRY_POST_PROCESS_LOCKS_BACKEND_OPTIONS"
                ],
                "prefix": [
                    "\n",
                    "SNOWFLAKE_VERSION_ID = 1\n",
                    "SNOWFLAKE_REGION_ID = 0\n"
                ],
                "suffix": [],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            }
        ],
        "src/sentry/tasks/post_process.py": [
            [
                "import logging\n",
                "\n",
                "import sentry_sdk\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "from django.conf import settings\n"
                ],
                "parent_version_range": {
                    "start": 3,
                    "end": 3
                },
                "child_version_range": {
                    "start": 3,
                    "end": 4
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 1,
                "hunk_diff": "File: src/sentry/tasks/post_process.py\nCode:\n  ...\n0 0    import logging\n1 1    \n2 2    import sentry_sdk\n  3  + from django.conf import settings\n3 4    \n4 5    from sentry import analytics, features\n     ...\n",
                "file_path": "src/sentry/tasks/post_process.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "conf",
                    "django",
                    "settings"
                ],
                "prefix": [
                    "import logging\n",
                    "\n",
                    "import sentry_sdk\n"
                ],
                "suffix": [
                    "\n",
                    "from sentry import analytics, features\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "\n",
                "from sentry import analytics, features\n"
            ],
            {
                "type": "delete",
                "before": [
                    "from sentry.app import locks\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 5,
                    "end": 6
                },
                "child_version_range": {
                    "start": 6,
                    "end": 6
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 2,
                "hunk_diff": "File: src/sentry/tasks/post_process.py\nCode:\n  ...\n3 4    \n4 5    from sentry import analytics, features\n5    - from sentry.app import locks\n6 6    from sentry.exceptions import PluginError\n7 7    from sentry.killswitches import killswitch_matches_context\n8 8    from sentry.signals import event_processed, issue_unignored, transaction_processed\n     ...\n",
                "file_path": "src/sentry/tasks/post_process.py",
                "identifiers_before": [
                    "app",
                    "locks",
                    "sentry"
                ],
                "identifiers_after": [],
                "prefix": [
                    "\n",
                    "from sentry import analytics, features\n"
                ],
                "suffix": [
                    "from sentry.exceptions import PluginError\n",
                    "from sentry.killswitches import killswitch_matches_context\n",
                    "from sentry.signals import event_processed, issue_unignored, transaction_processed\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "from sentry.exceptions import PluginError\n",
                "from sentry.killswitches import killswitch_matches_context\n",
                "from sentry.signals import event_processed, issue_unignored, transaction_processed\n",
                "from sentry.tasks.base import instrumented_task\n",
                "from sentry.types.activity import ActivityType\n",
                "from sentry.utils import metrics\n",
                "from sentry.utils.cache import cache\n",
                "from sentry.utils.event_frames import get_sdk_name\n",
                "from sentry.utils.locking import UnableToAcquireLock\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "from sentry.utils.locking.manager import LockManager\n"
                ],
                "parent_version_range": {
                    "start": 15,
                    "end": 15
                },
                "child_version_range": {
                    "start": 15,
                    "end": 16
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 3,
                "hunk_diff": "File: src/sentry/tasks/post_process.py\nCode:\n  ...\n12 12    from sentry.utils.cache import cache\n13 13    from sentry.utils.event_frames import get_sdk_name\n14 14    from sentry.utils.locking import UnableToAcquireLock\n   15  + from sentry.utils.locking.manager import LockManager\n15 16    from sentry.utils.safe import safe_execute\n16 17    from sentry.utils.sdk import bind_organization_context, set_current_event_project\n       ...\n",
                "file_path": "src/sentry/tasks/post_process.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "LockManager",
                    "locking",
                    "manager",
                    "sentry",
                    "utils"
                ],
                "prefix": [
                    "from sentry.utils.cache import cache\n",
                    "from sentry.utils.event_frames import get_sdk_name\n",
                    "from sentry.utils.locking import UnableToAcquireLock\n"
                ],
                "suffix": [
                    "from sentry.utils.safe import safe_execute\n",
                    "from sentry.utils.sdk import bind_organization_context, set_current_event_project\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [
                    {
                        "to_hunk_idx": 5,
                        "detail": {
                            "identifier": "LockManager",
                            "position": {
                                "start": {
                                    "line": 15,
                                    "column": 41
                                },
                                "end": {
                                    "line": 15,
                                    "column": 52
                                }
                            },
                            "type": "identifier",
                            "kind": "import",
                            "abs_file_path": "/data2/chenyan/repos/sentry/src/sentry/tasks/post_process.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    }
                ],
                "other_clones": []
            },
            [
                "from sentry.utils.safe import safe_execute\n",
                "from sentry.utils.sdk import bind_organization_context, set_current_event_project\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "from sentry.utils.services import build_instance_from_options\n"
                ],
                "parent_version_range": {
                    "start": 17,
                    "end": 17
                },
                "child_version_range": {
                    "start": 18,
                    "end": 19
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 4,
                "hunk_diff": "File: src/sentry/tasks/post_process.py\nCode:\n  ...\n15 16    from sentry.utils.safe import safe_execute\n16 17    from sentry.utils.sdk import bind_organization_context, set_current_event_project\n   18  + from sentry.utils.services import build_instance_from_options\n17 19    \n18 20    logger = logging.getLogger(\"sentry\")\n19 21    \n       ...\n",
                "file_path": "src/sentry/tasks/post_process.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "build_instance_from_options",
                    "sentry",
                    "services",
                    "utils"
                ],
                "prefix": [
                    "from sentry.utils.safe import safe_execute\n",
                    "from sentry.utils.sdk import bind_organization_context, set_current_event_project\n"
                ],
                "suffix": [
                    "\n",
                    "logger = logging.getLogger(\"sentry\")\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [
                    {
                        "to_hunk_idx": 5,
                        "detail": {
                            "identifier": "build_instance_from_options",
                            "position": {
                                "start": {
                                    "line": 18,
                                    "column": 34
                                },
                                "end": {
                                    "line": 18,
                                    "column": 61
                                }
                            },
                            "type": "identifier",
                            "kind": "import",
                            "abs_file_path": "/data2/chenyan/repos/sentry/src/sentry/tasks/post_process.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    }
                ],
                "other_clones": []
            },
            [
                "\n",
                "logger = logging.getLogger(\"sentry\")\n",
                "\n",
                "\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "locks = LockManager(build_instance_from_options(settings.SENTRY_POST_PROCESS_LOCKS_BACKEND_OPTIONS))\n",
                    "\n",
                    "\n"
                ],
                "parent_version_range": {
                    "start": 21,
                    "end": 21
                },
                "child_version_range": {
                    "start": 23,
                    "end": 26
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 5,
                "hunk_diff": "File: src/sentry/tasks/post_process.py\nCode:\n  ...\n18 20    logger = logging.getLogger(\"sentry\")\n19 21    \n20 22    \n   23  + locks = LockManager(build_instance_from_options(settings.SENTRY_POST_PROCESS_LOCKS_BACKEND_OPTIONS))\n   24  + \n   25  + \n21 26    def _get_service_hooks(project_id):\n22 27        from sentry.models import ServiceHook\n23 28    \n       ...\n",
                "file_path": "src/sentry/tasks/post_process.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "LockManager",
                    "SENTRY_POST_PROCESS_LOCKS_BACKEND_OPTIONS",
                    "build_instance_from_options",
                    "locks",
                    "settings"
                ],
                "prefix": [
                    "logger = logging.getLogger(\"sentry\")\n",
                    "\n",
                    "\n"
                ],
                "suffix": [
                    "def _get_service_hooks(project_id):\n",
                    "    from sentry.models import ServiceHook\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "LockManager",
                            "position": {
                                "start": {
                                    "line": 23,
                                    "column": 8
                                },
                                "end": {
                                    "line": 23,
                                    "column": 19
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/sentry/src/sentry/tasks/post_process.py",
                            "hunk_idx": 5,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "build_instance_from_options",
                            "position": {
                                "start": {
                                    "line": 23,
                                    "column": 20
                                },
                                "end": {
                                    "line": 23,
                                    "column": 47
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/sentry/src/sentry/tasks/post_process.py",
                            "hunk_idx": 5,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "def _get_service_hooks(project_id):\n",
                "    from sentry.models import ServiceHook\n",
                "\n",
                "    cache_key = f\"servicehooks:1:{project_id}\"\n",
                "    result = cache.get(cache_key)\n",
                "\n",
                "    if result is None:\n",
                "        hooks = ServiceHook.objects.filter(servicehookproject__project_id=project_id)\n",
                "        result = [(h.id, h.events) for h in hooks]\n",
                "        cache.set(cache_key, result, 60)\n",
                "    return result\n",
                "\n",
                "\n",
                "def _should_send_error_created_hooks(project):\n",
                "    from sentry.models import Organization, ServiceHook\n",
                "\n",
                "    cache_key = f\"servicehooks-error-created:1:{project.id}\"\n",
                "    result = cache.get(cache_key)\n",
                "\n",
                "    if result is None:\n",
                "\n",
                "        org = Organization.objects.get_from_cache(id=project.organization_id)\n",
                "        if not features.has(\"organizations:integrations-event-hooks\", organization=org):\n",
                "            cache.set(cache_key, 0, 60)\n",
                "            return False\n",
                "\n",
                "        result = (\n",
                "            ServiceHook.objects.filter(organization_id=org.id)\n",
                "            .extra(where=[\"events @> '{error.created}'\"])\n",
                "            .exists()\n",
                "        )\n",
                "\n",
                "        cache_value = 1 if result else 0\n",
                "        cache.set(cache_key, cache_value, 60)\n",
                "\n",
                "    return result\n",
                "\n",
                "\n",
                "def _capture_stats(event, is_new):\n",
                "    # TODO(dcramer): limit platforms to... something?\n",
                "    platform = event.group.platform\n",
                "    if not platform:\n",
                "        return\n",
                "    platform = platform.split(\"-\", 1)[0].split(\"_\", 1)[0]\n",
                "    tags = {\"platform\": platform}\n",
                "\n",
                "    if is_new:\n",
                "        metrics.incr(\"events.unique\", tags=tags, skip_internal=False)\n",
                "\n",
                "    metrics.incr(\"events.processed\", tags=tags, skip_internal=False)\n",
                "    metrics.incr(f\"events.processed.{platform}\", skip_internal=False)\n",
                "    metrics.timing(\"events.size.data\", event.size, tags=tags)\n",
                "\n",
                "    # This is an experiment to understand whether we have, in production,\n",
                "    # mismatches between event and group before we permanently rely on events\n",
                "    # for the platform. before adding some more verbose logging on this\n",
                "    # case, using a stats will give us a sense of the magnitude of the problem.\n",
                "    if event.group:\n",
                "        if event.group.platform != event.platform:\n",
                "            metrics.incr(\"events.platform_mismatch\", tags=tags)\n",
                "\n",
                "\n",
                "def handle_owner_assignment(project, group, event):\n",
                "    from sentry.models import GroupAssignee, ProjectOwnership\n",
                "\n",
                "    with metrics.timer(\"post_process.handle_owner_assignment\"):\n",
                "        with sentry_sdk.start_span(op=\"post_process.handle_owner_assignment.cache_set_owner\"):\n",
                "            owner_key = \"owner_exists:1:%s\" % group.id\n",
                "            owners_exists = cache.get(owner_key)\n",
                "            if owners_exists is None:\n",
                "                owners_exists = group.groupowner_set.exists()\n",
                "                # Cache for an hour if it's assigned. We don't need to move that fast.\n",
                "                cache.set(owner_key, owners_exists, 3600 if owners_exists else 60)\n",
                "\n",
                "        with sentry_sdk.start_span(op=\"post_process.handle_owner_assignment.cache_set_assignee\"):\n",
                "            # Is the issue already assigned to a team or user?\n",
                "            assignee_key = \"assignee_exists:1:%s\" % group.id\n",
                "            assignees_exists = cache.get(assignee_key)\n",
                "            if assignees_exists is None:\n",
                "                assignees_exists = group.assignee_set.exists()\n",
                "                # Cache for an hour if it's assigned. We don't need to move that fast.\n",
                "                cache.set(assignee_key, assignees_exists, 3600 if assignees_exists else 60)\n",
                "\n",
                "        if owners_exists and assignees_exists:\n",
                "            return\n",
                "\n",
                "        with sentry_sdk.start_span(op=\"post_process.handle_owner_assignment.get_autoassign_owners\"):\n",
                "            if killswitch_matches_context(\n",
                "                \"post_process.get-autoassign-owners\",\n",
                "                {\n",
                "                    \"project_id\": project.id,\n",
                "                },\n",
                "            ):\n",
                "                # see ProjectOwnership.get_autoassign_owners\n",
                "                auto_assignment = False\n",
                "                owners = []\n",
                "                assigned_by_codeowners = False\n",
                "            else:\n",
                "                (\n",
                "                    auto_assignment,\n",
                "                    owners,\n",
                "                    assigned_by_codeowners,\n",
                "                ) = ProjectOwnership.get_autoassign_owners(group.project_id, event.data)\n",
                "\n",
                "        with sentry_sdk.start_span(op=\"post_process.handle_owner_assignment.analytics_record\"):\n",
                "            if auto_assignment and owners and not assignees_exists:\n",
                "                assignment = GroupAssignee.objects.assign(group, owners[0], create_only=True)\n",
                "                if assignment[\"new_assignment\"] or assignment[\"updated_assignment\"]:\n",
                "                    analytics.record(\n",
                "                        \"codeowners.assignment\"\n",
                "                        if assigned_by_codeowners\n",
                "                        else \"issueowners.assignment\",\n",
                "                        organization_id=project.organization_id,\n",
                "                        project_id=project.id,\n",
                "                        group_id=group.id,\n",
                "                    )\n",
                "\n",
                "        with sentry_sdk.start_span(op=\"post_process.handle_owner_assignment.handle_group_owners\"):\n",
                "            if owners and not owners_exists:\n",
                "                try:\n",
                "                    handle_group_owners(project, group, owners)\n",
                "                except Exception:\n",
                "                    logger.exception(\"Failed to store group owners\")\n",
                "\n",
                "\n",
                "def handle_group_owners(project, group, owners):\n",
                "    \"\"\"\n",
                "    Stores group owners generated by `ProjectOwnership.get_autoassign_owners` in the\n",
                "    `GroupOwner` model, and handles any diffing/changes of which owners we're keeping.\n",
                "    :return:\n",
                "    \"\"\"\n",
                "    from sentry.models.groupowner import GroupOwner, GroupOwnerType\n",
                "    from sentry.models.team import Team\n",
                "    from sentry.models.user import User\n",
                "\n",
                "    lock = locks.get(f\"groupowner-bulk:{group.id}\", duration=10, name=\"groupowner_bulk\")\n",
                "    try:\n",
                "        with metrics.timer(\"post_process.handle_group_owners\"), sentry_sdk.start_span(\n",
                "            op=\"post_process.handle_group_owners\"\n",
                "        ), lock.acquire():\n",
                "            current_group_owners = GroupOwner.objects.filter(\n",
                "                group=group, type=GroupOwnerType.OWNERSHIP_RULE.value\n",
                "            )\n",
                "            new_owners = {(type(owner), owner.id) for owner in owners}\n",
                "            # Owners already in the database that we'll keep\n",
                "            keeping_owners = set()\n",
                "            for owner in current_group_owners:\n",
                "                lookup_key = (\n",
                "                    (Team, owner.team_id) if owner.team_id is not None else (User, owner.user_id)\n",
                "                )\n",
                "                if lookup_key not in new_owners:\n",
                "                    owner.delete()\n",
                "                else:\n",
                "                    keeping_owners.add(lookup_key)\n",
                "\n",
                "            new_group_owners = []\n",
                "\n",
                "            for key in new_owners:\n",
                "                if key not in keeping_owners:\n",
                "                    owner_type, owner_id = key\n",
                "                    user_id = None\n",
                "                    team_id = None\n",
                "                    if owner_type is User:\n",
                "                        user_id = owner_id\n",
                "                    if owner_type is Team:\n",
                "                        team_id = owner_id\n",
                "                    new_group_owners.append(\n",
                "                        GroupOwner(\n",
                "                            group=group,\n",
                "                            type=GroupOwnerType.OWNERSHIP_RULE.value,\n",
                "                            user_id=user_id,\n",
                "                            team_id=team_id,\n",
                "                            project=project,\n",
                "                            organization=project.organization,\n",
                "                        )\n",
                "                    )\n",
                "            if new_group_owners:\n",
                "                GroupOwner.objects.bulk_create(new_group_owners)\n",
                "    except UnableToAcquireLock:\n",
                "        pass\n",
                "\n",
                "\n",
                "def update_existing_attachments(event):\n",
                "    \"\"\"\n",
                "    Attaches the group_id to all event attachments that were either:\n",
                "\n",
                "    1) ingested prior to the event via the standalone attachment endpoint.\n",
                "    2) part of a different group before reprocessing started.\n",
                "    \"\"\"\n",
                "    from sentry.models import EventAttachment\n",
                "\n",
                "    EventAttachment.objects.filter(project_id=event.project_id, event_id=event.event_id).update(\n",
                "        group_id=event.group_id\n",
                "    )\n",
                "\n",
                "\n",
                "def fetch_buffered_group_stats(group):\n",
                "    \"\"\"\n",
                "    Fetches buffered increments to `times_seen` for this group and adds them to the current\n",
                "    `times_seen`.\n",
                "    \"\"\"\n",
                "    from sentry import buffer\n",
                "    from sentry.models import Group\n",
                "\n",
                "    result = buffer.get(Group, [\"times_seen\"], {\"pk\": group.id})\n",
                "    group.times_seen_pending = result[\"times_seen\"]\n",
                "\n",
                "\n",
                "@instrumented_task(\n",
                "    name=\"sentry.tasks.post_process.post_process_group\",\n",
                "    time_limit=120,\n",
                "    soft_time_limit=110,\n",
                ")\n",
                "def post_process_group(\n",
                "    is_new, is_regression, is_new_group_environment, cache_key, group_id=None, **kwargs\n",
                "):\n",
                "    \"\"\"\n",
                "    Fires post processing hooks for a group.\n",
                "    \"\"\"\n",
                "    from sentry.eventstore.models import Event\n",
                "    from sentry.eventstore.processing import event_processing_store\n",
                "    from sentry.reprocessing2 import is_reprocessed_event\n",
                "    from sentry.utils import snuba\n",
                "\n",
                "    with snuba.options_override({\"consistent\": True}):\n",
                "        # We use the data being present/missing in the processing store\n",
                "        # to ensure that we don't duplicate work should the forwarding consumers\n",
                "        # need to rewind history.\n",
                "        data = event_processing_store.get(cache_key)\n",
                "        if not data:\n",
                "            logger.info(\n",
                "                \"post_process.skipped\",\n",
                "                extra={\"cache_key\": cache_key, \"reason\": \"missing_cache\"},\n",
                "            )\n",
                "            return\n",
                "        event = Event(\n",
                "            project_id=data[\"project\"], event_id=data[\"event_id\"], group_id=group_id, data=data\n",
                "        )\n",
                "\n",
                "        set_current_event_project(event.project_id)\n",
                "\n",
                "        is_transaction_event = not bool(event.group_id)\n",
                "\n",
                "        from sentry.models import EventDict, Organization, Project\n",
                "\n",
                "        # Re-bind node data to avoid renormalization. We only want to\n",
                "        # renormalize when loading old data from the database.\n",
                "        event.data = EventDict(event.data, skip_renormalization=True)\n",
                "\n",
                "        with metrics.timer(\"tasks.post_process.delete_event_cache\"):\n",
                "            event_processing_store.delete_by_key(cache_key)\n",
                "\n",
                "        # Re-bind Project and Org since we're reading the Event object\n",
                "        # from cache which may contain stale parent models.\n",
                "        event.project = Project.objects.get_from_cache(id=event.project_id)\n",
                "        event.project.set_cached_field_value(\n",
                "            \"organization\", Organization.objects.get_from_cache(id=event.project.organization_id)\n",
                "        )\n",
                "\n",
                "        # Simplified post processing for transaction events.\n",
                "        # This should eventually be completely removed and transactions\n",
                "        # will not go through any post processing.\n",
                "        if is_transaction_event:\n",
                "            transaction_processed.send_robust(\n",
                "                sender=post_process_group,\n",
                "                project=event.project,\n",
                "                event=event,\n",
                "            )\n",
                "\n",
                "            return\n",
                "\n",
                "        is_reprocessed = is_reprocessed_event(event.data)\n",
                "        sentry_sdk.set_tag(\"is_reprocessed\", is_reprocessed)\n",
                "\n",
                "        # NOTE: we must pass through the full Event object, and not an\n",
                "        # event_id since the Event object may not actually have been stored\n",
                "        # in the database due to sampling.\n",
                "        from sentry.models import Commit, GroupInboxReason\n",
                "        from sentry.models.group import get_group_with_redirect\n",
                "        from sentry.models.groupinbox import add_group_to_inbox\n",
                "        from sentry.rules.processor import RuleProcessor\n",
                "        from sentry.tasks.groupowner import process_suspect_commits\n",
                "        from sentry.tasks.servicehooks import process_service_hook\n",
                "\n",
                "        # Re-bind Group since we're reading the Event object\n",
                "        # from cache, which may contain a stale group and project\n",
                "        event.group, _ = get_group_with_redirect(event.group_id)\n",
                "        event.group_id = event.group.id\n",
                "        # We fetch buffered updates to group aggregates here and populate them on the Group. This\n",
                "        # helps us avoid problems with processing group ignores and alert rules that rely on these\n",
                "        # stats.\n",
                "        fetch_buffered_group_stats(event.group)\n",
                "\n",
                "        event.group.project = event.project\n",
                "        event.group.project.set_cached_field_value(\"organization\", event.project.organization)\n",
                "\n",
                "        bind_organization_context(event.project.organization)\n",
                "\n",
                "        _capture_stats(event, is_new)\n",
                "\n",
                "        with sentry_sdk.start_span(op=\"tasks.post_process_group.add_group_to_inbox\"):\n",
                "            try:\n",
                "                if is_reprocessed and is_new:\n",
                "                    add_group_to_inbox(event.group, GroupInboxReason.REPROCESSED)\n",
                "            except Exception:\n",
                "                logger.exception(\"Failed to add group to inbox for reprocessed groups\")\n",
                "\n",
                "        if not is_reprocessed:\n",
                "            # we process snoozes before rules as it might create a regression\n",
                "            # but not if it's new because you can't immediately snooze a new group\n",
                "            has_reappeared = not is_new\n",
                "            try:\n",
                "                if has_reappeared:\n",
                "                    has_reappeared = process_snoozes(event.group)\n",
                "            except Exception:\n",
                "                logger.exception(\"Failed to process snoozes for group\")\n",
                "\n",
                "            try:\n",
                "                if not has_reappeared:  # If true, we added the .UNIGNORED reason already\n",
                "                    if is_new:\n",
                "                        add_group_to_inbox(event.group, GroupInboxReason.NEW)\n",
                "                    elif is_regression:\n",
                "                        add_group_to_inbox(event.group, GroupInboxReason.REGRESSION)\n",
                "            except Exception:\n",
                "                logger.exception(\"Failed to add group to inbox for non-reprocessed groups\")\n",
                "\n",
                "            with sentry_sdk.start_span(op=\"tasks.post_process_group.handle_owner_assignment\"):\n",
                "                try:\n",
                "                    handle_owner_assignment(event.project, event.group, event)\n",
                "                except Exception:\n",
                "                    logger.exception(\"Failed to handle owner assignments\")\n",
                "\n",
                "            rp = RuleProcessor(\n",
                "                event, is_new, is_regression, is_new_group_environment, has_reappeared\n",
                "            )\n",
                "            has_alert = False\n",
                "            with sentry_sdk.start_span(op=\"tasks.post_process_group.rule_processor_callbacks\"):\n",
                "                # TODO(dcramer): ideally this would fanout, but serializing giant\n",
                "                # objects back and forth isn't super efficient\n",
                "                for callback, futures in rp.apply():\n",
                "                    has_alert = True\n",
                "                    safe_execute(callback, event, futures, _with_transaction=False)\n",
                "\n",
                "            try:\n",
                "                lock = locks.get(\n",
                "                    f\"w-o:{event.group_id}-d-l\",\n",
                "                    duration=10,\n",
                "                    name=\"post_process_w_o\",\n",
                "                )\n",
                "                with lock.acquire():\n",
                "                    has_commit_key = f\"w-o:{event.project.organization_id}-h-c\"\n",
                "                    org_has_commit = cache.get(has_commit_key)\n",
                "                    if org_has_commit is None:\n",
                "                        org_has_commit = Commit.objects.filter(\n",
                "                            organization_id=event.project.organization_id\n",
                "                        ).exists()\n",
                "                        cache.set(has_commit_key, org_has_commit, 3600)\n",
                "\n",
                "                    if org_has_commit:\n",
                "                        group_cache_key = f\"w-o-i:g-{event.group_id}\"\n",
                "                        if cache.get(group_cache_key):\n",
                "                            metrics.incr(\n",
                "                                \"sentry.tasks.process_suspect_commits.debounce\",\n",
                "                                tags={\"detail\": \"w-o-i:g debounce\"},\n",
                "                            )\n",
                "                        else:\n",
                "                            from sentry.utils.committers import get_frame_paths\n",
                "\n",
                "                            cache.set(group_cache_key, True, 604800)  # 1 week in seconds\n",
                "                            event_frames = get_frame_paths(event)\n",
                "                            sdk_name = get_sdk_name(event.data)\n",
                "                            process_suspect_commits.delay(\n",
                "                                event_id=event.event_id,\n",
                "                                event_platform=event.platform,\n",
                "                                event_frames=event_frames,\n",
                "                                group_id=event.group_id,\n",
                "                                project_id=event.project_id,\n",
                "                                sdk_name=sdk_name,\n",
                "                            )\n",
                "            except UnableToAcquireLock:\n",
                "                pass\n",
                "            except Exception:\n",
                "                logger.exception(\"Failed to process suspect commits\")\n",
                "\n",
                "            if features.has(\"projects:servicehooks\", project=event.project):\n",
                "                allowed_events = {\"event.created\"}\n",
                "                if has_alert:\n",
                "                    allowed_events.add(\"event.alert\")\n",
                "\n",
                "                if allowed_events:\n",
                "                    for servicehook_id, events in _get_service_hooks(project_id=event.project_id):\n",
                "                        if any(e in allowed_events for e in events):\n",
                "                            process_service_hook.delay(servicehook_id=servicehook_id, event=event)\n",
                "\n",
                "            from sentry.tasks.sentry_apps import process_resource_change_bound\n",
                "\n",
                "            if event.get_event_type() == \"error\" and _should_send_error_created_hooks(\n",
                "                event.project\n",
                "            ):\n",
                "                process_resource_change_bound.delay(\n",
                "                    action=\"created\", sender=\"Error\", instance_id=event.event_id, instance=event\n",
                "                )\n",
                "            if is_new:\n",
                "                process_resource_change_bound.delay(\n",
                "                    action=\"created\", sender=\"Group\", instance_id=event.group_id\n",
                "                )\n",
                "\n",
                "            from sentry.plugins.base import plugins\n",
                "\n",
                "            for plugin in plugins.for_project(event.project):\n",
                "                plugin_post_process_group(\n",
                "                    plugin_slug=plugin.slug, event=event, is_new=is_new, is_regresion=is_regression\n",
                "                )\n",
                "\n",
                "            from sentry import similarity\n",
                "\n",
                "            with sentry_sdk.start_span(op=\"tasks.post_process_group.similarity\"):\n",
                "                safe_execute(similarity.record, event.project, [event], _with_transaction=False)\n",
                "\n",
                "        # Patch attachments that were ingested on the standalone path.\n",
                "        with sentry_sdk.start_span(op=\"tasks.post_process_group.update_existing_attachments\"):\n",
                "            try:\n",
                "                update_existing_attachments(event)\n",
                "            except Exception:\n",
                "                logger.exception(\"Failed to update existing attachments\")\n",
                "\n",
                "        if not is_reprocessed:\n",
                "            event_processed.send_robust(\n",
                "                sender=post_process_group,\n",
                "                project=event.project,\n",
                "                event=event,\n",
                "                primary_hash=kwargs.get(\"primary_hash\"),\n",
                "            )\n",
                "\n",
                "\n",
                "def process_snoozes(group):\n",
                "    \"\"\"\n",
                "    Return True if the group is transitioning from \"resolved\" to \"unresolved\",\n",
                "    otherwise return False.\n",
                "    \"\"\"\n",
                "    from sentry.models import (\n",
                "        Activity,\n",
                "        GroupInboxReason,\n",
                "        GroupSnooze,\n",
                "        GroupStatus,\n",
                "        add_group_to_inbox,\n",
                "    )\n",
                "    from sentry.models.grouphistory import GroupHistoryStatus, record_group_history\n",
                "\n",
                "    key = GroupSnooze.get_cache_key(group.id)\n",
                "    snooze = cache.get(key)\n",
                "    if snooze is None:\n",
                "        try:\n",
                "            snooze = GroupSnooze.objects.get(group=group)\n",
                "        except GroupSnooze.DoesNotExist:\n",
                "            snooze = False\n",
                "        # This cache is also set in post_save|delete.\n",
                "        cache.set(key, snooze, 3600)\n",
                "    if not snooze:\n",
                "        return False\n",
                "\n",
                "    if not snooze.is_valid(group, test_rates=True, use_pending_data=True):\n",
                "        snooze_details = {\n",
                "            \"until\": snooze.until,\n",
                "            \"count\": snooze.count,\n",
                "            \"window\": snooze.window,\n",
                "            \"user_count\": snooze.user_count,\n",
                "            \"user_window\": snooze.user_window,\n",
                "        }\n",
                "        add_group_to_inbox(group, GroupInboxReason.UNIGNORED, snooze_details)\n",
                "        record_group_history(group, GroupHistoryStatus.UNIGNORED)\n",
                "        Activity.objects.create(\n",
                "            project=group.project,\n",
                "            group=group,\n",
                "            type=ActivityType.SET_UNRESOLVED.value,\n",
                "            user=None,\n",
                "        )\n",
                "\n",
                "        snooze.delete()\n",
                "        group.update(status=GroupStatus.UNRESOLVED)\n",
                "        issue_unignored.send_robust(\n",
                "            project=group.project,\n",
                "            user=None,\n",
                "            group=group,\n",
                "            transition_type=\"automatic\",\n",
                "            sender=\"process_snoozes\",\n",
                "        )\n",
                "        return True\n",
                "\n",
                "    return False\n",
                "\n",
                "\n",
                "@instrumented_task(\n",
                "    name=\"sentry.tasks.post_process.plugin_post_process_group\",\n",
                "    stat_suffix=lambda plugin_slug, *a, **k: plugin_slug,\n",
                ")\n",
                "def plugin_post_process_group(plugin_slug, event, **kwargs):\n",
                "    \"\"\"\n",
                "    Fires post processing hooks for a group.\n",
                "    \"\"\"\n",
                "    set_current_event_project(event.project_id)\n",
                "\n",
                "    from sentry.plugins.base import plugins\n",
                "\n",
                "    plugin = plugins.get(plugin_slug)\n",
                "    safe_execute(\n",
                "        plugin.post_process,\n",
                "        event=event,\n",
                "        group=event.group,\n",
                "        expected_errors=(PluginError,),\n",
                "        _with_transaction=False,\n",
                "        **kwargs,\n",
                "    )"
            ]
        ],
        "src/sentry/utils/locking/backends/redis.py": [
            [
                "from typing import Optional\n",
                "from uuid import uuid4\n",
                "\n",
                "from sentry.utils import redis\n",
                "from sentry.utils.locking.backends import LockBackend\n",
                "\n",
                "delete_lock = redis.load_script(\"utils/locking/delete_lock.lua\")\n",
                "\n",
                "\n",
                "class RedisLockBackend(LockBackend):\n",
                "    def __init__(self, cluster, prefix=\"l:\", uuid=None):\n",
                "        if uuid is None:\n",
                "            uuid = uuid4().hex\n",
                "\n"
            ],
            {
                "type": "replace",
                "before": [
                    "        self.cluster = cluster\n"
                ],
                "after": [
                    "        if isinstance(cluster, str):\n",
                    "            self.cluster = redis.clusters.get(cluster)\n",
                    "        else:\n",
                    "            self.cluster = cluster\n",
                    "\n"
                ],
                "parent_version_range": {
                    "start": 14,
                    "end": 15
                },
                "child_version_range": {
                    "start": 14,
                    "end": 19
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "RedisLockBackend",
                        "signature": "class RedisLockBackend(LockBackend):",
                        "at_line": 9
                    },
                    {
                        "type": "function",
                        "name": "__init__",
                        "signature": "def __init__(self, cluster, prefix=\"l:\", uuid=None):",
                        "at_line": 10
                    }
                ],
                "idx": 6,
                "hunk_diff": "File: src/sentry/utils/locking/backends/redis.py\nCode:\n         class RedisLockBackend(LockBackend):\n             ...\n             def __init__(self, cluster, prefix=\"l:\", uuid=None):\n                 ...\n11 11            if uuid is None:\n12 12                uuid = uuid4().hex\n13 13    \n14     -         self.cluster = cluster\n   14  +         if isinstance(cluster, str):\n   15  +             self.cluster = redis.clusters.get(cluster)\n   16  +         else:\n   17  +             self.cluster = cluster\n   18  + \n15 19            self.prefix = prefix\n16 20            self.uuid = uuid\n17 21    \n       ...\n",
                "file_path": "src/sentry/utils/locking/backends/redis.py",
                "identifiers_before": [
                    "cluster",
                    "self"
                ],
                "identifiers_after": [
                    "cluster",
                    "clusters",
                    "get",
                    "isinstance",
                    "redis",
                    "self",
                    "str"
                ],
                "prefix": [
                    "        if uuid is None:\n",
                    "            uuid = uuid4().hex\n",
                    "\n"
                ],
                "suffix": [
                    "        self.prefix = prefix\n",
                    "        self.uuid = uuid\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "        self.prefix = prefix\n",
                "        self.uuid = uuid\n",
                "\n",
                "    def get_client(self, key, routing_key=None):\n",
                "        # This is a bit of an abstraction leak, but if an integer is provided\n",
                "        # we use that value to determine placement rather than the cluster\n",
                "        # router. This leaking allows us us to have more fine-grained control\n",
                "        # when data is already placed within partitions where the router\n",
                "        # wouldn't have placed it based on the key hash, and maintain data\n",
                "        # locality and failure isolation within those partitions. (For example,\n",
                "        # the entirety of a digest is bound to a specific partition by the\n",
                "        # *digest* key, even though a digest is composed of multiple values at\n",
                "        # different keys that would otherwise be placed on different\n",
                "        # partitions.)\n",
                "        if isinstance(routing_key, int):\n",
                "            index = routing_key % len(self.cluster.hosts)\n",
                "            return self.cluster.get_local_client(index)\n",
                "\n",
                "        if routing_key is not None:\n",
                "            key = routing_key\n",
                "        else:\n",
                "            key = self.prefix_key(key)\n",
                "\n",
                "        return self.cluster.get_local_client_for_key(key)\n",
                "\n",
                "    def prefix_key(self, key):\n",
                "        return f\"{self.prefix}{key}\"\n",
                "\n",
                "    def acquire(self, key: str, duration: int, routing_key: Optional[str] = None) -> None:\n",
                "        client = self.get_client(key, routing_key)\n",
                "        full_key = self.prefix_key(key)\n",
                "        if client.set(full_key, self.uuid, ex=duration, nx=True) is not True:\n",
                "            raise Exception(f\"Could not set key: {full_key!r}\")\n",
                "\n",
                "    def release(self, key, routing_key=None):\n",
                "        client = self.get_client(key, routing_key)\n",
                "        delete_lock(client, (self.prefix_key(key),), (self.uuid,))\n",
                "\n",
                "    def locked(self, key, routing_key=None):\n",
                "        client = self.get_client(key, routing_key)\n",
                "        return client.get(self.prefix_key(key)) is not None"
            ]
        ],
        "tests/sentry/utils/locking/backends/test_redis.py": [
            [
                "from unittest import TestCase\n",
                "\n",
                "import pytest\n",
                "from exam import fixture\n",
                "\n",
                "from sentry.utils.locking.backends.redis import RedisLockBackend\n",
                "from sentry.utils.redis import clusters\n",
                "\n",
                "\n",
                "class RedisLockBackendTestCase(TestCase):\n",
                "    @fixture\n",
                "    def cluster(self):\n",
                "        return clusters.get(\"default\")\n",
                "\n",
                "    @fixture\n",
                "    def backend(self):\n",
                "        return RedisLockBackend(self.cluster)\n",
                "\n",
                "    def test_success(self):\n",
                "        key = \"\\U0001F4A9\"\n",
                "        duration = 60\n",
                "        full_key = self.backend.prefix_key(key)\n",
                "        client = self.backend.get_client(key)\n",
                "\n",
                "        self.backend.acquire(key, duration)\n",
                "        assert client.get(full_key) == self.backend.uuid.encode(\"utf-8\")\n",
                "        assert duration - 2 < float(client.ttl(full_key)) <= duration\n",
                "\n",
                "        self.backend.release(key)\n",
                "        assert not client.exists(full_key)\n",
                "\n",
                "    def test_acquire_fail_on_conflict(self):\n",
                "        key = \"lock\"\n",
                "        duration = 60\n",
                "\n",
                "        other_cluster = RedisLockBackend(self.cluster)\n",
                "        other_cluster.acquire(key, duration)\n",
                "        with pytest.raises(Exception):\n",
                "            self.backend.acquire(key, duration)\n",
                "\n",
                "    def test_release_fail_on_missing(self):\n",
                "        with pytest.raises(Exception):\n",
                "            self.backend.release(\"missing-key\")\n",
                "\n",
                "    def test_release_fail_on_conflict(self):\n",
                "        key = \"lock\"\n",
                "        duration = 60\n",
                "        self.backend.get_client(key).set(self.backend.prefix_key(key), \"someone-elses-uuid\")\n",
                "\n",
                "        with pytest.raises(Exception):\n",
                "            self.backend.acquire(key, duration)\n",
                "\n",
                "    def test_locked(self):\n",
                "        key = \"lock:testkey\"\n",
                "        duration = 60\n",
                "        assert self.backend.locked(key) is False\n",
                "\n",
                "        self.backend.acquire(key, duration)\n",
                "        assert self.backend.locked(key)\n",
                "        self.backend.release(key)\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "\n",
                    "    def test_cluster_as_str(self):\n",
                    "        assert RedisLockBackend(cluster=\"default\").cluster == self.cluster"
                ],
                "parent_version_range": {
                    "start": 60,
                    "end": 60
                },
                "child_version_range": {
                    "start": 60,
                    "end": 63
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "RedisLockBackendTestCase",
                        "signature": "class RedisLockBackendTestCase(TestCase):",
                        "at_line": 9
                    },
                    {
                        "type": "function",
                        "name": "test_locked",
                        "signature": "def test_locked(self):",
                        "at_line": 52
                    },
                    {
                        "type": "call",
                        "name": "self.backend.release",
                        "signature": "self.backend.release(key)",
                        "at_line": 59,
                        "argument": "key"
                    }
                ],
                "idx": 7,
                "hunk_diff": "File: tests/sentry/utils/locking/backends/test_redis.py\nCode:\n         class RedisLockBackendTestCase(TestCase):\n             ...\n             def test_locked(self):\n                 ...\n57 57            self.backend.acquire(key, duration)\n58 58            assert self.backend.locked(key)\n59 59            self.backend.release(key)\n   60  + \n   61  +     def test_cluster_as_str(self):\n   62  +         assert RedisLockBackend(cluster=\"default\").cluster == self.cluster\n       ...\n",
                "file_path": "tests/sentry/utils/locking/backends/test_redis.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "RedisLockBackend",
                    "cluster",
                    "self",
                    "test_cluster_as_str"
                ],
                "prefix": [
                    "        self.backend.acquire(key, duration)\n",
                    "        assert self.backend.locked(key)\n",
                    "        self.backend.release(key)\n"
                ],
                "suffix": [],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            }
        ]
    },
    "partial_orders": [
        {
            "edit_hunk_pair": [
                0,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "def use"
        },
        {
            "edit_hunk_pair": [
                1,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "import use"
        },
        {
            "edit_hunk_pair": [
                2,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "refactor"
        },
        {
            "edit_hunk_pair": [
                3,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "import use"
        },
        {
            "edit_hunk_pair": [
                4,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "import use"
        },
        {
            "edit_hunk_pair": [
                6,
                7
            ],
            "edit_order": "bi-directional",
            "reason": "implement and test"
        }
    ]
}