{
    "language": "python",
    "commit_url": "https://github.com/pandas-dev/pandas/commit/d04f908a7af35602a3477bbc10d2ec05c61088e3",
    "commit_message": "CLN: remove deprecated classes 'NumericBlock' and 'ObjectBlock' (#57815)\n\nremove deprecated classes NumericBlock, ObjectBlock",
    "commit_snapshots": {
        "pandas/core/internals/__init__.py": [
            [
                "from pandas.core.internals.api import make_block  # 2023-09-18 pyarrow uses this\n",
                "from pandas.core.internals.concat import concatenate_managers\n",
                "from pandas.core.internals.managers import (\n",
                "    BlockManager,\n",
                "    SingleBlockManager,\n",
                ")\n",
                "\n",
                "__all__ = [\n",
                "    \"Block\",  # pylint: disable=undefined-all-variable\n",
                "    \"DatetimeTZBlock\",  # pylint: disable=undefined-all-variable\n",
                "    \"ExtensionBlock\",  # pylint: disable=undefined-all-variable\n",
                "    \"make_block\",\n",
                "    \"BlockManager\",\n",
                "    \"SingleBlockManager\",\n",
                "    \"concatenate_managers\",\n",
                "]\n",
                "\n",
                "\n",
                "def __getattr__(name: str):\n",
                "    # GH#55139\n",
                "    import warnings\n",
                "\n",
                "    if name == \"create_block_manager_from_blocks\":\n",
                "        # GH#33892\n",
                "        warnings.warn(\n",
                "            f\"{name} is deprecated and will be removed in a future version. \"\n",
                "            \"Use public APIs instead.\",\n",
                "            DeprecationWarning,\n",
                "            # https://github.com/pandas-dev/pandas/pull/55139#pullrequestreview-1720690758\n",
                "            # on hard-coding stacklevel\n",
                "            stacklevel=2,\n",
                "        )\n",
                "        from pandas.core.internals.managers import create_block_manager_from_blocks\n",
                "\n",
                "        return create_block_manager_from_blocks\n",
                "\n",
                "    if name in [\n"
            ],
            {
                "type": "delete",
                "before": [
                    "        \"NumericBlock\",\n",
                    "        \"ObjectBlock\",\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 37,
                    "end": 39
                },
                "child_version_range": {
                    "start": 37,
                    "end": 37
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if name in [\n        \"NumericBlock\",\n        \"ObjectBlock\",\n        \"Block\",\n        \"ExtensionBlock\",\n        \"DatetimeTZBlock\",\n    ]:",
                        "start_line": 36,
                        "end_line": 70
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "__getattr__",
                        "signature": "def __getattr__(name: str):",
                        "at_line": 18
                    }
                ],
                "idx": 0,
                "hunk_diff": "File: pandas/core/internals/__init__.py\nCode:\n         def __getattr__(name: str):\n             ...\n34 34            return create_block_manager_from_blocks\n35 35    \n36 36        if name in [\n37     -         \"NumericBlock\",\n38     -         \"ObjectBlock\",\n39 37            \"Block\",\n40 38            \"ExtensionBlock\",\n41 39            \"DatetimeTZBlock\",\n       ...\n",
                "file_path": "pandas/core/internals/__init__.py",
                "identifiers_before": [],
                "identifiers_after": [],
                "prefix": [
                    "        return create_block_manager_from_blocks\n",
                    "\n",
                    "    if name in [\n"
                ],
                "suffix": [
                    "        \"Block\",\n",
                    "        \"ExtensionBlock\",\n",
                    "        \"DatetimeTZBlock\",\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    5
                ]
            },
            [
                "        \"Block\",\n",
                "        \"ExtensionBlock\",\n",
                "        \"DatetimeTZBlock\",\n",
                "    ]:\n",
                "        warnings.warn(\n",
                "            f\"{name} is deprecated and will be removed in a future version. \"\n",
                "            \"Use public APIs instead.\",\n",
                "            DeprecationWarning,\n",
                "            # https://github.com/pandas-dev/pandas/pull/55139#pullrequestreview-1720690758\n",
                "            # on hard-coding stacklevel\n",
                "            stacklevel=2,\n",
                "        )\n"
            ],
            {
                "type": "replace",
                "before": [
                    "        if name == \"NumericBlock\":\n",
                    "            from pandas.core.internals.blocks import NumericBlock\n",
                    "\n",
                    "            return NumericBlock\n",
                    "        elif name == \"DatetimeTZBlock\":\n"
                ],
                "after": [
                    "        if name == \"DatetimeTZBlock\":\n"
                ],
                "parent_version_range": {
                    "start": 51,
                    "end": 56
                },
                "child_version_range": {
                    "start": 49,
                    "end": 50
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if name in [\n        \"NumericBlock\",\n        \"ObjectBlock\",\n        \"Block\",\n        \"ExtensionBlock\",\n        \"DatetimeTZBlock\",\n    ]:",
                        "start_line": 36,
                        "end_line": 70
                    },
                    {
                        "type": "if_statement",
                        "statement": "if name == \"NumericBlock\":",
                        "start_line": 51,
                        "end_line": 70
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "__getattr__",
                        "signature": "def __getattr__(name: str):",
                        "at_line": 18
                    }
                ],
                "idx": 1,
                "hunk_diff": "File: pandas/core/internals/__init__.py\nCode:\n         def __getattr__(name: str):\n             ...\n48 46                # on hard-coding stacklevel\n49 47                stacklevel=2,\n50 48            )\n51     -         if name == \"NumericBlock\":\n52     -             from pandas.core.internals.blocks import NumericBlock\n53     - \n54     -             return NumericBlock\n55     -         elif name == \"DatetimeTZBlock\":\n   49  +         if name == \"DatetimeTZBlock\":\n56 50                from pandas.core.internals.blocks import DatetimeTZBlock\n57 51    \n58 52                return DatetimeTZBlock\n       ...\n",
                "file_path": "pandas/core/internals/__init__.py",
                "identifiers_before": [
                    "NumericBlock",
                    "blocks",
                    "core",
                    "internals",
                    "name",
                    "pandas"
                ],
                "identifiers_after": [
                    "name"
                ],
                "prefix": [
                    "            # on hard-coding stacklevel\n",
                    "            stacklevel=2,\n",
                    "        )\n"
                ],
                "suffix": [
                    "            from pandas.core.internals.blocks import DatetimeTZBlock\n",
                    "\n",
                    "            return DatetimeTZBlock\n"
                ],
                "base_dependency_callee": [
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "NumericBlock",
                            "position": {
                                "start": {
                                    "line": 54,
                                    "column": 19
                                },
                                "end": {
                                    "line": 54,
                                    "column": 31
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/__init__.py",
                            "hunk_idx": 1,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "NumericBlock",
                            "position": {
                                "start": {
                                    "line": 52,
                                    "column": 53
                                },
                                "end": {
                                    "line": 52,
                                    "column": 65
                                }
                            },
                            "type": "identifier",
                            "kind": "import",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/__init__.py",
                            "hunk_idx": 1,
                            "dependency_checked": true
                        }
                    }
                ],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "            from pandas.core.internals.blocks import DatetimeTZBlock\n",
                "\n",
                "            return DatetimeTZBlock\n",
                "        elif name == \"ExtensionBlock\":\n",
                "            from pandas.core.internals.blocks import ExtensionBlock\n",
                "\n",
                "            return ExtensionBlock\n"
            ],
            {
                "type": "replace",
                "before": [
                    "        elif name == \"Block\":\n"
                ],
                "after": [
                    "        else:\n"
                ],
                "parent_version_range": {
                    "start": 63,
                    "end": 64
                },
                "child_version_range": {
                    "start": 57,
                    "end": 58
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if name in [\n        \"NumericBlock\",\n        \"ObjectBlock\",\n        \"Block\",\n        \"ExtensionBlock\",\n        \"DatetimeTZBlock\",\n    ]:",
                        "start_line": 36,
                        "end_line": 70
                    },
                    {
                        "type": "if_statement",
                        "statement": "if name == \"NumericBlock\":",
                        "start_line": 51,
                        "end_line": 70
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "__getattr__",
                        "signature": "def __getattr__(name: str):",
                        "at_line": 18
                    }
                ],
                "idx": 2,
                "hunk_diff": "File: pandas/core/internals/__init__.py\nCode:\n         def __getattr__(name: str):\n             ...\n60 54                from pandas.core.internals.blocks import ExtensionBlock\n61 55    \n62 56                return ExtensionBlock\n63     -         elif name == \"Block\":\n   57  +         else:\n64 58                from pandas.core.internals.blocks import Block\n65 59    \n66 60                return Block\n       ...\n",
                "file_path": "pandas/core/internals/__init__.py",
                "identifiers_before": [
                    "elif",
                    "name"
                ],
                "identifiers_after": [
                    "else"
                ],
                "prefix": [
                    "            from pandas.core.internals.blocks import ExtensionBlock\n",
                    "\n",
                    "            return ExtensionBlock\n"
                ],
                "suffix": [
                    "            from pandas.core.internals.blocks import Block\n",
                    "\n",
                    "            return Block\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "            from pandas.core.internals.blocks import Block\n",
                "\n",
                "            return Block\n"
            ],
            {
                "type": "delete",
                "before": [
                    "        else:\n",
                    "            from pandas.core.internals.blocks import ObjectBlock\n",
                    "\n",
                    "            return ObjectBlock\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 67,
                    "end": 71
                },
                "child_version_range": {
                    "start": 61,
                    "end": 61
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if name in [\n        \"NumericBlock\",\n        \"ObjectBlock\",\n        \"Block\",\n        \"ExtensionBlock\",\n        \"DatetimeTZBlock\",\n    ]:",
                        "start_line": 36,
                        "end_line": 70
                    },
                    {
                        "type": "if_statement",
                        "statement": "if name == \"NumericBlock\":",
                        "start_line": 51,
                        "end_line": 70
                    },
                    {
                        "type": "else_clause",
                        "statement": "else:",
                        "start_line": 67,
                        "end_line": 70
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "__getattr__",
                        "signature": "def __getattr__(name: str):",
                        "at_line": 18
                    }
                ],
                "idx": 3,
                "hunk_diff": "File: pandas/core/internals/__init__.py\nCode:\n         def __getattr__(name: str):\n             ...\n64 58                from pandas.core.internals.blocks import Block\n65 59    \n66 60                return Block\n67     -         else:\n68     -             from pandas.core.internals.blocks import ObjectBlock\n69     - \n70     -             return ObjectBlock\n71 61    \n72 62        raise AttributeError(f\"module 'pandas.core.internals' has no attribute '{name}'\")\n       ...\n",
                "file_path": "pandas/core/internals/__init__.py",
                "identifiers_before": [
                    "ObjectBlock",
                    "blocks",
                    "core",
                    "else",
                    "from",
                    "import",
                    "internals",
                    "pandas"
                ],
                "identifiers_after": [],
                "prefix": [
                    "            from pandas.core.internals.blocks import Block\n",
                    "\n",
                    "            return Block\n"
                ],
                "suffix": [
                    "\n",
                    "    raise AttributeError(f\"module 'pandas.core.internals' has no attribute '{name}'\")"
                ],
                "base_dependency_callee": [
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "ObjectBlock",
                            "position": {
                                "start": {
                                    "line": 70,
                                    "column": 19
                                },
                                "end": {
                                    "line": 70,
                                    "column": 30
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/__init__.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "ObjectBlock",
                            "position": {
                                "start": {
                                    "line": 68,
                                    "column": 53
                                },
                                "end": {
                                    "line": 68,
                                    "column": 64
                                }
                            },
                            "type": "identifier",
                            "kind": "import",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/__init__.py",
                            "hunk_idx": 3,
                            "dependency_checked": true
                        }
                    }
                ],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "\n",
                "    raise AttributeError(f\"module 'pandas.core.internals' has no attribute '{name}'\")"
            ]
        ],
        "pandas/core/internals/blocks.py": [
            [
                "from __future__ import annotations\n",
                "\n",
                "from functools import wraps\n",
                "import inspect\n",
                "import re\n",
                "from typing import (\n",
                "    TYPE_CHECKING,\n",
                "    Any,\n",
                "    Callable,\n",
                "    Literal,\n",
                "    cast,\n",
                "    final,\n",
                ")\n",
                "import warnings\n",
                "import weakref\n",
                "\n",
                "import numpy as np\n",
                "\n",
                "from pandas._libs import (\n",
                "    NaT,\n",
                "    internals as libinternals,\n",
                "    lib,\n",
                ")\n",
                "from pandas._libs.internals import (\n",
                "    BlockPlacement,\n",
                "    BlockValuesRefs,\n",
                ")\n",
                "from pandas._libs.missing import NA\n",
                "from pandas._typing import (\n",
                "    ArrayLike,\n",
                "    AxisInt,\n",
                "    DtypeBackend,\n",
                "    DtypeObj,\n",
                "    F,\n",
                "    FillnaOptions,\n",
                "    IgnoreRaise,\n",
                "    InterpolateOptions,\n",
                "    QuantileInterpolation,\n",
                "    Self,\n",
                "    Shape,\n",
                "    npt,\n",
                ")\n",
                "from pandas.errors import AbstractMethodError\n",
                "from pandas.util._decorators import cache_readonly\n",
                "from pandas.util._exceptions import find_stack_level\n",
                "from pandas.util._validators import validate_bool_kwarg\n",
                "\n",
                "from pandas.core.dtypes.astype import (\n",
                "    astype_array_safe,\n",
                "    astype_is_view,\n",
                ")\n",
                "from pandas.core.dtypes.cast import (\n",
                "    LossySetitemError,\n",
                "    can_hold_element,\n",
                "    convert_dtypes,\n",
                "    find_result_type,\n",
                "    np_can_hold_element,\n",
                ")\n",
                "from pandas.core.dtypes.common import (\n",
                "    is_1d_only_ea_dtype,\n",
                "    is_float_dtype,\n",
                "    is_integer_dtype,\n",
                "    is_list_like,\n",
                "    is_scalar,\n",
                "    is_string_dtype,\n",
                ")\n",
                "from pandas.core.dtypes.dtypes import (\n",
                "    DatetimeTZDtype,\n",
                "    ExtensionDtype,\n",
                "    IntervalDtype,\n",
                "    NumpyEADtype,\n",
                "    PeriodDtype,\n",
                ")\n",
                "from pandas.core.dtypes.generic import (\n",
                "    ABCDataFrame,\n",
                "    ABCIndex,\n",
                "    ABCNumpyExtensionArray,\n",
                "    ABCSeries,\n",
                ")\n",
                "from pandas.core.dtypes.missing import (\n",
                "    is_valid_na_for_dtype,\n",
                "    isna,\n",
                "    na_value_for_dtype,\n",
                ")\n",
                "\n",
                "from pandas.core import missing\n",
                "import pandas.core.algorithms as algos\n",
                "from pandas.core.array_algos.putmask import (\n",
                "    extract_bool_array,\n",
                "    putmask_inplace,\n",
                "    putmask_without_repeat,\n",
                "    setitem_datetimelike_compat,\n",
                "    validate_putmask,\n",
                ")\n",
                "from pandas.core.array_algos.quantile import quantile_compat\n",
                "from pandas.core.array_algos.replace import (\n",
                "    compare_or_regex_search,\n",
                "    replace_regex,\n",
                "    should_use_regex,\n",
                ")\n",
                "from pandas.core.array_algos.transforms import shift\n",
                "from pandas.core.arrays import (\n",
                "    Categorical,\n",
                "    DatetimeArray,\n",
                "    ExtensionArray,\n",
                "    IntervalArray,\n",
                "    NumpyExtensionArray,\n",
                "    PeriodArray,\n",
                "    TimedeltaArray,\n",
                ")\n",
                "from pandas.core.base import PandasObject\n",
                "import pandas.core.common as com\n",
                "from pandas.core.computation import expressions\n",
                "from pandas.core.construction import (\n",
                "    ensure_wrapped_if_datetimelike,\n",
                "    extract_array,\n",
                ")\n",
                "from pandas.core.indexers import check_setitem_lengths\n",
                "from pandas.core.indexes.base import get_values_for_csv\n",
                "\n",
                "if TYPE_CHECKING:\n",
                "    from collections.abc import (\n",
                "        Iterable,\n",
                "        Sequence,\n",
                "    )\n",
                "\n",
                "    from pandas.core.api import Index\n",
                "    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\n",
                "\n",
                "# comparison is faster than is_object_dtype\n",
                "_dtype_obj = np.dtype(\"object\")\n",
                "\n",
                "\n",
                "def maybe_split(meth: F) -> F:\n",
                "    \"\"\"\n",
                "    If we have a multi-column block, split and operate block-wise.  Otherwise\n",
                "    use the original method.\n",
                "    \"\"\"\n",
                "\n",
                "    @wraps(meth)\n",
                "    def newfunc(self, *args, **kwargs) -> list[Block]:\n",
                "        if self.ndim == 1 or self.shape[0] == 1:\n",
                "            return meth(self, *args, **kwargs)\n",
                "        else:\n",
                "            # Split and operate column-by-column\n",
                "            return self.split_and_operate(meth, *args, **kwargs)\n",
                "\n",
                "    return cast(F, newfunc)\n",
                "\n",
                "\n",
                "class Block(PandasObject, libinternals.Block):\n",
                "    \"\"\"\n",
                "    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\n",
                "    data structure\n",
                "\n",
                "    Index-ignorant; let the container take care of that\n",
                "    \"\"\"\n",
                "\n",
                "    values: np.ndarray | ExtensionArray\n",
                "    ndim: int\n",
                "    refs: BlockValuesRefs\n",
                "    __init__: Callable\n",
                "\n",
                "    __slots__ = ()\n",
                "    is_numeric = False\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def _validate_ndim(self) -> bool:\n",
                "        \"\"\"\n",
                "        We validate dimension for blocks that can hold 2D values, which for now\n",
                "        means numpy dtypes or DatetimeTZDtype.\n",
                "        \"\"\"\n",
                "        dtype = self.dtype\n",
                "        return not isinstance(dtype, ExtensionDtype) or isinstance(\n",
                "            dtype, DatetimeTZDtype\n",
                "        )\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def is_object(self) -> bool:\n",
                "        return self.values.dtype == _dtype_obj\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def is_extension(self) -> bool:\n",
                "        return not lib.is_np_dtype(self.values.dtype)\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def _can_consolidate(self) -> bool:\n",
                "        # We _could_ consolidate for DatetimeTZDtype but don't for now.\n",
                "        return not self.is_extension\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def _consolidate_key(self):\n",
                "        return self._can_consolidate, self.dtype.name\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def _can_hold_na(self) -> bool:\n",
                "        \"\"\"\n",
                "        Can we store NA values in this Block?\n",
                "        \"\"\"\n",
                "        dtype = self.dtype\n",
                "        if isinstance(dtype, np.dtype):\n",
                "            return dtype.kind not in \"iub\"\n",
                "        return dtype._can_hold_na\n",
                "\n",
                "    @final\n",
                "    @property\n",
                "    def is_bool(self) -> bool:\n",
                "        \"\"\"\n",
                "        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\n",
                "        \"\"\"\n",
                "        return self.values.dtype == np.dtype(bool)\n",
                "\n",
                "    @final\n",
                "    def external_values(self):\n",
                "        return external_values(self.values)\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def fill_value(self):\n",
                "        # Used in reindex_indexer\n",
                "        return na_value_for_dtype(self.dtype, compat=False)\n",
                "\n",
                "    @final\n",
                "    def _standardize_fill_value(self, value):\n",
                "        # if we are passed a scalar None, convert it here\n",
                "        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\n",
                "            value = self.fill_value\n",
                "        return value\n",
                "\n",
                "    @property\n",
                "    def mgr_locs(self) -> BlockPlacement:\n",
                "        return self._mgr_locs\n",
                "\n",
                "    @mgr_locs.setter\n",
                "    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\n",
                "        self._mgr_locs = new_mgr_locs\n",
                "\n",
                "    @final\n",
                "    def make_block(\n",
                "        self,\n",
                "        values,\n",
                "        placement: BlockPlacement | None = None,\n",
                "        refs: BlockValuesRefs | None = None,\n",
                "    ) -> Block:\n",
                "        \"\"\"\n",
                "        Create a new block, with type inference propagate any values that are\n",
                "        not specified\n",
                "        \"\"\"\n",
                "        if placement is None:\n",
                "            placement = self._mgr_locs\n",
                "        if self.is_extension:\n",
                "            values = ensure_block_shape(values, ndim=self.ndim)\n",
                "\n",
                "        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\n",
                "\n",
                "    @final\n",
                "    def make_block_same_class(\n",
                "        self,\n",
                "        values,\n",
                "        placement: BlockPlacement | None = None,\n",
                "        refs: BlockValuesRefs | None = None,\n",
                "    ) -> Self:\n",
                "        \"\"\"Wrap given values in a block of same type as self.\"\"\"\n",
                "        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\n",
                "        #  relied on it, as of 2.0 the caller is responsible for this.\n",
                "        if placement is None:\n",
                "            placement = self._mgr_locs\n",
                "\n",
                "        # We assume maybe_coerce_values has already been called\n",
                "        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\n",
                "\n",
                "    @final\n",
                "    def __repr__(self) -> str:\n",
                "        # don't want to print out all of the items here\n",
                "        name = type(self).__name__\n",
                "        if self.ndim == 1:\n",
                "            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\n",
                "        else:\n",
                "            shape = \" x \".join([str(s) for s in self.shape])\n",
                "            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\n",
                "\n",
                "        return result\n",
                "\n",
                "    @final\n",
                "    def __len__(self) -> int:\n",
                "        return len(self.values)\n",
                "\n",
                "    @final\n",
                "    def slice_block_columns(self, slc: slice) -> Self:\n",
                "        \"\"\"\n",
                "        Perform __getitem__-like, return result as block.\n",
                "        \"\"\"\n",
                "        new_mgr_locs = self._mgr_locs[slc]\n",
                "\n",
                "        new_values = self._slice(slc)\n",
                "        refs = self.refs\n",
                "        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\n",
                "\n",
                "    @final\n",
                "    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\n",
                "        \"\"\"\n",
                "        Perform __getitem__-like, return result as block.\n",
                "\n",
                "        Only supports slices that preserve dimensionality.\n",
                "        \"\"\"\n",
                "        # Note: only called from is from internals.concat, and we can verify\n",
                "        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\n",
                "\n",
                "        new_mgr_locs = self._mgr_locs[indices]\n",
                "\n",
                "        new_values = self._slice(indices)\n",
                "        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\n",
                "\n",
                "    @final\n",
                "    def getitem_block_columns(\n",
                "        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\n",
                "    ) -> Self:\n",
                "        \"\"\"\n",
                "        Perform __getitem__-like, return result as block.\n",
                "\n",
                "        Only supports slices that preserve dimensionality.\n",
                "        \"\"\"\n",
                "        new_values = self._slice(slicer)\n",
                "        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\n",
                "        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\n",
                "\n",
                "    @final\n",
                "    def _can_hold_element(self, element: Any) -> bool:\n",
                "        \"\"\"require the same dtype as ourselves\"\"\"\n",
                "        element = extract_array(element, extract_numpy=True)\n",
                "        return can_hold_element(self.values, element)\n",
                "\n",
                "    @final\n",
                "    def should_store(self, value: ArrayLike) -> bool:\n",
                "        \"\"\"\n",
                "        Should we set self.values[indexer] = value inplace or do we need to cast?\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        value : np.ndarray or ExtensionArray\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        bool\n",
                "        \"\"\"\n",
                "        return value.dtype == self.dtype\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # Apply/Reduce and Helpers\n",
                "\n",
                "    @final\n",
                "    def apply(self, func, **kwargs) -> list[Block]:\n",
                "        \"\"\"\n",
                "        apply the function to my values; return a block if we are not\n",
                "        one\n",
                "        \"\"\"\n",
                "        result = func(self.values, **kwargs)\n",
                "\n",
                "        result = maybe_coerce_values(result)\n",
                "        return self._split_op_result(result)\n",
                "\n",
                "    @final\n",
                "    def reduce(self, func) -> list[Block]:\n",
                "        # We will apply the function and reshape the result into a single-row\n",
                "        #  Block with the same mgr_locs; squeezing will be done at a higher level\n",
                "        assert self.ndim == 2\n",
                "\n",
                "        result = func(self.values)\n",
                "\n",
                "        if self.values.ndim == 1:\n",
                "            res_values = result\n",
                "        else:\n",
                "            res_values = result.reshape(-1, 1)\n",
                "\n",
                "        nb = self.make_block(res_values)\n",
                "        return [nb]\n",
                "\n",
                "    @final\n",
                "    def _split_op_result(self, result: ArrayLike) -> list[Block]:\n",
                "        # See also: split_and_operate\n",
                "        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\n",
                "            # TODO(EA2D): unnecessary with 2D EAs\n",
                "            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\n",
                "            nbs = []\n",
                "            for i, loc in enumerate(self._mgr_locs):\n",
                "                if not is_1d_only_ea_dtype(result.dtype):\n",
                "                    vals = result[i : i + 1]\n",
                "                else:\n",
                "                    vals = result[i]\n",
                "\n",
                "                bp = BlockPlacement(loc)\n",
                "                block = self.make_block(values=vals, placement=bp)\n",
                "                nbs.append(block)\n",
                "            return nbs\n",
                "\n",
                "        nb = self.make_block(result)\n",
                "\n",
                "        return [nb]\n",
                "\n",
                "    @final\n",
                "    def _split(self) -> list[Block]:\n",
                "        \"\"\"\n",
                "        Split a block into a list of single-column blocks.\n",
                "        \"\"\"\n",
                "        assert self.ndim == 2\n",
                "\n",
                "        new_blocks = []\n",
                "        for i, ref_loc in enumerate(self._mgr_locs):\n",
                "            vals = self.values[slice(i, i + 1)]\n",
                "\n",
                "            bp = BlockPlacement(ref_loc)\n",
                "            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)\n",
                "            new_blocks.append(nb)\n",
                "        return new_blocks\n",
                "\n",
                "    @final\n",
                "    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\n",
                "        \"\"\"\n",
                "        Split the block and apply func column-by-column.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        func : Block method\n",
                "        *args\n",
                "        **kwargs\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        List[Block]\n",
                "        \"\"\"\n",
                "        assert self.ndim == 2 and self.shape[0] != 1\n",
                "\n",
                "        res_blocks = []\n",
                "        for nb in self._split():\n",
                "            rbs = func(nb, *args, **kwargs)\n",
                "            res_blocks.extend(rbs)\n",
                "        return res_blocks\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # Up/Down-casting\n",
                "\n",
                "    @final\n",
                "    def coerce_to_target_dtype(self, other, warn_on_upcast: bool = False) -> Block:\n",
                "        \"\"\"\n",
                "        coerce the current block to a dtype compat for other\n",
                "        we will return a block, possibly object, and not raise\n",
                "\n",
                "        we can also safely try to coerce to the same dtype\n",
                "        and will receive the same block\n",
                "        \"\"\"\n",
                "        new_dtype = find_result_type(self.values.dtype, other)\n",
                "        if new_dtype == self.dtype:\n",
                "            # GH#52927 avoid RecursionError\n",
                "            raise AssertionError(\n",
                "                \"Something has gone wrong, please report a bug at \"\n",
                "                \"https://github.com/pandas-dev/pandas/issues\"\n",
                "            )\n",
                "\n",
                "        # In a future version of pandas, the default will be that\n",
                "        # setting `nan` into an integer series won't raise.\n",
                "        if (\n",
                "            is_scalar(other)\n",
                "            and is_integer_dtype(self.values.dtype)\n",
                "            and isna(other)\n",
                "            and other is not NaT\n",
                "            and not (\n",
                "                isinstance(other, (np.datetime64, np.timedelta64)) and np.isnat(other)\n",
                "            )\n",
                "        ):\n",
                "            warn_on_upcast = False\n",
                "        elif (\n",
                "            isinstance(other, np.ndarray)\n",
                "            and other.ndim == 1\n",
                "            and is_integer_dtype(self.values.dtype)\n",
                "            and is_float_dtype(other.dtype)\n",
                "            and lib.has_only_ints_or_nan(other)\n",
                "        ):\n",
                "            warn_on_upcast = False\n",
                "\n",
                "        if warn_on_upcast:\n",
                "            warnings.warn(\n",
                "                f\"Setting an item of incompatible dtype is deprecated \"\n",
                "                \"and will raise an error in a future version of pandas. \"\n",
                "                f\"Value '{other}' has dtype incompatible with {self.values.dtype}, \"\n",
                "                \"please explicitly cast to a compatible dtype first.\",\n",
                "                FutureWarning,\n",
                "                stacklevel=find_stack_level(),\n",
                "            )\n",
                "        if self.values.dtype == new_dtype:\n",
                "            raise AssertionError(\n",
                "                f\"Did not expect new dtype {new_dtype} to equal self.dtype \"\n",
                "                f\"{self.values.dtype}. Please report a bug at \"\n",
                "                \"https://github.com/pandas-dev/pandas/issues.\"\n",
                "            )\n",
                "        return self.astype(new_dtype)\n",
                "\n",
                "    @final\n",
                "    def convert(self) -> list[Block]:\n",
                "        \"\"\"\n",
                "        Attempt to coerce any object types to better types. Return a copy\n",
                "        of the block (if copy = True).\n",
                "        \"\"\"\n",
                "        if not self.is_object:\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        if self.ndim != 1 and self.shape[0] != 1:\n",
                "            blocks = self.split_and_operate(Block.convert)\n",
                "            if all(blk.dtype.kind == \"O\" for blk in blocks):\n",
                "                # Avoid fragmenting the block if convert is a no-op\n",
                "                return [self.copy(deep=False)]\n",
                "            return blocks\n",
                "\n",
                "        values = self.values\n",
                "        if values.ndim == 2:\n",
                "            # the check above ensures we only get here with values.shape[0] == 1,\n",
                "            # avoid doing .ravel as that might make a copy\n",
                "            values = values[0]\n",
                "\n",
                "        res_values = lib.maybe_convert_objects(\n",
                "            values,  # type: ignore[arg-type]\n",
                "            convert_non_numeric=True,\n",
                "        )\n",
                "        refs = None\n",
                "        if res_values is values:\n",
                "            refs = self.refs\n",
                "\n",
                "        res_values = ensure_block_shape(res_values, self.ndim)\n",
                "        res_values = maybe_coerce_values(res_values)\n",
                "        return [self.make_block(res_values, refs=refs)]\n",
                "\n",
                "    def convert_dtypes(\n",
                "        self,\n",
                "        infer_objects: bool = True,\n",
                "        convert_string: bool = True,\n",
                "        convert_integer: bool = True,\n",
                "        convert_boolean: bool = True,\n",
                "        convert_floating: bool = True,\n",
                "        dtype_backend: DtypeBackend = \"numpy_nullable\",\n",
                "    ) -> list[Block]:\n",
                "        if infer_objects and self.is_object:\n",
                "            blks = self.convert()\n",
                "        else:\n",
                "            blks = [self]\n",
                "\n",
                "        if not any(\n",
                "            [convert_floating, convert_integer, convert_boolean, convert_string]\n",
                "        ):\n",
                "            return [b.copy(deep=False) for b in blks]\n",
                "\n",
                "        rbs = []\n",
                "        for blk in blks:\n",
                "            # Determine dtype column by column\n",
                "            sub_blks = [blk] if blk.ndim == 1 or self.shape[0] == 1 else blk._split()\n",
                "            dtypes = [\n",
                "                convert_dtypes(\n",
                "                    b.values,\n",
                "                    convert_string,\n",
                "                    convert_integer,\n",
                "                    convert_boolean,\n",
                "                    convert_floating,\n",
                "                    infer_objects,\n",
                "                    dtype_backend,\n",
                "                )\n",
                "                for b in sub_blks\n",
                "            ]\n",
                "            if all(dtype == self.dtype for dtype in dtypes):\n",
                "                # Avoid block splitting if no dtype changes\n",
                "                rbs.append(blk.copy(deep=False))\n",
                "                continue\n",
                "\n",
                "            for dtype, b in zip(dtypes, sub_blks):\n",
                "                rbs.append(b.astype(dtype=dtype, squeeze=b.ndim != 1))\n",
                "        return rbs\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # Array-Like Methods\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def dtype(self) -> DtypeObj:\n",
                "        return self.values.dtype\n",
                "\n",
                "    @final\n",
                "    def astype(\n",
                "        self,\n",
                "        dtype: DtypeObj,\n",
                "        errors: IgnoreRaise = \"raise\",\n",
                "        squeeze: bool = False,\n",
                "    ) -> Block:\n",
                "        \"\"\"\n",
                "        Coerce to the new dtype.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        dtype : np.dtype or ExtensionDtype\n",
                "        errors : str, {'raise', 'ignore'}, default 'raise'\n",
                "            - ``raise`` : allow exceptions to be raised\n",
                "            - ``ignore`` : suppress exceptions. On error return original object\n",
                "        squeeze : bool, default False\n",
                "            squeeze values to ndim=1 if only one column is given\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        Block\n",
                "        \"\"\"\n",
                "        values = self.values\n",
                "        if squeeze and values.ndim == 2 and is_1d_only_ea_dtype(dtype):\n",
                "            if values.shape[0] != 1:\n",
                "                raise ValueError(\"Can not squeeze with more than one column.\")\n",
                "            values = values[0, :]  # type: ignore[call-overload]\n",
                "\n",
                "        new_values = astype_array_safe(values, dtype, errors=errors)\n",
                "\n",
                "        new_values = maybe_coerce_values(new_values)\n",
                "\n",
                "        refs = None\n",
                "        if astype_is_view(values.dtype, new_values.dtype):\n",
                "            refs = self.refs\n",
                "\n",
                "        newb = self.make_block(new_values, refs=refs)\n",
                "        if newb.shape != self.shape:\n",
                "            raise TypeError(\n",
                "                f\"cannot set astype for dtype \"\n",
                "                f\"({self.dtype.name} [{self.shape}]) to different shape \"\n",
                "                f\"({newb.dtype.name} [{newb.shape}])\"\n",
                "            )\n",
                "        return newb\n",
                "\n",
                "    @final\n",
                "    def get_values_for_csv(\n",
                "        self, *, float_format, date_format, decimal, na_rep: str = \"nan\", quoting=None\n",
                "    ) -> Block:\n",
                "        \"\"\"convert to our native types format\"\"\"\n",
                "        result = get_values_for_csv(\n",
                "            self.values,\n",
                "            na_rep=na_rep,\n",
                "            quoting=quoting,\n",
                "            float_format=float_format,\n",
                "            date_format=date_format,\n",
                "            decimal=decimal,\n",
                "        )\n",
                "        return self.make_block(result)\n",
                "\n",
                "    @final\n",
                "    def copy(self, deep: bool = True) -> Self:\n",
                "        \"\"\"copy constructor\"\"\"\n",
                "        values = self.values\n",
                "        refs: BlockValuesRefs | None\n",
                "        if deep:\n",
                "            values = values.copy()\n",
                "            refs = None\n",
                "        else:\n",
                "            refs = self.refs\n",
                "        return type(self)(values, placement=self._mgr_locs, ndim=self.ndim, refs=refs)\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # Copy-on-Write Helpers\n",
                "\n",
                "    def _maybe_copy(self, inplace: bool) -> Self:\n",
                "        if inplace:\n",
                "            deep = self.refs.has_reference()\n",
                "            return self.copy(deep=deep)\n",
                "        return self.copy()\n",
                "\n",
                "    @final\n",
                "    def _get_refs_and_copy(self, inplace: bool):\n",
                "        refs = None\n",
                "        copy = not inplace\n",
                "        if inplace:\n",
                "            if self.refs.has_reference():\n",
                "                copy = True\n",
                "            else:\n",
                "                refs = self.refs\n",
                "        return copy, refs\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # Replace\n",
                "\n",
                "    @final\n",
                "    def replace(\n",
                "        self,\n",
                "        to_replace,\n",
                "        value,\n",
                "        inplace: bool = False,\n",
                "        # mask may be pre-computed if we're called from replace_list\n",
                "        mask: npt.NDArray[np.bool_] | None = None,\n",
                "    ) -> list[Block]:\n",
                "        \"\"\"\n",
                "        replace the to_replace value with value, possible to create new\n",
                "        blocks here this is just a call to putmask.\n",
                "        \"\"\"\n",
                "\n",
                "        # Note: the checks we do in NDFrame.replace ensure we never get\n",
                "        #  here with listlike to_replace or value, as those cases\n",
                "        #  go through replace_list\n",
                "        values = self.values\n",
                "\n",
                "        if isinstance(values, Categorical):\n",
                "            # TODO: avoid special-casing\n",
                "            # GH49404\n",
                "            blk = self._maybe_copy(inplace)\n",
                "            values = cast(Categorical, blk.values)\n",
                "            values._replace(to_replace=to_replace, value=value, inplace=True)\n",
                "            return [blk]\n",
                "\n",
                "        if not self._can_hold_element(to_replace):\n",
                "            # We cannot hold `to_replace`, so we know immediately that\n",
                "            #  replacing it is a no-op.\n",
                "            # Note: If to_replace were a list, NDFrame.replace would call\n",
                "            #  replace_list instead of replace.\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        if mask is None:\n",
                "            mask = missing.mask_missing(values, to_replace)\n",
                "        if not mask.any():\n",
                "            # Note: we get here with test_replace_extension_other incorrectly\n",
                "            #  bc _can_hold_element is incorrect.\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        elif self._can_hold_element(value):\n",
                "            # TODO(CoW): Maybe split here as well into columns where mask has True\n",
                "            # and rest?\n",
                "            blk = self._maybe_copy(inplace)\n",
                "            putmask_inplace(blk.values, mask, value)\n",
                "            return [blk]\n",
                "\n",
                "        elif self.ndim == 1 or self.shape[0] == 1:\n",
                "            if value is None or value is NA:\n",
                "                blk = self.astype(np.dtype(object))\n",
                "            else:\n",
                "                blk = self.coerce_to_target_dtype(value)\n",
                "            return blk.replace(\n",
                "                to_replace=to_replace,\n",
                "                value=value,\n",
                "                inplace=True,\n",
                "                mask=mask,\n",
                "            )\n",
                "\n",
                "        else:\n",
                "            # split so that we only upcast where necessary\n",
                "            blocks = []\n",
                "            for i, nb in enumerate(self._split()):\n",
                "                blocks.extend(\n",
                "                    type(self).replace(\n",
                "                        nb,\n",
                "                        to_replace=to_replace,\n",
                "                        value=value,\n",
                "                        inplace=True,\n",
                "                        mask=mask[i : i + 1],\n",
                "                    )\n",
                "                )\n",
                "            return blocks\n",
                "\n",
                "    @final\n",
                "    def _replace_regex(\n",
                "        self,\n",
                "        to_replace,\n",
                "        value,\n",
                "        inplace: bool = False,\n",
                "        mask=None,\n",
                "    ) -> list[Block]:\n",
                "        \"\"\"\n",
                "        Replace elements by the given value.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        to_replace : object or pattern\n",
                "            Scalar to replace or regular expression to match.\n",
                "        value : object\n",
                "            Replacement object.\n",
                "        inplace : bool, default False\n",
                "            Perform inplace modification.\n",
                "        mask : array-like of bool, optional\n",
                "            True indicate corresponding element is ignored.\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        List[Block]\n",
                "        \"\"\"\n",
                "        if not self._can_hold_element(to_replace):\n",
                "            # i.e. only if self.is_object is True, but could in principle include a\n",
                "            #  String ExtensionBlock\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        rx = re.compile(to_replace)\n",
                "\n",
                "        block = self._maybe_copy(inplace)\n",
                "\n",
                "        replace_regex(block.values, rx, value, mask)\n",
                "        return [block]\n",
                "\n",
                "    @final\n",
                "    def replace_list(\n",
                "        self,\n",
                "        src_list: Iterable[Any],\n",
                "        dest_list: Sequence[Any],\n",
                "        inplace: bool = False,\n",
                "        regex: bool = False,\n",
                "    ) -> list[Block]:\n",
                "        \"\"\"\n",
                "        See BlockManager.replace_list docstring.\n",
                "        \"\"\"\n",
                "        values = self.values\n",
                "\n",
                "        if isinstance(values, Categorical):\n",
                "            # TODO: avoid special-casing\n",
                "            # GH49404\n",
                "            blk = self._maybe_copy(inplace)\n",
                "            values = cast(Categorical, blk.values)\n",
                "            values._replace(to_replace=src_list, value=dest_list, inplace=True)\n",
                "            return [blk]\n",
                "\n",
                "        # Exclude anything that we know we won't contain\n",
                "        pairs = [\n",
                "            (x, y) for x, y in zip(src_list, dest_list) if self._can_hold_element(x)\n",
                "        ]\n",
                "        if not len(pairs):\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        src_len = len(pairs) - 1\n",
                "\n",
                "        if is_string_dtype(values.dtype):\n",
                "            # Calculate the mask once, prior to the call of comp\n",
                "            # in order to avoid repeating the same computations\n",
                "            na_mask = ~isna(values)\n",
                "            masks: Iterable[npt.NDArray[np.bool_]] = (\n",
                "                extract_bool_array(\n",
                "                    cast(\n",
                "                        ArrayLike,\n",
                "                        compare_or_regex_search(\n",
                "                            values, s[0], regex=regex, mask=na_mask\n",
                "                        ),\n",
                "                    )\n",
                "                )\n",
                "                for s in pairs\n",
                "            )\n",
                "        else:\n",
                "            # GH#38086 faster if we know we dont need to check for regex\n",
                "            masks = (missing.mask_missing(values, s[0]) for s in pairs)\n",
                "        # Materialize if inplace = True, since the masks can change\n",
                "        # as we replace\n",
                "        if inplace:\n",
                "            masks = list(masks)\n",
                "\n",
                "        # Don't set up refs here, otherwise we will think that we have\n",
                "        # references when we check again later\n",
                "        rb = [self]\n",
                "\n",
                "        for i, ((src, dest), mask) in enumerate(zip(pairs, masks)):\n",
                "            new_rb: list[Block] = []\n",
                "\n",
                "            # GH-39338: _replace_coerce can split a block into\n",
                "            # single-column blocks, so track the index so we know\n",
                "            # where to index into the mask\n",
                "            for blk_num, blk in enumerate(rb):\n",
                "                if len(rb) == 1:\n",
                "                    m = mask\n",
                "                else:\n",
                "                    mib = mask\n",
                "                    assert not isinstance(mib, bool)\n",
                "                    m = mib[blk_num : blk_num + 1]\n",
                "\n",
                "                # error: Argument \"mask\" to \"_replace_coerce\" of \"Block\" has\n",
                "                # incompatible type \"Union[ExtensionArray, ndarray[Any, Any], bool]\";\n",
                "                # expected \"ndarray[Any, dtype[bool_]]\"\n",
                "                result = blk._replace_coerce(\n",
                "                    to_replace=src,\n",
                "                    value=dest,\n",
                "                    mask=m,\n",
                "                    inplace=inplace,\n",
                "                    regex=regex,\n",
                "                )\n",
                "\n",
                "                if i != src_len:\n",
                "                    # This is ugly, but we have to get rid of intermediate refs\n",
                "                    # that did not go out of scope yet, otherwise we will trigger\n",
                "                    # many unnecessary copies\n",
                "                    for b in result:\n",
                "                        ref = weakref.ref(b)\n",
                "                        b.refs.referenced_blocks.pop(\n",
                "                            b.refs.referenced_blocks.index(ref)\n",
                "                        )\n",
                "                new_rb.extend(result)\n",
                "            rb = new_rb\n",
                "        return rb\n",
                "\n",
                "    @final\n",
                "    def _replace_coerce(\n",
                "        self,\n",
                "        to_replace,\n",
                "        value,\n",
                "        mask: npt.NDArray[np.bool_],\n",
                "        inplace: bool = True,\n",
                "        regex: bool = False,\n",
                "    ) -> list[Block]:\n",
                "        \"\"\"\n",
                "        Replace value corresponding to the given boolean array with another\n",
                "        value.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        to_replace : object or pattern\n",
                "            Scalar to replace or regular expression to match.\n",
                "        value : object\n",
                "            Replacement object.\n",
                "        mask : np.ndarray[bool]\n",
                "            True indicate corresponding element is ignored.\n",
                "        inplace : bool, default True\n",
                "            Perform inplace modification.\n",
                "        regex : bool, default False\n",
                "            If true, perform regular expression substitution.\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        List[Block]\n",
                "        \"\"\"\n",
                "        if should_use_regex(regex, to_replace):\n",
                "            return self._replace_regex(\n",
                "                to_replace,\n",
                "                value,\n",
                "                inplace=inplace,\n",
                "                mask=mask,\n",
                "            )\n",
                "        else:\n",
                "            if value is None:\n",
                "                # gh-45601, gh-45836, gh-46634\n",
                "                if mask.any():\n",
                "                    has_ref = self.refs.has_reference()\n",
                "                    nb = self.astype(np.dtype(object))\n",
                "                    if not inplace:\n",
                "                        nb = nb.copy()\n",
                "                    elif inplace and has_ref and nb.refs.has_reference():\n",
                "                        # no copy in astype and we had refs before\n",
                "                        nb = nb.copy()\n",
                "                    putmask_inplace(nb.values, mask, value)\n",
                "                    return [nb]\n",
                "                return [self]\n",
                "            return self.replace(\n",
                "                to_replace=to_replace,\n",
                "                value=value,\n",
                "                inplace=inplace,\n",
                "                mask=mask,\n",
                "            )\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # 2D Methods - Shared by NumpyBlock and NDArrayBackedExtensionBlock\n",
                "    #  but not ExtensionBlock\n",
                "\n",
                "    def _maybe_squeeze_arg(self, arg: np.ndarray) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        For compatibility with 1D-only ExtensionArrays.\n",
                "        \"\"\"\n",
                "        return arg\n",
                "\n",
                "    def _unwrap_setitem_indexer(self, indexer):\n",
                "        \"\"\"\n",
                "        For compatibility with 1D-only ExtensionArrays.\n",
                "        \"\"\"\n",
                "        return indexer\n",
                "\n",
                "    # NB: this cannot be made cache_readonly because in mgr.set_values we pin\n",
                "    #  new .values that can have different shape GH#42631\n",
                "    @property\n",
                "    def shape(self) -> Shape:\n",
                "        return self.values.shape\n",
                "\n",
                "    def iget(self, i: int | tuple[int, int] | tuple[slice, int]) -> np.ndarray:\n",
                "        # In the case where we have a tuple[slice, int], the slice will always\n",
                "        #  be slice(None)\n",
                "        # Note: only reached with self.ndim == 2\n",
                "        # Invalid index type \"Union[int, Tuple[int, int], Tuple[slice, int]]\"\n",
                "        # for \"Union[ndarray[Any, Any], ExtensionArray]\"; expected type\n",
                "        # \"Union[int, integer[Any]]\"\n",
                "        return self.values[i]  # type: ignore[index]\n",
                "\n",
                "    def _slice(\n",
                "        self, slicer: slice | npt.NDArray[np.bool_] | npt.NDArray[np.intp]\n",
                "    ) -> ArrayLike:\n",
                "        \"\"\"return a slice of my values\"\"\"\n",
                "\n",
                "        return self.values[slicer]\n",
                "\n",
                "    def set_inplace(self, locs, values: ArrayLike, copy: bool = False) -> None:\n",
                "        \"\"\"\n",
                "        Modify block values in-place with new item value.\n",
                "\n",
                "        If copy=True, first copy the underlying values in place before modifying\n",
                "        (for Copy-on-Write).\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        `set_inplace` never creates a new array or new Block, whereas `setitem`\n",
                "        _may_ create a new array and always creates a new Block.\n",
                "\n",
                "        Caller is responsible for checking values.dtype == self.dtype.\n",
                "        \"\"\"\n",
                "        if copy:\n",
                "            self.values = self.values.copy()\n",
                "        self.values[locs] = values\n",
                "\n",
                "    @final\n",
                "    def take_nd(\n",
                "        self,\n",
                "        indexer: npt.NDArray[np.intp],\n",
                "        axis: AxisInt,\n",
                "        new_mgr_locs: BlockPlacement | None = None,\n",
                "        fill_value=lib.no_default,\n",
                "    ) -> Block:\n",
                "        \"\"\"\n",
                "        Take values according to indexer and return them as a block.\n",
                "        \"\"\"\n",
                "        values = self.values\n",
                "\n",
                "        if fill_value is lib.no_default:\n",
                "            fill_value = self.fill_value\n",
                "            allow_fill = False\n",
                "        else:\n",
                "            allow_fill = True\n",
                "\n",
                "        # Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\n",
                "        new_values = algos.take_nd(\n",
                "            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n",
                "        )\n",
                "\n",
                "        # Called from three places in managers, all of which satisfy\n",
                "        #  these assertions\n",
                "        if isinstance(self, ExtensionBlock):\n",
                "            # NB: in this case, the 'axis' kwarg will be ignored in the\n",
                "            #  algos.take_nd call above.\n",
                "            assert not (self.ndim == 1 and new_mgr_locs is None)\n",
                "        assert not (axis == 0 and new_mgr_locs is None)\n",
                "\n",
                "        if new_mgr_locs is None:\n",
                "            new_mgr_locs = self._mgr_locs\n",
                "\n",
                "        if new_values.dtype != self.dtype:\n",
                "            return self.make_block(new_values, new_mgr_locs)\n",
                "        else:\n",
                "            return self.make_block_same_class(new_values, new_mgr_locs)\n",
                "\n",
                "    def _unstack(\n",
                "        self,\n",
                "        unstacker,\n",
                "        fill_value,\n",
                "        new_placement: npt.NDArray[np.intp],\n",
                "        needs_masking: npt.NDArray[np.bool_],\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Return a list of unstacked blocks of self\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        unstacker : reshape._Unstacker\n",
                "        fill_value : int\n",
                "            Only used in ExtensionBlock._unstack\n",
                "        new_placement : np.ndarray[np.intp]\n",
                "        allow_fill : bool\n",
                "        needs_masking : np.ndarray[bool]\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        blocks : list of Block\n",
                "            New blocks of unstacked values.\n",
                "        mask : array-like of bool\n",
                "            The mask of columns of `blocks` we should keep.\n",
                "        \"\"\"\n",
                "        new_values, mask = unstacker.get_new_values(\n",
                "            self.values.T, fill_value=fill_value\n",
                "        )\n",
                "\n",
                "        mask = mask.any(0)\n",
                "        # TODO: in all tests we have mask.all(); can we rely on that?\n",
                "\n",
                "        # Note: these next two lines ensure that\n",
                "        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\n",
                "        #  which the calling function needs in order to pass verify_integrity=False\n",
                "        #  to the BlockManager constructor\n",
                "        new_values = new_values.T[mask]\n",
                "        new_placement = new_placement[mask]\n",
                "\n",
                "        bp = BlockPlacement(new_placement)\n",
                "        blocks = [new_block_2d(new_values, placement=bp)]\n",
                "        return blocks, mask\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "\n",
                "    def setitem(self, indexer, value) -> Block:\n",
                "        \"\"\"\n",
                "        Attempt self.values[indexer] = value, possibly creating a new array.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        indexer : tuple, list-like, array-like, slice, int\n",
                "            The subset of self.values to set\n",
                "        value : object\n",
                "            The value being set\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        Block\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        `indexer` is a direct slice/positional indexer. `value` must\n",
                "        be a compatible shape.\n",
                "        \"\"\"\n",
                "\n",
                "        value = self._standardize_fill_value(value)\n",
                "\n",
                "        values = cast(np.ndarray, self.values)\n",
                "        if self.ndim == 2:\n",
                "            values = values.T\n",
                "\n",
                "        # length checking\n",
                "        check_setitem_lengths(indexer, value, values)\n",
                "\n",
                "        if self.dtype != _dtype_obj:\n",
                "            # GH48933: extract_array would convert a pd.Series value to np.ndarray\n",
                "            value = extract_array(value, extract_numpy=True)\n",
                "        try:\n",
                "            casted = np_can_hold_element(values.dtype, value)\n",
                "        except LossySetitemError:\n",
                "            # current dtype cannot store value, coerce to common dtype\n",
                "            nb = self.coerce_to_target_dtype(value, warn_on_upcast=True)\n",
                "            return nb.setitem(indexer, value)\n",
                "        else:\n",
                "            if self.dtype == _dtype_obj:\n",
                "                # TODO: avoid having to construct values[indexer]\n",
                "                vi = values[indexer]\n",
                "                if lib.is_list_like(vi):\n",
                "                    # checking lib.is_scalar here fails on\n",
                "                    #  test_iloc_setitem_custom_object\n",
                "                    casted = setitem_datetimelike_compat(values, len(vi), casted)\n",
                "\n",
                "            self = self._maybe_copy(inplace=True)\n",
                "            values = cast(np.ndarray, self.values.T)\n",
                "            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\n",
                "                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\n",
                "                casted = casted[0, ...]\n",
                "            try:\n",
                "                values[indexer] = casted\n",
                "            except (TypeError, ValueError) as err:\n",
                "                if is_list_like(casted):\n",
                "                    raise ValueError(\n",
                "                        \"setting an array element with a sequence.\"\n",
                "                    ) from err\n",
                "                raise\n",
                "        return self\n",
                "\n",
                "    def putmask(self, mask, new) -> list[Block]:\n",
                "        \"\"\"\n",
                "        putmask the data to the block; it is possible that we may create a\n",
                "        new dtype of block\n",
                "\n",
                "        Return the resulting block(s).\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\n",
                "        new : a ndarray/object\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        List[Block]\n",
                "        \"\"\"\n",
                "        orig_mask = mask\n",
                "        values = cast(np.ndarray, self.values)\n",
                "        mask, noop = validate_putmask(values.T, mask)\n",
                "        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\n",
                "\n",
                "        if new is lib.no_default:\n",
                "            new = self.fill_value\n",
                "\n",
                "        new = self._standardize_fill_value(new)\n",
                "        new = extract_array(new, extract_numpy=True)\n",
                "\n",
                "        if noop:\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        try:\n",
                "            casted = np_can_hold_element(values.dtype, new)\n",
                "\n",
                "            self = self._maybe_copy(inplace=True)\n",
                "            values = cast(np.ndarray, self.values)\n",
                "\n",
                "            putmask_without_repeat(values.T, mask, casted)\n",
                "            return [self]\n",
                "        except LossySetitemError:\n",
                "            if self.ndim == 1 or self.shape[0] == 1:\n",
                "                # no need to split columns\n",
                "\n",
                "                if not is_list_like(new):\n",
                "                    # using just new[indexer] can't save us the need to cast\n",
                "                    return self.coerce_to_target_dtype(\n",
                "                        new, warn_on_upcast=True\n",
                "                    ).putmask(mask, new)\n",
                "                else:\n",
                "                    indexer = mask.nonzero()[0]\n",
                "                    nb = self.setitem(indexer, new[indexer])\n",
                "                    return [nb]\n",
                "\n",
                "            else:\n",
                "                is_array = isinstance(new, np.ndarray)\n",
                "\n",
                "                res_blocks = []\n",
                "                nbs = self._split()\n",
                "                for i, nb in enumerate(nbs):\n",
                "                    n = new\n",
                "                    if is_array:\n",
                "                        # we have a different value per-column\n",
                "                        n = new[:, i : i + 1]\n",
                "\n",
                "                    submask = orig_mask[:, i : i + 1]\n",
                "                    rbs = nb.putmask(submask, n)\n",
                "                    res_blocks.extend(rbs)\n",
                "                return res_blocks\n",
                "\n",
                "    def where(self, other, cond) -> list[Block]:\n",
                "        \"\"\"\n",
                "        evaluate the block; return result block(s) from the result\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        other : a ndarray/object\n",
                "        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        List[Block]\n",
                "        \"\"\"\n",
                "        assert cond.ndim == self.ndim\n",
                "        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\n",
                "\n",
                "        transpose = self.ndim == 2\n",
                "\n",
                "        cond = extract_bool_array(cond)\n",
                "\n",
                "        # EABlocks override where\n",
                "        values = cast(np.ndarray, self.values)\n",
                "        orig_other = other\n",
                "        if transpose:\n",
                "            values = values.T\n",
                "\n",
                "        icond, noop = validate_putmask(values, ~cond)\n",
                "        if noop:\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        if other is lib.no_default:\n",
                "            other = self.fill_value\n",
                "\n",
                "        other = self._standardize_fill_value(other)\n",
                "\n",
                "        try:\n",
                "            # try/except here is equivalent to a self._can_hold_element check,\n",
                "            #  but this gets us back 'casted' which we will reuse below;\n",
                "            #  without using 'casted', expressions.where may do unwanted upcasts.\n",
                "            casted = np_can_hold_element(values.dtype, other)\n",
                "        except (ValueError, TypeError, LossySetitemError):\n",
                "            # we cannot coerce, return a compat dtype\n",
                "\n",
                "            if self.ndim == 1 or self.shape[0] == 1:\n",
                "                # no need to split columns\n",
                "\n",
                "                block = self.coerce_to_target_dtype(other)\n",
                "                return block.where(orig_other, cond)\n",
                "\n",
                "            else:\n",
                "                is_array = isinstance(other, (np.ndarray, ExtensionArray))\n",
                "\n",
                "                res_blocks = []\n",
                "                nbs = self._split()\n",
                "                for i, nb in enumerate(nbs):\n",
                "                    oth = other\n",
                "                    if is_array:\n",
                "                        # we have a different value per-column\n",
                "                        oth = other[:, i : i + 1]\n",
                "\n",
                "                    submask = cond[:, i : i + 1]\n",
                "                    rbs = nb.where(oth, submask)\n",
                "                    res_blocks.extend(rbs)\n",
                "                return res_blocks\n",
                "\n",
                "        else:\n",
                "            other = casted\n",
                "            alt = setitem_datetimelike_compat(values, icond.sum(), other)\n",
                "            if alt is not other:\n",
                "                if is_list_like(other) and len(other) < len(values):\n",
                "                    # call np.where with other to get the appropriate ValueError\n",
                "                    np.where(~icond, values, other)\n",
                "                    raise NotImplementedError(\n",
                "                        \"This should not be reached; call to np.where above is \"\n",
                "                        \"expected to raise ValueError. Please report a bug at \"\n",
                "                        \"github.com/pandas-dev/pandas\"\n",
                "                    )\n",
                "                result = values.copy()\n",
                "                np.putmask(result, icond, alt)\n",
                "            else:\n",
                "                # By the time we get here, we should have all Series/Index\n",
                "                #  args extracted to ndarray\n",
                "                if (\n",
                "                    is_list_like(other)\n",
                "                    and not isinstance(other, np.ndarray)\n",
                "                    and len(other) == self.shape[-1]\n",
                "                ):\n",
                "                    # If we don't do this broadcasting here, then expressions.where\n",
                "                    #  will broadcast a 1D other to be row-like instead of\n",
                "                    #  column-like.\n",
                "                    other = np.array(other).reshape(values.shape)\n",
                "                    # If lengths don't match (or len(other)==1), we will raise\n",
                "                    #  inside expressions.where, see test_series_where\n",
                "\n",
                "                # Note: expressions.where may upcast.\n",
                "                result = expressions.where(~icond, values, other)\n",
                "                # The np_can_hold_element check _should_ ensure that we always\n",
                "                #  have result.dtype == self.dtype here.\n",
                "\n",
                "        if transpose:\n",
                "            result = result.T\n",
                "\n",
                "        return [self.make_block(result)]\n",
                "\n",
                "    def fillna(\n",
                "        self,\n",
                "        value,\n",
                "        limit: int | None = None,\n",
                "        inplace: bool = False,\n",
                "    ) -> list[Block]:\n",
                "        \"\"\"\n",
                "        fillna on the block with the value. If we fail, then convert to\n",
                "        block to hold objects instead and try again\n",
                "        \"\"\"\n",
                "        # Caller is responsible for validating limit; if int it is strictly positive\n",
                "        inplace = validate_bool_kwarg(inplace, \"inplace\")\n",
                "\n",
                "        if not self._can_hold_na:\n",
                "            # can short-circuit the isna call\n",
                "            noop = True\n",
                "        else:\n",
                "            mask = isna(self.values)\n",
                "            mask, noop = validate_putmask(self.values, mask)\n",
                "\n",
                "        if noop:\n",
                "            # we can't process the value, but nothing to do\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        if limit is not None:\n",
                "            mask[mask.cumsum(self.ndim - 1) > limit] = False\n",
                "\n",
                "        if inplace:\n",
                "            nbs = self.putmask(mask.T, value)\n",
                "        else:\n",
                "            nbs = self.where(value, ~mask.T)\n",
                "        return extend_blocks(nbs)\n",
                "\n",
                "    def pad_or_backfill(\n",
                "        self,\n",
                "        *,\n",
                "        method: FillnaOptions,\n",
                "        axis: AxisInt = 0,\n",
                "        inplace: bool = False,\n",
                "        limit: int | None = None,\n",
                "        limit_area: Literal[\"inside\", \"outside\"] | None = None,\n",
                "    ) -> list[Block]:\n",
                "        if not self._can_hold_na:\n",
                "            # If there are no NAs, then interpolate is a no-op\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        copy, refs = self._get_refs_and_copy(inplace)\n",
                "\n",
                "        # Dispatch to the NumpyExtensionArray method.\n",
                "        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\n",
                "        vals = cast(NumpyExtensionArray, self.array_values)\n",
                "        if axis == 1:\n",
                "            vals = vals.T\n",
                "        new_values = vals._pad_or_backfill(\n",
                "            method=method,\n",
                "            limit=limit,\n",
                "            limit_area=limit_area,\n",
                "            copy=copy,\n",
                "        )\n",
                "        if axis == 1:\n",
                "            new_values = new_values.T\n",
                "\n",
                "        data = extract_array(new_values, extract_numpy=True)\n",
                "        return [self.make_block_same_class(data, refs=refs)]\n",
                "\n",
                "    @final\n",
                "    def interpolate(\n",
                "        self,\n",
                "        *,\n",
                "        method: InterpolateOptions,\n",
                "        index: Index,\n",
                "        inplace: bool = False,\n",
                "        limit: int | None = None,\n",
                "        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\n",
                "        limit_area: Literal[\"inside\", \"outside\"] | None = None,\n",
                "        **kwargs,\n",
                "    ) -> list[Block]:\n",
                "        inplace = validate_bool_kwarg(inplace, \"inplace\")\n",
                "        # error: Non-overlapping equality check [...]\n",
                "        if method == \"asfreq\":  # type: ignore[comparison-overlap]\n",
                "            # clean_fill_method used to allow this\n",
                "            missing.clean_fill_method(method)\n",
                "\n",
                "        if not self._can_hold_na:\n",
                "            # If there are no NAs, then interpolate is a no-op\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        # TODO(3.0): this case will not be reachable once GH#53638 is enforced\n",
                "        if self.dtype == _dtype_obj:\n",
                "            # only deal with floats\n",
                "            # bc we already checked that can_hold_na, we don't have int dtype here\n",
                "            # test_interp_basic checks that we make a copy here\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        copy, refs = self._get_refs_and_copy(inplace)\n",
                "\n",
                "        # Dispatch to the EA method.\n",
                "        new_values = self.array_values.interpolate(\n",
                "            method=method,\n",
                "            axis=self.ndim - 1,\n",
                "            index=index,\n",
                "            limit=limit,\n",
                "            limit_direction=limit_direction,\n",
                "            limit_area=limit_area,\n",
                "            copy=copy,\n",
                "            **kwargs,\n",
                "        )\n",
                "        data = extract_array(new_values, extract_numpy=True)\n",
                "        return [self.make_block_same_class(data, refs=refs)]\n",
                "\n",
                "    @final\n",
                "    def diff(self, n: int) -> list[Block]:\n",
                "        \"\"\"return block for the diff of the values\"\"\"\n",
                "        # only reached with ndim == 2\n",
                "        # TODO(EA2D): transpose will be unnecessary with 2D EAs\n",
                "        new_values = algos.diff(self.values.T, n, axis=0).T\n",
                "        return [self.make_block(values=new_values)]\n",
                "\n",
                "    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\n",
                "        \"\"\"shift the block by periods, possibly upcast\"\"\"\n",
                "        # convert integer to float if necessary. need to do a lot more than\n",
                "        # that, handle boolean etc also\n",
                "        axis = self.ndim - 1\n",
                "\n",
                "        # Note: periods is never 0 here, as that is handled at the top of\n",
                "        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\n",
                "        #  and possibly avoid coercing.\n",
                "\n",
                "        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\n",
                "            # with object dtype there is nothing to promote, and the user can\n",
                "            #  pass pretty much any weird fill_value they like\n",
                "            # see test_shift_object_non_scalar_fill\n",
                "            raise ValueError(\"fill_value must be a scalar\")\n",
                "\n",
                "        fill_value = self._standardize_fill_value(fill_value)\n",
                "\n",
                "        try:\n",
                "            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\n",
                "            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\n",
                "            casted = np_can_hold_element(\n",
                "                self.dtype,  # type: ignore[arg-type]\n",
                "                fill_value,\n",
                "            )\n",
                "        except LossySetitemError:\n",
                "            nb = self.coerce_to_target_dtype(fill_value)\n",
                "            return nb.shift(periods, fill_value=fill_value)\n",
                "\n",
                "        else:\n",
                "            values = cast(np.ndarray, self.values)\n",
                "            new_values = shift(values, periods, axis, casted)\n",
                "            return [self.make_block_same_class(new_values)]\n",
                "\n",
                "    @final\n",
                "    def quantile(\n",
                "        self,\n",
                "        qs: Index,  # with dtype float64\n",
                "        interpolation: QuantileInterpolation = \"linear\",\n",
                "    ) -> Block:\n",
                "        \"\"\"\n",
                "        compute the quantiles of the\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        qs : Index\n",
                "            The quantiles to be computed in float64.\n",
                "        interpolation : str, default 'linear'\n",
                "            Type of interpolation.\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        Block\n",
                "        \"\"\"\n",
                "        # We should always have ndim == 2 because Series dispatches to DataFrame\n",
                "        assert self.ndim == 2\n",
                "        assert is_list_like(qs)  # caller is responsible for this\n",
                "\n",
                "        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\n",
                "        # ensure_block_shape needed for cases where we start with EA and result\n",
                "        #  is ndarray, e.g. IntegerArray, SparseArray\n",
                "        result = ensure_block_shape(result, ndim=2)\n",
                "        return new_block_2d(result, placement=self._mgr_locs)\n",
                "\n",
                "    @final\n",
                "    def round(self, decimals: int) -> Self:\n",
                "        \"\"\"\n",
                "        Rounds the values.\n",
                "        If the block is not of an integer or float dtype, nothing happens.\n",
                "        This is consistent with DataFrame.round behavivor.\n",
                "        (Note: Series.round would raise)\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        decimals: int,\n",
                "            Number of decimal places to round to.\n",
                "            Caller is responsible for validating this\n",
                "        \"\"\"\n",
                "        if not self.is_numeric or self.is_bool:\n",
                "            return self.copy(deep=False)\n",
                "        # TODO: round only defined on BaseMaskedArray\n",
                "        # Series also does this, so would need to fix both places\n",
                "        # error: Item \"ExtensionArray\" of \"Union[ndarray[Any, Any], ExtensionArray]\"\n",
                "        # has no attribute \"round\"\n",
                "        values = self.values.round(decimals)  # type: ignore[union-attr]\n",
                "\n",
                "        refs = None\n",
                "        if values is self.values:\n",
                "            refs = self.refs\n",
                "\n",
                "        return self.make_block_same_class(values, refs=refs)\n",
                "\n",
                "    # ---------------------------------------------------------------------\n",
                "    # Abstract Methods Overridden By EABackedBlock and NumpyBlock\n",
                "\n",
                "    def delete(self, loc) -> list[Block]:\n",
                "        \"\"\"Deletes the locs from the block.\n",
                "\n",
                "        We split the block to avoid copying the underlying data. We create new\n",
                "        blocks for every connected segment of the initial block that is not deleted.\n",
                "        The new blocks point to the initial array.\n",
                "        \"\"\"\n",
                "        if not is_list_like(loc):\n",
                "            loc = [loc]\n",
                "\n",
                "        if self.ndim == 1:\n",
                "            values = cast(np.ndarray, self.values)\n",
                "            values = np.delete(values, loc)\n",
                "            mgr_locs = self._mgr_locs.delete(loc)\n",
                "            return [type(self)(values, placement=mgr_locs, ndim=self.ndim)]\n",
                "\n",
                "        if np.max(loc) >= self.values.shape[0]:\n",
                "            raise IndexError\n",
                "\n",
                "        # Add one out-of-bounds indexer as maximum to collect\n",
                "        # all columns after our last indexer if any\n",
                "        loc = np.concatenate([loc, [self.values.shape[0]]])\n",
                "        mgr_locs_arr = self._mgr_locs.as_array\n",
                "        new_blocks: list[Block] = []\n",
                "\n",
                "        previous_loc = -1\n",
                "        # TODO(CoW): This is tricky, if parent block goes out of scope\n",
                "        # all split blocks are referencing each other even though they\n",
                "        # don't share data\n",
                "        refs = self.refs if self.refs.has_reference() else None\n",
                "        for idx in loc:\n",
                "            if idx == previous_loc + 1:\n",
                "                # There is no column between current and last idx\n",
                "                pass\n",
                "            else:\n",
                "                # No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\n",
                "                # argument type \"Tuple[slice, slice]\"\n",
                "                values = self.values[previous_loc + 1 : idx, :]  # type: ignore[call-overload]\n",
                "                locs = mgr_locs_arr[previous_loc + 1 : idx]\n",
                "                nb = type(self)(\n",
                "                    values, placement=BlockPlacement(locs), ndim=self.ndim, refs=refs\n",
                "                )\n",
                "                new_blocks.append(nb)\n",
                "\n",
                "            previous_loc = idx\n",
                "\n",
                "        return new_blocks\n",
                "\n",
                "    @property\n",
                "    def is_view(self) -> bool:\n",
                "        \"\"\"return a boolean if I am possibly a view\"\"\"\n",
                "        raise AbstractMethodError(self)\n",
                "\n",
                "    @property\n",
                "    def array_values(self) -> ExtensionArray:\n",
                "        \"\"\"\n",
                "        The array that Series.array returns. Always an ExtensionArray.\n",
                "        \"\"\"\n",
                "        raise AbstractMethodError(self)\n",
                "\n",
                "    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        return an internal format, currently just the ndarray\n",
                "        this is often overridden to handle to_dense like operations\n",
                "        \"\"\"\n",
                "        raise AbstractMethodError(self)\n",
                "\n",
                "\n",
                "class EABackedBlock(Block):\n",
                "    \"\"\"\n",
                "    Mixin for Block subclasses backed by ExtensionArray.\n",
                "    \"\"\"\n",
                "\n",
                "    values: ExtensionArray\n",
                "\n",
                "    @final\n",
                "    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\n",
                "        \"\"\"\n",
                "        Shift the block by `periods`.\n",
                "\n",
                "        Dispatches to underlying ExtensionArray and re-boxes in an\n",
                "        ExtensionBlock.\n",
                "        \"\"\"\n",
                "        # Transpose since EA.shift is always along axis=0, while we want to shift\n",
                "        #  along rows.\n",
                "        new_values = self.values.T.shift(periods=periods, fill_value=fill_value).T\n",
                "        return [self.make_block_same_class(new_values)]\n",
                "\n",
                "    @final\n",
                "    def setitem(self, indexer, value):\n",
                "        \"\"\"\n",
                "        Attempt self.values[indexer] = value, possibly creating a new array.\n",
                "\n",
                "        This differs from Block.setitem by not allowing setitem to change\n",
                "        the dtype of the Block.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        indexer : tuple, list-like, array-like, slice, int\n",
                "            The subset of self.values to set\n",
                "        value : object\n",
                "            The value being set\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        Block\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        `indexer` is a direct slice/positional indexer. `value` must\n",
                "        be a compatible shape.\n",
                "        \"\"\"\n",
                "        orig_indexer = indexer\n",
                "        orig_value = value\n",
                "\n",
                "        indexer = self._unwrap_setitem_indexer(indexer)\n",
                "        value = self._maybe_squeeze_arg(value)\n",
                "\n",
                "        values = self.values\n",
                "        if values.ndim == 2:\n",
                "            # TODO(GH#45419): string[pyarrow] tests break if we transpose\n",
                "            #  unconditionally\n",
                "            values = values.T\n",
                "        check_setitem_lengths(indexer, value, values)\n",
                "\n",
                "        try:\n",
                "            values[indexer] = value\n",
                "        except (ValueError, TypeError):\n",
                "            if isinstance(self.dtype, IntervalDtype):\n",
                "                # see TestSetitemFloatIntervalWithIntIntervalValues\n",
                "                nb = self.coerce_to_target_dtype(orig_value, warn_on_upcast=True)\n",
                "                return nb.setitem(orig_indexer, orig_value)\n",
                "\n",
                "            elif isinstance(self, NDArrayBackedExtensionBlock):\n",
                "                nb = self.coerce_to_target_dtype(orig_value, warn_on_upcast=True)\n",
                "                return nb.setitem(orig_indexer, orig_value)\n",
                "\n",
                "            else:\n",
                "                raise\n",
                "\n",
                "        else:\n",
                "            return self\n",
                "\n",
                "    @final\n",
                "    def where(self, other, cond) -> list[Block]:\n",
                "        arr = self.values.T\n",
                "\n",
                "        cond = extract_bool_array(cond)\n",
                "\n",
                "        orig_other = other\n",
                "        orig_cond = cond\n",
                "        other = self._maybe_squeeze_arg(other)\n",
                "        cond = self._maybe_squeeze_arg(cond)\n",
                "\n",
                "        if other is lib.no_default:\n",
                "            other = self.fill_value\n",
                "\n",
                "        icond, noop = validate_putmask(arr, ~cond)\n",
                "        if noop:\n",
                "            # GH#44181, GH#45135\n",
                "            # Avoid a) raising for Interval/PeriodDtype and b) unnecessary object upcast\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        try:\n",
                "            res_values = arr._where(cond, other).T\n",
                "        except (ValueError, TypeError):\n",
                "            if self.ndim == 1 or self.shape[0] == 1:\n",
                "                if isinstance(self.dtype, IntervalDtype):\n",
                "                    # TestSetitemFloatIntervalWithIntIntervalValues\n",
                "                    blk = self.coerce_to_target_dtype(orig_other)\n",
                "                    return blk.where(orig_other, orig_cond)\n",
                "\n",
                "                elif isinstance(self, NDArrayBackedExtensionBlock):\n",
                "                    # NB: not (yet) the same as\n",
                "                    #  isinstance(values, NDArrayBackedExtensionArray)\n",
                "                    blk = self.coerce_to_target_dtype(orig_other)\n",
                "                    return blk.where(orig_other, orig_cond)\n",
                "\n",
                "                else:\n",
                "                    raise\n",
                "\n",
                "            else:\n",
                "                # Same pattern we use in Block.putmask\n",
                "                is_array = isinstance(orig_other, (np.ndarray, ExtensionArray))\n",
                "\n",
                "                res_blocks = []\n",
                "                nbs = self._split()\n",
                "                for i, nb in enumerate(nbs):\n",
                "                    n = orig_other\n",
                "                    if is_array:\n",
                "                        # we have a different value per-column\n",
                "                        n = orig_other[:, i : i + 1]\n",
                "\n",
                "                    submask = orig_cond[:, i : i + 1]\n",
                "                    rbs = nb.where(n, submask)\n",
                "                    res_blocks.extend(rbs)\n",
                "                return res_blocks\n",
                "\n",
                "        nb = self.make_block_same_class(res_values)\n",
                "        return [nb]\n",
                "\n",
                "    @final\n",
                "    def putmask(self, mask, new) -> list[Block]:\n",
                "        \"\"\"\n",
                "        See Block.putmask.__doc__\n",
                "        \"\"\"\n",
                "        mask = extract_bool_array(mask)\n",
                "        if new is lib.no_default:\n",
                "            new = self.fill_value\n",
                "\n",
                "        orig_new = new\n",
                "        orig_mask = mask\n",
                "        new = self._maybe_squeeze_arg(new)\n",
                "        mask = self._maybe_squeeze_arg(mask)\n",
                "\n",
                "        if not mask.any():\n",
                "            return [self.copy(deep=False)]\n",
                "\n",
                "        self = self._maybe_copy(inplace=True)\n",
                "        values = self.values\n",
                "        if values.ndim == 2:\n",
                "            values = values.T\n",
                "\n",
                "        try:\n",
                "            # Caller is responsible for ensuring matching lengths\n",
                "            values._putmask(mask, new)\n",
                "        except (TypeError, ValueError):\n",
                "            if self.ndim == 1 or self.shape[0] == 1:\n",
                "                if isinstance(self.dtype, IntervalDtype):\n",
                "                    # Discussion about what we want to support in the general\n",
                "                    #  case GH#39584\n",
                "                    blk = self.coerce_to_target_dtype(orig_new, warn_on_upcast=True)\n",
                "                    return blk.putmask(orig_mask, orig_new)\n",
                "\n",
                "                elif isinstance(self, NDArrayBackedExtensionBlock):\n",
                "                    # NB: not (yet) the same as\n",
                "                    #  isinstance(values, NDArrayBackedExtensionArray)\n",
                "                    blk = self.coerce_to_target_dtype(orig_new, warn_on_upcast=True)\n",
                "                    return blk.putmask(orig_mask, orig_new)\n",
                "\n",
                "                else:\n",
                "                    raise\n",
                "\n",
                "            else:\n",
                "                # Same pattern we use in Block.putmask\n",
                "                is_array = isinstance(orig_new, (np.ndarray, ExtensionArray))\n",
                "\n",
                "                res_blocks = []\n",
                "                nbs = self._split()\n",
                "                for i, nb in enumerate(nbs):\n",
                "                    n = orig_new\n",
                "                    if is_array:\n",
                "                        # we have a different value per-column\n",
                "                        n = orig_new[:, i : i + 1]\n",
                "\n",
                "                    submask = orig_mask[:, i : i + 1]\n",
                "                    rbs = nb.putmask(submask, n)\n",
                "                    res_blocks.extend(rbs)\n",
                "                return res_blocks\n",
                "\n",
                "        return [self]\n",
                "\n",
                "    @final\n",
                "    def delete(self, loc) -> list[Block]:\n",
                "        # This will be unnecessary if/when __array_function__ is implemented\n",
                "        if self.ndim == 1:\n",
                "            values = self.values.delete(loc)\n",
                "            mgr_locs = self._mgr_locs.delete(loc)\n",
                "            return [type(self)(values, placement=mgr_locs, ndim=self.ndim)]\n",
                "        elif self.values.ndim == 1:\n",
                "            # We get here through to_stata\n",
                "            return []\n",
                "        return super().delete(loc)\n",
                "\n",
                "    @final\n",
                "    @cache_readonly\n",
                "    def array_values(self) -> ExtensionArray:\n",
                "        return self.values\n",
                "\n",
                "    @final\n",
                "    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        return object dtype as boxed values, such as Timestamps/Timedelta\n",
                "        \"\"\"\n",
                "        values: ArrayLike = self.values\n",
                "        if dtype == _dtype_obj:\n",
                "            values = values.astype(object)\n",
                "        # TODO(EA2D): reshape not needed with 2D EAs\n",
                "        return np.asarray(values).reshape(self.shape)\n",
                "\n",
                "    @final\n",
                "    def pad_or_backfill(\n",
                "        self,\n",
                "        *,\n",
                "        method: FillnaOptions,\n",
                "        axis: AxisInt = 0,\n",
                "        inplace: bool = False,\n",
                "        limit: int | None = None,\n",
                "        limit_area: Literal[\"inside\", \"outside\"] | None = None,\n",
                "    ) -> list[Block]:\n",
                "        values = self.values\n",
                "\n",
                "        kwargs: dict[str, Any] = {\"method\": method, \"limit\": limit}\n",
                "        if \"limit_area\" in inspect.signature(values._pad_or_backfill).parameters:\n",
                "            kwargs[\"limit_area\"] = limit_area\n",
                "        elif limit_area is not None:\n",
                "            raise NotImplementedError(\n",
                "                f\"{type(values).__name__} does not implement limit_area \"\n",
                "                \"(added in pandas 2.2). 3rd-party ExtnsionArray authors \"\n",
                "                \"need to add this argument to _pad_or_backfill.\"\n",
                "            )\n",
                "\n",
                "        if values.ndim == 2 and axis == 1:\n",
                "            # NDArrayBackedExtensionArray.fillna assumes axis=0\n",
                "            new_values = values.T._pad_or_backfill(**kwargs).T\n",
                "        else:\n",
                "            new_values = values._pad_or_backfill(**kwargs)\n",
                "        return [self.make_block_same_class(new_values)]\n",
                "\n",
                "\n",
                "class ExtensionBlock(EABackedBlock):\n",
                "    \"\"\"\n",
                "    Block for holding extension types.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    This holds all 3rd-party extension array types. It's also the immediate\n",
                "    parent class for our internal extension types' blocks.\n",
                "\n",
                "    ExtensionArrays are limited to 1-D.\n",
                "    \"\"\"\n",
                "\n",
                "    values: ExtensionArray\n",
                "\n",
                "    def fillna(\n",
                "        self,\n",
                "        value,\n",
                "        limit: int | None = None,\n",
                "        inplace: bool = False,\n",
                "    ) -> list[Block]:\n",
                "        if isinstance(self.dtype, IntervalDtype):\n",
                "            # Block.fillna handles coercion (test_fillna_interval)\n",
                "            return super().fillna(\n",
                "                value=value,\n",
                "                limit=limit,\n",
                "                inplace=inplace,\n",
                "            )\n",
                "        if self._can_hold_na and not self.values._hasna:\n",
                "            refs = self.refs\n",
                "            new_values = self.values\n",
                "        else:\n",
                "            copy, refs = self._get_refs_and_copy(inplace)\n",
                "\n",
                "            try:\n",
                "                new_values = self.values.fillna(\n",
                "                    value=value, method=None, limit=limit, copy=copy\n",
                "                )\n",
                "            except TypeError:\n",
                "                # 3rd party EA that has not implemented copy keyword yet\n",
                "                refs = None\n",
                "                new_values = self.values.fillna(value=value, method=None, limit=limit)\n",
                "                # issue the warning *after* retrying, in case the TypeError\n",
                "                #  was caused by an invalid fill_value\n",
                "                warnings.warn(\n",
                "                    # GH#53278\n",
                "                    \"ExtensionArray.fillna added a 'copy' keyword in pandas \"\n",
                "                    \"2.1.0. In a future version, ExtensionArray subclasses will \"\n",
                "                    \"need to implement this keyword or an exception will be \"\n",
                "                    \"raised. In the interim, the keyword is ignored by \"\n",
                "                    f\"{type(self.values).__name__}.\",\n",
                "                    DeprecationWarning,\n",
                "                    stacklevel=find_stack_level(),\n",
                "                )\n",
                "\n",
                "        return [self.make_block_same_class(new_values, refs=refs)]\n",
                "\n",
                "    @cache_readonly\n",
                "    def shape(self) -> Shape:\n",
                "        # TODO(EA2D): override unnecessary with 2D EAs\n",
                "        if self.ndim == 1:\n",
                "            return (len(self.values),)\n",
                "        return len(self._mgr_locs), len(self.values)\n",
                "\n",
                "    def iget(self, i: int | tuple[int, int] | tuple[slice, int]):\n",
                "        # In the case where we have a tuple[slice, int], the slice will always\n",
                "        #  be slice(None)\n",
                "        # We _could_ make the annotation more specific, but mypy would\n",
                "        #  complain about override mismatch:\n",
                "        #  Literal[0] | tuple[Literal[0], int] | tuple[slice, int]\n",
                "\n",
                "        # Note: only reached with self.ndim == 2\n",
                "\n",
                "        if isinstance(i, tuple):\n",
                "            # TODO(EA2D): unnecessary with 2D EAs\n",
                "            col, loc = i\n",
                "            if not com.is_null_slice(col) and col != 0:\n",
                "                raise IndexError(f\"{self} only contains one item\")\n",
                "            if isinstance(col, slice):\n",
                "                # the is_null_slice check above assures that col is slice(None)\n",
                "                #  so what we want is a view on all our columns and row loc\n",
                "                if loc < 0:\n",
                "                    loc += len(self.values)\n",
                "                # Note: loc:loc+1 vs [[loc]] makes a difference when called\n",
                "                #  from fast_xs because we want to get a view back.\n",
                "                return self.values[loc : loc + 1]\n",
                "            return self.values[loc]\n",
                "        else:\n",
                "            if i != 0:\n",
                "                raise IndexError(f\"{self} only contains one item\")\n",
                "            return self.values\n",
                "\n",
                "    def set_inplace(self, locs, values: ArrayLike, copy: bool = False) -> None:\n",
                "        # When an ndarray, we should have locs.tolist() == [0]\n",
                "        # When a BlockPlacement we should have list(locs) == [0]\n",
                "        if copy:\n",
                "            self.values = self.values.copy()\n",
                "        self.values[:] = values\n",
                "\n",
                "    def _maybe_squeeze_arg(self, arg):\n",
                "        \"\"\"\n",
                "        If necessary, squeeze a (N, 1) ndarray to (N,)\n",
                "        \"\"\"\n",
                "        # e.g. if we are passed a 2D mask for putmask\n",
                "        if (\n",
                "            isinstance(arg, (np.ndarray, ExtensionArray))\n",
                "            and arg.ndim == self.values.ndim + 1\n",
                "        ):\n",
                "            # TODO(EA2D): unnecessary with 2D EAs\n",
                "            assert arg.shape[1] == 1\n",
                "            # error: No overload variant of \"__getitem__\" of \"ExtensionArray\"\n",
                "            # matches argument type \"Tuple[slice, int]\"\n",
                "            arg = arg[:, 0]  # type: ignore[call-overload]\n",
                "        elif isinstance(arg, ABCDataFrame):\n",
                "            # 2022-01-06 only reached for setitem\n",
                "            # TODO: should we avoid getting here with DataFrame?\n",
                "            assert arg.shape[1] == 1\n",
                "            arg = arg._ixs(0, axis=1)._values\n",
                "\n",
                "        return arg\n",
                "\n",
                "    def _unwrap_setitem_indexer(self, indexer):\n",
                "        \"\"\"\n",
                "        Adapt a 2D-indexer to our 1D values.\n",
                "\n",
                "        This is intended for 'setitem', not 'iget' or '_slice'.\n",
                "        \"\"\"\n",
                "        # TODO: ATM this doesn't work for iget/_slice, can we change that?\n",
                "\n",
                "        if isinstance(indexer, tuple) and len(indexer) == 2:\n",
                "            # TODO(EA2D): not needed with 2D EAs\n",
                "            #  Should never have length > 2.  Caller is responsible for checking.\n",
                "            #  Length 1 is reached vis setitem_single_block and setitem_single_column\n",
                "            #  each of which pass indexer=(pi,)\n",
                "            if all(isinstance(x, np.ndarray) and x.ndim == 2 for x in indexer):\n",
                "                # GH#44703 went through indexing.maybe_convert_ix\n",
                "                first, second = indexer\n",
                "                if not (\n",
                "                    second.size == 1 and (second == 0).all() and first.shape[1] == 1\n",
                "                ):\n",
                "                    raise NotImplementedError(\n",
                "                        \"This should not be reached. Please report a bug at \"\n",
                "                        \"github.com/pandas-dev/pandas/\"\n",
                "                    )\n",
                "                indexer = first[:, 0]\n",
                "\n",
                "            elif lib.is_integer(indexer[1]) and indexer[1] == 0:\n",
                "                # reached via setitem_single_block passing the whole indexer\n",
                "                indexer = indexer[0]\n",
                "\n",
                "            elif com.is_null_slice(indexer[1]):\n",
                "                indexer = indexer[0]\n",
                "\n",
                "            elif is_list_like(indexer[1]) and indexer[1][0] == 0:\n",
                "                indexer = indexer[0]\n",
                "\n",
                "            else:\n",
                "                raise NotImplementedError(\n",
                "                    \"This should not be reached. Please report a bug at \"\n",
                "                    \"github.com/pandas-dev/pandas/\"\n",
                "                )\n",
                "        return indexer\n",
                "\n",
                "    @property\n",
                "    def is_view(self) -> bool:\n",
                "        \"\"\"Extension arrays are never treated as views.\"\"\"\n",
                "        return False\n",
                "\n",
                "    # error: Cannot override writeable attribute with read-only property\n",
                "    @cache_readonly\n",
                "    def is_numeric(self) -> bool:  # type: ignore[override]\n",
                "        return self.values.dtype._is_numeric\n",
                "\n",
                "    def _slice(\n",
                "        self, slicer: slice | npt.NDArray[np.bool_] | npt.NDArray[np.intp]\n",
                "    ) -> ExtensionArray:\n",
                "        \"\"\"\n",
                "        Return a slice of my values.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        slicer : slice, ndarray[int], or ndarray[bool]\n",
                "            Valid (non-reducing) indexer for self.values.\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        ExtensionArray\n",
                "        \"\"\"\n",
                "        # Notes: ndarray[bool] is only reachable when via get_rows_with_mask, which\n",
                "        #  is only for Series, i.e. self.ndim == 1.\n",
                "\n",
                "        # return same dims as we currently have\n",
                "        if self.ndim == 2:\n",
                "            # reached via getitem_block via _slice_take_blocks_ax0\n",
                "            # TODO(EA2D): won't be necessary with 2D EAs\n",
                "\n",
                "            if not isinstance(slicer, slice):\n",
                "                raise AssertionError(\n",
                "                    \"invalid slicing for a 1-ndim ExtensionArray\", slicer\n",
                "                )\n",
                "            # GH#32959 only full-slicers along fake-dim0 are valid\n",
                "            # TODO(EA2D): won't be necessary with 2D EAs\n",
                "            # range(1) instead of self._mgr_locs to avoid exception on [::-1]\n",
                "            #  see test_iloc_getitem_slice_negative_step_ea_block\n",
                "            new_locs = range(1)[slicer]\n",
                "            if not len(new_locs):\n",
                "                raise AssertionError(\n",
                "                    \"invalid slicing for a 1-ndim ExtensionArray\", slicer\n",
                "                )\n",
                "            slicer = slice(None)\n",
                "\n",
                "        return self.values[slicer]\n",
                "\n",
                "    @final\n",
                "    def slice_block_rows(self, slicer: slice) -> Self:\n",
                "        \"\"\"\n",
                "        Perform __getitem__-like specialized to slicing along index.\n",
                "        \"\"\"\n",
                "        # GH#42787 in principle this is equivalent to values[..., slicer], but we don't\n",
                "        # require subclasses of ExtensionArray to support that form (for now).\n",
                "        new_values = self.values[slicer]\n",
                "        return type(self)(new_values, self._mgr_locs, ndim=self.ndim, refs=self.refs)\n",
                "\n",
                "    def _unstack(\n",
                "        self,\n",
                "        unstacker,\n",
                "        fill_value,\n",
                "        new_placement: npt.NDArray[np.intp],\n",
                "        needs_masking: npt.NDArray[np.bool_],\n",
                "    ):\n",
                "        # ExtensionArray-safe unstack.\n",
                "        # We override Block._unstack, which unstacks directly on the\n",
                "        # values of the array. For EA-backed blocks, this would require\n",
                "        # converting to a 2-D ndarray of objects.\n",
                "        # Instead, we unstack an ndarray of integer positions, followed by\n",
                "        # a `take` on the actual values.\n",
                "\n",
                "        # Caller is responsible for ensuring self.shape[-1] == len(unstacker.index)\n",
                "        new_values, mask = unstacker.arange_result\n",
                "\n",
                "        # Note: these next two lines ensure that\n",
                "        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\n",
                "        #  which the calling function needs in order to pass verify_integrity=False\n",
                "        #  to the BlockManager constructor\n",
                "        new_values = new_values.T[mask]\n",
                "        new_placement = new_placement[mask]\n",
                "\n",
                "        # needs_masking[i] calculated once in BlockManager.unstack tells\n",
                "        #  us if there are any -1s in the relevant indices.  When False,\n",
                "        #  that allows us to go through a faster path in 'take', among\n",
                "        #  other things avoiding e.g. Categorical._validate_scalar.\n",
                "        blocks = [\n",
                "            # TODO: could cast to object depending on fill_value?\n",
                "            type(self)(\n",
                "                self.values.take(\n",
                "                    indices, allow_fill=needs_masking[i], fill_value=fill_value\n",
                "                ),\n",
                "                BlockPlacement(place),\n",
                "                ndim=2,\n",
                "            )\n",
                "            for i, (indices, place) in enumerate(zip(new_values, new_placement))\n",
                "        ]\n",
                "        return blocks, mask\n",
                "\n",
                "\n",
                "class NumpyBlock(Block):\n",
                "    values: np.ndarray\n",
                "    __slots__ = ()\n",
                "\n",
                "    @property\n",
                "    def is_view(self) -> bool:\n",
                "        \"\"\"return a boolean if I am possibly a view\"\"\"\n",
                "        return self.values.base is not None\n",
                "\n",
                "    @property\n",
                "    def array_values(self) -> ExtensionArray:\n",
                "        return NumpyExtensionArray(self.values)\n",
                "\n",
                "    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:\n",
                "        if dtype == _dtype_obj:\n",
                "            return self.values.astype(_dtype_obj)\n",
                "        return self.values\n",
                "\n",
                "    @cache_readonly\n",
                "    def is_numeric(self) -> bool:  # type: ignore[override]\n",
                "        dtype = self.values.dtype\n",
                "        kind = dtype.kind\n",
                "\n",
                "        return kind in \"fciub\"\n",
                "\n",
                "\n"
            ],
            {
                "type": "delete",
                "before": [
                    "class NumericBlock(NumpyBlock):\n",
                    "    # this Block type is kept for backwards-compatibility\n",
                    "    # TODO(3.0): delete and remove deprecation in __init__.py.\n",
                    "    __slots__ = ()\n",
                    "\n",
                    "\n",
                    "class ObjectBlock(NumpyBlock):\n",
                    "    # this Block type is kept for backwards-compatibility\n",
                    "    # TODO(3.0): delete and remove deprecation in __init__.py.\n",
                    "    __slots__ = ()\n",
                    "\n",
                    "\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 2150,
                    "end": 2162
                },
                "child_version_range": {
                    "start": 2150,
                    "end": 2150
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "NumericBlock",
                        "signature": "class NumericBlock(NumpyBlock):",
                        "at_line": 2150
                    }
                ],
                "idx": 4,
                "hunk_diff": "File: pandas/core/internals/blocks.py\nCode:\n2147 2147            return kind in \"fciub\"\n2148 2148    \n2149 2149    \n2150       - class NumericBlock(NumpyBlock):\n2151       -     # this Block type is kept for backwards-compatibility\n2152       -     # TODO(3.0): delete and remove deprecation in __init__.py.\n2153       -     __slots__ = ()\n2154       - \n2155       - \n2156       - class ObjectBlock(NumpyBlock):\n2157       -     # this Block type is kept for backwards-compatibility\n2158       -     # TODO(3.0): delete and remove deprecation in __init__.py.\n2159       -     __slots__ = ()\n2160       - \n2161       - \n2162 2150    class NDArrayBackedExtensionBlock(EABackedBlock):\n2163 2151        \"\"\"\n2164 2152        Block backed by an NDArrayBackedExtensionArray\n           ...\n",
                "file_path": "pandas/core/internals/blocks.py",
                "identifiers_before": [
                    "NumericBlock",
                    "NumpyBlock",
                    "ObjectBlock",
                    "__slots__"
                ],
                "identifiers_after": [],
                "prefix": [
                    "        return kind in \"fciub\"\n",
                    "\n",
                    "\n"
                ],
                "suffix": [
                    "class NDArrayBackedExtensionBlock(EABackedBlock):\n",
                    "    \"\"\"\n",
                    "    Block backed by an NDArrayBackedExtensionArray\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [
                    {
                        "to_hunk_idx": 1,
                        "detail": {
                            "identifier": "NumericBlock",
                            "position": {
                                "start": {
                                    "line": 2150,
                                    "column": 6
                                },
                                "end": {
                                    "line": 2150,
                                    "column": 18
                                }
                            },
                            "type": "identifier",
                            "kind": "class",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/blocks.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 1,
                        "detail": {
                            "identifier": "NumericBlock",
                            "position": {
                                "start": {
                                    "line": 2150,
                                    "column": 6
                                },
                                "end": {
                                    "line": 2150,
                                    "column": 18
                                }
                            },
                            "type": "identifier",
                            "kind": "class",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/blocks.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "ObjectBlock",
                            "position": {
                                "start": {
                                    "line": 2156,
                                    "column": 6
                                },
                                "end": {
                                    "line": 2156,
                                    "column": 17
                                }
                            },
                            "type": "identifier",
                            "kind": "class",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/blocks.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    },
                    {
                        "to_hunk_idx": 3,
                        "detail": {
                            "identifier": "ObjectBlock",
                            "position": {
                                "start": {
                                    "line": 2156,
                                    "column": 6
                                },
                                "end": {
                                    "line": 2156,
                                    "column": 17
                                }
                            },
                            "type": "identifier",
                            "kind": "class",
                            "abs_file_path": "/data2/chenyan/repos/pandas/pandas/core/internals/blocks.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "class NDArrayBackedExtensionBlock(EABackedBlock):\n",
                "    \"\"\"\n",
                "    Block backed by an NDArrayBackedExtensionArray\n",
                "    \"\"\"\n",
                "\n",
                "    values: NDArrayBackedExtensionArray\n",
                "\n",
                "    @property\n",
                "    def is_view(self) -> bool:\n",
                "        \"\"\"return a boolean if I am possibly a view\"\"\"\n",
                "        # check the ndarray values of the DatetimeIndex values\n",
                "        return self.values._ndarray.base is not None\n",
                "\n",
                "\n",
                "class DatetimeLikeBlock(NDArrayBackedExtensionBlock):\n",
                "    \"\"\"Block for datetime64[ns], timedelta64[ns].\"\"\"\n",
                "\n",
                "    __slots__ = ()\n",
                "    is_numeric = False\n",
                "    values: DatetimeArray | TimedeltaArray\n",
                "\n",
                "\n",
                "class DatetimeTZBlock(DatetimeLikeBlock):\n",
                "    \"\"\"implement a datetime64 block with a tz attribute\"\"\"\n",
                "\n",
                "    values: DatetimeArray\n",
                "\n",
                "    __slots__ = ()\n",
                "\n",
                "\n",
                "# -----------------------------------------------------------------\n",
                "# Constructor Helpers\n",
                "\n",
                "\n",
                "def maybe_coerce_values(values: ArrayLike) -> ArrayLike:\n",
                "    \"\"\"\n",
                "    Input validation for values passed to __init__. Ensure that\n",
                "    any datetime64/timedelta64 dtypes are in nanoseconds.  Ensure\n",
                "    that we do not have string dtypes.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    values : np.ndarray or ExtensionArray\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    values : np.ndarray or ExtensionArray\n",
                "    \"\"\"\n",
                "    # Caller is responsible for ensuring NumpyExtensionArray is already extracted.\n",
                "\n",
                "    if isinstance(values, np.ndarray):\n",
                "        values = ensure_wrapped_if_datetimelike(values)\n",
                "\n",
                "        if issubclass(values.dtype.type, str):\n",
                "            values = np.array(values, dtype=object)\n",
                "\n",
                "    if isinstance(values, (DatetimeArray, TimedeltaArray)) and values.freq is not None:\n",
                "        # freq is only stored in DatetimeIndex/TimedeltaIndex, not in Series/DataFrame\n",
                "        values = values._with_freq(None)\n",
                "\n",
                "    return values\n",
                "\n",
                "\n",
                "def get_block_type(dtype: DtypeObj) -> type[Block]:\n",
                "    \"\"\"\n",
                "    Find the appropriate Block subclass to use for the given values and dtype.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    dtype : numpy or pandas dtype\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    cls : class, subclass of Block\n",
                "    \"\"\"\n",
                "    if isinstance(dtype, DatetimeTZDtype):\n",
                "        return DatetimeTZBlock\n",
                "    elif isinstance(dtype, PeriodDtype):\n",
                "        return NDArrayBackedExtensionBlock\n",
                "    elif isinstance(dtype, ExtensionDtype):\n",
                "        # Note: need to be sure NumpyExtensionArray is unwrapped before we get here\n",
                "        return ExtensionBlock\n",
                "\n",
                "    # We use kind checks because it is much more performant\n",
                "    #  than is_foo_dtype\n",
                "    kind = dtype.kind\n",
                "    if kind in \"Mm\":\n",
                "        return DatetimeLikeBlock\n",
                "\n",
                "    return NumpyBlock\n",
                "\n",
                "\n",
                "def new_block_2d(\n",
                "    values: ArrayLike, placement: BlockPlacement, refs: BlockValuesRefs | None = None\n",
                ") -> Block:\n",
                "    # new_block specialized to case with\n",
                "    #  ndim=2\n",
                "    #  isinstance(placement, BlockPlacement)\n",
                "    #  check_ndim/ensure_block_shape already checked\n",
                "    klass = get_block_type(values.dtype)\n",
                "\n",
                "    values = maybe_coerce_values(values)\n",
                "    return klass(values, ndim=2, placement=placement, refs=refs)\n",
                "\n",
                "\n",
                "def new_block(\n",
                "    values,\n",
                "    placement: BlockPlacement,\n",
                "    *,\n",
                "    ndim: int,\n",
                "    refs: BlockValuesRefs | None = None,\n",
                ") -> Block:\n",
                "    # caller is responsible for ensuring:\n",
                "    # - values is NOT a NumpyExtensionArray\n",
                "    # - check_ndim/ensure_block_shape already checked\n",
                "    # - maybe_coerce_values already called/unnecessary\n",
                "    klass = get_block_type(values.dtype)\n",
                "    return klass(values, ndim=ndim, placement=placement, refs=refs)\n",
                "\n",
                "\n",
                "def check_ndim(values, placement: BlockPlacement, ndim: int) -> None:\n",
                "    \"\"\"\n",
                "    ndim inference and validation.\n",
                "\n",
                "    Validates that values.ndim and ndim are consistent.\n",
                "    Validates that len(values) and len(placement) are consistent.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    values : array-like\n",
                "    placement : BlockPlacement\n",
                "    ndim : int\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    ValueError : the number of dimensions do not match\n",
                "    \"\"\"\n",
                "\n",
                "    if values.ndim > ndim:\n",
                "        # Check for both np.ndarray and ExtensionArray\n",
                "        raise ValueError(\n",
                "            \"Wrong number of dimensions. \"\n",
                "            f\"values.ndim > ndim [{values.ndim} > {ndim}]\"\n",
                "        )\n",
                "\n",
                "    if not is_1d_only_ea_dtype(values.dtype):\n",
                "        # TODO(EA2D): special case not needed with 2D EAs\n",
                "        if values.ndim != ndim:\n",
                "            raise ValueError(\n",
                "                \"Wrong number of dimensions. \"\n",
                "                f\"values.ndim != ndim [{values.ndim} != {ndim}]\"\n",
                "            )\n",
                "        if len(placement) != len(values):\n",
                "            raise ValueError(\n",
                "                f\"Wrong number of items passed {len(values)}, \"\n",
                "                f\"placement implies {len(placement)}\"\n",
                "            )\n",
                "    elif ndim == 2 and len(placement) != 1:\n",
                "        # TODO(EA2D): special case unnecessary with 2D EAs\n",
                "        raise ValueError(\"need to split\")\n",
                "\n",
                "\n",
                "def extract_pandas_array(\n",
                "    values: ArrayLike, dtype: DtypeObj | None, ndim: int\n",
                ") -> tuple[ArrayLike, DtypeObj | None]:\n",
                "    \"\"\"\n",
                "    Ensure that we don't allow NumpyExtensionArray / NumpyEADtype in internals.\n",
                "    \"\"\"\n",
                "    # For now, blocks should be backed by ndarrays when possible.\n",
                "    if isinstance(values, ABCNumpyExtensionArray):\n",
                "        values = values.to_numpy()\n",
                "        if ndim and ndim > 1:\n",
                "            # TODO(EA2D): special case not needed with 2D EAs\n",
                "            values = np.atleast_2d(values)\n",
                "\n",
                "    if isinstance(dtype, NumpyEADtype):\n",
                "        dtype = dtype.numpy_dtype\n",
                "\n",
                "    return values, dtype\n",
                "\n",
                "\n",
                "# -----------------------------------------------------------------\n",
                "\n",
                "\n",
                "def extend_blocks(result, blocks=None) -> list[Block]:\n",
                "    \"\"\"return a new extended blocks, given the result\"\"\"\n",
                "    if blocks is None:\n",
                "        blocks = []\n",
                "    if isinstance(result, list):\n",
                "        for r in result:\n",
                "            if isinstance(r, list):\n",
                "                blocks.extend(r)\n",
                "            else:\n",
                "                blocks.append(r)\n",
                "    else:\n",
                "        assert isinstance(result, Block), type(result)\n",
                "        blocks.append(result)\n",
                "    return blocks\n",
                "\n",
                "\n",
                "def ensure_block_shape(values: ArrayLike, ndim: int = 1) -> ArrayLike:\n",
                "    \"\"\"\n",
                "    Reshape if possible to have values.ndim == ndim.\n",
                "    \"\"\"\n",
                "\n",
                "    if values.ndim < ndim:\n",
                "        if not is_1d_only_ea_dtype(values.dtype):\n",
                "            # TODO(EA2D): https://github.com/pandas-dev/pandas/issues/23023\n",
                "            # block.shape is incorrect for \"2D\" ExtensionArrays\n",
                "            # We can't, and don't need to, reshape.\n",
                "            values = cast(\"np.ndarray | DatetimeArray | TimedeltaArray\", values)\n",
                "            values = values.reshape(1, -1)\n",
                "\n",
                "    return values\n",
                "\n",
                "\n",
                "def external_values(values: ArrayLike) -> ArrayLike:\n",
                "    \"\"\"\n",
                "    The array that Series.values returns (public attribute).\n",
                "\n",
                "    This has some historical constraints, and is overridden in block\n",
                "    subclasses to return the correct array (e.g. period returns\n",
                "    object ndarray and datetimetz a datetime64[ns] ndarray instead of\n",
                "    proper extension array).\n",
                "    \"\"\"\n",
                "    if isinstance(values, (PeriodArray, IntervalArray)):\n",
                "        return values.astype(object)\n",
                "    elif isinstance(values, (DatetimeArray, TimedeltaArray)):\n",
                "        # NB: for datetime64tz this is different from np.asarray(values), since\n",
                "        #  that returns an object-dtype ndarray of Timestamps.\n",
                "        # Avoid raising in .astype in casting from dt64tz to dt64\n",
                "        values = values._ndarray\n",
                "\n",
                "    if isinstance(values, np.ndarray):\n",
                "        values = values.view()\n",
                "        values.flags.writeable = False\n",
                "\n",
                "    # TODO(CoW) we should also mark our ExtensionArrays as read-only\n",
                "\n",
                "    return values"
            ]
        ],
        "pandas/tests/internals/test_api.py": [
            [
                "\"\"\"\n",
                "Tests for the pseudo-public API implemented in internals/api.py and exposed\n",
                "in core.internals\n",
                "\"\"\"\n",
                "\n",
                "import pytest\n",
                "\n",
                "import pandas as pd\n",
                "import pandas._testing as tm\n",
                "from pandas.core import internals\n",
                "from pandas.core.internals import api\n",
                "\n",
                "\n",
                "def test_internals_api():\n",
                "    assert internals.make_block is api.make_block\n",
                "\n",
                "\n",
                "def test_namespace():\n",
                "    # SUBJECT TO CHANGE\n",
                "\n",
                "    modules = [\n",
                "        \"blocks\",\n",
                "        \"concat\",\n",
                "        \"managers\",\n",
                "        \"construction\",\n",
                "        \"api\",\n",
                "        \"ops\",\n",
                "    ]\n",
                "    expected = [\n",
                "        \"make_block\",\n",
                "        \"BlockManager\",\n",
                "        \"SingleBlockManager\",\n",
                "        \"concatenate_managers\",\n",
                "    ]\n",
                "\n",
                "    result = [x for x in dir(internals) if not x.startswith(\"__\")]\n",
                "    assert set(result) == set(expected + modules)\n",
                "\n",
                "\n",
                "@pytest.mark.parametrize(\n",
                "    \"name\",\n",
                "    [\n"
            ],
            {
                "type": "delete",
                "before": [
                    "        \"NumericBlock\",\n",
                    "        \"ObjectBlock\",\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 42,
                    "end": 44
                },
                "child_version_range": {
                    "start": 42,
                    "end": 42
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "call",
                        "name": "pytest.mark.parametrize",
                        "signature": "pytest.mark.parametrize(\n    \"name\",\n    [\n        \"NumericBlock\",\n        \"ObjectBlock\",\n        \"Block\",\n        \"ExtensionBlock\",\n        \"DatetimeTZBlock\",\n    ],\n)",
                        "at_line": 39,
                        "argument": "[\n        \"NumericBlock\",\n    ..."
                    }
                ],
                "idx": 5,
                "hunk_diff": "File: pandas/tests/internals/test_api.py\nCode:\n39 39    @pytest.mark.parametrize(\n40 40        \"name\",\n41 41        [\n42     -         \"NumericBlock\",\n43     -         \"ObjectBlock\",\n44 42            \"Block\",\n45 43            \"ExtensionBlock\",\n46 44            \"DatetimeTZBlock\",\n       ...\n",
                "file_path": "pandas/tests/internals/test_api.py",
                "identifiers_before": [],
                "identifiers_after": [],
                "prefix": [
                    "@pytest.mark.parametrize(\n",
                    "    \"name\",\n",
                    "    [\n"
                ],
                "suffix": [
                    "        \"Block\",\n",
                    "        \"ExtensionBlock\",\n",
                    "        \"DatetimeTZBlock\",\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    0
                ]
            },
            [
                "        \"Block\",\n",
                "        \"ExtensionBlock\",\n",
                "        \"DatetimeTZBlock\",\n",
                "    ],\n",
                ")\n",
                "def test_deprecations(name):\n",
                "    # GH#55139\n",
                "    msg = f\"{name} is deprecated.* Use public APIs instead\"\n",
                "    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n",
                "        getattr(internals, name)\n",
                "\n"
            ],
            {
                "type": "delete",
                "before": [
                    "    if name not in [\"NumericBlock\", \"ObjectBlock\"]:\n",
                    "        # NumericBlock and ObjectBlock are not in the internals.api namespace\n",
                    "        with tm.assert_produces_warning(DeprecationWarning, match=msg):\n",
                    "            getattr(api, name)\n",
                    "\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 55,
                    "end": 60
                },
                "child_version_range": {
                    "start": 53,
                    "end": 53
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if name not in [\"NumericBlock\", \"ObjectBlock\"]:",
                        "start_line": 55,
                        "end_line": 58
                    }
                ],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "test_deprecations",
                        "signature": "def test_deprecations(name):",
                        "at_line": 49
                    }
                ],
                "idx": 6,
                "hunk_diff": "File: pandas/tests/internals/test_api.py\nCode:\n         def test_deprecations(name):\n             ...\n52 50        with tm.assert_produces_warning(DeprecationWarning, match=msg):\n53 51            getattr(internals, name)\n54 52    \n55     -     if name not in [\"NumericBlock\", \"ObjectBlock\"]:\n56     -         # NumericBlock and ObjectBlock are not in the internals.api namespace\n57     -         with tm.assert_produces_warning(DeprecationWarning, match=msg):\n58     -             getattr(api, name)\n59     - \n60 53    \n61 54    def test_make_block_2d_with_dti():\n62 55        # GH#41168\n       ...\n",
                "file_path": "pandas/tests/internals/test_api.py",
                "identifiers_before": [
                    "DeprecationWarning",
                    "api",
                    "assert_produces_warning",
                    "getattr",
                    "match",
                    "msg",
                    "name",
                    "tm"
                ],
                "identifiers_after": [],
                "prefix": [
                    "    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n",
                    "        getattr(internals, name)\n",
                    "\n"
                ],
                "suffix": [
                    "\n",
                    "def test_make_block_2d_with_dti():\n",
                    "    # GH#41168\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "\n",
                "def test_make_block_2d_with_dti():\n",
                "    # GH#41168\n",
                "    dti = pd.date_range(\"2012\", periods=3, tz=\"UTC\")\n",
                "    blk = api.make_block(dti, placement=[0])\n",
                "\n",
                "    assert blk.shape == (1, 3)\n",
                "    assert blk.values.shape == (1, 3)\n",
                "\n",
                "\n",
                "def test_create_block_manager_from_blocks_deprecated():\n",
                "    # GH#33892\n",
                "    # If they must, downstream packages should get this from internals.api,\n",
                "    #  not internals.\n",
                "    msg = (\n",
                "        \"create_block_manager_from_blocks is deprecated and will be \"\n",
                "        \"removed in a future version. Use public APIs instead\"\n",
                "    )\n",
                "    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n",
                "        internals.create_block_manager_from_blocks"
            ]
        ]
    },
    "partial_orders": [
        {
            "edit_hunk_pair": [
                0,
                1
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                0,
                2
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                0,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                0,
                4
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                0,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                0,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "implement and test"
        },
        {
            "edit_hunk_pair": [
                1,
                4
            ],
            "edit_order": "bi-directional",
            "reason": "dependency"
        },
        {
            "edit_hunk_pair": [
                3,
                4
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                4,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                4,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        },
        {
            "edit_hunk_pair": [
                5,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "semantic update"
        }
    ]
}