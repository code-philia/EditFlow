{
    "language": "python",
    "commit_url": "https://github.com/keras-team/keras/commit/3e31a224db02ca79aa4d63c6eecc7d4a19c38768",
    "commit_message": "Add `is_legacy_optimizer` to optimizer config to keep saving/loading consistent.\n\nPiperOrigin-RevId: 463690549",
    "commit_snapshots": {
        "keras/mixed_precision/loss_scale_optimizer.py": [
            [
                "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\"\"\"Contains the loss scaling optimizer class.\"\"\"\n",
                "\n",
                "import tensorflow.compat.v2 as tf\n",
                "\n",
                "from keras import backend\n",
                "from keras import optimizers\n",
                "from keras.optimizers.optimizer_experimental import (\n",
                "    optimizer as optimizer_experimental,\n",
                ")\n",
                "from keras.optimizers.optimizer_v2 import optimizer_v2\n",
                "from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n",
                "from keras.utils import generic_utils\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.keras.optimizer_v2 import (\n",
                "    optimizer_v2 as legacy_optimizer,\n",
                ")\n",
                "from tensorflow.python.platform import tf_logging\n",
                "from tensorflow.python.util.tf_export import keras_export\n",
                "\n",
                "\n",
                "class _UnwrapPreventer:\n",
                "    \"\"\"Wrapper that DistributionStrategy will not unwrap.\n",
                "\n",
                "    Typically, DistributionStrategy will unwrap values when going from a cross-\n",
                "    replica context to a replica context via `call_for_each_replica`. This class\n",
                "    is a wrapper that DistributionStrategy will not unwrap, so it can be used to\n",
                "    prevent it from unwrapping a value.\n",
                "\n",
                "    TODO(reedwm): Find/implement a better way of preventing values from being\n",
                "    unwrapped by DistributionStrategy\n",
                "    \"\"\"\n",
                "\n",
                "    __slots__ = [\"value\"]\n",
                "\n",
                "    def __init__(self, value):\n",
                "        self.value = value\n",
                "\n",
                "\n",
                "def _is_all_finite(grads):\n",
                "    \"\"\"Returns a scalar boolean tensor indicating if all gradients are\n",
                "    finite.\"\"\"\n",
                "    is_finite_per_grad = [\n",
                "        tf.reduce_all(tf.math.is_finite(g)) for g in grads if g is not None\n",
                "    ]\n",
                "    return tf.reduce_all(is_finite_per_grad)\n",
                "\n",
                "\n",
                "def _op_in_graph_mode(tensor):\n",
                "    \"\"\"Returns the tensor's op in graph mode, or the tensor in eager mode.\n",
                "\n",
                "    This is useful because sometimes an op is needed in graph mode instead of a\n",
                "    tensor. In eager mode, there are no ops.\n",
                "\n",
                "    Args:\n",
                "      tensor: A tensor.\n",
                "\n",
                "    Returns:\n",
                "      The tensor's op in graph mode. The tensor in eager mode.\n",
                "    \"\"\"\n",
                "    if tf.executing_eagerly():\n",
                "        return tensor\n",
                "    return tensor.op\n",
                "\n",
                "\n",
                "def _assign_if_finite(var, value):\n",
                "    \"\"\"Assigns a value to a variable if the value is finite.\"\"\"\n",
                "    return tf.cond(\n",
                "        tf.math.is_finite(value),\n",
                "        lambda: _op_in_graph_mode(var.assign(value)),\n",
                "        tf.no_op,\n",
                "    )\n",
                "\n",
                "\n",
                "def _maybe_warn_about_scaling(\n",
                "    loss_has_been_scaled, gradients_have_been_unscaled\n",
                "):\n",
                "    \"\"\"Warn if the loss or gradients hasn't been scaled or unscaled.\"\"\"\n",
                "    if loss_has_been_scaled and gradients_have_been_unscaled:\n",
                "        return\n",
                "\n",
                "    example_code = \"\"\"\n",
                "    with tf.GradientTape() as tape:\n",
                "      loss = loss_fn()\n",
                "      scaled_loss = opt.get_scaled_loss(loss)\n",
                "    scaled_grads = tape.gradient(scaled_loss, vars)\n",
                "    grads = opt.get_unscaled_gradients(scaled_grads)\n",
                "    opt.apply_gradients([(grads, var)])\"\"\"\n",
                "\n",
                "    if not loss_has_been_scaled and not gradients_have_been_unscaled:\n",
                "        tf_logging.warning(\n",
                "            \"You forgot to call LossScaleOptimizer.get_scaled_loss() and \"\n",
                "            \"LossScaleOptimizer.get_unscaled_gradients() before calling \"\n",
                "            \"LossScaleOptimizer.apply_gradients(). This will likely result in \"\n",
                "            \"worse model quality, so please call them in the correct places! \"\n",
                "            f\"For example:{example_code}\\nFor more information, see \"\n",
                "            \"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer\"  # noqa: E501\n",
                "        )\n",
                "    elif not loss_has_been_scaled:\n",
                "        tf_logging.warning(\n",
                "            \"You forgot to call LossScaleOptimizer.get_scaled_loss() before \"\n",
                "            \"calling LossScaleOptimizer.apply_gradients() (you did call \"\n",
                "            \"get_unscaled_gradients() however). This will likely result in \"\n",
                "            \"worse model quality, so please call get_scaled_loss() in the \"\n",
                "            f\"correct place! For example:{example_code}\\nFor more information, \"\n",
                "            \"see \"\n",
                "            \"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer\"  # noqa: E501\n",
                "        )\n",
                "    elif not gradients_have_been_unscaled:\n",
                "        tf_logging.warning(\n",
                "            \"You forgot to call LossScaleOptimizer.get_unscaled_gradients() \"\n",
                "            \"before calling LossScaleOptimizer.apply_gradients() (you did call \"\n",
                "            \"get_scaled_loss() however). This will likely result in worse \"\n",
                "            \"model quality, so please call get_unscaled_gradients() in the \"\n",
                "            f\"correct place! For example:{example_code}\\nFor more information, \"\n",
                "            \"see \"\n",
                "            \"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer\"  # noqa: E501\n",
                "        )\n",
                "\n",
                "\n",
                "class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n",
                "    \"\"\"The state of a dynamic loss scale.\"\"\"\n",
                "\n",
                "    def __init__(self, initial_loss_scale, growth_steps, multiplier):\n",
                "        \"\"\"Creates the dynamic loss scale.\"\"\"\n",
                "        super().__init__()\n",
                "        self._initial_loss_scale = float(initial_loss_scale)\n",
                "        self._growth_steps = int(growth_steps)\n",
                "        self._multiplier = float(multiplier)\n",
                "\n",
                "        self._weights = {}\n",
                "        self._current_loss_scale = self._add_weight(\n",
                "            name=\"current_loss_scale\",\n",
                "            dtype=tf.float32,\n",
                "            initial_value=self._initial_loss_scale,\n",
                "        )\n",
                "        # The number of consecutive steps with finite gradients since the last\n",
                "        # nonfinite gradient or change in loss scale. The name is 'good_steps'\n",
                "        # for backwards compatibility with older checkpoints.\n",
                "        self._counter = self._add_weight(\n",
                "            name=\"good_steps\", dtype=tf.int64, initial_value=0\n",
                "        )\n",
                "\n",
                "    def _add_weight(self, name, initial_value, dtype=None):\n",
                "        \"\"\"Adds a weight to this loss scale.\n",
                "\n",
                "        Args:\n",
                "          name: Variable name.\n",
                "          initial_value: The variable's initial value.\n",
                "          dtype: The type of the variable.\n",
                "\n",
                "        Returns:\n",
                "          A variable.\n",
                "\n",
                "        Raises:\n",
                "          RuntimeError: If a weight with `name` has already been added.\n",
                "        \"\"\"\n",
                "        variable = tf.Variable(\n",
                "            initial_value=initial_value,\n",
                "            name=name,\n",
                "            dtype=dtype,\n",
                "            trainable=False,\n",
                "            synchronization=tf.VariableSynchronization.AUTO,\n",
                "            # Set aggregation to NONE, as loss scaling variables should never be\n",
                "            # aggregated.\n",
                "            aggregation=tf.VariableAggregation.NONE,\n",
                "        )\n",
                "        if tf.executing_eagerly():\n",
                "            graph_key = None\n",
                "        else:\n",
                "            graph = tf.compat.v1.get_default_graph()\n",
                "            graph_key = graph._graph_key\n",
                "\n",
                "        key = (name, graph_key)\n",
                "        self._weights[key] = variable\n",
                "        self._handle_deferred_dependencies(name=name, trackable=variable)\n",
                "        backend.track_variable(variable)\n",
                "        return variable\n",
                "\n",
                "    def _trackable_children(self, save_type=\"checkpoint\", **kwargs):\n",
                "        \"\"\"From Trackable. Gather graph-specific weights to save.\"\"\"\n",
                "        if tf.executing_eagerly():\n",
                "            graph_key = None\n",
                "        else:\n",
                "            graph = tf.compat.v1.get_default_graph()\n",
                "            graph_key = graph._graph_key\n",
                "        weights = {}\n",
                "        for (name, g), v in sorted(\n",
                "            self._weights.items(), key=lambda i: i[0][0]\n",
                "        ):\n",
                "            if g == graph_key:\n",
                "                weights[name] = v\n",
                "        weights.update(super()._trackable_children(save_type, **kwargs))\n",
                "        return weights\n",
                "\n",
                "    def _lookup_dependency(self, name):\n",
                "        \"\"\"From Trackable. Find a weight in the current graph.\"\"\"\n",
                "        unconditional = super()._lookup_dependency(name)\n",
                "        if unconditional is not None:\n",
                "            return unconditional\n",
                "        if tf.executing_eagerly():\n",
                "            graph_key = None\n",
                "        else:\n",
                "            graph = tf.compat.v1.get_default_graph()\n",
                "            graph_key = graph._graph_key\n",
                "        return self._weights.get((name, graph_key), None)\n",
                "\n",
                "    @property\n",
                "    def initial_loss_scale(self):\n",
                "        return self._initial_loss_scale\n",
                "\n",
                "    @property\n",
                "    def growth_steps(self):\n",
                "        return self._growth_steps\n",
                "\n",
                "    @property\n",
                "    def multiplier(self):\n",
                "        return self._multiplier\n",
                "\n",
                "    @property\n",
                "    def current_loss_scale(self):\n",
                "        \"\"\"Returns the current loss scale as a float32 `tf.Variable`.\"\"\"\n",
                "        return self._current_loss_scale\n",
                "\n",
                "    @property\n",
                "    def counter(self):\n",
                "        \"\"\"Returns the counter as a float32 `tf.Variable`.\"\"\"\n",
                "        return self._counter\n",
                "\n",
                "    def __call__(self):\n",
                "        \"\"\"Returns the current loss scale as a scalar `float32` tensor.\"\"\"\n",
                "        return tf.convert_to_tensor(self._current_loss_scale)\n",
                "\n",
                "    def update(self, grads):\n",
                "        \"\"\"Updates the value of the loss scale.\n",
                "\n",
                "        Args:\n",
                "          grads: A nested structure of unscaled gradients, each which is an\n",
                "            all-reduced gradient of the loss with respect to a weight.\n",
                "\n",
                "        Returns:\n",
                "          update_op: In eager mode, None. In graph mode, an op to update the\n",
                "            loss scale.\n",
                "          should_apply_gradients: Either a bool or a scalar boolean tensor. If\n",
                "            False, the caller should skip applying `grads` to the variables this\n",
                "            step.\n",
                "        \"\"\"\n",
                "        grads = tf.nest.flatten(grads)\n",
                "        if (\n",
                "            tf.distribute.has_strategy()\n",
                "            and tf.distribute.in_cross_replica_context()\n",
                "        ):\n",
                "            distribution = tf.distribute.get_strategy()\n",
                "            is_finite_per_replica = distribution.extended.call_for_each_replica(\n",
                "                _is_all_finite, args=(grads,)\n",
                "            )\n",
                "            # Each replica computed the same `is_finite` value, since `grads` is\n",
                "            # all-reduced across replicas. Arbitrarily take `is_finite` from the\n",
                "            # first replica.\n",
                "            is_finite = distribution.experimental_local_results(\n",
                "                is_finite_per_replica\n",
                "            )[0]\n",
                "        else:\n",
                "            is_finite = _is_all_finite(grads)\n",
                "\n",
                "        def update_if_finite_grads():\n",
                "            \"\"\"Update assuming the gradients are finite.\"\"\"\n",
                "\n",
                "            def incr_loss_scale():\n",
                "                new_loss_scale = self.current_loss_scale * self.multiplier\n",
                "                return tf.group(\n",
                "                    _assign_if_finite(self.current_loss_scale, new_loss_scale),\n",
                "                    self.counter.assign(0),\n",
                "                )\n",
                "\n",
                "            return tf.cond(\n",
                "                self.counter + 1 >= self.growth_steps,\n",
                "                incr_loss_scale,\n",
                "                lambda: _op_in_graph_mode(self.counter.assign_add(1)),\n",
                "            )\n",
                "\n",
                "        def update_if_not_finite_grads():\n",
                "            \"\"\"Update assuming the gradients are nonfinite.\"\"\"\n",
                "\n",
                "            new_loss_scale = tf.maximum(\n",
                "                self.current_loss_scale / self.multiplier, 1\n",
                "            )\n",
                "            return tf.group(\n",
                "                self.counter.assign(0),\n",
                "                self.current_loss_scale.assign(new_loss_scale),\n",
                "            )\n",
                "\n",
                "        update_op = tf.cond(\n",
                "            is_finite, update_if_finite_grads, update_if_not_finite_grads\n",
                "        )\n",
                "        should_apply_gradients = is_finite\n",
                "        return update_op, should_apply_gradients\n",
                "\n",
                "\n",
                "# See LossScaleOptimizer docstring for why this is so big\n",
                "_DEFAULT_INITIAL_SCALE = 2**15\n",
                "_DEFAULT_GROWTH_STEPS = 2000\n",
                "\n",
                "\n",
                "# TODO(b/215389169): Delete this class after `OptimizerV2` is deprecated.\n",
                "class LossScaleOptimizerMetaclass(type):\n",
                "    \"\"\"Metaclass that delegates LossScaleOptimizer instance creation.\n",
                "\n",
                "    This metaclass causes a LossScaleOptimizer or LossScaleOptimizerV3 to be\n",
                "    created when a BaseLossScaleOptimizer is constructed. As a result, when a\n",
                "    user creates a loss scale optimizer with\n",
                "    `tf.keras.mixed_precision.LossScaleOptimizer(opt)`, either a\n",
                "    LossScaleOptimizer or LossScaleOptimizerV3 will be created, depending on the\n",
                "    type of `opt`.\n",
                "    \"\"\"\n",
                "\n",
                "    def __call__(cls, inner_optimizer, *args, **kwargs):\n",
                "        if cls is not BaseLossScaleOptimizer:\n",
                "            return super(LossScaleOptimizerMetaclass, cls).__call__(\n",
                "                inner_optimizer, *args, **kwargs\n",
                "            )\n",
                "        if isinstance(inner_optimizer, optimizer_v2.OptimizerV2):\n",
                "            return LossScaleOptimizer(inner_optimizer, *args, **kwargs)\n",
                "        elif isinstance(inner_optimizer, optimizer_experimental.Optimizer):\n",
                "            return LossScaleOptimizerV3(inner_optimizer, *args, **kwargs)\n",
                "\n",
                "        # Raise TypeError because inner_optimizer is not an optimizer\n",
                "        msg = (\n",
                "            f'\"inner_optimizer\" must be an instance of '\n",
                "            f\"`tf.keras.optimizers.Optimizer` or \"\n",
                "            f\"`tf.keras.optimizers.experimental.Optimizer`, but got: \"\n",
                "            f\"{inner_optimizer}.\"\n",
                "        )\n",
                "        if isinstance(inner_optimizer, legacy_optimizer.OptimizerV2):\n",
                "            msg += (\n",
                "                ' Please make sure \"inner_optimizer\" is not an instance of '\n",
                "                \"`tensorflow.python.keras.optimizers`, which is \"\n",
                "                \"the legacy keras code and will be removed in future release. \"\n",
                "                \"Please use the tf.keras public API instead.\"\n",
                "            )\n",
                "        raise TypeError(msg)\n",
                "\n",
                "\n",
                "# TODO(b/215389169): Delete this class after `OptimizerV2` is deprecated.\n",
                "\n",
                "\n",
                "@keras_export(\"keras.mixed_precision.LossScaleOptimizer\")\n",
                "class BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass):\n",
                "    \"\"\"An optimizer that applies loss scaling to prevent numeric underflow.\n",
                "\n",
                "    Loss scaling is a technique to prevent numeric underflow in intermediate\n",
                "    gradients when float16 is used. To prevent underflow, the loss is multiplied\n",
                "    (or \"scaled\") by a certain factor called the \"loss scale\", which causes\n",
                "    intermediate gradients to be scaled by the loss scale as well. The final\n",
                "    gradients are divided (or \"unscaled\") by the loss scale to bring them back\n",
                "    to their original value.\n",
                "\n",
                "    `LossScaleOptimizer` wraps another optimizer and applies loss scaling to it.\n",
                "    By default, the loss scale is dynamically updated over time so you do not\n",
                "    have to choose the loss scale. The `minimize` method automatically scales\n",
                "    the loss, unscales the gradients, and updates the loss scale so all you have\n",
                "    to do is wrap your optimizer with a `LossScaleOptimizer` if you use\n",
                "    `minimize`. For example:\n",
                "\n",
                "    >>> opt = tf.keras.optimizers.SGD(0.25)\n",
                "    >>> opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
                "    >>> var = tf.Variable(1.)\n",
                "    >>> loss_fn = lambda: var ** 2\n",
                "    >>> # 'minimize' applies loss scaling and updates the loss sale.\n",
                "    >>> opt.minimize(loss_fn, var_list=var)\n",
                "    >>> var.numpy()\n",
                "    0.5\n",
                "\n",
                "    If a `tf.GradientTape` is used to compute gradients instead of `minimize`,\n",
                "    you must scale the loss and gradients manually. This can be done with the\n",
                "    `LossScaleOptimizer.get_scaled_loss` and\n",
                "    `LossScaleOptimizer.get_unscaled_gradients` methods. For example:\n",
                "\n",
                "    >>> with tf.GradientTape() as tape:\n",
                "    ...   loss = loss_fn()\n",
                "    ...   scaled_loss = opt.get_scaled_loss(loss)\n",
                "    >>> scaled_grad = tape.gradient(scaled_loss, var)\n",
                "    >>> (grad,) = opt.get_unscaled_gradients([scaled_grad])\n",
                "    >>> opt.apply_gradients([(grad, var)])  # Loss scale is updated here\n",
                "    >>> var.numpy()\n",
                "    0.25\n",
                "\n",
                "    Warning: If you forget to call `get_scaled_loss` or `get_unscaled_gradients`\n",
                "    (or both) when using a `tf.GradientTape`, the model will likely converge to\n",
                "    a worse quality. Please make sure you call each function exactly once.\n",
                "\n",
                "    When mixed precision with float16 is used, there is typically no risk of\n",
                "    underflow affecting model quality if loss scaling is properly used. See\n",
                "    [the mixed precision guide](\n",
                "    https://www.tensorflow.org/guide/keras/mixed_precision) for more information\n",
                "    on how to use mixed precision.\n",
                "\n",
                "    Args:\n",
                "      inner_optimizer: The `tf.keras.optimizers.Optimizer` or\n",
                "        `tf.keras.optimizers.experimental.Optimizer` instance to wrap.\n",
                "      dynamic: Bool indicating whether dynamic loss scaling is used. Defaults to\n",
                "        True. If True, the loss scale will be dynamically updated over time\n",
                "        using an algorithm that keeps the loss scale at approximately its\n",
                "        optimal value.  If False, a single fixed loss scale is used and\n",
                "        `initial_scale` must be specified, which is used as the loss scale.\n",
                "        Recommended to keep as True, as choosing a fixed loss scale can be\n",
                "        tricky. Currently, there is a small performance overhead to dynamic loss\n",
                "        scaling compared to fixed loss scaling.\n",
                "      initial_scale: The initial loss scale. If `dynamic` is True, this defaults\n",
                "        to `2 ** 15`. If `dynamic` is False, this must be specified and acts as\n",
                "        the sole loss scale, as the loss scale does not change over time. When\n",
                "        dynamic loss scaling is used, is better for this to be a very high\n",
                "        number, because a loss scale that is too high gets lowered far more\n",
                "        quickly than a loss scale that is too low gets raised.\n",
                "      dynamic_growth_steps: With dynamic loss scaling, every\n",
                "        `dynamic_growth_steps` steps with finite gradients, the loss scale is\n",
                "        doubled. Defaults to 2000. If a nonfinite gradient is encountered, the\n",
                "        count is reset back to zero, gradients are skipped that step, and the\n",
                "        loss scale is halved. The count can be queried with\n",
                "        `LossScaleOptimizer.dynamic_counter`. This argument can only be\n",
                "        specified if `dynamic` is True.\n",
                "\n",
                "    `LossScaleOptimizer` will occasionally skip applying gradients to the\n",
                "    variables, in which case the trainable variables will not change that step.\n",
                "    This is done because the dynamic loss scale will sometimes be raised too\n",
                "    high, causing overflow in the gradients. Typically, the first 2 to 15 steps\n",
                "    of the model are skipped as the initial loss scale is very high, but\n",
                "    afterwards steps will only be skipped on average 0.05% of the time (the\n",
                "    fraction of steps skipped is `1 / dynamic_growth_steps`).\n",
                "\n",
                "    `LossScaleOptimizer` delegates all public `Optimizer` methods to the inner\n",
                "    optimizer. Additionally, in methods `minimize` and `get_gradients`, it\n",
                "    scales the loss and unscales the gradients. In methods `minimize` and\n",
                "    `apply_gradients`, it additionally updates the loss scale and skips applying\n",
                "    gradients if any gradient has a nonfinite value.\n",
                "\n",
                "    ### Hyperparameters\n",
                "\n",
                "    If wrapping a `tf.keras.optimizers.Optimizer`, hyperparameters can be\n",
                "    accessed and set on the LossScaleOptimizer, which will be delegated to the\n",
                "    wrapped optimizer.\n",
                "\n",
                "    >>> opt = tf.keras.optimizers.Adam(beta_1=0.8, epsilon=1e-5)\n",
                "    >>> opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
                "    >>> opt.beta_1  # Equivalent to `opt.inner_optimizer.beta_1`\n",
                "    0.8\n",
                "    >>> opt.beta_1 = 0.7  # Equivalent to `opt.inner_optimizer.beta_1 = 0.7`\n",
                "    >>> opt.beta_1\n",
                "    0.7\n",
                "    >>> opt.inner_optimizer.beta_1\n",
                "    0.7\n",
                "\n",
                "    However, accessing or setting non-hyperparameters is not delegated to the\n",
                "    LossScaleOptimizer. In an Adam optimizer, `beta_1` is a hyperparameter but\n",
                "    `epsilon` is not, as the Adam optimizer only calls `Optimizer._set_hyper` on\n",
                "    `beta_1`.\n",
                "\n",
                "    >>> opt.inner_optimizer.epsilon\n",
                "    1e-5\n",
                "    >>> opt.epsilon\n",
                "    Traceback (most recent call last):\n",
                "    ...\n",
                "    AttributeError: 'LossScaleOptimizer' object has no attribute 'epsilon'\n",
                "    >>> opt.epsilon = 1e-4  # This does NOT set epsilon on `opt.inner_optimizer`\n",
                "    >>> opt.inner_optimizer.epsilon\n",
                "    >>> 1e-5\n",
                "\n",
                "    In the above example, despite epsilon being set on the LossScaleOptimizer,\n",
                "    the old epsilon value will still be used when training as epsilon was not\n",
                "    set on the inner optimizer.\n",
                "    \"\"\"\n",
                "\n",
                "    @property\n",
                "    def dynamic(self):\n",
                "        \"\"\"Bool indicating whether dynamic loss scaling is used.\"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    @property\n",
                "    def loss_scale(self):\n",
                "        \"\"\"The current loss scale as a float32 scalar tensor.\"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    @property\n",
                "    def dynamic_counter(self):\n",
                "        \"\"\"The number of steps since the loss scale was last increased or\n",
                "        decreased.\n",
                "\n",
                "        This is None if `LossScaleOptimizer.dynamic` is False.\n",
                "\n",
                "        The counter is incremented every step. Once it reaches\n",
                "        `LossScaleOptimizer.dynamic_growth_steps`, the loss scale will be\n",
                "        doubled and the counter will be reset back to zero. If nonfinite\n",
                "        gradients are encountered, the loss scale will be halved and the counter\n",
                "        will be reset back to zero.\n",
                "        \"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    @property\n",
                "    def initial_scale(self):\n",
                "        \"\"\"The initial loss scale.\n",
                "\n",
                "        If `LossScaleOptimizer.dynamic` is False, this is the same number as\n",
                "        `LossScaleOptimizer.loss_scale`, as the loss scale never changes.\n",
                "        \"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    @property\n",
                "    def dynamic_growth_steps(self):\n",
                "        \"\"\"The number of steps it takes to increase the loss scale.\n",
                "\n",
                "        This is None if `LossScaleOptimizer.dynamic` is False.\n",
                "\n",
                "        Every `dynamic_growth_steps` consecutive steps with finite gradients,\n",
                "        the loss scale is increased.\n",
                "        \"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    @property\n",
                "    def inner_optimizer(self):\n",
                "        \"\"\"The optimizer that this LossScaleOptimizer is wrapping.\"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    def get_scaled_loss(self, loss):\n",
                "        \"\"\"Scales the loss by the loss scale.\n",
                "\n",
                "        This method is only needed if you compute gradients manually, e.g. with\n",
                "        `tf.GradientTape`. In that case, call this method to scale the loss\n",
                "        before passing the loss to `tf.GradientTape`. If you use\n",
                "        `LossScaleOptimizer.minimize` or `LossScaleOptimizer.get_gradients`,\n",
                "        loss scaling is automatically applied and this method is unneeded.\n",
                "\n",
                "        If this method is called, `get_unscaled_gradients` should also be\n",
                "        called.  See the `tf.keras.mixed_precision.LossScaleOptimizer` doc for\n",
                "        an example.\n",
                "\n",
                "        Args:\n",
                "          loss: The loss, which will be multiplied by the loss scale. Can either\n",
                "            be a tensor or a callable returning a tensor.\n",
                "\n",
                "        Returns:\n",
                "          `loss` multiplied by `LossScaleOptimizer.loss_scale`.\n",
                "        \"\"\"\n",
                "        # Calls to this function would be delegated to `get_scaled_loss`\n",
                "        # of either `LossScaleOptimizer` or `LossScaleOptimizerV3`, depending on\n",
                "        # the type of `inner_optimizer`.\n",
                "        raise NotImplementedError\n",
                "\n",
                "    def get_unscaled_gradients(self, grads):\n",
                "        \"\"\"Unscales the gradients by the loss scale.\n",
                "\n",
                "        This method is only needed if you compute gradients manually, e.g. with\n",
                "        `tf.GradientTape`. In that case, call this method to unscale the\n",
                "        gradients after computing them with `tf.GradientTape`. If you use\n",
                "        `LossScaleOptimizer.minimize` or `LossScaleOptimizer.get_gradients`,\n",
                "        loss scaling is automatically applied and this method is unneeded.\n",
                "\n",
                "        If this method is called, `get_scaled_loss` should also be called. See\n",
                "        the `tf.keras.mixed_precision.LossScaleOptimizer` doc for an\n",
                "        example.\n",
                "\n",
                "        Args:\n",
                "          grads: A list of tensors, each which will be divided by the loss\n",
                "            scale. Can have None values, which are ignored.\n",
                "\n",
                "        Returns:\n",
                "          A new list the same size as `grads`, where every non-None value in\n",
                "          `grads` is divided by `LossScaleOptimizer.loss_scale`.\n",
                "        \"\"\"\n",
                "        # Calls to this function would be delegated to `get_unscaled_gradients`\n",
                "        # of either `LossScaleOptimizer` or `LossScaleOptimizerV3`, depending on\n",
                "        # the type of `inner_optimizer`.\n",
                "        raise NotImplementedError\n",
                "\n",
                "\n",
                "class LossScaleOptimizer(\n",
                "    tf.__internal__.tracking.DelegatingTrackableMixin,\n",
                "    optimizer_v2.OptimizerV2,\n",
                "    BaseLossScaleOptimizer,\n",
                "):\n",
                "    \"\"\"An optimizer that applies loss scaling to prevent numeric underflow.\"\"\"\n",
                "\n",
                "    _HAS_AGGREGATE_GRAD = True\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        inner_optimizer,\n",
                "        dynamic=True,\n",
                "        initial_scale=None,\n",
                "        dynamic_growth_steps=None,\n",
                "    ):\n",
                "        if not isinstance(inner_optimizer, optimizer_v2.OptimizerV2):\n",
                "            if isinstance(inner_optimizer, optimizer_experimental.Optimizer):\n",
                "                # Give better error message if the new experimental optimizer is\n",
                "                # passed.\n",
                "                raise TypeError(\n",
                "                    f\"You passed an instance of the new experimental \"\n",
                "                    f\"optimizer, `optimizer_experimental.Optimizer`, \"\n",
                "                    f\"to LossScaleOptimizer, but \"\n",
                "                    f\"only the classic optimizers subclassing from \"\n",
                "                    f\"`tf.keras.optimizers.Optimizer` can be passed. Please \"\n",
                "                    f\"use `loss_scale_optimizer.LossScaleOptimizerV3` \"\n",
                "                    f\"instead of \"\n",
                "                    f\"`tf.keras.mixed_precision.LossScaleOptimizer`, \"\n",
                "                    f\"as the former supports wrapping \"\n",
                "                    f\"instances of the new experimental optimizer. \"\n",
                "                    f\"Got optimizer: {inner_optimizer}\"\n",
                "                )\n",
                "            msg = (\n",
                "                '\"inner_optimizer\" must be an instance of '\n",
                "                \"`tf.keras.optimizers.Optimizer`, but got: %s. \"\n",
                "                % inner_optimizer\n",
                "            )\n",
                "            if isinstance(inner_optimizer, legacy_optimizer.OptimizerV2):\n",
                "                msg += (\n",
                "                    'Please make sure \"inner_optimizer\" is not an instance of '\n",
                "                    \"`tensorflow.python.keras.optimizers`, which is \"\n",
                "                    \"the legacy keras code and will be removed in future \"\n",
                "                    \"release. Please use the tf.keras public API instead.\"\n",
                "                )\n",
                "            raise TypeError(msg)\n",
                "        if not isinstance(dynamic, bool):\n",
                "            # Catch errors if a user incorrectly passes a string or float to the\n",
                "            # second argument argument, as this was commonly done for the\n",
                "            # now-removed LossScaleOptimizerV1.\n",
                "            raise TypeError(\n",
                "                '\"dynamic\" argument to LossScaleOptimizer.__init__ must '\n",
                "                \"be a bool, but got: %r\" % (dynamic,)\n",
                "            )\n",
                "        if isinstance(inner_optimizer, LossScaleOptimizer):\n",
                "            raise TypeError(\n",
                "                \"LossScaleOptimizer cannot wrap another \"\n",
                "                \"LossScaleOptimizer, but got: %s\" % (inner_optimizer,)\n",
                "            )\n",
                "        _raise_if_strategy_unsupported()\n",
                "        if getattr(\n",
                "            inner_optimizer, \"_is_wrapped_by_loss_scale_optimizer\", False\n",
                "        ):\n",
                "            # TODO(reedwm): Maybe support this. The difficulty is that LSO has\n",
                "            # the same checkpoint format as the inner optimizer, so multiple\n",
                "            # LSOs wrapping the same optimizer causes the checkpointing logic to\n",
                "            # become confused.\n",
                "            raise ValueError(\n",
                "                '\"inner_optimizer\" is already wrapped by a '\n",
                "                \"LossScaleOptimizer. An optimizer can only be wrapped \"\n",
                "                \"by a single LossScaleOptimizer\"\n",
                "            )\n",
                "        self._optimizer = inner_optimizer\n",
                "        self._optimizer._is_wrapped_by_loss_scale_optimizer = True\n",
                "\n",
                "        # We don't call super().__init__, since we do not want to call\n",
                "        # OptimizerV2's constructor.\n",
                "        tf.__internal__.tracking.DelegatingTrackableMixin.__init__(\n",
                "            self, self._optimizer\n",
                "        )\n",
                "\n",
                "        if dynamic:\n",
                "            if initial_scale is None:\n",
                "                initial_scale = _DEFAULT_INITIAL_SCALE\n",
                "            if dynamic_growth_steps is None:\n",
                "                dynamic_growth_steps = _DEFAULT_GROWTH_STEPS\n",
                "            self._loss_scale = _DynamicLossScaleState(\n",
                "                initial_scale, dynamic_growth_steps, multiplier=2\n",
                "            )\n",
                "            self._track_trackable(self._loss_scale, \"loss_scale\")\n",
                "        else:\n",
                "            if initial_scale is None:\n",
                "                raise ValueError(\n",
                "                    '\"initial_scale\" must be specified if \"dynamic\" is ' \"False\"\n",
                "                )\n",
                "            self._loss_scale = float(initial_scale)\n",
                "            if dynamic_growth_steps is not None:\n",
                "                raise ValueError(\n",
                "                    '\"dynamic_growth_steps\" must be None if \"dynamic\" '\n",
                "                    \"is False, but got: %s\" % (dynamic_growth_steps,)\n",
                "                )\n",
                "\n",
                "        # Used to track whether get_scaled_loss() and get_unscaled_gradients()\n",
                "        # have been called\n",
                "        self._loss_has_been_scaled = False\n",
                "        self._gradients_have_been_unscaled = False\n",
                "\n",
                "        # To support restoring TensorFlow 2.2 checkpoints.\n",
                "        self._track_trackable(\n",
                "            FakeOptimizerForRestoration(self._optimizer), \"base_optimizer\"\n",
                "        )\n",
                "\n",
                "    @property\n",
                "    def dynamic(self):\n",
                "        return isinstance(self._loss_scale, _DynamicLossScaleState)\n",
                "\n",
                "    @property\n",
                "    def loss_scale(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return tf.convert_to_tensor(self._loss_scale.current_loss_scale)\n",
                "        else:\n",
                "            return tf.convert_to_tensor(self._loss_scale)\n",
                "\n",
                "    @property\n",
                "    def dynamic_counter(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return self._loss_scale.counter\n",
                "        else:\n",
                "            return None\n",
                "\n",
                "    @property\n",
                "    def initial_scale(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return self._loss_scale.initial_loss_scale\n",
                "        else:\n",
                "            return self._loss_scale\n",
                "\n",
                "    @property\n",
                "    def dynamic_growth_steps(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return self._loss_scale.growth_steps\n",
                "        else:\n",
                "            return None\n",
                "\n",
                "    @property\n",
                "    def inner_optimizer(self):\n",
                "        return self._optimizer\n",
                "\n",
                "    def get_scaled_loss(self, loss):\n",
                "        self._loss_has_been_scaled = True\n",
                "        if callable(loss):\n",
                "\n",
                "            def new_loss():\n",
                "                loss_val = loss()\n",
                "                return loss_val * tf.cast(self.loss_scale, loss_val.dtype)\n",
                "\n",
                "            return new_loss\n",
                "        else:\n",
                "            return loss * tf.cast(self.loss_scale, loss.dtype)\n",
                "\n",
                "    def get_unscaled_gradients(self, grads):\n",
                "        self._gradients_have_been_unscaled = True\n",
                "        loss_scale_reciprocal = 1.0 / self.loss_scale\n",
                "        return [\n",
                "            _multiply_gradient(g, loss_scale_reciprocal)\n",
                "            if g is not None\n",
                "            else None\n",
                "            for g in grads\n",
                "        ]\n",
                "\n",
                "    def _compute_gradients(self, loss, var_list, grad_loss=None, tape=None):\n",
                "        tape = tf.GradientTape() if tape is None else tape\n",
                "        with tape:\n",
                "            loss = self.get_scaled_loss(loss)\n",
                "        grads_and_vars = self._optimizer._compute_gradients(\n",
                "            loss, var_list, grad_loss, tape=tape\n",
                "        )\n",
                "        grads = [g for g, _ in grads_and_vars]\n",
                "        weights = [v for _, v in grads_and_vars]\n",
                "        unscaled_grads = self.get_unscaled_gradients(grads)\n",
                "        return list(zip(unscaled_grads, weights))\n",
                "\n",
                "    def get_gradients(self, loss, params):\n",
                "        loss = self.get_scaled_loss(loss)\n",
                "        grads = self._optimizer.get_gradients(loss, params)\n",
                "        return self.get_unscaled_gradients(grads)\n",
                "\n",
                "    def _create_all_weights(self, var_list):\n",
                "        self._optimizer._create_all_weights(var_list)\n",
                "\n",
                "    def apply_gradients(\n",
                "        self, grads_and_vars, name=None, experimental_aggregate_gradients=True\n",
                "    ):\n",
                "        if tf.distribute.in_cross_replica_context():\n",
                "            raise ValueError(\n",
                "                \"apply_gradients() must be called in a replica context.\"\n",
                "            )\n",
                "        # We check for the strategy here despite already checking in the\n",
                "        # constructor as frequently the optimizer is created outside the\n",
                "        # strategy's scope.\n",
                "        _raise_if_strategy_unsupported()\n",
                "        _maybe_warn_about_scaling(\n",
                "            self._loss_has_been_scaled, self._gradients_have_been_unscaled\n",
                "        )\n",
                "\n",
                "        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n",
                "        if experimental_aggregate_gradients:\n",
                "            # We must aggregate the gradients here instead of in\n",
                "            # self.optimizer.apply_gradients, so that any NaN or Inf gradients\n",
                "            # are propagated to each replica. If any replica has a NaN or Inf\n",
                "            # gradient, they must all have a NaN or Inf gradient so that they\n",
                "            # all skip the step.\n",
                "            grads_and_vars = self._optimizer._transform_unaggregated_gradients(\n",
                "                grads_and_vars\n",
                "            )\n",
                "            grads_and_vars = self._optimizer._aggregate_gradients(\n",
                "                grads_and_vars\n",
                "            )\n",
                "\n",
                "        grads_and_vars = tuple(grads_and_vars)\n",
                "        grads = [g for g, _ in grads_and_vars]\n",
                "        # We do not want DistributionStrategy to unwrap any MirroredVariables in\n",
                "        # grads_and_vars, because even in a replica context, the wrapped\n",
                "        # optimizer expects mirrored variables. So we wrap the variables with an\n",
                "        # _UnwrapPreventer, preventing DistributionStrategy from unwrapping the\n",
                "        # MirroredVariables.\n",
                "        wrapped_vars = _UnwrapPreventer([v for _, v in grads_and_vars])\n",
                "\n",
                "        def do_not_apply_fn():\n",
                "            # Normally self._optimizer.iterations is incremented in\n",
                "            # self._optimizer.apply_gradients(). Since that is not called in\n",
                "            # this branch, we increment it here instead.\n",
                "            return self._optimizer.iterations.assign_add(1, read_value=False)\n",
                "\n",
                "        def _if_should_apply_grads(grads):\n",
                "            if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "                return self._loss_scale.update(grads)\n",
                "            else:\n",
                "                return (tf.no_op(), True)\n",
                "\n",
                "        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n",
                "            loss_scale_update_op, should_apply_grads = _if_should_apply_grads(\n",
                "                grads\n",
                "            )\n",
                "\n",
                "            def apply_fn():\n",
                "                return self._apply_gradients(grads, wrapped_vars, name)\n",
                "\n",
                "            maybe_apply_op = tf.__internal__.smart_cond.smart_cond(\n",
                "                should_apply_grads, apply_fn, do_not_apply_fn\n",
                "            )\n",
                "            return tf.group(maybe_apply_op, loss_scale_update_op)\n",
                "\n",
                "        else:\n",
                "\n",
                "            def _apply_gradients_cross_replica(\n",
                "                distribution, grads, wrapped_vars, name\n",
                "            ):\n",
                "                (\n",
                "                    loss_scale_update_op,\n",
                "                    should_apply_grads,\n",
                "                ) = _if_should_apply_grads(grads)\n",
                "\n",
                "                def apply_fn():\n",
                "                    return distribution.extended.call_for_each_replica(\n",
                "                        self._apply_gradients, args=(grads, wrapped_vars, name)\n",
                "                    )\n",
                "\n",
                "                # Note: We must call this cond() in a cross-replica context.\n",
                "                # DistributionStrategy does not support having a cond in a\n",
                "                # replica context with a branch that calls `merge_call`, and\n",
                "                # self._optimizer.apply_gradients calls `merge_call`.\n",
                "                maybe_apply_op = tf.__internal__.smart_cond.smart_cond(\n",
                "                    should_apply_grads, apply_fn, do_not_apply_fn\n",
                "                )\n",
                "                return tf.group(maybe_apply_op, loss_scale_update_op)\n",
                "\n",
                "            return tf.distribute.get_replica_context().merge_call(\n",
                "                _apply_gradients_cross_replica, args=(grads, wrapped_vars, name)\n",
                "            )\n",
                "\n",
                "    def _apply_gradients(self, grads, wrapped_vars, name):\n",
                "        # Pass experimental_aggregate_gradients=False since LossScaleOptimizer\n",
                "        # already aggregated the gradients.\n",
                "        # TODO(reedwm): This will raise a fairly cryptic error message if\n",
                "        # self._optimizer.apply_gradients does not take\n",
                "        # experimental_aggregate_gradients.\n",
                "        return self._optimizer.apply_gradients(\n",
                "            list(zip(grads, wrapped_vars.value)),\n",
                "            name=name,\n",
                "            experimental_aggregate_gradients=False,\n",
                "        )\n",
                "\n",
                "    def get_config(self):\n",
                "        serialized_optimizer = optimizers.serialize(self._optimizer)\n",
                "        return {\n",
                "            \"inner_optimizer\": serialized_optimizer,\n",
                "            \"dynamic\": self.dynamic,\n",
                "            \"initial_scale\": self.initial_scale,\n",
                "            \"dynamic_growth_steps\": self.dynamic_growth_steps,\n",
                "        }\n",
                "\n",
                "    @classmethod\n",
                "    def from_config(cls, config, custom_objects=None):\n",
                "        config = config.copy()  # Make a copy, since we mutate config\n",
                "        if \"loss_scale\" in config:\n",
                "            # If loss_scale is in config, we assume we are deserializing a\n",
                "            # LossScaleOptimizer from TF 2.3 or below. We convert the config so\n",
                "            # it can be deserialized in the current LossScaleOptimizer.\n",
                "            loss_scale = generic_utils.deserialize_keras_object(\n",
                "                config.pop(\"loss_scale\"),\n",
                "                module_objects={\n",
                "                    \"FixedLossScale\": tf.compat.v1.mixed_precision.FixedLossScale,  # noqa: E501\n",
                "                    \"DynamicLossScale\": tf.compat.v1.mixed_precision.DynamicLossScale,  # noqa: E501\n",
                "                },\n",
                "                printable_module_name=\"loss scale\",\n",
                "            )\n",
                "\n",
                "            if isinstance(\n",
                "                loss_scale, tf.compat.v1.mixed_precision.FixedLossScale\n",
                "            ):\n",
                "                config[\"dynamic\"] = False\n",
                "                config[\"initial_scale\"] = loss_scale._loss_scale_value\n",
                "            elif isinstance(\n",
                "                loss_scale, tf.compat.v1.mixed_precision.DynamicLossScale\n",
                "            ):\n",
                "                config[\"dynamic\"] = True\n",
                "                config[\"initial_scale\"] = loss_scale.initial_loss_scale\n",
                "                config[\"dynamic_growth_steps\"] = loss_scale.increment_period\n",
                "                if loss_scale.multiplier != 2:\n",
                "                    raise ValueError(\n",
                "                        \"Cannot deserialize LossScaleOptimizer with a \"\n",
                "                        \"DynamicLossScale whose multiplier is not 2. Got \"\n",
                "                        \"DynamicLossScale: %s\" % (loss_scale,)\n",
                "                    )\n",
                "            else:\n",
                "                raise ValueError(\n",
                "                    \"Serialized LossScaleOptimizers with a LossScale that is \"\n",
                "                    \"neither a FixedLossScale nor a DynamicLossScale can no \"\n",
                "                    \"longer be deserialized\"\n",
                "                )\n",
                "            config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n",
                "        inner_optimizer = optimizers.deserialize(\n"
            ],
            {
                "type": "replace",
                "before": [
                    "            config[\"inner_optimizer\"], custom_objects=custom_objects\n"
                ],
                "after": [
                    "            config[\"inner_optimizer\"],\n",
                    "            custom_objects=custom_objects,\n",
                    "            use_legacy_optimizer=True,\n"
                ],
                "parent_version_range": {
                    "start": 931,
                    "end": 932
                },
                "child_version_range": {
                    "start": 931,
                    "end": 934
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "LossScaleOptimizer",
                        "signature": "class LossScaleOptimizer(\n    tf.__internal__.tracking.DelegatingTrackableMixin,\n    optimizer_v2.OptimizerV2,\n    BaseLossScaleOptimizer,\n):",
                        "at_line": 588
                    },
                    {
                        "type": "function",
                        "name": "from_config",
                        "signature": "def from_config(cls, config, custom_objects=None):",
                        "at_line": 891
                    },
                    {
                        "type": "call",
                        "name": "optimizers.deserialize",
                        "signature": "optimizers.deserialize(\n            config[\"inner_optimizer\"], custom_objects=custom_objects\n        )",
                        "at_line": 930,
                        "argument": "config[\"inner_optimizer\"]"
                    }
                ],
                "idx": 0,
                "hunk_diff": "File: keras/mixed_precision/loss_scale_optimizer.py\nCode:\n           class LossScaleOptimizer(\n    tf.__internal__.tracking.DelegatingTrackableMixin,\n    optimizer_v2.OptimizerV2,\n    BaseLossScaleOptimizer,\n):\n               ...\n               def from_config(cls, config, custom_objects=None):\n                   ...\n928 928                    )\n929 929                config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n930 930            inner_optimizer = optimizers.deserialize(\n931      -             config[\"inner_optimizer\"], custom_objects=custom_objects\n    931  +             config[\"inner_optimizer\"],\n    932  +             custom_objects=custom_objects,\n    933  +             use_legacy_optimizer=True,\n932 934            )\n933 935            del config[\"inner_optimizer\"]\n934 936            return cls(inner_optimizer, **config)\n         ...\n",
                "file_path": "keras/mixed_precision/loss_scale_optimizer.py",
                "identifiers_before": [
                    "config",
                    "custom_objects"
                ],
                "identifiers_after": [
                    "config",
                    "custom_objects",
                    "use_legacy_optimizer"
                ],
                "prefix": [
                    "                )\n",
                    "            config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n",
                    "        inner_optimizer = optimizers.deserialize(\n"
                ],
                "suffix": [
                    "        )\n",
                    "        del config[\"inner_optimizer\"]\n",
                    "        return cls(inner_optimizer, **config)\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    1
                ]
            },
            [
                "        )\n",
                "        del config[\"inner_optimizer\"]\n",
                "        return cls(inner_optimizer, **config)\n",
                "\n",
                "    # Delegations: We delegate most OptimizerV2 methods to the wrapped optimizer\n",
                "    # below.\n",
                "\n",
                "    @property\n",
                "    def iterations(self):\n",
                "        return self._optimizer.iterations\n",
                "\n",
                "    @iterations.setter\n",
                "    def iterations(self, variable):\n",
                "        self._optimizer.iterations = variable\n",
                "\n",
                "    def get_slot_names(self):\n",
                "        return self._optimizer.get_slot_names()\n",
                "\n",
                "    def variables(self):\n",
                "        return self._optimizer.variables()\n",
                "\n",
                "    @property\n",
                "    def weights(self):\n",
                "        return self._optimizer.weights\n",
                "\n",
                "    def get_weights(self):\n",
                "        return self._optimizer.get_weights()\n",
                "\n",
                "    def set_weights(self, weights):\n",
                "        return self._optimizer.set_weights(weights)\n",
                "\n",
                "    @property\n",
                "    def clipnorm(self):\n",
                "        return self._optimizer.clipnorm\n",
                "\n",
                "    @clipnorm.setter\n",
                "    def clipnorm(self, val):\n",
                "        self._optimizer.clipnorm = val\n",
                "\n",
                "    @property\n",
                "    def global_clipnorm(self):\n",
                "        return self._optimizer.global_clipnorm\n",
                "\n",
                "    @global_clipnorm.setter\n",
                "    def global_clipnorm(self, val):\n",
                "        self._optimizer.global_clipnorm = val\n",
                "\n",
                "    @property\n",
                "    def clipvalue(self):\n",
                "        return self._optimizer.clipvalue\n",
                "\n",
                "    @clipvalue.setter\n",
                "    def clipvalue(self, val):\n",
                "        self._optimizer.clipvalue = val\n",
                "\n",
                "    def _aggregate_gradients(self, grads_and_vars):\n",
                "        return self._optimizer._aggregate_gradients(grads_and_vars)\n",
                "\n",
                "    def _restore_slot_variable(self, slot_name, variable, slot_variable):\n",
                "        return self._optimizer._restore_slot_variable(\n",
                "            slot_name,\n",
                "            variable,\n",
                "            slot_variable,\n",
                "        )\n",
                "\n",
                "    def _create_or_restore_slot_variable(\n",
                "        self, slot_variable_position, slot_name, variable\n",
                "    ):\n",
                "        return self._optimizer._create_or_restore_slot_variable(\n",
                "            slot_variable_position, slot_name, variable\n",
                "        )\n",
                "\n",
                "    def get_slot(self, var, slot_name):\n",
                "        return self._optimizer.get_slot(var, slot_name)\n",
                "\n",
                "    def add_slot(self, var, slot_name, initializer=\"zeros\"):\n",
                "        return self._optimizer.add_slot(var, slot_name, initializer)\n",
                "\n",
                "    def __getattribute__(self, name):\n",
                "        try:\n",
                "            return object.__getattribute__(self, name)\n",
                "        except AttributeError as e:\n",
                "            if name == \"_optimizer\" or name == \"_hyper\":\n",
                "                # Avoid infinite recursion\n",
                "                raise e\n",
                "\n",
                "            # Delegate hyperparameter accesses to inner optimizer.\n",
                "            if name == \"lr\":\n",
                "                name = \"learning_rate\"\n",
                "            if name in self._optimizer._hyper:\n",
                "                return self._optimizer._get_hyper(name)\n",
                "            raise e\n",
                "\n",
                "    def __dir__(self):\n",
                "        result = set(super().__dir__())\n",
                "        if \"_optimizer\" in result:\n",
                "            result |= self._optimizer._hyper.keys()\n",
                "            if \"learning_rate\" in self._optimizer._hyper.keys():\n",
                "                result.add(\"lr\")\n",
                "        return list(result)\n",
                "\n",
                "    def __setattr__(self, name, value):\n",
                "        if name == \"lr\":\n",
                "            name = \"learning_rate\"\n",
                "        # Delegate setting hyperparameter to inner optimizer if the attribute\n",
                "        # does not exist on the LossScaleOptimizer\n",
                "        try:\n",
                "            # We cannot check for the 'iterations' attribute as it cannot be set\n",
                "            # after it is accessed.\n",
                "            if name != \"iterations\":\n",
                "                object.__getattribute__(self, name)\n",
                "            has_attribute = True\n",
                "        except AttributeError:\n",
                "            has_attribute = False\n",
                "        if (\n",
                "            name != \"_optimizer\"\n",
                "            and name in self._optimizer._hyper\n",
                "            and not has_attribute\n",
                "        ):\n",
                "            self._optimizer._set_hyper(name, value)\n",
                "        else:\n",
                "            super().__setattr__(name, value)\n",
                "\n",
                "    # Explicitly delegate learning_rate. Normally hyperparameters are delegated\n",
                "    # in __getattribute__, but if a hyperparameter is not in\n",
                "    # self._optimizer._hyper (e.g. because self._optimizer itself wraps another\n",
                "    # optimizer), then it won't be delegated. Since learning_rate is a very\n",
                "    # commonly accessed hyperparameter, we delegate it here.\n",
                "    @property\n",
                "    def learning_rate(self):\n",
                "        return self._optimizer.learning_rate\n",
                "\n",
                "    @learning_rate.setter\n",
                "    def learning_rate(self, value):\n",
                "        self._optimizer.learning_rate = value\n",
                "\n",
                "    @property\n",
                "    def lr(self):\n",
                "        return self._optimizer.learning_rate\n",
                "\n",
                "    @lr.setter\n",
                "    def lr(self, value):\n",
                "        self._optimizer.lr = value\n",
                "\n",
                "    # We do not override some OptimizerV2 methods. For each, we describe why we\n",
                "    # do not delegate them to self._optimizer:\n",
                "    # * get_updates: get_updates() calls get_gradients(). Since we override\n",
                "    #   get_gradients(), we cannot delegate get_updates() to self._optimizer,\n",
                "    #   otherwise the overridden get_gradients() method would not be called.\n",
                "    #   Luckily, get_updates() does not access any OptimizerV2 fields, so\n",
                "    #   inheriting the OptimizerV2 version works fine.\n",
                "    # * minimize: We don't delegate for a similar as get_updates(): it calls\n",
                "    #   both self._compute_gradients() and self.apply_gradients(), and both need\n",
                "    #   to have the LossScaleOptimizer version called.\n",
                "\n",
                "    # TODO(reedwm): Maybe throw an error if mixed precision is used without this\n",
                "    # optimizer being used.\n",
                "\n",
                "\n",
                "class LossScaleOptimizerV3(\n",
                "    tf.__internal__.tracking.DelegatingTrackableMixin,\n",
                "    optimizer_experimental.Optimizer,\n",
                "    BaseLossScaleOptimizer,\n",
                "):\n",
                "    \"\"\"An optimizer that applies loss scaling to prevent numeric underflow.\n",
                "\n",
                "    This is a copy of the `mixed_precision.LossScaleOptimizer` class\n",
                "    defined above, except it subclasses and wraps the new experimental Optimizer\n",
                "    class instead of the `tf.keras.optimizers.Optimizer` class. Some of the\n",
                "    methods this class defines and calls are different compared to\n",
                "    LossScaleOptimizer due to the differences between the two Optimizer base\n",
                "    classes. Additionally, this class does not support the legacy graph mode,\n",
                "    but LossScaleOptimizer does.\n",
                "\n",
                "    Since the new experimental Optimizer does not have a hyperparameter concept,\n",
                "    LossScaleOptimizerV3 does not delegate arbitrary hyperparameter accesses to\n",
                "    the inner optimizer, unlike LossScaleOptimizer. LossScaleOptimizerV3 does\n",
                "    delegate the \"learning_rate\" attribute, however.\n",
                "    \"\"\"\n",
                "\n",
                "    @tf.__internal__.tracking.no_automatic_dependency_tracking\n",
                "    def __init__(\n",
                "        self,\n",
                "        inner_optimizer,\n",
                "        dynamic=True,\n",
                "        initial_scale=None,\n",
                "        dynamic_growth_steps=None,\n",
                "    ):\n",
                "        if not isinstance(inner_optimizer, optimizer_experimental.Optimizer):\n",
                "            if isinstance(inner_optimizer, optimizer_v2.OptimizerV2):\n",
                "                # Give better error message if the OptimizerV2 class is passed\n",
                "                # instead of the new experimental optimizer.\n",
                "                raise TypeError(\n",
                "                    f\"You passed a `tf.keras.optimizer.Optimizer` instance to \"\n",
                "                    f\"LossScaleOptimizerV3, but only the new experimental \"\n",
                "                    f\"optimizer defined in \"\n",
                "                    f\"keras/optimizer_expeirmental/optimizer.py can be \"\n",
                "                    f\"passed. Please use \"\n",
                "                    f\"`tf.keras.mixed_precision.LossScaleOptimizer` \"\n",
                "                    f\"instead of LossScaleOptimizerV3, as the former supports \"\n",
                "                    f\"`tf.keras.optimizer.Optimizer`s. Got optimizer: \"\n",
                "                    f\"{inner_optimizer}\"\n",
                "                )\n",
                "            raise TypeError(\n",
                "                f'\"inner_optimizer\" must be an instance of '\n",
                "                f\"Optimizer, but got: {inner_optimizer}.\"\n",
                "            )\n",
                "        if not isinstance(dynamic, bool):\n",
                "            # Catch errors if a user incorrectly passes a string or float to the\n",
                "            # second argument argument, as this was commonly done for the\n",
                "            # now-removed LossScaleOptimizerV1.\n",
                "            raise TypeError(\n",
                "                f'\"dynamic\" argument to LossScaleOptimizer.__init__ must '\n",
                "                f\"be a bool, but got: {repr(dynamic)}\"\n",
                "            )\n",
                "        if isinstance(inner_optimizer, LossScaleOptimizerV3):\n",
                "            raise TypeError(\n",
                "                f\"LossScaleOptimizer cannot wrap another \"\n",
                "                f\"LossScaleOptimizer, but got: {inner_optimizer}\"\n",
                "            )\n",
                "        _raise_if_strategy_unsupported()\n",
                "        if getattr(\n",
                "            inner_optimizer, \"_is_wrapped_by_loss_scale_optimizer\", False\n",
                "        ):\n",
                "            # TODO(reedwm): Maybe support this. The difficulty is that LSO has\n",
                "            # the same checkpoint format as the inner optimizer, so multiple\n",
                "            # LSOs wrapping the same optimizer causes the checkpointing logic to\n",
                "            # become confused.\n",
                "            raise ValueError(\n",
                "                '\"inner_optimizer\" is already wrapped by a '\n",
                "                \"LossScaleOptimizer. An optimizer can only be wrapped \"\n",
                "                \"by a single LossScaleOptimizer\"\n",
                "            )\n",
                "        self._optimizer = inner_optimizer\n",
                "        self._optimizer._is_wrapped_by_loss_scale_optimizer = True\n",
                "\n",
                "        # We don't call super().__init__, since we do not want to call\n",
                "        # Optimizer's constructor.\n",
                "        tf.__internal__.tracking.DelegatingTrackableMixin.__init__(\n",
                "            self, self._optimizer\n",
                "        )\n",
                "\n",
                "        if dynamic:\n",
                "            if initial_scale is None:\n",
                "                initial_scale = _DEFAULT_INITIAL_SCALE\n",
                "            if dynamic_growth_steps is None:\n",
                "                dynamic_growth_steps = _DEFAULT_GROWTH_STEPS\n",
                "            self._loss_scale = _DynamicLossScaleState(\n",
                "                initial_scale, dynamic_growth_steps, multiplier=2\n",
                "            )\n",
                "            self._track_trackable(self._loss_scale, \"loss_scale\")\n",
                "        else:\n",
                "            if initial_scale is None:\n",
                "                raise ValueError(\n",
                "                    '\"initial_scale\" must be specified if \"dynamic\" is ' \"False\"\n",
                "                )\n",
                "            self._loss_scale = float(initial_scale)\n",
                "            if dynamic_growth_steps is not None:\n",
                "                raise ValueError(\n",
                "                    f'\"dynamic_growth_steps\" must be None if \"dynamic\" '\n",
                "                    f\"is False, but got: {dynamic_growth_steps}\"\n",
                "                )\n",
                "\n",
                "        # Used to track whether get_scaled_loss() and get_unscaled_gradients()\n",
                "        # have been called\n",
                "        self._loss_has_been_scaled = False\n",
                "        self._gradients_have_been_unscaled = False\n",
                "\n",
                "    @property\n",
                "    def dynamic(self):\n",
                "        return isinstance(self._loss_scale, _DynamicLossScaleState)\n",
                "\n",
                "    @property\n",
                "    def loss_scale(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return tf.convert_to_tensor(self._loss_scale.current_loss_scale)\n",
                "        else:\n",
                "            return tf.convert_to_tensor(self._loss_scale)\n",
                "\n",
                "    @property\n",
                "    def dynamic_counter(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return self._loss_scale.counter\n",
                "        else:\n",
                "            return None\n",
                "\n",
                "    @property\n",
                "    def initial_scale(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return self._loss_scale.initial_loss_scale\n",
                "        else:\n",
                "            return self._loss_scale\n",
                "\n",
                "    @property\n",
                "    def dynamic_growth_steps(self):\n",
                "        if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "            return self._loss_scale.growth_steps\n",
                "        else:\n",
                "            return None\n",
                "\n",
                "    @property\n",
                "    def inner_optimizer(self):\n",
                "        return self._optimizer\n",
                "\n",
                "    def get_scaled_loss(self, loss):\n",
                "        self._loss_has_been_scaled = True\n",
                "        if callable(loss):\n",
                "\n",
                "            def new_loss():\n",
                "                loss_val = loss()\n",
                "                return loss_val * tf.cast(self.loss_scale, loss_val.dtype)\n",
                "\n",
                "            return new_loss\n",
                "        else:\n",
                "            return loss * tf.cast(self.loss_scale, loss.dtype)\n",
                "\n",
                "    def get_unscaled_gradients(self, grads):\n",
                "        self._gradients_have_been_unscaled = True\n",
                "        loss_scale_reciprocal = 1.0 / self.loss_scale\n",
                "        return [\n",
                "            _multiply_gradient(g, loss_scale_reciprocal)\n",
                "            if g is not None\n",
                "            else None\n",
                "            for g in grads\n",
                "        ]\n",
                "\n",
                "    def compute_gradients(self, loss, var_list, tape=None):\n",
                "        tape = tf.GradientTape() if tape is None else tape\n",
                "        with tape:\n",
                "            loss = self.get_scaled_loss(loss)\n",
                "        grads_and_vars = self._optimizer.compute_gradients(\n",
                "            loss, var_list, tape=tape\n",
                "        )\n",
                "        grads = [g for g, _ in grads_and_vars]\n",
                "        weights = [v for _, v in grads_and_vars]\n",
                "        unscaled_grads = self.get_unscaled_gradients(grads)\n",
                "        return list(zip(unscaled_grads, weights))\n",
                "\n",
                "    def apply_gradients(self, grads_and_vars, skip_gradients_aggregation=False):\n",
                "        if tf.distribute.in_cross_replica_context():\n",
                "            raise ValueError(\n",
                "                \"apply_gradients() must be called in a replica context.\"\n",
                "            )\n",
                "        # We check for the strategy here despite already checking in the\n",
                "        # constructor as frequently the optimizer is created outside the\n",
                "        # strategy's scope.\n",
                "        _raise_if_strategy_unsupported()\n",
                "        _maybe_warn_about_scaling(\n",
                "            self._loss_has_been_scaled, self._gradients_have_been_unscaled\n",
                "        )\n",
                "\n",
                "        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n",
                "        if not skip_gradients_aggregation:\n",
                "            # We must aggregate the gradients here instead of in\n",
                "            # self.optimizer.apply_gradients, so that any NaN or Inf gradients\n",
                "            # are propagated to each replica. If any replica has a NaN or Inf\n",
                "            # gradient, they must all have a NaN or Inf gradient so that they\n",
                "            # all skip the step.\n",
                "            grads_and_vars = self._optimizer.aggregate_gradients(grads_and_vars)\n",
                "\n",
                "        grads_and_vars = tuple(grads_and_vars)\n",
                "        grads = [g for g, _ in grads_and_vars]\n",
                "        # We do not want DistributionStrategy to unwrap any MirroredVariables in\n",
                "        # grads_and_vars, because even in a replica context, the wrapped\n",
                "        # optimizer expects mirrored variables. So we wrap the variables with an\n",
                "        # _UnwrapPreventer, preventing DistributionStrategy from unwrapping the\n",
                "        # MirroredVariables.\n",
                "        wrapped_vars = _UnwrapPreventer([v for _, v in grads_and_vars])\n",
                "\n",
                "        def do_not_apply_fn():\n",
                "            # Normally self._optimizer.iterations is incremented in\n",
                "            # self._optimizer.apply_gradients(). Since that is not called in\n",
                "            # this branch, we increment it here instead.\n",
                "            self._optimizer.iterations.assign_add(1, read_value=False)\n",
                "\n",
                "        def _if_should_apply_grads(grads):\n",
                "            if isinstance(self._loss_scale, _DynamicLossScaleState):\n",
                "                _, should_apply_grad = self._loss_scale.update(grads)\n",
                "                return should_apply_grad\n",
                "            else:\n",
                "                return True\n",
                "\n",
                "        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n",
                "            should_apply_grads = _if_should_apply_grads(grads)\n",
                "\n",
                "            def apply_fn():\n",
                "                return self._apply_gradients(grads, wrapped_vars)\n",
                "\n",
                "            tf.__internal__.smart_cond.smart_cond(\n",
                "                should_apply_grads, apply_fn, do_not_apply_fn\n",
                "            )\n",
                "        else:\n",
                "\n",
                "            def _apply_gradients_cross_replica(\n",
                "                distribution, grads, wrapped_vars\n",
                "            ):\n",
                "                should_apply_grads = _if_should_apply_grads(grads)\n",
                "\n",
                "                def apply_fn():\n",
                "                    distribution.extended.call_for_each_replica(\n",
                "                        self._apply_gradients, args=(grads, wrapped_vars)\n",
                "                    )\n",
                "\n",
                "                # Note: We must call this cond() in a cross-replica context.\n",
                "                # DistributionStrategy does not support having a cond in a\n",
                "                # replica context with a branch that calls `merge_call`, and\n",
                "                # self._optimizer.apply_gradients calls `merge_call`.\n",
                "                tf.__internal__.smart_cond.smart_cond(\n",
                "                    should_apply_grads, apply_fn, do_not_apply_fn\n",
                "                )\n",
                "\n",
                "            tf.distribute.get_replica_context().merge_call(\n",
                "                _apply_gradients_cross_replica, args=(grads, wrapped_vars)\n",
                "            )\n",
                "\n",
                "    def _apply_gradients(self, grads, wrapped_vars):\n",
                "        # Pass skip_gradients_aggregation=True since LossScaleOptimizer\n",
                "        # already aggregated the gradients.\n",
                "        self._optimizer.apply_gradients(\n",
                "            list(zip(grads, wrapped_vars.value)),\n",
                "            skip_gradients_aggregation=True,\n",
                "        )\n",
                "\n",
                "    def get_config(self):\n",
                "        serialized_optimizer = optimizers.serialize(self._optimizer)\n",
                "        return {\n",
                "            \"inner_optimizer\": serialized_optimizer,\n",
                "            \"dynamic\": self.dynamic,\n",
                "            \"initial_scale\": self.initial_scale,\n",
                "            \"dynamic_growth_steps\": self.dynamic_growth_steps,\n",
                "        }\n",
                "\n",
                "    @classmethod\n",
                "    def from_config(cls, config, custom_objects=None):\n",
                "        config = config.copy()  # Make a copy, since we mutate config\n",
                "        inner_optimizer = optimizers.deserialize(\n"
            ],
            {
                "type": "replace",
                "before": [
                    "            config[\"inner_optimizer\"], custom_objects=custom_objects\n"
                ],
                "after": [
                    "            config[\"inner_optimizer\"],\n",
                    "            custom_objects=custom_objects,\n",
                    "            use_legacy_optimizer=False,\n"
                ],
                "parent_version_range": {
                    "start": 1368,
                    "end": 1369
                },
                "child_version_range": {
                    "start": 1370,
                    "end": 1373
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "LossScaleOptimizerV3",
                        "signature": "class LossScaleOptimizerV3(\n    tf.__internal__.tracking.DelegatingTrackableMixin,\n    optimizer_experimental.Optimizer,\n    BaseLossScaleOptimizer,\n):",
                        "at_line": 1091
                    },
                    {
                        "type": "function",
                        "name": "from_config",
                        "signature": "def from_config(cls, config, custom_objects=None):",
                        "at_line": 1365
                    },
                    {
                        "type": "call",
                        "name": "optimizers.deserialize",
                        "signature": "optimizers.deserialize(\n            config[\"inner_optimizer\"], custom_objects=custom_objects\n        )",
                        "at_line": 1367,
                        "argument": "config[\"inner_optimizer\"]"
                    }
                ],
                "idx": 1,
                "hunk_diff": "File: keras/mixed_precision/loss_scale_optimizer.py\nCode:\n             class LossScaleOptimizerV3(\n    tf.__internal__.tracking.DelegatingTrackableMixin,\n    optimizer_experimental.Optimizer,\n    BaseLossScaleOptimizer,\n):\n                 ...\n1365 1367        def from_config(cls, config, custom_objects=None):\n1366 1368            config = config.copy()  # Make a copy, since we mutate config\n1367 1369            inner_optimizer = optimizers.deserialize(\n1368       -             config[\"inner_optimizer\"], custom_objects=custom_objects\n     1370  +             config[\"inner_optimizer\"],\n     1371  +             custom_objects=custom_objects,\n     1372  +             use_legacy_optimizer=False,\n1369 1373            )\n1370 1374            del config[\"inner_optimizer\"]\n1371 1375            return cls(inner_optimizer, **config)\n           ...\n",
                "file_path": "keras/mixed_precision/loss_scale_optimizer.py",
                "identifiers_before": [
                    "config",
                    "custom_objects"
                ],
                "identifiers_after": [
                    "config",
                    "custom_objects",
                    "use_legacy_optimizer"
                ],
                "prefix": [
                    "    def from_config(cls, config, custom_objects=None):\n",
                    "        config = config.copy()  # Make a copy, since we mutate config\n",
                    "        inner_optimizer = optimizers.deserialize(\n"
                ],
                "suffix": [
                    "        )\n",
                    "        del config[\"inner_optimizer\"]\n",
                    "        return cls(inner_optimizer, **config)\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    0
                ]
            },
            [
                "        )\n",
                "        del config[\"inner_optimizer\"]\n",
                "        return cls(inner_optimizer, **config)\n",
                "\n",
                "    @property\n",
                "    def iterations(self):\n",
                "        return self._optimizer.iterations\n",
                "\n",
                "    @iterations.setter\n",
                "    def iterations(self, variable):\n",
                "        self._optimizer.iterations = variable\n",
                "\n",
                "    @property\n",
                "    def learning_rate(self):\n",
                "        return self._optimizer.learning_rate\n",
                "\n",
                "    @learning_rate.setter\n",
                "    def learning_rate(self, learning_rate):\n",
                "        self._optimizer.learning_rate = learning_rate\n",
                "\n",
                "    @property\n",
                "    def use_ema(self):\n",
                "        return self._optimizer.use_ema\n",
                "\n",
                "    @use_ema.setter\n",
                "    def use_ema(self, use_ema):\n",
                "        self._optimizer.use_ema = use_ema\n",
                "\n",
                "    @property\n",
                "    def ema_momentum(self):\n",
                "        return self._optimizer.ema_momentum\n",
                "\n",
                "    @ema_momentum.setter\n",
                "    def ema_momentum(self, ema_momentum):\n",
                "        self._optimizer.ema_momentum = ema_momentum\n",
                "\n",
                "\n",
                "class FakeOptimizerForRestoration(tf.__internal__.tracking.Trackable):\n",
                "    \"\"\"A fake optimizer used to support restoring TensorFlow 2.2 checkpoints.\n",
                "\n",
                "    The checkpoint format for LossScaleOptimizers changed after TF 2.2. This\n",
                "    class exists to support restoring TF 2.2 checkpoints in newer version of\n",
                "    TensorFlow.\n",
                "\n",
                "    In TF 2.2, LossScaleOptimizer would track the wrapped optimizer by calling\n",
                "    the following in LossScaleOptimizer.__init__\n",
                "\n",
                "    ```\n",
                "    self._track_trackable(self._optimizer, 'base_optimizer')\n",
                "    ```\n",
                "\n",
                "    This means a dependency from the LossScaleOptimizer to the wrapped optimizer\n",
                "    would be stored in the checkpoint. However now, the checkpoint format with a\n",
                "    LossScaleOptimizer is the same as the format without a LossScaleOptimizer,\n",
                "    except the loss scale is also stored. This means there is no dependency from\n",
                "    the LossScaleOptimizer to the wrapped optimizer. Instead, the\n",
                "    LossScaleOptimizer acts as if it is the wrapped optimizer, from a\n",
                "    checkpoint's perspective, by overriding all Trackable methods and delegating\n",
                "    them to the wrapped optimizer.\n",
                "\n",
                "    To allow restoring TF 2.2. checkpoints, LossScaleOptimizer adds a dependency\n",
                "    on this class instead of the inner optimizer. When restored, this class will\n",
                "    instead restore the slot variables of the inner optimizer. Since this class\n",
                "    has no variables, it does not affect the checkpoint when saved.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, optimizer):\n",
                "        self._optimizer = optimizer\n",
                "\n",
                "    def get_slot_names(self):\n",
                "        return self._optimizer.get_slot_names()\n",
                "\n",
                "    def _create_or_restore_slot_variable(\n",
                "        self, slot_variable_position, slot_name, variable\n",
                "    ):\n",
                "        return self._optimizer._create_or_restore_slot_variable(\n",
                "            slot_variable_position, slot_name, variable\n",
                "        )\n",
                "\n",
                "\n",
                "def _create_loss_scale_optimizer_from_v1_loss_scale(optimizer, loss_scale):\n",
                "    \"\"\"Creates an LSO from a tf.compat.v1.mixed_precision.LossScale.\n",
                "\n",
                "    This is only used to pass to\n",
                "    `tf.__internal__.mixed_precision.register_loss_scale_wrapper` below, which\n",
                "    is called so that\n",
                "    `tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite` can\n",
                "    wrap a Keras optimizer with a LossScaleOptimizer.\n",
                "\n",
                "    Args:\n",
                "      optimizer: An OptimizerV2 instance.\n",
                "      loss_scale: A `tf.compat.v1.mixed_precision.LossScale` instance\n",
                "\n",
                "    Returns:\n",
                "      A LossScaleOptimizer that wraps `optimizer` and uses the same loss scaling\n",
                "      algorithm as `loss_scale`.\n",
                "    \"\"\"\n",
                "    if isinstance(loss_scale, (int, float)):\n",
                "        return LossScaleOptimizer(\n",
                "            optimizer, dynamic=False, initial_scale=loss_scale\n",
                "        )\n",
                "    elif isinstance(loss_scale, tf.compat.v1.mixed_precision.FixedLossScale):\n",
                "        ls_val = loss_scale._loss_scale_value\n",
                "        return LossScaleOptimizer(\n",
                "            optimizer, dynamic=False, initial_scale=ls_val\n",
                "        )\n",
                "    elif loss_scale == \"dynamic\":\n",
                "        return LossScaleOptimizer(optimizer)\n",
                "    elif isinstance(loss_scale, tf.compat.v1.mixed_precision.DynamicLossScale):\n",
                "        if loss_scale.multiplier != 2:\n",
                "            raise ValueError(\n",
                "                f'When passing a DynamicLossScale to \"loss_scale\", '\n",
                "                f\"DynamicLossScale.multiplier must be 2. Got: \"\n",
                "                f\"{loss_scale}\"\n",
                "            )\n",
                "        return LossScaleOptimizer(\n",
                "            optimizer,\n",
                "            initial_scale=loss_scale.initial_loss_scale,\n",
                "            dynamic_growth_steps=loss_scale.increment_period,\n",
                "        )\n",
                "    elif isinstance(loss_scale, tf.compat.v1.mixed_precision.LossScale):\n",
                "        raise TypeError(\n",
                "            f\"Passing a LossScale that is not a FixedLossScale or a \"\n",
                "            f\"DynamicLossScale is not supported. Got: {loss_scale}\"\n",
                "        )\n",
                "    else:\n",
                "        raise ValueError(\n",
                "            f\"Invalid value passed to loss_scale. loss_scale \"\n",
                "            f'must be the string \"dynamic\" (recommended), an int, '\n",
                "            f\"a float, a FixedLossScale, or a DynamicLossScale. Got \"\n",
                "            f\"value: {loss_scale}\"\n",
                "        )\n",
                "\n",
                "\n",
                "tf.__internal__.mixed_precision.register_loss_scale_wrapper(\n",
                "    optimizer_v2.OptimizerV2,\n",
                "    _create_loss_scale_optimizer_from_v1_loss_scale,\n",
                "    LossScaleOptimizer,\n",
                ")\n",
                "\n",
                "\n",
                "def _multiply_gradient(gradient, scale):\n",
                "    \"\"\"Multiply a (possibly sparse) gradient by the given scale factor.\"\"\"\n",
                "    scale = tf.cast(scale, gradient.dtype)\n",
                "    if isinstance(gradient, tf.IndexedSlices):\n",
                "        return tf.IndexedSlices(\n",
                "            gradient.values * scale,\n",
                "            gradient.indices,\n",
                "            dense_shape=gradient.dense_shape,\n",
                "        )\n",
                "    else:\n",
                "        return gradient * scale\n",
                "\n",
                "\n",
                "def strategy_supports_loss_scaling():\n",
                "    \"\"\"Returns True if the current Strategy supports loss scaling.\"\"\"\n",
                "    if not tf.distribute.has_strategy():\n",
                "        return True\n",
                "    strategy = tf.distribute.get_strategy()\n",
                "    # Strategies are supported if either there is only one replica or if\n",
                "    # variables are replicated per device. Otherwise, the current model.fit()\n",
                "    # implementation and most custom training loops incorrectly unscale the\n",
                "    # gradients. Currently, gradients are unscaled once per compute replica, but\n",
                "    # they should be unscaled once per variable replica. When there is one\n",
                "    # variable replica for each compute replica, this works fine, but otherwise\n",
                "    # issues will occur.\n",
                "    # TODO(reedwm): Support all strategies.\n",
                "    return isinstance(\n",
                "        strategy,\n",
                "        (\n",
                "            tf.distribute.MultiWorkerMirroredStrategy,\n",
                "            tf.compat.v1.distribute.experimental.MultiWorkerMirroredStrategy,\n",
                "            tf.distribute.OneDeviceStrategy,\n",
                "            tf.compat.v1.distribute.OneDeviceStrategy,\n",
                "            tf.distribute.MirroredStrategy,\n",
                "            tf.compat.v1.distribute.MirroredStrategy,\n",
                "        ),\n",
                "    )\n",
                "\n",
                "\n",
                "def _raise_if_strategy_unsupported():\n",
                "    \"\"\"Raise an exception if the current strategy doesn't support loss\n",
                "    scaling.\"\"\"\n",
                "    if not strategy_supports_loss_scaling():\n",
                "        strategy = tf.distribute.get_strategy()\n",
                "        if isinstance(\n",
                "            strategy,\n",
                "            (\n",
                "                tf.distribute.experimental.TPUStrategy,\n",
                "                tf.compat.v1.distribute.experimental.TPUStrategy,\n",
                "                tf.distribute.TPUStrategy,\n",
                "            ),\n",
                "        ):\n",
                "            raise ValueError(\n",
                "                \"Loss scaling is not supported with TPUStrategy. Loss scaling \"\n",
                "                \"is unnecessary with TPUs, since they support bfloat16 instead \"\n",
                "                \"of float16 and bfloat16 does not require loss scaling. You \"\n",
                "                \"should remove the use of the LossScaleOptimizer when TPUs are \"\n",
                "                \"used.\"\n",
                "            )\n",
                "        else:\n",
                "            raise ValueError(\n",
                "                f\"Loss scaling is not supported with the \"\n",
                "                f\"tf.distribute.Strategy: \"\n",
                "                f\"{strategy.__class__.__name__}. Try using a different \"\n",
                "                f\"Strategy, e.g. a MirroredStrategy\"\n",
                "            )"
            ]
        ],
        "keras/optimizers/__init__.py": [
            [
                "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\n",
                "\n",
                "\"\"\"Built-in optimizer classes.\n",
                "\n",
                "For more examples see the base class `tf.keras.optimizers.Optimizer`.\n",
                "\"\"\"\n",
                "\n",
                "import tensorflow.compat.v2 as tf\n",
                "\n",
                "# Imports needed for deserialization.\n",
                "from keras import backend\n",
                "from keras.optimizers.legacy import adadelta as adadelta_legacy\n",
                "from keras.optimizers.legacy import adagrad as adagrad_legacy\n",
                "from keras.optimizers.legacy import adam as adam_legacy\n",
                "from keras.optimizers.legacy import adamax as adamax_legacy\n",
                "from keras.optimizers.legacy import ftrl as ftrl_legacy\n",
                "from keras.optimizers.legacy import nadam as nadam_legacy\n",
                "from keras.optimizers.legacy import optimizer as optimizer_legacy\n",
                "from keras.optimizers.legacy import rmsprop as rmsprop_legacy\n",
                "from keras.optimizers.legacy import sgd as sgd_legacy\n",
                "from keras.optimizers.optimizer_experimental import (\n",
                "    adadelta as adadelta_experimental,\n",
                ")\n",
                "from keras.optimizers.optimizer_experimental import (\n",
                "    adagrad as adagrad_experimental,\n",
                ")\n",
                "from keras.optimizers.optimizer_experimental import adam as adam_experimental\n",
                "from keras.optimizers.optimizer_experimental import (\n",
                "    adamax as adamax_experimental,\n",
                ")\n",
                "from keras.optimizers.optimizer_experimental import adamw as adamw_experimental\n",
                "from keras.optimizers.optimizer_experimental import ftrl as ftrl_experimental\n",
                "from keras.optimizers.optimizer_experimental import nadam as nadam_experimental\n",
                "from keras.optimizers.optimizer_experimental import (\n",
                "    optimizer as optimizer_experimental,\n",
                ")\n",
                "from keras.optimizers.optimizer_experimental import (\n",
                "    rmsprop as rmsprop_experimental,\n",
                ")\n",
                "from keras.optimizers.optimizer_experimental import sgd as sgd_experimental\n",
                "from keras.optimizers.optimizer_v1 import Optimizer\n",
                "from keras.optimizers.optimizer_v1 import TFOptimizer\n",
                "from keras.optimizers.optimizer_v2 import adadelta as adadelta_v2\n",
                "from keras.optimizers.optimizer_v2 import adagrad as adagrad_v2\n",
                "from keras.optimizers.optimizer_v2 import adam as adam_v2\n",
                "from keras.optimizers.optimizer_v2 import adamax as adamax_v2\n",
                "from keras.optimizers.optimizer_v2 import ftrl\n",
                "from keras.optimizers.optimizer_v2 import (\n",
                "    gradient_descent as gradient_descent_v2,\n",
                ")\n",
                "from keras.optimizers.optimizer_v2 import nadam as nadam_v2\n",
                "from keras.optimizers.optimizer_v2 import optimizer_v2 as base_optimizer_v2\n",
                "from keras.optimizers.optimizer_v2 import rmsprop as rmsprop_v2\n",
                "from keras.optimizers.optimizer_v2.adadelta import Adadelta\n",
                "from keras.optimizers.optimizer_v2.adagrad import Adagrad\n",
                "from keras.optimizers.optimizer_v2.adam import Adam\n",
                "from keras.optimizers.optimizer_v2.adamax import Adamax\n",
                "from keras.optimizers.optimizer_v2.ftrl import Ftrl\n",
                "\n",
                "# Symbols to be accessed under keras.optimizers. To be replaced with\n",
                "# optimizers v2022 when they graduate out of experimental.\n",
                "from keras.optimizers.optimizer_v2.gradient_descent import SGD\n",
                "from keras.optimizers.optimizer_v2.nadam import Nadam\n",
                "from keras.optimizers.optimizer_v2.rmsprop import RMSprop\n",
                "from keras.utils.generic_utils import deserialize_keras_object\n",
                "from keras.utils.generic_utils import serialize_keras_object\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.util.tf_export import keras_export\n",
                "\n",
                "\n",
                "@keras_export(\"keras.optimizers.serialize\")\n",
                "def serialize(optimizer):\n",
                "    \"\"\"Serialize the optimizer configuration to JSON compatible python dict.\n",
                "\n",
                "    The configuration can be used for persistence and reconstruct the\n",
                "    `Optimizer` instance again.\n",
                "\n",
                "    >>> tf.keras.optimizers.serialize(tf.keras.optimizers.SGD())\n"
            ],
            {
                "type": "replace",
                "before": [
                    "    {'class_name': 'SGD', 'config': {'name': 'SGD', 'learning_rate': 0.01,\n"
                ],
                "after": [
                    "    {'class_name': 'SGD', 'config': {'name': 'SGD', 'is_legacy_optimizer': True,\n",
                    "                                     'learning_rate': 0.01,\n"
                ],
                "parent_version_range": {
                    "start": 93,
                    "end": 94
                },
                "child_version_range": {
                    "start": 93,
                    "end": 95
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "serialize",
                        "signature": "def serialize(optimizer):",
                        "at_line": 86
                    }
                ],
                "idx": 2,
                "hunk_diff": "File: keras/optimizers/__init__.py\nCode:\n         def serialize(optimizer):\n             ...\n90 90        `Optimizer` instance again.\n91 91    \n92 92        >>> tf.keras.optimizers.serialize(tf.keras.optimizers.SGD())\n93     -     {'class_name': 'SGD', 'config': {'name': 'SGD', 'learning_rate': 0.01,\n   93  +     {'class_name': 'SGD', 'config': {'name': 'SGD', 'is_legacy_optimizer': True,\n   94  +                                      'learning_rate': 0.01,\n94 95                                         'decay': 0.0, 'momentum': 0.0,\n95 96                                         'nesterov': False}}\n96 97    \n       ...\n",
                "file_path": "keras/optimizers/__init__.py",
                "identifiers_before": [],
                "identifiers_after": [],
                "prefix": [
                    "    `Optimizer` instance again.\n",
                    "\n",
                    "    >>> tf.keras.optimizers.serialize(tf.keras.optimizers.SGD())\n"
                ],
                "suffix": [
                    "                                     'decay': 0.0, 'momentum': 0.0,\n",
                    "                                     'nesterov': False}}\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "                                     'decay': 0.0, 'momentum': 0.0,\n",
                "                                     'nesterov': False}}\n",
                "\n",
                "    Args:\n",
                "      optimizer: An `Optimizer` instance to serialize.\n",
                "\n",
                "    Returns:\n",
                "      Python dict which contains the configuration of the input optimizer.\n",
                "    \"\"\"\n",
                "    return serialize_keras_object(optimizer)\n",
                "\n",
                "\n",
                "@keras_export(\"keras.optimizers.deserialize\")\n",
                "def deserialize(config, custom_objects=None, **kwargs):\n",
                "    \"\"\"Inverse of the `serialize` function.\n",
                "\n",
                "    Args:\n",
                "        config: Optimizer configuration dictionary.\n",
                "        custom_objects: Optional dictionary mapping names (strings) to custom\n",
                "          objects (classes and functions) to be considered during\n",
                "          deserialization.\n",
                "\n",
                "    Returns:\n",
                "        A Keras Optimizer instance.\n",
                "    \"\"\"\n",
                "    # loss_scale_optimizer has a direct dependency of optimizer, import here\n",
                "    # rather than top to avoid the cyclic dependency.\n",
                "    from keras.mixed_precision import (\n",
                "        loss_scale_optimizer,\n",
                "    )\n",
                "\n",
                "    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "    if \"is_legacy_optimizer\" in config[\"config\"]:\n",
                    "        # If the optimizer to deserialize has `is_legacy_optimizer`, use it to\n",
                    "        # override `use_legacy_optimizer`. This happens when loading a saved\n",
                    "        # optimizer.\n",
                    "        use_legacy_optimizer = config[\"config\"][\"is_legacy_optimizer\"]\n"
                ],
                "parent_version_range": {
                    "start": 126,
                    "end": 126
                },
                "child_version_range": {
                    "start": 127,
                    "end": 132
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "function",
                        "name": "deserialize",
                        "signature": "def deserialize(config, custom_objects=None, **kwargs):",
                        "at_line": 107
                    }
                ],
                "idx": 3,
                "hunk_diff": "File: keras/optimizers/__init__.py\nCode:\n           def deserialize(config, custom_objects=None, **kwargs):\n               ...\n123 124        )\n124 125    \n125 126        use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n    127  +     if \"is_legacy_optimizer\" in config[\"config\"]:\n    128  +         # If the optimizer to deserialize has `is_legacy_optimizer`, use it to\n    129  +         # override `use_legacy_optimizer`. This happens when loading a saved\n    130  +         # optimizer.\n    131  +         use_legacy_optimizer = config[\"config\"][\"is_legacy_optimizer\"]\n126 132        if (\n127 133            tf.__internal__.tf2.enabled()\n128 134            and tf.executing_eagerly()\n         ...\n",
                "file_path": "keras/optimizers/__init__.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "config",
                    "use_legacy_optimizer"
                ],
                "prefix": [
                    "    )\n",
                    "\n",
                    "    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n"
                ],
                "suffix": [
                    "    if (\n",
                    "        tf.__internal__.tf2.enabled()\n",
                    "        and tf.executing_eagerly()\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "    if (\n",
                "        tf.__internal__.tf2.enabled()\n",
                "        and tf.executing_eagerly()\n",
                "        and not use_legacy_optimizer\n",
                "    ):\n",
                "        all_classes = {\n",
                "            \"adadelta\": adadelta_experimental.Adadelta,\n",
                "            \"adagrad\": adagrad_experimental.Adagrad,\n",
                "            \"adam\": adam_experimental.Adam,\n",
                "            \"adamax\": adamax_experimental.Adamax,\n",
                "            \"experimentaladadelta\": adadelta_experimental.Adadelta,\n",
                "            \"experimentaladagrad\": adagrad_experimental.Adagrad,\n",
                "            \"experimentaladam\": adam_experimental.Adam,\n",
                "            \"experimentalsgd\": sgd_experimental.SGD,\n",
                "            \"nadam\": nadam_experimental.Nadam,\n",
                "            \"rmsprop\": rmsprop_experimental.RMSprop,\n",
                "            \"sgd\": sgd_experimental.SGD,\n",
                "            \"ftrl\": ftrl_experimental.Ftrl,\n",
                "            \"lossscaleoptimizer\": loss_scale_optimizer.LossScaleOptimizerV3,\n",
                "            \"lossscaleoptimizerv3\": loss_scale_optimizer.LossScaleOptimizerV3,\n",
                "            # LossScaleOptimizerV1 was an old version of LSO that was removed.\n",
                "            # Deserializing it turns it into a LossScaleOptimizer\n",
                "            \"lossscaleoptimizerv1\": loss_scale_optimizer.LossScaleOptimizer,\n",
                "        }\n",
                "    else:\n",
                "        all_classes = {\n",
                "            \"adadelta\": adadelta_v2.Adadelta,\n",
                "            \"adagrad\": adagrad_v2.Adagrad,\n",
                "            \"adam\": adam_v2.Adam,\n",
                "            \"adamax\": adamax_v2.Adamax,\n",
                "            \"experimentaladadelta\": adadelta_experimental.Adadelta,\n",
                "            \"experimentaladagrad\": adagrad_experimental.Adagrad,\n",
                "            \"experimentaladam\": adam_experimental.Adam,\n",
                "            \"experimentalsgd\": sgd_experimental.SGD,\n",
                "            \"nadam\": nadam_v2.Nadam,\n",
                "            \"rmsprop\": rmsprop_v2.RMSprop,\n",
                "            \"sgd\": gradient_descent_v2.SGD,\n",
                "            \"ftrl\": ftrl.Ftrl,\n",
                "            \"lossscaleoptimizer\": loss_scale_optimizer.LossScaleOptimizer,\n",
                "            \"lossscaleoptimizerv3\": loss_scale_optimizer.LossScaleOptimizerV3,\n",
                "            # LossScaleOptimizerV1 was an old version of LSO that was removed.\n",
                "            # Deserializing it turns it into a LossScaleOptimizer\n",
                "            \"lossscaleoptimizerv1\": loss_scale_optimizer.LossScaleOptimizer,\n",
                "        }\n",
                "\n",
                "    # Make deserialization case-insensitive for built-in optimizers.\n",
                "    if config[\"class_name\"].lower() in all_classes:\n",
                "        config[\"class_name\"] = config[\"class_name\"].lower()\n",
                "    return deserialize_keras_object(\n",
                "        config,\n",
                "        module_objects=all_classes,\n",
                "        custom_objects=custom_objects,\n",
                "        printable_module_name=\"optimizer\",\n",
                "    )\n",
                "\n",
                "\n",
                "@keras_export(\"keras.optimizers.get\")\n",
                "def get(identifier, **kwargs):\n",
                "    \"\"\"Retrieves a Keras Optimizer instance.\n",
                "\n",
                "    Args:\n",
                "        identifier: Optimizer identifier, one of\n",
                "            - String: name of an optimizer\n",
                "            - Dictionary: configuration dictionary.\n",
                "            - Keras Optimizer instance (it will be returned unchanged).\n",
                "            - TensorFlow Optimizer instance (it will be wrapped as a Keras\n",
                "              Optimizer).\n",
                "\n",
                "    Returns:\n",
                "        A Keras Optimizer instance.\n",
                "\n",
                "    Raises:\n",
                "        ValueError: If `identifier` cannot be interpreted.\n",
                "    \"\"\"\n",
                "    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n",
                "    if isinstance(\n",
                "        identifier,\n",
                "        (\n",
                "            Optimizer,\n",
                "            base_optimizer_v2.OptimizerV2,\n",
                "            optimizer_experimental.Optimizer,\n",
                "        ),\n",
                "    ):\n",
                "        return identifier\n",
                "    # Wrap legacy TF optimizer instances\n",
                "    elif isinstance(identifier, tf.compat.v1.train.Optimizer):\n",
                "        opt = TFOptimizer(identifier)\n",
                "        backend.track_tf_optimizer(opt)\n",
                "        return opt\n",
                "    elif isinstance(identifier, dict):\n",
                "        return deserialize(\n",
                "            identifier, use_legacy_optimizer=use_legacy_optimizer\n",
                "        )\n",
                "    elif isinstance(identifier, str):\n",
                "        config = {\"class_name\": str(identifier), \"config\": {}}\n",
                "        return deserialize(config, use_legacy_optimizer=use_legacy_optimizer)\n",
                "    else:\n",
                "        raise ValueError(\n",
                "            f\"Could not interpret optimizer identifier: {identifier}\"\n",
                "        )"
            ]
        ],
        "keras/optimizers/optimizer_experimental/optimizer.py": [
            [
                "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\"\"\"Base class of optimizer.\n",
                "\n",
                "This is under development, and subject to interface/implementation changes.\n",
                "\"\"\"\n",
                "\n",
                "import abc\n",
                "\n",
                "import tensorflow.compat.v2 as tf\n",
                "from absl import logging\n",
                "\n",
                "from keras import backend\n",
                "from keras import initializers\n",
                "from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n",
                "from keras.optimizers.schedules import learning_rate_schedule\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.util.tf_export import keras_export\n",
                "from tensorflow.tools.docs import doc_controls\n",
                "\n",
                "\n",
                "class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n",
                "    \"\"\"Optimizer base class, which only supports non-distribute use case.\"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        name,\n",
                "        clipnorm=None,\n",
                "        clipvalue=None,\n",
                "        global_clipnorm=None,\n",
                "        use_ema=False,\n",
                "        ema_momentum=0.99,\n",
                "        ema_overwrite_frequency=None,\n",
                "        jit_compile=True,\n",
                "        **kwargs,\n",
                "    ):\n",
                "        self.name = name\n",
                "        self.clipnorm = clipnorm\n",
                "        self.global_clipnorm = global_clipnorm\n",
                "        self.clipvalue = clipvalue\n",
                "        self.use_ema = use_ema\n",
                "        self.jit_compile = jit_compile\n",
                "        if not tf.config.list_physical_devices(\"GPU\"):\n",
                "            # Optimizer only benefits from XLA when training on GPU. So if no\n",
                "            # GPU is found, we turn off XLA.\n",
                "            self.jit_compile = False\n",
                "        if use_ema:\n",
                "            # Verify the arguments related to EMA.\n",
                "            if ema_momentum > 1 or ema_momentum < 0:\n",
                "                raise ValueError(\n",
                "                    \"`ema_momentum` must be in the range [0, 1]. \"\n",
                "                    f\"Received: ema_momentum={ema_momentum}\"\n",
                "                )\n",
                "            if ema_overwrite_frequency and (\n",
                "                not isinstance(ema_overwrite_frequency, int)\n",
                "                or ema_overwrite_frequency < 1\n",
                "            ):\n",
                "                raise ValueError(\n",
                "                    \"`ema_overwrite_frequency` must be an integer > 1 or None. \"\n",
                "                    f\"Received: ema_overwrite_frequency=\"\n",
                "                    f\"{ema_overwrite_frequency}\"\n",
                "                )\n",
                "        self.ema_momentum = ema_momentum\n",
                "        self.ema_overwrite_frequency = ema_overwrite_frequency\n",
                "\n",
                "        if self.clipnorm is not None and self.global_clipnorm is not None:\n",
                "            raise ValueError(\n",
                "                f\"At most one of `clipnorm` and `global_clipnorm` can \"\n",
                "                f\"be set. Received: clipnorm={self.clipnorm}, \"\n",
                "                f\"global_clipnorm={self.global_clipnorm}.\"\n",
                "            )\n",
                "\n",
                "        self._create_iteration_variable()\n",
                "        self._process_kwargs(kwargs)\n",
                "        self._variables = []\n",
                "\n",
                "    def _create_iteration_variable(self):\n",
                "        \"\"\"Create the iterations counter variable.\"\"\"\n",
                "        with tf.init_scope():\n",
                "            # Lift the variable creation to init scope to avoid environment\n",
                "            # issue.\n",
                "            self._iterations = tf.Variable(\n",
                "                0, name=\"iteration\", dtype=tf.int64, trainable=False\n",
                "            )\n",
                "\n",
                "    def _process_kwargs(self, kwargs):\n",
                "        legacy_kwargs = {\n",
                "            \"lr\",\n",
                "            \"decay\",\n",
                "            \"gradient_transformers\",\n",
                "            \"gradient_aggregator\",\n",
                "        }\n",
                "        for k in kwargs:\n",
                "            if k in legacy_kwargs:\n",
                "                logging.warning(\n",
                "                    \"%s is deprecated in `optimizer_experimental.Optimizer`\"\n",
                "                    \", please check the docstring for valid arguments.\",\n",
                "                    k,\n",
                "                )\n",
                "            else:\n",
                "                raise TypeError(\n",
                "                    f\"{k} is not a valid argument, kwargs should be empty \"\n",
                "                    \" for `optimizer_experimental.Optimizer`.\"\n",
                "                )\n",
                "\n",
                "    def _var_key(self, variable):\n",
                "        \"\"\"Get a unique identifier of the given variable.\"\"\"\n",
                "        # Get the distributed variable if it exists.\n",
                "        # TODO(b/199214315): replace _unique_id with ref() after fixing ref()\n",
                "        # issues on AggregatingVariable.\n",
                "        return variable._unique_id\n",
                "\n",
                "    def _deduplicate_sparse_grad(self, grads):\n",
                "        \"\"\"Deduplicate sparse gradient.\n",
                "\n",
                "        For sparse gradients, i.e., gradient is of type `tf.IndexedSlices`,\n",
                "        it is possible that `gradient.indices` has duplicated indices.\n",
                "        This function adds up values for the duplicated indices, and returns\n",
                "        a `tf.IndexedSlices` with indices of unique values.\n",
                "        \"\"\"\n",
                "        processed_grads = []\n",
                "        for grad in grads:\n",
                "            if isinstance(grad, tf.IndexedSlices):\n",
                "                values = grad.values\n",
                "                indices = grad.indices\n",
                "                unique_indices, new_index_positions = tf.unique(indices)\n",
                "                summed_values = tf.math.unsorted_segment_sum(\n",
                "                    values, new_index_positions, tf.shape(unique_indices)[0]\n",
                "                )\n",
                "                processed_grads.append(\n",
                "                    tf.IndexedSlices(\n",
                "                        summed_values, unique_indices, grad.dense_shape\n",
                "                    )\n",
                "                )\n",
                "            else:\n",
                "                processed_grads.append(grad)\n",
                "\n",
                "        return processed_grads\n",
                "\n",
                "    @abc.abstractmethod\n",
                "    def update_step(self, gradient, variable):\n",
                "        \"\"\"Function to update variable value based on given gradients.\n",
                "\n",
                "        This method must be implemented in customized optimizers.\n",
                "\n",
                "        Args:\n",
                "          gradient: backpropagated gradient of the given variable.\n",
                "          variable: variable whose value needs to be updated.\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` that applies the specified gradients.\n",
                "\n",
                "        \"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    @tf.function(jit_compile=True)\n",
                "    def _update_step_xla(self, gradient, variable, key):\n",
                "        \"\"\"A wrapper of `update_step` to enable XLA acceleration.\n",
                "\n",
                "        Due to `tf.function` tracing mechanism, for (gradient, variable) pairs\n",
                "        of the same shape and dtype, the execution graph always invoke the first\n",
                "        pair it has seen. Thus, we need a `key` argument to make each (gradient,\n",
                "        variable) pair unique. In additions, XLA cannot understand string input,\n",
                "        so the key is an integer.\n",
                "\n",
                "        Args:\n",
                "          gradient: backpropagated gradient of the given variable.\n",
                "          variable: variable whose value needs to be updated.\n",
                "          key (int): a unique key that identifies the variable.\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` that applies the specified gradients.\n",
                "        \"\"\"\n",
                "        return self._update_step(gradient, variable)\n",
                "\n",
                "    def _update_step(self, gradient, variable):\n",
                "        if getattr(variable, \"_unique_id\", None) is None:\n",
                "            # Variable has no `_unique_id` if called during `model.save()`, in\n",
                "            # which case we do not want to update the variable.\n",
                "            return\n",
                "        if self._var_key(variable) not in self._index_dict:\n",
                "            raise KeyError(\n",
                "                f\"The optimizer cannot recognize variable {variable.name}. \"\n",
                "                f\"This usually means that you're reusing an optimizer \"\n",
                "                f\"previously created for a different model. Try creating a \"\n",
                "                \"new optimizer instance.\"\n",
                "            )\n",
                "        self.update_step(gradient, variable)\n",
                "\n",
                "    def compute_gradients(self, loss, var_list, tape=None):\n",
                "        \"\"\"Compute gradients of loss on trainable variables.\n",
                "\n",
                "        Args:\n",
                "          loss: `Tensor` or callable. If a callable, `loss` should take no\n",
                "            arguments and return the value to minimize.\n",
                "          var_list: list or tuple of `Variable` objects to update to minimize\n",
                "            `loss`.\n",
                "          tape: (Optional) `tf.GradientTape`. If `loss` is provided as a\n",
                "            `Tensor`, the tape that computed the `loss` must be provided.\n",
                "\n",
                "        Returns:\n",
                "          A list of (gradient, variable) pairs. Variable is always present, but\n",
                "          gradient can be `None`.\n",
                "        \"\"\"\n",
                "        if not callable(loss) and tape is None:\n",
                "            raise ValueError(\n",
                "                \"`tape` is required when a `Tensor` loss is passed. \"\n",
                "                f\"Received: loss={loss}, tape={tape}.\"\n",
                "            )\n",
                "        if tape is None:\n",
                "            tape = tf.GradientTape()\n",
                "        if callable(loss):\n",
                "            with tape:\n",
                "                tape.watch(var_list)\n",
                "                loss = loss()\n",
                "        grads = tape.gradient(loss, var_list)\n",
                "        return list(zip(grads, var_list))\n",
                "\n",
                "    def _clip_gradients(self, grads):\n",
                "        clipped_grads = []\n",
                "        if self.clipnorm and self.clipnorm > 0:\n",
                "            for g in grads:\n",
                "                if g is None:\n",
                "                    clipped_grads.append(g)\n",
                "                else:\n",
                "                    clipped_grads.append(tf.clip_by_norm(g, self.clipnorm))\n",
                "            return clipped_grads\n",
                "\n",
                "        if self.global_clipnorm and self.global_clipnorm > 0:\n",
                "            return tf.clip_by_global_norm(grads, self.global_clipnorm)[0]\n",
                "\n",
                "        if self.clipvalue and self.clipvalue > 0:\n",
                "            for g in grads:\n",
                "                if g is None:\n",
                "                    clipped_grads.append(g)\n",
                "                else:\n",
                "                    clipped_grads.append(\n",
                "                        tf.clip_by_value(\n",
                "                            g,\n",
                "                            clip_value_min=-self.clipvalue,\n",
                "                            clip_value_max=self.clipvalue,\n",
                "                        )\n",
                "                    )\n",
                "            return clipped_grads\n",
                "\n",
                "        return grads\n",
                "\n",
                "    @property\n",
                "    def iterations(self):\n",
                "        \"\"\"The number of training steps this `optimizer` has run.\n",
                "\n",
                "        By default, iterations would be incremented by one every time\n",
                "        `apply_gradients()` is called.\n",
                "        \"\"\"\n",
                "        return self._iterations\n",
                "\n",
                "    @iterations.setter\n",
                "    def iterations(self, variable):\n",
                "        if getattr(self, \"_built\", False):\n",
                "            raise RuntimeError(\n",
                "                \"Cannot set `iterations` to a new Variable after \"\n",
                "                \"the Optimizer weights have been created. Here it is \"\n",
                "                f\"attempting to set `iterations` to {variable}.\"\n",
                "                \"Usually this means you are trying to set `iterations`\"\n",
                "                \" after calling `apply_gradients()`. Please set \"\n",
                "                \"`iterations` before calling `apply_gradients()`.\"\n",
                "            )\n",
                "        self._iterations = variable\n",
                "\n",
                "    @property\n",
                "    def learning_rate(self):\n",
                "        if not hasattr(self, \"_learning_rate\") or self._learning_rate is None:\n",
                "            raise ValueError(\n",
                "                \"Missing learning rate, please set self.learning_rate at\"\n",
                "                \" optimizer creation time.\"\n",
                "            )\n",
                "        lr = self._learning_rate\n",
                "        if isinstance(lr, learning_rate_schedule.LearningRateSchedule):\n",
                "            # If the optimizer takes in LearningRateSchedule, then each call to\n",
                "            # learning_rate would return `self._current_learning_rate`, which is\n",
                "            # updated at each call to `apply_gradients`.\n",
                "            return self._current_learning_rate\n",
                "        return lr\n",
                "\n",
                "    @learning_rate.setter\n",
                "    def learning_rate(self, learning_rate):\n",
                "        if isinstance(\n",
                "            learning_rate, learning_rate_schedule.LearningRateSchedule\n",
                "        ):\n",
                "            self._learning_rate = learning_rate\n",
                "        else:\n",
                "            if isinstance(\n",
                "                self._learning_rate, learning_rate_schedule.LearningRateSchedule\n",
                "            ):\n",
                "                raise TypeError(\n",
                "                    \"This optimizer was created with a `LearningRateSchedule`\"\n",
                "                    \" object as its `learning_rate` constructor argument, \"\n",
                "                    \"hence its learning rate is not settable. If you need the\"\n",
                "                    \" learning rate to be settable, you should instantiate \"\n",
                "                    \"the optimizer with a float `learning_rate` argument.\"\n",
                "                )\n",
                "            self._learning_rate.assign(learning_rate)\n",
                "\n",
                "    @property\n",
                "    @doc_controls.do_not_generate_docs\n",
                "    def lr(self):\n",
                "        \"\"\"Alias of `learning_rate()`.\n",
                "\n",
                "        `lr()` is heavily called in workflows using `optimizer_v2.OptimizerV2`,\n",
                "        so we keep it for backward compabitliy.\n",
                "        \"\"\"\n",
                "        return self.learning_rate\n",
                "\n",
                "    @lr.setter\n",
                "    def lr(self, learning_rate):\n",
                "        self.learning_rate = learning_rate\n",
                "\n",
                "    def _build_learning_rate(self, learning_rate):\n",
                "        if isinstance(\n",
                "            learning_rate, learning_rate_schedule.LearningRateSchedule\n",
                "        ):\n",
                "            # Create a variable to hold the current learning rate.\n",
                "            self._current_learning_rate = tf.Variable(\n",
                "                learning_rate(self.iterations),\n",
                "                name=\"learning_rate\",\n",
                "                dtype=tf.float32,\n",
                "                trainable=False,\n",
                "            )\n",
                "            return learning_rate\n",
                "        return tf.Variable(\n",
                "            learning_rate,\n",
                "            name=\"learning_rate\",\n",
                "            dtype=backend.floatx(),\n",
                "            trainable=False,\n",
                "        )\n",
                "\n",
                "    @abc.abstractmethod\n",
                "    def build(self, var_list):\n",
                "        \"\"\"Initialize the optimizer's variables, such as momemtum variables.\n",
                "\n",
                "        This function has to be implemented by subclass optimizers, and subclass\n",
                "        optimizers need to call `super().build(var_list)`.\n",
                "\n",
                "        Args:\n",
                "          var_list: List of model variables to build optimizers on. For example,\n",
                "            SGD optimizer with momentum will store one momentum variable\n",
                "            corresponding to each model variable.\n",
                "        \"\"\"\n",
                "        if getattr(self, \"_built\", False):\n",
                "            return\n",
                "        self._build_index_dict(var_list)\n",
                "        if self.use_ema:\n",
                "            self._model_variables_moving_average = []\n",
                "            for var in var_list:\n",
                "                # Make a copy of the model variables, we will use the copy to\n",
                "                # store the moving average of model variables.\n",
                "                self._model_variables_moving_average.append(\n",
                "                    self.add_variable_from_reference(\n",
                "                        var, \"average\", initial_value=var\n",
                "                    )\n",
                "                )\n",
                "\n",
                "    def _build_index_dict(self, var_list):\n",
                "        \"\"\"Build variable to index dictionary.\n",
                "\n",
                "        Build a dictionary that maps variable to the index of it in the given\n",
                "        var_list.\n",
                "\n",
                "        Args:\n",
                "          var_list: List of variables to build index dict on.\n",
                "\n",
                "        Returns:\n",
                "          None\n",
                "        \"\"\"\n",
                "        self._index_dict = {}\n",
                "        for i, var in enumerate(var_list):\n",
                "            var_key = self._var_key(var)\n",
                "            self._index_dict[var_key] = i\n",
                "\n",
                "    def add_variable(self, shape, dtype=None, initializer=\"zeros\", name=None):\n",
                "        \"\"\"Create an optimizer variable.\n",
                "\n",
                "        Args:\n",
                "          shape: A list of integers, a tuple of integers, or a 1-D Tensor of\n",
                "            type int32. Defaults to scalar if unspecified.\n",
                "          dtype: The DType of the optimizer variable to be created. Defaults to\n",
                "            `tf.keras.backend.floatx` if unspecified.\n",
                "          initializer: string or callable. Initializer instance.\n",
                "          name: The name of the optimizer variable to be created.\n",
                "\n",
                "        Returns:\n",
                "          An optimizer variable, in the format of tf.Variable.\n",
                "\n",
                "        \"\"\"\n",
                "        if isinstance(initializer, str):\n",
                "            initializer = initializers.get(initializer)\n",
                "        if dtype is None:\n",
                "            dtype = backend.floatx()\n",
                "        if shape is None:\n",
                "            shape = []\n",
                "        variable = tf.Variable(\n",
                "            initial_value=initializer(shape, dtype), name=name, trainable=False\n",
                "        )\n",
                "        self._variables.append(variable)\n",
                "        return variable\n",
                "\n",
                "    def add_variable_from_reference(\n",
                "        self, model_variable, variable_name, shape=None, initial_value=None\n",
                "    ):\n",
                "        \"\"\"Create an optimizer variable from model variable.\n",
                "\n",
                "        Create an optimizer variable based on the information of model variable.\n",
                "        For example, in SGD optimizer momemtum, for each model variable, a\n",
                "        corresponding momemtum variable is created of the same shape and dtype.\n",
                "\n",
                "        Args:\n",
                "          model_variable: tf.Variable. The corresponding model variable to the\n",
                "            optimizer variable to be created.\n",
                "          variable_name: String. The name prefix of the optimizer variable to be\n",
                "            created. The create variables name will follow the pattern\n",
                "            `{variable_name}/{model_variable.name}`, e.g., `momemtum/dense_1`.\n",
                "          shape: List or Tuple, defaults to None. The shape of the optimizer\n",
                "            variable to be created. If None, the created variable will have the\n",
                "            same shape as `model_variable`.\n",
                "          initial_value: A Tensor, or Python object convertible to a Tensor,\n",
                "            defaults to None. The initial value of the optimizer variable, if\n",
                "            None, the initial value will be default to 0.\n",
                "\n",
                "        Returns:\n",
                "          An optimizer variable.\n",
                "        \"\"\"\n",
                "        if initial_value is None:\n",
                "            if shape is None:\n",
                "                initial_value = tf.zeros(\n",
                "                    shape=model_variable.shape, dtype=model_variable.dtype\n",
                "                )\n",
                "            else:\n",
                "                initial_value = tf.zeros(shape, dtype=model_variable.dtype)\n",
                "        variable = tf.Variable(\n",
                "            initial_value=initial_value,\n",
                "            name=f\"{variable_name}/{model_variable._shared_name}\",\n",
                "            dtype=model_variable.dtype,\n",
                "            trainable=False,\n",
                "        )\n",
                "        self._variables.append(variable)\n",
                "        return variable\n",
                "\n",
                "    def minimize(self, loss, var_list, tape=None):\n",
                "        \"\"\"Minimize `loss` by updating `var_list`.\n",
                "\n",
                "        This method simply computes gradient using `tf.GradientTape` and calls\n",
                "        `apply_gradients()`. If you want to process the gradient before applying\n",
                "        then call `tf.GradientTape` and `apply_gradients()` explicitly instead\n",
                "        of using this function.\n",
                "\n",
                "        Args:\n",
                "          loss: `Tensor` or callable. If a callable, `loss` should take no\n",
                "            arguments and return the value to minimize.\n",
                "          var_list: list or tuple of `Variable` objects to update to minimize\n",
                "            `loss`.\n",
                "          tape: (Optional) `tf.GradientTape`.\n",
                "\n",
                "        Returns:\n",
                "          None\n",
                "        \"\"\"\n",
                "        grads_and_vars = self.compute_gradients(loss, var_list, tape)\n",
                "        self.apply_gradients(grads_and_vars)\n",
                "\n",
                "    def apply_gradients(self, grads_and_vars):\n",
                "        \"\"\"Apply gradients to variables.\n",
                "\n",
                "        Args:\n",
                "          grads_and_vars: List of (gradient, variable) pairs.\n",
                "\n",
                "        Returns:\n",
                "          None\n",
                "\n",
                "        Raises:\n",
                "          TypeError: If `grads_and_vars` is malformed.\n",
                "        \"\"\"\n",
                "        if isinstance(\n",
                "            self._learning_rate, learning_rate_schedule.LearningRateSchedule\n",
                "        ):\n",
                "            # Compute the current learning rate at the beginning of variable\n",
                "            # update.\n",
                "            if hasattr(self, \"_current_learning_rate\"):\n",
                "                self._current_learning_rate.assign(\n",
                "                    self._learning_rate(self.iterations)\n",
                "                )\n",
                "            else:\n",
                "                self._current_learning_rate = tf.Variable(\n",
                "                    self._learning_rate(self.iterations),\n",
                "                    name=\"learning_rate\",\n",
                "                    dtype=tf.float32,\n",
                "                    trainable=False,\n",
                "                )\n",
                "        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n",
                "        if len(list(grads_and_vars)) == 0:\n",
                "            # It is possible that the grad is empty. In this case,\n",
                "            # `apply_gradients` is a no-op.\n",
                "            return\n",
                "        grads, trainable_variables = zip(*grads_and_vars)\n",
                "        scope_name = self.name or \"optimizer\"\n",
                "        with tf.name_scope(scope_name):\n",
                "            with tf.init_scope():\n",
                "                # Lift variable creation to init scope to avoid environment\n",
                "                # issues.\n",
                "                self.build(trainable_variables)\n",
                "        grads = self._clip_gradients(grads)\n",
                "        grads = self._deduplicate_sparse_grad(grads)\n",
                "        grads_and_vars = list(zip(grads, trainable_variables))\n",
                "        self._internal_apply_gradients(grads_and_vars)\n",
                "\n",
                "    def _internal_apply_gradients(self, grads_and_vars):\n",
                "        \"\"\"Helper function of apply gradients.\n",
                "\n",
                "        This is required for separating out distributed training logic.\n",
                "\n",
                "        Args:\n",
                "          grads_and_vars: List of (gradient, variable) pairs.\n",
                "        \"\"\"\n",
                "        if self.jit_compile:\n",
                "            for grad, var in grads_and_vars:\n",
                "                self._update_step_xla(grad, var, id(self._var_key(var)))\n",
                "        else:\n",
                "            for grad, var in grads_and_vars:\n",
                "                self._update_step(grad, var)\n",
                "\n",
                "        self.iterations.assign_add(1)\n",
                "\n",
                "    def _update_model_variables_moving_average(self, var_list):\n",
                "        \"\"\"Update the stored moving average using the latest value.\"\"\"\n",
                "        if self.use_ema:\n",
                "            for (var, average) in zip(\n",
                "                var_list, self._model_variables_moving_average\n",
                "            ):\n",
                "                average.assign(\n",
                "                    self.ema_momentum * average + (1 - self.ema_momentum) * var\n",
                "                )\n",
                "\n",
                "    def _overwrite_model_variables_with_average_value(self, var_list):\n",
                "        \"\"\"Overwrite model variables with its moving average.\"\"\"\n",
                "        if len(var_list) != len(self._model_variables_moving_average):\n",
                "            raise ValueError(\n",
                "                f\"The length of model variables ({len(var_list)}) to \"\n",
                "                f\"override does not match the length of model variables \"\n",
                "                f\"stored in the optimizer \"\n",
                "                f\"({len(self._model_variables_moving_average)}). Please \"\n",
                "                f\"check if the optimizer was called on your model.\"\n",
                "            )\n",
                "        self._overwrite_model_variables_with_average_value_helper(var_list)\n",
                "\n",
                "    def _overwrite_model_variables_with_average_value_helper(self, var_list):\n",
                "        \"\"\"Helper function that overwrites model variables.\"\"\"\n",
                "        for var, average_var in zip(\n",
                "            var_list, self._model_variables_moving_average\n",
                "        ):\n",
                "            var.assign(average_var)\n",
                "\n",
                "    def finalize_variable_values(self, var_list):\n",
                "        \"\"\"Set the final value of model's trainable variables.\n",
                "\n",
                "        Sometimes there are some extra steps before ending the variable updates,\n",
                "        such as overriding the model variables with its average value.\n",
                "\n",
                "        Args:\n",
                "          var_list: list of model variables.\n",
                "        \"\"\"\n",
                "        if self.use_ema:\n",
                "            # If the optimizer uses EMA, then when finalizing, we replace the\n",
                "            # model variable value with its moving average stored inside\n",
                "            # optimizer.\n",
                "            self._overwrite_model_variables_with_average_value(var_list)\n",
                "\n",
                "    def _serialize_hyperparameter(self, hyperparameter):\n",
                "        \"\"\"Serialize a hyperparameter that can be a numeric or callable.\"\"\"\n",
                "        if isinstance(\n",
                "            hyperparameter, learning_rate_schedule.LearningRateSchedule\n",
                "        ):\n",
                "            return learning_rate_schedule.serialize(hyperparameter)\n",
                "        if isinstance(hyperparameter, tf.Variable):\n",
                "            return hyperparameter.numpy()\n",
                "        if callable(hyperparameter):\n",
                "            return hyperparameter()\n",
                "        return hyperparameter\n",
                "\n",
                "    def get_config(self):\n",
                "        \"\"\"Returns the config of the optimizer.\n",
                "\n",
                "        An optimizer config is a Python dictionary (serializable)\n",
                "        containing the configuration of an optimizer.\n",
                "        The same optimizer can be reinstantiated later\n",
                "        (without any saved state) from this configuration.\n",
                "\n",
                "        Subclass optimizer should override this method to include other\n",
                "        hyperparameters.\n",
                "\n",
                "        Returns:\n",
                "            Python dictionary.\n",
                "        \"\"\"\n",
                "        config = {\n",
                "            \"clipnorm\": self.clipnorm,\n",
                "            \"global_clipnorm\": self.global_clipnorm,\n",
                "            \"clipvalue\": self.clipvalue,\n",
                "            \"use_ema\": self.use_ema,\n",
                "            \"ema_momentum\": self.ema_momentum,\n",
                "            \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n",
                "            \"jit_compile\": self.jit_compile,\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "            \"is_legacy_optimizer\": False,\n"
                ],
                "parent_version_range": {
                    "start": 621,
                    "end": 621
                },
                "child_version_range": {
                    "start": 621,
                    "end": 622
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "_BaseOptimizer",
                        "signature": "class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):",
                        "at_line": 34
                    },
                    {
                        "type": "function",
                        "name": "get_config",
                        "signature": "def get_config(self):",
                        "at_line": 599
                    }
                ],
                "idx": 4,
                "hunk_diff": "File: keras/optimizers/optimizer_experimental/optimizer.py\nCode:\n           class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n               ...\n               def get_config(self):\n                   ...\n618 618                \"ema_momentum\": self.ema_momentum,\n619 619                \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n620 620                \"jit_compile\": self.jit_compile,\n    621  +             \"is_legacy_optimizer\": False,\n621 622            }\n622 623            return config\n623 624    \n         ...\n",
                "file_path": "keras/optimizers/optimizer_experimental/optimizer.py",
                "identifiers_before": [],
                "identifiers_after": [],
                "prefix": [
                    "            \"ema_momentum\": self.ema_momentum,\n",
                    "            \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n",
                    "            \"jit_compile\": self.jit_compile,\n"
                ],
                "suffix": [
                    "        }\n",
                    "        return config\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    6
                ]
            },
            [
                "        }\n",
                "        return config\n",
                "\n",
                "    @classmethod\n",
                "    def from_config(cls, config):\n",
                "        \"\"\"Creates an optimizer from its config.\n",
                "\n",
                "        This method is the reverse of `get_config`, capable of instantiating the\n",
                "        same optimizer from the config dictionary.\n",
                "\n",
                "        Args:\n",
                "            config: A Python dictionary, typically the output of get_config.\n",
                "\n",
                "        Returns:\n",
                "            An optimizer instance.\n",
                "        \"\"\"\n",
                "        if \"learning_rate\" in config:\n",
                "            if isinstance(config[\"learning_rate\"], dict):\n",
                "                config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n",
                "                    config[\"learning_rate\"]\n",
                "                )\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "        if \"is_legacy_optimizer\" in config:\n",
                    "            del config[\"is_legacy_optimizer\"]\n"
                ],
                "parent_version_range": {
                    "start": 642,
                    "end": 642
                },
                "child_version_range": {
                    "start": 643,
                    "end": 645
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if \"learning_rate\" in config:",
                        "start_line": 637,
                        "end_line": 641
                    },
                    {
                        "type": "if_statement",
                        "statement": "if isinstance(config[\"learning_rate\"], dict):",
                        "start_line": 638,
                        "end_line": 641
                    }
                ],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "_BaseOptimizer",
                        "signature": "class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):",
                        "at_line": 34
                    },
                    {
                        "type": "function",
                        "name": "from_config",
                        "signature": "def from_config(cls, config):",
                        "at_line": 625
                    },
                    {
                        "type": "call",
                        "name": "learning_rate_schedule.deserialize",
                        "signature": "learning_rate_schedule.deserialize(\n                    config[\"learning_rate\"]\n                )",
                        "at_line": 639
                    }
                ],
                "idx": 5,
                "hunk_diff": "File: keras/optimizers/optimizer_experimental/optimizer.py\nCode:\n           class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n               ...\n               def from_config(cls, config):\n                   ...\n639 640                    config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n640 641                        config[\"learning_rate\"]\n641 642                    )\n    643  +         if \"is_legacy_optimizer\" in config:\n    644  +             del config[\"is_legacy_optimizer\"]\n642 645            return cls(**config)\n643 646    \n644 647        @doc_controls.do_not_generate_docs\n         ...\n",
                "file_path": "keras/optimizers/optimizer_experimental/optimizer.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "config"
                ],
                "prefix": [
                    "                config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n",
                    "                    config[\"learning_rate\"]\n",
                    "                )\n"
                ],
                "suffix": [
                    "        return cls(**config)\n",
                    "\n",
                    "    @doc_controls.do_not_generate_docs\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    8,
                    9,
                    11
                ]
            },
            [
                "        return cls(**config)\n",
                "\n",
                "    @doc_controls.do_not_generate_docs\n",
                "    def variables(self):\n",
                "        \"\"\"Returns variables of this Optimizer.\n",
                "\n",
                "        We override the `variable` property method of `tf.Module` for the\n",
                "        sake of backward compatibility with `optimizer_v2.Optimizer`'s\n",
                "        `variable()` method.\n",
                "        \"\"\"\n",
                "        return self._variables\n",
                "\n",
                "\n",
                "base_optimizer_keyword_args = \"\"\"name: String. The name to use\n",
                "        for momentum accumulator weights created by\n",
                "        the optimizer.\n",
                "      clipnorm: Float. If set, the gradient of each weight is individually\n",
                "        clipped so that its norm is no higher than this value.\n",
                "      clipvalue: Float. If set, the gradient of each weight is clipped to be no\n",
                "        higher than this value.\n",
                "      global_clipnorm: Float. If set, the gradient of all weights is clipped so\n",
                "        that their global norm is no higher than this value.\n",
                "      use_ema: Boolean, defaults to False. If True, exponential moving average\n",
                "        (EMA) is applied. EMA consists of computing an exponential moving\n",
                "        average of the weights of the model (as the weight values change after\n",
                "        each training batch), and periodically overwriting the weights with\n",
                "        their moving average.\n",
                "      ema_momentum: Float, defaults to 0.99. Only used if `use_ema=True`. This is  # noqa: E501\n",
                "        the momentum to use when computing the EMA of the model's weights:\n",
                "        `new_average = ema_momentum * old_average + (1 - ema_momentum) *\n",
                "        current_variable_value`.\n",
                "      ema_overwrite_frequency: Int or None, defaults to None. Only used if\n",
                "        `use_ema=True`. Every `ema_overwrite_frequency` steps of iterations, we\n",
                "        overwrite the model variable by its moving average. If None, the optimizer  # noqa: E501\n",
                "         does not overwrite model variables in the middle of training, and you\n",
                "        need to explicitly overwrite the variables at the end of training\n",
                "        by calling `optimizer.finalize_variable_values()` (which updates the model  # noqa: E501\n",
                "        variables in-place). When using the built-in `fit()` training loop, this\n",
                "        happens automatically after the last epoch, and you don't need to do\n",
                "        anything.\n",
                "      jit_compile: Boolean, defaults to True. If True, the optimizer will use XLA  # noqa: E501\n",
                "        compilation. If no GPU device is found, this flag will be ignored.\n",
                "      **kwargs: keyword arguments only used for backward compatibility.\"\"\"\n",
                "\n",
                "\n",
                "@keras_export(\"keras.optimizers.experimental.Optimizer\", v1=[])\n",
                "class Optimizer(_BaseOptimizer):\n",
                "    \"\"\"Abstract optimizer base class.\n",
                "\n",
                "    This class supports distributed training. If you want to implement your own\n",
                "    optimizer, please subclass this class instead of _BaseOptimizer.\n",
                "\n",
                "    Args:\n",
                "      {{base_optimizer_keyword_args}}\n",
                "\n",
                "    ### Usage\n",
                "\n",
                "    ```python\n",
                "    # Create an optimizer with the desired parameters.\n",
                "    opt = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n",
                "    var1, var2 = tf.Variable(1.0), tf.Variable(2.0)\n",
                "    # `loss` is a callable that takes no argument and returns the value\n",
                "    # to minimize.\n",
                "    loss = lambda: 3 * var1 * var1 + 2 * var2 * var2\n",
                "    # Call minimize to update the list of variables.\n",
                "    opt.minimize(loss, var_list=[var1, var2])\n",
                "    ```\n",
                "\n",
                "    ### Processing gradients before applying them\n",
                "\n",
                "    Calling `minimize()` takes care of both computing the gradients and\n",
                "    applying them to the variables. If you want to process the gradients\n",
                "    before applying them you can instead use the optimizer in three steps:\n",
                "\n",
                "    1.  Compute the gradients with `tf.GradientTape`.\n",
                "    2.  Process the gradients as you wish.\n",
                "    3.  Apply the processed gradients with `apply_gradients()`.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    ```python\n",
                "    # Create an optimizer.\n",
                "    opt = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n",
                "    var1, var2 = tf.Variable(1.0), tf.Variable(2.0)\n",
                "\n",
                "    # Compute the gradients for a list of variables.\n",
                "    with tf.GradientTape() as tape:\n",
                "      loss = 3 * var1 * var1 + 2 * var2 * var2\n",
                "    grads = tape.gradient(loss, [var1, var2])\n",
                "\n",
                "    # Process the gradients.\n",
                "    grads[0] = grads[0] + 1\n",
                "\n",
                "    # Ask the optimizer to apply the gradients on variables.\n",
                "    opt.apply_gradients(zip(grads, [var1, var2]))\n",
                "    ```\n",
                "\n",
                "    ### Dynamic learning rate\n",
                "\n",
                "    Dynamic learning rate can be achieved by setting learning rate as a built-in\n",
                "    or customized `tf.keras.optimizers.schedules.LearningRateSchedule`.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    >>> var = tf.Variable(np.random.random(size=(1,)))\n",
                "    >>> learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
                "    ...   initial_learning_rate=.01, decay_steps=20, decay_rate=.1)\n",
                "    >>> opt = tf.keras.optimizers.experimental.SGD(learning_rate=learning_rate)\n",
                "    >>> loss = lambda: 3 * var\n",
                "    >>> opt.minimize(loss, var_list=[var])\n",
                "\n",
                "    ### Gradients clipping\n",
                "\n",
                "    Users can clip the gradients before applying to variables by setting\n",
                "    `clipnorm`, `clipvalue` and `global_clipnorm`. Notice that `clipnorm` and\n",
                "    `global_clipnorm` can only have one being set.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    >>> opt = tf.keras.optimizers.experimental.SGD(learning_rate=1, clipvalue=1)\n",
                "    >>> var1, var2 = tf.Variable(2.0), tf.Variable(2.0)\n",
                "    >>> with tf.GradientTape() as tape:\n",
                "    ...   loss = 2 * var1 + 2 * var2\n",
                "    >>> grads = tape.gradient(loss, [var1, var2])\n",
                "    >>> print([grads[0].numpy(), grads[1].numpy()])\n",
                "    [2.0, 2.0]\n",
                "    >>> opt.apply_gradients(zip(grads, [var1, var2]))\n",
                "    >>> # Without clipping, we should get [0, 0], but as gradients are clipped\n",
                "    >>> # to\n",
                "    >>> # have max value 1, we get [1.0, 1.0].\n",
                "    >>> print([var1.numpy(), var2.numpy()])\n",
                "    [1.0, 1.0]\n",
                "\n",
                "    ### Using exponential moving average.\n",
                "\n",
                "    Empirically it has been found that using the exponential moving average\n",
                "    (EMA) of the trained parameters of a deep network achieves a better\n",
                "    performance than using its trained parameters directly. Keras optimizers\n",
                "    allows users to compute this moving average and overwrite the model\n",
                "    variables at desired time.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    ```python\n",
                "    # Create an SGD optimizer with EMA on. `ema_momentum` controls the decay\n",
                "    # rate of the moving average. `ema_momentum=1` means no decay and the stored\n",
                "    # moving average is always model variable's initial value before training.\n",
                "    # Reversely, `ema_momentum=0` is equivalent to not using EMA.\n",
                "    # `ema_overwrite_frequency=3` means every 3 iterations, we overwrite the\n",
                "    # trainable variables with their moving average values.\n",
                "    opt = tf.keras.optimizers.experimental.SGD(\n",
                "        learning_rate=1,\n",
                "        use_ema=True,\n",
                "        ema_momentum=0.5,\n",
                "        ema_overwrite_frequency=3)\n",
                "    var1, var2 = tf.Variable(2.0), tf.Variable(2.0)\n",
                "    with tf.GradientTape() as tape:\n",
                "      loss = var1 + var2\n",
                "    grads = tape.gradient(loss, [var1, var2])\n",
                "    # First iteration: [var1, var2] = [1.0, 1.0]\n",
                "    opt.apply_gradients(zip(grads, [var1, var2]))\n",
                "    print([var1, var2])\n",
                "\n",
                "    # Second iteration: [var1, var2] = [0.0, 0.0]\n",
                "    opt.apply_gradients(zip(grads, [var1, var2]))\n",
                "    print([var1, var2])\n",
                "\n",
                "    # Third iteration, without EMA, we should see [var1, var2] = [-1.0, -1.0],\n",
                "    # but overwriting results in [var1, var2] = [-0.125, -0.125]. The full\n",
                "    # calculation for the moving average of var1 is:\n",
                "    # var1=2*0.5**3+1*(1-0.5)*0.5**2+0*(1-0.5)*0.5**1+(-1)*(1-0.5)=-0.125.\n",
                "    opt.apply_gradients(zip(grads, [var1, var2]))\n",
                "    print([var1, var2])\n",
                "\n",
                "    ```\n",
                "    When optimizer is constructed with `use_ema=True`, in custom training loop,\n",
                "    users can explicitly call `finalize_variable_values()` to overwrite\n",
                "    trainable variables with their EMA values. `finalize_variable_values()` is\n",
                "    by default called at the end of `model.fit()`.\n",
                "\n",
                "    ### Use with `tf.distribute.Strategy`\n",
                "\n",
                "    This optimizer class is `tf.distribute.Strategy` aware, which means it\n",
                "    automatically sums gradients across all replicas. To aggregate gradients\n",
                "    yourself, call `apply_gradients` with `skip_aggregate_gradients` set to\n",
                "    True.  This is useful if you need to process aggregated gradients.\n",
                "\n",
                "    ```python\n",
                "    # This example is not runnable, it consists of dummy code for simple\n",
                "    # tutorial.\n",
                "    strategy = tf.distribute.experimental.TPUStrategy()\n",
                "\n",
                "    with strategy.scope():\n",
                "      opt = tf.keras.optimizers.experimental.SGD()\n",
                "      model = magic_function_that_returns_model()\n",
                "      gradients = magic_function_that_returns_gradients()\n",
                "      # Custom logic to aggregate gradients.\n",
                "      gradients = strategy.reduce(\"SUM\", gradients, axis=None)\n",
                "      opt.apply_gradients(zip(gradients, model.trainable_variables),\n",
                "          skip_aggregate_gradients=True)\n",
                "    ```\n",
                "\n",
                "    ### Creating a custom optimizer\n",
                "\n",
                "    If you intend to create your own optimization algorithm, please inherit from\n",
                "    this class and override the following methods:\n",
                "\n",
                "      - `build`: Create your optimizer-related variables, such as `momentums` in\n",
                "        SGD optimizer.\n",
                "      - `update_step`: Implement your optimizer's updating logic.\n",
                "      - `get_config`: serialization of the optimizer, include all hyper\n",
                "        parameters.\n",
                "\n",
                "    Your optimizer would automatically be compatible with tensorflow distributed\n",
                "    training if you subclass `optimizer_experimental.Optimizer`.\n",
                "\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        name,\n",
                "        clipnorm=None,\n",
                "        clipvalue=None,\n",
                "        global_clipnorm=None,\n",
                "        use_ema=False,\n",
                "        ema_momentum=0.99,\n",
                "        ema_overwrite_frequency=None,\n",
                "        jit_compile=True,\n",
                "        **kwargs,\n",
                "    ):\n",
                "        \"\"\"Create a new Optimizer.\"\"\"\n",
                "\n",
                "        super().__init__(\n",
                "            name,\n",
                "            clipnorm,\n",
                "            clipvalue,\n",
                "            global_clipnorm,\n",
                "            use_ema,\n",
                "            ema_momentum,\n",
                "            ema_overwrite_frequency,\n",
                "            jit_compile,\n",
                "            **kwargs,\n",
                "        )\n",
                "        self._distribution_strategy = tf.distribute.get_strategy()\n",
                "\n",
                "    def add_variable_from_reference(\n",
                "        self, model_variable, variable_name, shape=None, initial_value=None\n",
                "    ):\n",
                "        strategy = tf.distribute.get_strategy()\n",
                "        with strategy.extended.colocate_vars_with(model_variable):\n",
                "            return super().add_variable_from_reference(\n",
                "                model_variable, variable_name, shape, initial_value\n",
                "            )\n",
                "\n",
                "    def _var_key(self, variable):\n",
                "        \"\"\"Get a unique identifier of the given variable.\"\"\"\n",
                "\n",
                "        # Get the distributed variable if it exists.\n",
                "        # TODO(b/197554203): replace _distributed_container() with a public api.\n",
                "        if hasattr(variable, \"_distributed_container\"):\n",
                "            variable = variable._distributed_container()\n",
                "        return super()._var_key(variable)\n",
                "\n",
                "    def aggregate_gradients(self, grads_and_vars):\n",
                "        \"\"\"Aggregate gradients on all devices.\n",
                "\n",
                "        By default we will perform reduce_sum of gradients across devices. Users\n",
                "        can implement their own aggregation logic by overriding this method.\n",
                "\n",
                "        Args:\n",
                "          grads_and_vars: List of (gradient, variable) pairs.\n",
                "\n",
                "        Returns:\n",
                "          List of (gradient, variable) pairs.\n",
                "        \"\"\"\n",
                "        return optimizer_utils.all_reduce_sum_gradients(grads_and_vars)\n",
                "\n",
                "    def apply_gradients(self, grads_and_vars, skip_gradients_aggregation=False):\n",
                "        \"\"\"Apply gradients to variables.\n",
                "\n",
                "        Args:\n",
                "          grads_and_vars: List of (gradient, variable) pairs.\n",
                "          skip_gradients_aggregation: If true, gradients aggregation will not be\n",
                "            performed inside optimizer. Usually this arg is set to True when you\n",
                "            write custom code aggregating gradients outside the optimizer.\n",
                "\n",
                "        Returns:\n",
                "          None\n",
                "\n",
                "        Raises:\n",
                "          TypeError: If `grads_and_vars` is malformed.\n",
                "          RuntimeError: If called in a cross-replica context.\n",
                "        \"\"\"\n",
                "        if not skip_gradients_aggregation:\n",
                "            grads_and_vars = self.aggregate_gradients(grads_and_vars)\n",
                "        super().apply_gradients(grads_and_vars)\n",
                "\n",
                "    def _internal_apply_gradients(self, grads_and_vars):\n",
                "        tf.__internal__.distribute.interim.maybe_merge_call(\n",
                "            self._distributed_apply_gradients_fn,\n",
                "            self._distribution_strategy,\n",
                "            grads_and_vars,\n",
                "        )\n",
                "\n",
                "    def _overwrite_model_variables_with_average_value_helper(self, var_list):\n",
                "        \"\"\"Helper function to _overwrite_model_variables_with_average_value.\n",
                "\n",
                "        This function overwrites variables on each device.\n",
                "        Args:\n",
                "          var_list: list of model variables.\n",
                "        \"\"\"\n",
                "        strategy = self._distribution_strategy\n",
                "        # Override model variable by the stored average value on all devices.\n",
                "        for var, average_var in zip(\n",
                "            var_list, self._model_variables_moving_average\n",
                "        ):\n",
                "            strategy.extended.update(\n",
                "                var, lambda a, b: a.assign(b), args=(average_var,)\n",
                "            )\n",
                "\n",
                "    def _update_model_variables_moving_average(self, var_list):\n",
                "        \"\"\"Update the stored moving average using the latest value.\"\"\"\n",
                "        if self.use_ema:\n",
                "\n",
                "            def update_average(average, var):\n",
                "                average.assign(\n",
                "                    self.ema_momentum * average + (1 - self.ema_momentum) * var\n",
                "                )\n",
                "\n",
                "            for (var, average) in zip(\n",
                "                var_list, self._model_variables_moving_average\n",
                "            ):\n",
                "                self._distribution_strategy.extended.update(\n",
                "                    average, update_average, args=(var,), group=False\n",
                "                )\n",
                "\n",
                "    def _distributed_apply_gradients_fn(\n",
                "        self, distribution, grads_and_vars, **kwargs\n",
                "    ):\n",
                "        \"\"\"`apply_gradients` using a `DistributionStrategy`.\"\"\"\n",
                "\n",
                "        def apply_grad_to_update_var(var, grad):\n",
                "            if self.jit_compile:\n",
                "                return self._update_step_xla(grad, var, id(self._var_key(var)))\n",
                "            else:\n",
                "                return self._update_step(grad, var)\n",
                "\n",
                "        for grad, var in grads_and_vars:\n",
                "            distribution.extended.update(\n",
                "                var, apply_grad_to_update_var, args=(grad,), group=False\n",
                "            )\n",
                "        self.iterations.assign_add(1)\n",
                "\n",
                "        if self.use_ema:\n",
                "            _, var_list = zip(*grads_and_vars)\n",
                "            self._update_model_variables_moving_average(var_list)\n",
                "            if self.ema_overwrite_frequency:\n",
                "                # Only when self.ema_overwrite_frequency is not None, we\n",
                "                # overwrite the model variables.\n",
                "                should_overwrite_model_vars = (\n",
                "                    self.iterations % self.ema_overwrite_frequency == 0\n",
                "                )\n",
                "                tf.cond(\n",
                "                    tf.cast(should_overwrite_model_vars, tf.bool),\n",
                "                    true_fn=lambda: self._overwrite_model_variables_with_average_value(  # noqa: E501\n",
                "                        var_list\n",
                "                    ),\n",
                "                    false_fn=lambda: None,\n",
                "                )\n",
                "\n",
                "\n",
                "class RestoredOptimizer(Optimizer):\n",
                "    def __init__(self):\n",
                "        super().__init__(\"RestoredOptimizer\")\n",
                "\n",
                "    def get_config(self):\n",
                "        raise NotImplementedError(\n",
                "            \"Restoring functional Optimizers from SavedModels is not currently \"\n",
                "            \"supported. Please file a feature request if this limitation \"\n",
                "            \"bothers you.\"\n",
                "        )\n",
                "\n",
                "\n",
                "# Register the optimizer for loading from saved_model purpose.\n",
                "tf.__internal__.saved_model.load.register_revived_type(\n",
                "    \"experimentalOptimizer\",\n",
                "    lambda obj: isinstance(obj, Optimizer),\n",
                "    versions=[\n",
                "        tf.__internal__.saved_model.load.VersionedTypeRegistration(\n",
                "            object_factory=lambda proto: RestoredOptimizer(),\n",
                "            version=2,\n",
                "            min_producer_version=1,\n",
                "            min_consumer_version=1,\n",
                "        )\n",
                "    ],\n",
                ")\n",
                "\n",
                "Optimizer.__doc__ = Optimizer.__doc__.replace(\n",
                "    \"{{base_optimizer_keyword_args}}\", base_optimizer_keyword_args\n",
                ")"
            ]
        ],
        "keras/optimizers/optimizer_experimental/optimizer_test.py": [
            [
                "\"\"\"Tests for the reworked optimizer.\n",
                "\n",
                "More context in go/new-keras-optimizer\n",
                "\"\"\"\n",
                "\n",
                "import os\n",
                "import re\n",
                "\n",
                "import numpy as np\n",
                "import tensorflow.compat.v2 as tf\n",
                "from absl import logging\n",
                "from absl.testing import parameterized\n",
                "\n",
                "import keras\n",
                "from keras.optimizers.optimizer_experimental import adadelta as adadelta_new\n",
                "from keras.optimizers.optimizer_experimental import adagrad as adagrad_new\n",
                "from keras.optimizers.optimizer_experimental import adam as adam_new\n",
                "from keras.optimizers.optimizer_experimental import adamax as adamax_new\n",
                "from keras.optimizers.optimizer_experimental import adamw as adamw_new\n",
                "from keras.optimizers.optimizer_experimental import ftrl as ftrl_new\n",
                "from keras.optimizers.optimizer_experimental import nadam as nadam_new\n",
                "from keras.optimizers.optimizer_experimental import rmsprop as rmsprop_new\n",
                "from keras.optimizers.optimizer_experimental import sgd as sgd_new\n",
                "from keras.optimizers.optimizer_v2 import adadelta as adadelta_old\n",
                "from keras.optimizers.optimizer_v2 import adagrad as adagrad_old\n",
                "from keras.optimizers.optimizer_v2 import adam as adam_old\n",
                "from keras.optimizers.optimizer_v2 import ftrl as ftrl_old\n",
                "from keras.optimizers.optimizer_v2 import gradient_descent as sgd_old\n",
                "from keras.optimizers.optimizer_v2 import rmsprop as rmsprop_old\n",
                "from keras.optimizers.schedules import learning_rate_schedule\n",
                "from keras.utils import losses_utils\n",
                "\n",
                "ds_combinations = tf.__internal__.distribute.combinations\n",
                "\n",
                "STRATEGIES = [\n",
                "    # TODO(b/202992598): Add PSS strategy once the XLA issues is resolved.\n",
                "    ds_combinations.one_device_strategy,\n",
                "    ds_combinations.mirrored_strategy_with_cpu_1_and_2,\n",
                "    ds_combinations.mirrored_strategy_with_two_gpus,\n",
                "    ds_combinations.tpu_strategy,\n",
                "    ds_combinations.cloud_tpu_strategy,\n",
                "    ds_combinations.multi_worker_mirrored_2x1_cpu,\n",
                "    ds_combinations.multi_worker_mirrored_2x2_gpu,\n",
                "    ds_combinations.central_storage_strategy_with_two_gpus,\n",
                "]\n",
                "\n",
                "adadelta_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentaladadelta\",\n",
                "    lambda: adadelta_new.Adadelta(\n",
                "        0.002, use_ema=True, ema_overwrite_frequency=None\n",
                "    ),\n",
                ")\n",
                "adagrad_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentaladagrad\", lambda: adagrad_new.Adagrad(0.002)\n",
                ")\n",
                "adam_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentaladam\", lambda: adam_new.Adam(0.002)\n",
                ")\n",
                "adamax_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentaladamax\", lambda: adamax_new.Adamax(0.002)\n",
                ")\n",
                "adamw_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentaladamw\", lambda: adamw_new.AdamW(0.002, weight_decay=0.004)\n",
                ")\n",
                "ftrl_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentalftrl\", lambda: ftrl_new.Ftrl(0.002)\n",
                ")\n",
                "nadam_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentnadam\", lambda: nadam_new.Nadam(0.002)\n",
                ")\n",
                "rmsprop_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentalrmsprop\", lambda: rmsprop_new.RMSprop(0.002)\n",
                ")\n",
                "sgd_new_fn = tf.__internal__.test.combinations.NamedObject(\n",
                "    \"experimentalsgdaverage\",\n",
                "    lambda: sgd_new.SGD(0.002, use_ema=True, ema_overwrite_frequency=1),\n",
                ")\n",
                "\n",
                "OPTIMIZER_FN = [\n",
                "    adadelta_new_fn,\n",
                "    adagrad_new_fn,\n",
                "    adam_new_fn,\n",
                "    adamax_new_fn,\n",
                "    adamw_new_fn,\n",
                "    ftrl_new_fn,\n",
                "    nadam_new_fn,\n",
                "    rmsprop_new_fn,\n",
                "    sgd_new_fn,\n",
                "]\n",
                "\n",
                "\n",
                "class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n",
                "    \"\"\"Test the functionality of optimizer.\"\"\"\n",
                "\n",
                "    def testAddVariableFromReference(self):\n",
                "        optimizer = adam_new.Adam()\n",
                "        variable = optimizer.add_variable_from_reference(\n",
                "            tf.Variable(1.0, name=\"tmp\"), \"test\"\n",
                "        )\n",
                "        self.assertEqual(variable._shared_name, \"test/tmp\")\n",
                "        self.assertEqual(self.evaluate(variable), 0)\n",
                "\n",
                "    def testAddVarialeWithCustomShape(self):\n",
                "        optimizer = adam_new.Adam()\n",
                "        variable = optimizer.add_variable_from_reference(\n",
                "            tf.Variable([1.0, 2.0], name=\"tmp\"), \"test\", shape=[]\n",
                "        )\n",
                "        self.assertEqual(variable, tf.Variable(0.0))\n",
                "\n",
                "    def testBuildIndexDict(self):\n",
                "        optimizer = adam_new.Adam()\n",
                "        var_list = [tf.Variable(0, name=f\"var{i}\") for i in range(10)]\n",
                "        optimizer._build_index_dict(var_list)\n",
                "        self.assertEqual(\n",
                "            optimizer._index_dict[optimizer._var_key(var_list[7])], 7\n",
                "        )\n",
                "\n",
                "    def testClipNorm(self):\n",
                "        optimizer = adam_new.Adam(clipnorm=1)\n",
                "        grad = [tf.convert_to_tensor([100.0, 100.0])]\n",
                "        clipped_grad = optimizer._clip_gradients(grad)\n",
                "        self.assertAllClose(clipped_grad[0], [2**0.5 / 2, 2**0.5 / 2])\n",
                "\n",
                "    def testClipValue(self):\n",
                "        optimizer = adam_new.Adam(clipvalue=1)\n",
                "        grad = [tf.convert_to_tensor([100.0, 100.0])]\n",
                "        clipped_grad = optimizer._clip_gradients(grad)\n",
                "        self.assertAllEqual(clipped_grad[0], [1.0, 1.0])\n",
                "\n",
                "    def testWeightDecay(self):\n",
                "        grads, var1, var2, var3 = (\n",
                "            tf.zeros(()),\n",
                "            tf.Variable(2.0),\n",
                "            tf.Variable(2.0, name=\"exclude\"),\n",
                "            tf.Variable(2.0),\n",
                "        )\n",
                "        optimizer_1 = adamw_new.AdamW(learning_rate=1, weight_decay=0.004)\n",
                "        optimizer_1.apply_gradients(zip([grads], [var1]))\n",
                "\n",
                "        optimizer_2 = adamw_new.AdamW(learning_rate=1, weight_decay=0.004)\n",
                "        optimizer_2.exclude_from_weight_decay(var_names=[\"exclude\"])\n",
                "        optimizer_2.apply_gradients(zip([grads], [var2]))\n",
                "\n",
                "        optimizer_3 = adamw_new.AdamW(learning_rate=1, weight_decay=0.004)\n",
                "        optimizer_3.exclude_from_weight_decay(var_list=[var3])\n",
                "        optimizer_3.apply_gradients(zip([grads], [var3]))\n",
                "\n",
                "        self.assertEqual(var1, 1.992)\n",
                "        self.assertEqual(var2, 2.0)\n",
                "        self.assertEqual(var3, 2.0)\n",
                "\n",
                "    def testClipGlobalNorm(self):\n",
                "        optimizer = adam_new.Adam(global_clipnorm=1)\n",
                "        grad = [\n",
                "            tf.cast([100.0, 100.0], dtype=tf.float32),\n",
                "            tf.cast([100.0, 100.0], dtype=tf.float32),\n",
                "        ]\n",
                "        clipped_grad = optimizer._clip_gradients(grad)\n",
                "        self.assertAllClose(clipped_grad[0], [0.5, 0.5])\n",
                "\n",
                "    def testPassingLegacyArgsRaiseWarning(self):\n",
                "        with self.assertLogs(level=\"WARNING\") as log_output:\n",
                "            logging.set_verbosity(logging.WARNING)\n",
                "            _ = adam_new.Adam(clipnorm=1, decay=0.5)\n",
                "            expected_log = \"decay is deprecated in\"\n",
                "            output = log_output[0][0].message\n",
                "\n",
                "            self.assertTrue(re.search(expected_log, output))\n",
                "\n",
                "    def testPassingLegacyClipnorm(self):\n",
                "        optimizer = adam_new.Adam(clipnorm=1)\n",
                "        self.assertEqual(optimizer.clipnorm, 1)\n",
                "\n",
                "    def testReturnAllOptimizerVariables(self):\n",
                "        x = tf.Variable([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n",
                "        optimizer = adam_new.Adam()\n",
                "        grads = tf.convert_to_tensor([[1.0, 2.0], [3.0, 4.0]])\n",
                "        optimizer.apply_gradients(zip([grads], [x]))\n",
                "        optimizer_variables = optimizer.variables()\n",
                "        all_names = [var._shared_name for var in optimizer_variables]\n",
                "        self.assertLen(optimizer_variables, 2)\n",
                "        self.assertCountEqual(\n",
                "            all_names,\n",
                "            [\n",
                "                \"Adam/m/Variable\",\n",
                "                \"Adam/v/Variable\",\n",
                "            ],\n",
                "        )\n",
                "\n",
                "    def testSetLearningRate(self):\n",
                "        optimizer = adam_new.Adam(learning_rate=1.0)\n",
                "        self.assertIsInstance(optimizer._learning_rate, tf.Variable)\n",
                "        self.assertEqual(self.evaluate(optimizer.learning_rate), 1.0)\n",
                "        optimizer.learning_rate = 2.0\n",
                "        self.assertEqual(self.evaluate(optimizer.learning_rate), 2.0)\n",
                "        # Test the legacy setter.\n",
                "        optimizer.lr = 3.0\n",
                "        self.assertEqual(self.evaluate(optimizer.learning_rate), 3.0)\n",
                "\n",
                "        lr_schedule = learning_rate_schedule.ExponentialDecay(\n",
                "            initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n",
                "        )\n",
                "        optimizer = adam_new.Adam(learning_rate=lr_schedule)\n",
                "        self.assertIsInstance(\n",
                "            optimizer._learning_rate, learning_rate_schedule.ExponentialDecay\n",
                "        )\n",
                "        self.assertEqual(optimizer.learning_rate, 0.01)\n",
                "        # Test the legacy property.\n",
                "        self.assertEqual(optimizer.lr, 0.01)\n",
                "\n",
                "        x = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "        grads = tf.convert_to_tensor([1.0, 2.0])\n",
                "        for _ in range(2):\n",
                "            optimizer.apply_gradients(zip([grads], [x]))\n",
                "        self.assertTrue(\n",
                "            optimizer.learning_rate < 0.01 and optimizer.learning_rate > 0.00999\n",
                "        )\n",
                "        # Check it does not throw error to set `learning_rate` by a\n",
                "        # LearningRateScheduler instance.\n",
                "        optimizer.learning_rate = learning_rate_schedule.ExponentialDecay(\n",
                "            initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n",
                "        )\n",
                "        with self.assertRaisesRegex(\n",
                "            TypeError, \"This optimizer was created with*\"\n",
                "        ):\n",
                "            optimizer.learning_rate = 2.0\n",
                "\n",
                "    def testSetIterations(self):\n",
                "        optimizer = adam_new.Adam(jit_compile=False)\n",
                "        optimizer.iterations = tf.Variable(2, dtype=tf.int32)\n",
                "        self.assertEqual(optimizer.iterations, 2)\n",
                "        var_list = [tf.Variable(2.0), tf.Variable(2.0)]\n",
                "        grads = tf.convert_to_tensor([1.0, 1.0])\n",
                "        optimizer.apply_gradients(zip(grads, var_list))\n",
                "        self.assertEqual(optimizer.iterations, 3)\n",
                "        with self.assertRaisesRegex(RuntimeError, \"Cannot set*\"):\n",
                "            optimizer.iterations = 2\n",
                "\n",
                "    def testNoGradients(self):\n",
                "        optimizer = adam_new.Adam(jit_compile=False)\n",
                "        optimizer.apply_gradients(zip([], []))\n",
                "\n",
                "    def testPassingMissingWDError(self):\n",
                "        with self.assertRaises(ValueError):\n",
                "            _ = adamw_new.AdamW(0.01, weight_decay=None)\n",
                "\n",
                "        with self.assertRaisesRegex(ValueError, \"Missing value of\"):\n",
                "            _ = adamw_new.AdamW(0.01, weight_decay=None)\n",
                "\n",
                "    def testMovingAverageOptimizer(self):\n",
                "        optimizer = sgd_new.SGD(\n",
                "            learning_rate=1,\n",
                "            use_ema=True,\n",
                "            ema_momentum=0.5,\n",
                "            ema_overwrite_frequency=3,\n",
                "        )\n",
                "\n",
                "        var1, var2 = tf.Variable(2.0), tf.Variable(2.0)\n",
                "        with tf.GradientTape() as tape:\n",
                "            loss = var1 + var2\n",
                "        grads = tape.gradient(loss, [var1, var2])\n",
                "        # First iteration: [var1, var2] = [1.0, 1.0]\n",
                "        optimizer.apply_gradients(zip(grads, [var1, var2]))\n",
                "        self.assertAllEqual([var1.numpy(), var2.numpy()], [1.0, 1.0])\n",
                "\n",
                "        # Second iteration: [var1, var2] = [0.0, 0.0]\n",
                "        optimizer.apply_gradients(zip(grads, [var1, var2]))\n",
                "        self.assertAllEqual([var1.numpy(), var2.numpy()], [0.0, 0.0])\n",
                "\n",
                "        # Third iteration, without EMA, we should see [var1, var2] = [-1.0,\n",
                "        # -1.0], but overwriting results in [var1, var2] = [-0.125, -0.125].\n",
                "        optimizer.apply_gradients(zip(grads, [var1, var2]))\n",
                "        self.assertAllEqual([var1.numpy(), var2.numpy()], [-0.125, -0.125])\n",
                "\n",
                "    def testGetAndFromConfig(self):\n",
                "        optimizer = adam_new.Adam(\n",
                "            learning_rate=np.float64(0.05),\n",
                "            beta_1=0.7,\n",
                "            beta_2=0.77,\n",
                "            amsgrad=True,\n",
                "            epsilon=0.001,\n",
                "            clipnorm=0.5,\n",
                "            use_ema=True,\n",
                "            ema_momentum=0.5,\n",
                "            ema_overwrite_frequency=50,\n",
                "        )\n",
                "        config = optimizer.get_config()\n",
                "        expected_config = {\n",
                "            \"learning_rate\": np.float32(0.05),\n",
                "            \"beta_1\": 0.7,\n",
                "            \"beta_2\": 0.77,\n",
                "            \"epsilon\": 0.001,\n",
                "            \"amsgrad\": True,\n",
                "            \"clipnorm\": 0.5,\n",
                "            \"global_clipnorm\": None,\n",
                "            \"clipvalue\": None,\n",
                "            \"use_ema\": True,\n",
                "            \"ema_momentum\": 0.5,\n",
                "            \"ema_overwrite_frequency\": 50,\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "            \"is_legacy_optimizer\": False,\n"
                ],
                "parent_version_range": {
                    "start": 299,
                    "end": 299
                },
                "child_version_range": {
                    "start": 299,
                    "end": 300
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "OptimizerFuntionalityTest",
                        "signature": "class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):",
                        "at_line": 91
                    },
                    {
                        "type": "function",
                        "name": "testGetAndFromConfig",
                        "signature": "def testGetAndFromConfig(self):",
                        "at_line": 274
                    }
                ],
                "idx": 6,
                "hunk_diff": "File: keras/optimizers/optimizer_experimental/optimizer_test.py\nCode:\n           class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n               ...\n               def testGetAndFromConfig(self):\n                   ...\n296 296                \"use_ema\": True,\n297 297                \"ema_momentum\": 0.5,\n298 298                \"ema_overwrite_frequency\": 50,\n    299  +             \"is_legacy_optimizer\": False,\n299 300            }\n300 301            self.assertDictContainsSubset(expected_config, config)\n301 302            restored_optimizer = adam_new.Adam.from_config(config)\n         ...\n",
                "file_path": "keras/optimizers/optimizer_experimental/optimizer_test.py",
                "identifiers_before": [],
                "identifiers_after": [],
                "prefix": [
                    "            \"use_ema\": True,\n",
                    "            \"ema_momentum\": 0.5,\n",
                    "            \"ema_overwrite_frequency\": 50,\n"
                ],
                "suffix": [
                    "        }\n",
                    "        self.assertDictContainsSubset(expected_config, config)\n",
                    "        restored_optimizer = adam_new.Adam.from_config(config)\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    4
                ]
            },
            [
                "        }\n",
                "        self.assertDictContainsSubset(expected_config, config)\n",
                "        restored_optimizer = adam_new.Adam.from_config(config)\n",
                "        self.assertDictEqual(\n",
                "            restored_optimizer.get_config(), optimizer.get_config()\n",
                "        )\n",
                "\n",
                "    def testCheckpointOptimizer(self):\n",
                "        x = tf.Variable([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n",
                "        lr_schedule = learning_rate_schedule.ExponentialDecay(\n",
                "            initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n",
                "        )\n",
                "        optimizer_1 = adam_new.Adam(\n",
                "            learning_rate=lr_schedule, beta_1=0.8, beta_2=0.888\n",
                "        )\n",
                "        grads = tf.convert_to_tensor([[1.0, 2.0], [3.0, 4.0]])\n",
                "\n",
                "        for _ in range(1):\n",
                "            optimizer_1.apply_gradients(zip([grads], [x]))\n",
                "\n",
                "        # Then save the variable and optimizer to a checkpoint.\n",
                "        checkpoint_1 = tf.train.Checkpoint(var=x, optimizer=optimizer_1)\n",
                "        checkpoint_path = checkpoint_1.save(self.get_temp_dir())\n",
                "\n",
                "        # Create a new optimizer and call restore on it (and x)\n",
                "        x2 = tf.Variable([[0.0, 0.0], [0.0, 0.0]], dtype=x.dtype)\n",
                "        optimizer_2 = adam_new.Adam(\n",
                "            learning_rate=0.02, beta_1=0.7, beta_2=0.777\n",
                "        )\n",
                "        optimizer_2.build([x2])\n",
                "        checkpoint_2 = tf.train.Checkpoint(var=x2, optimizer=optimizer_2)\n",
                "        checkpoint_2.restore(checkpoint_path)\n",
                "\n",
                "        self.assertTrue(\n",
                "            (\n",
                "                self.evaluate(optimizer_1._momentums._storage[0])\n",
                "                == self.evaluate(optimizer_2._momentums._storage[0])\n",
                "            ).all()\n",
                "        )\n",
                "        self.assertEqual(\n",
                "            self.evaluate(optimizer_1._iterations),\n",
                "            self.evaluate(optimizer_2._iterations),\n",
                "        )\n",
                "\n",
                "    def testCheckpointOptimizerWithModel(self):\n",
                "        inputs = keras.layers.Input(shape=(1,))\n",
                "        outputs = keras.layers.Dense(1)(inputs)\n",
                "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
                "        optimizer = adamax_new_fn()\n",
                "        x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n",
                "        y = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n",
                "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
                "        path = os.path.join(self.get_temp_dir(), \"ckpt\")\n",
                "        checkpoint_callback = keras.callbacks.ModelCheckpoint(path)\n",
                "        model.fit(x, y, callbacks=[checkpoint_callback])\n",
                "\n",
                "        new_model = keras.Model(inputs=inputs, outputs=outputs)\n",
                "        new_optimizer = adamax_new_fn()\n",
                "        new_model.compile(loss=\"mse\", optimizer=new_optimizer)\n",
                "        new_model.load_weights(path)\n",
                "        self.assertEqual(\n",
                "            new_model.optimizer.iterations.numpy(),\n",
                "            model.optimizer.iterations.numpy(),\n",
                "        )\n",
                "\n",
                "    @parameterized.product(optimizer_fn=OPTIMIZER_FN)\n",
                "    def testSaveAndLoadOptimizerWithModel(self, optimizer_fn):\n",
                "        inputs = keras.layers.Input(shape=(1,))\n",
                "        outputs = keras.layers.Dense(1)(inputs)\n",
                "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
                "        optimizer = optimizer_fn()\n",
                "        optimizer.clipnorm = 0.1\n",
                "        x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n",
                "        y = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n",
                "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
                "        model.fit(x, y)\n",
                "\n",
                "        # Save in h5 format.\n",
                "        path = os.path.join(self.get_temp_dir(), \"model.h5\")\n",
                "        model.save(path)\n",
                "        loaded_model = keras.models.load_model(path)\n",
                "        loaded_model.load_weights(path)\n",
                "        loaded_optimizer = loaded_model.optimizer\n",
                "        self.assertEqual(type(optimizer), type(loaded_optimizer))\n",
                "        self.assertEqual(loaded_optimizer.learning_rate, 0.002)\n",
                "        self.assertEqual(loaded_optimizer.clipnorm, 0.1)\n",
                "\n",
                "        # Save in Keras SavedModel format.\n",
                "        model.fit(x, y)\n",
                "        path = os.path.join(self.get_temp_dir(), \"model\")\n",
                "        model.save(path)\n",
                "        loaded_model = keras.models.load_model(path)\n",
                "        loaded_model.load_weights(path)\n",
                "        loaded_optimizer = loaded_model.optimizer\n",
                "        self.assertEqual(type(optimizer), type(loaded_optimizer))\n",
                "        self.assertEqual(loaded_optimizer.learning_rate, 0.002)\n",
                "        self.assertEqual(loaded_optimizer.clipnorm, 0.1)\n",
                "\n",
                "    @parameterized.product(optimizer_fn=OPTIMIZER_FN)\n",
                "    def testSparseGradientsWorkAsExpected(self, optimizer_fn):\n",
                "        optimizer_1 = optimizer_fn()\n",
                "        optimizer_2 = optimizer_fn()\n",
                "        x1 = tf.Variable(np.ones([5]), dtype=tf.float64)\n",
                "        x2 = tf.Variable(np.ones([5]), dtype=tf.float64)\n",
                "        grads = tf.convert_to_tensor([0, 1.0, 1.5, 0, 0], dtype=tf.float64)\n",
                "        sparse_grads = tf.IndexedSlices(\n",
                "            tf.convert_to_tensor([1.0, 1.5], dtype=tf.float64),\n",
                "            tf.convert_to_tensor([1, 2]),\n",
                "            dense_shape=tf.convert_to_tensor([len(grads)]),\n",
                "        )\n",
                "        for _ in range(5):\n",
                "            optimizer_1.apply_gradients(zip([grads], [x1]))\n",
                "            optimizer_2.apply_gradients(zip([sparse_grads], [x2]))\n",
                "            self.assertAllClose(x1, x2)\n",
                "\n",
                "\n",
                "class OptimizerRegressionTest(tf.test.TestCase, parameterized.TestCase):\n",
                "    \"\"\"Test optimizer outputs the same numerical results as optimizer_v2.\"\"\"\n",
                "\n",
                "    def _compare_numerical(self, old_optimizer, new_optimizer):\n",
                "        x1 = tf.Variable(np.ones([10]), dtype=tf.float64)\n",
                "        x2 = tf.Variable(np.ones([10]), dtype=tf.float64)\n",
                "        grads = tf.convert_to_tensor(np.arange(0.1, 1.1, 0.1))\n",
                "        sparse_grads = tf.IndexedSlices(\n",
                "            tf.convert_to_tensor([0, 0.2, 0.4, 0.8, 0.8], dtype=tf.float64),\n",
                "            tf.convert_to_tensor([0, 2, 4, 6, 6]),\n",
                "            dense_shape=tf.convert_to_tensor([len(grads)]),\n",
                "        )\n",
                "\n",
                "        for _ in range(5):\n",
                "            self.assertAllClose(x1, x2)\n",
                "            old_optimizer.apply_gradients(zip([grads], [x1]))\n",
                "            new_optimizer.apply_gradients(zip([grads], [x2]))\n",
                "\n",
                "        for _ in range(5):\n",
                "            self.assertAllClose(x1, x2)\n",
                "            old_optimizer.apply_gradients(zip([sparse_grads], [x1]))\n",
                "            new_optimizer.apply_gradients(zip([sparse_grads], [x2]))\n",
                "\n",
                "    def testAdam(self):\n",
                "        self._compare_numerical(\n",
                "            adam_old.Adam(amsgrad=True), adam_new.Adam(amsgrad=True)\n",
                "        )\n",
                "\n",
                "    def testAdadelta(self):\n",
                "        self._compare_numerical(\n",
                "            adadelta_old.Adadelta(), adadelta_new.Adadelta()\n",
                "        )\n",
                "\n",
                "    def testAdagrad(self):\n",
                "        self._compare_numerical(adagrad_old.Adagrad(), adagrad_new.Adagrad())\n",
                "\n",
                "    def testFtrl(self):\n",
                "        self._compare_numerical(ftrl_old.Ftrl(), ftrl_new.Ftrl())\n",
                "\n",
                "    def testRMSprop(self):\n",
                "        self._compare_numerical(rmsprop_old.RMSprop(), rmsprop_new.RMSprop())\n",
                "\n",
                "    @parameterized.product(nesterov=[True, False])\n",
                "    def testSgd(self, nesterov):\n",
                "        self._compare_numerical(\n",
                "            sgd_old.SGD(nesterov=nesterov), sgd_new.SGD(nesterov=nesterov)\n",
                "        )\n",
                "\n",
                "\n",
                "class DistributedTrainingTest(tf.test.TestCase, parameterized.TestCase):\n",
                "    @ds_combinations.generate(\n",
                "        tf.__internal__.test.combinations.combine(\n",
                "            strategy=STRATEGIES, optimizer_fn=OPTIMIZER_FN\n",
                "        )\n",
                "    )\n",
                "    def testGetGradientsInModel(self, strategy, optimizer_fn):\n",
                "        with strategy.scope():\n",
                "            model = keras.Sequential(\n",
                "                [keras.layers.Input(shape=(1,)), keras.layers.Dense(1)]\n",
                "            )\n",
                "            optimizer = optimizer_fn()\n",
                "            x = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n",
                "            y = tf.expand_dims(tf.convert_to_tensor([1, 1, 1, 0, 0, 0]), axis=1)\n",
                "            model.compile(loss=\"mse\", optimizer=optimizer)\n",
                "        model.fit(x, y, epochs=1, steps_per_epoch=5)\n",
                "        if optimizer.name == \"Adam\":\n",
                "            # Assert the momentum variable is not 0.\n",
                "            self.assertNotEqual(\n",
                "                self.evaluate(optimizer._momentums._storage[0]), 0\n",
                "            )\n",
                "        elif optimizer.name == \"Adadelta\":\n",
                "            # Assert the accumulated variable is not 0.\n",
                "            self.assertNotEqual(\n",
                "                self.evaluate(optimizer._accumulated_grads._storage[0]), 0\n",
                "            )\n",
                "        elif optimizer.name == \"Adagrad\":\n",
                "            # Assert the accumulated variable is not 0.\n",
                "            self.assertNotEqual(\n",
                "                self.evaluate(optimizer._accumulators._storage[0]), 0\n",
                "            )\n",
                "\n",
                "    @ds_combinations.generate(\n",
                "        tf.__internal__.test.combinations.combine(\n",
                "            strategy=STRATEGIES, optimizer_fn=OPTIMIZER_FN\n",
                "        )\n",
                "    )\n",
                "    def testGetGradientsInCustomTrainingLoop(self, strategy, optimizer_fn):\n",
                "        with strategy.scope():\n",
                "            model = keras.Sequential(\n",
                "                [keras.layers.Input(shape=(1,)), keras.layers.Dense(1)]\n",
                "            )\n",
                "            optimizer = optimizer_fn()\n",
                "\n",
                "            def per_worker_dataset_fn():\n",
                "                def dataset_fn(_):\n",
                "                    x, y = [1, 1, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0]\n",
                "                    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
                "                    ds = ds.repeat().batch(6)\n",
                "                    return ds\n",
                "\n",
                "                return strategy.distribute_datasets_from_function(dataset_fn)\n",
                "\n",
                "            ds = per_worker_dataset_fn()\n",
                "\n",
                "            @tf.function\n",
                "            def train_step(ds):\n",
                "                def replica_fn(data):\n",
                "                    features, labels = data\n",
                "                    with tf.GradientTape() as tape:\n",
                "                        output = model(tf.expand_dims(features, axis=1))\n",
                "                        loss = keras.losses.MeanSquaredError(\n",
                "                            reduction=losses_utils.ReductionV2.NONE\n",
                "                        )(labels, output)\n",
                "                    grads = tape.gradient(loss, model.trainable_variables)\n",
                "                    optimizer.apply_gradients(\n",
                "                        zip(grads, model.trainable_variables)\n",
                "                    )\n",
                "\n",
                "                strategy.run(replica_fn, args=(next(iter(ds)),))\n",
                "\n",
                "            for _ in range(3):\n",
                "                train_step(ds)\n",
                "        self.assertEqual(self.evaluate(optimizer.iterations), 3)\n",
                "\n",
                "    @ds_combinations.generate(\n",
                "        tf.__internal__.test.combinations.combine(\n",
                "            strategy=[\n",
                "                ds_combinations.mirrored_strategy_with_two_gpus,\n",
                "                ds_combinations.tpu_strategy,\n",
                "                ds_combinations.multi_worker_mirrored_2x2_gpu,\n",
                "                ds_combinations.central_storage_strategy_with_two_gpus,\n",
                "            ]\n",
                "        )\n",
                "    )\n",
                "    def testJitCompile(self, strategy):\n",
                "        # Test the optimizer yields same numerical results when jit_compile is\n",
                "        # on and off.\n",
                "        with strategy.scope():\n",
                "            optimizer_1 = adam_new.Adam(\n",
                "                jit_compile=False, use_ema=True, ema_overwrite_frequency=1\n",
                "            )\n",
                "            optimizer_2 = adam_new.Adam(\n",
                "                jit_compile=True, use_ema=True, ema_overwrite_frequency=1\n",
                "            )\n",
                "            model_1 = keras.Sequential(\n",
                "                [\n",
                "                    keras.layers.Input(shape=(2,)),\n",
                "                    keras.layers.Dense(5),\n",
                "                    keras.layers.Dense(1),\n",
                "                ]\n",
                "            )\n",
                "            model_2 = keras.models.clone_model(model_1)\n",
                "            model_2.set_weights(model_1.get_weights())\n",
                "\n",
                "            def per_worker_dataset_fn():\n",
                "                def dataset_fn(_):\n",
                "                    x = np.random.rand(6, 2)\n",
                "                    y = [1, 1, 1, 0, 0, 0]\n",
                "                    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
                "                    ds = ds.repeat().batch(6)\n",
                "                    return ds\n",
                "\n",
                "                return strategy.distribute_datasets_from_function(dataset_fn)\n",
                "\n",
                "            ds = per_worker_dataset_fn()\n",
                "\n",
                "            @tf.function\n",
                "            def train_step(ds):\n",
                "                def replica_fn(data):\n",
                "                    features, labels = data\n",
                "                    with tf.GradientTape() as tape:\n",
                "                        output_1 = model_1(features)\n",
                "                        loss_1 = keras.losses.MeanSquaredError(\n",
                "                            reduction=losses_utils.ReductionV2.NONE\n",
                "                        )(labels, output_1)\n",
                "                    grads_1 = tape.gradient(loss_1, model_1.trainable_variables)\n",
                "                    optimizer_1.apply_gradients(\n",
                "                        zip(grads_1, model_1.trainable_variables)\n",
                "                    )\n",
                "\n",
                "                    with tf.GradientTape() as tape:\n",
                "                        output_2 = model_2(features)\n",
                "                        loss_2 = keras.losses.MeanSquaredError(\n",
                "                            reduction=losses_utils.ReductionV2.NONE\n",
                "                        )(labels, output_2)\n",
                "                    grads_2 = tape.gradient(loss_2, model_2.trainable_variables)\n",
                "                    optimizer_2.apply_gradients(\n",
                "                        zip(grads_2, model_2.trainable_variables)\n",
                "                    )\n",
                "\n",
                "                strategy.run(replica_fn, args=(next(iter(ds)),))\n",
                "\n",
                "            for _ in range(3):\n",
                "                train_step(ds)\n",
                "                self.assertAllClose(\n",
                "                    model_1.trainable_variables[0][0],\n",
                "                    model_2.trainable_variables[0][0],\n",
                "                )\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    tf.__internal__.distribute.multi_process_runner.test_main()"
            ]
        ],
        "keras/optimizers/optimizer_v1.py": [
            [
                "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\n",
                "\n",
                "\"\"\"Legacy v1 optimizer classes.\n",
                "\n",
                "For more examples see the base class `tf.compat.v1.keras.optimizers.Optimizer`.\n",
                "\"\"\"\n",
                "\n",
                "import tensorflow.compat.v2 as tf\n",
                "\n",
                "from keras import backend\n",
                "\n",
                "\n",
                "class Optimizer:\n",
                "    \"\"\"Abstract optimizer base class.\n",
                "\n",
                "    Note: this is the parent class of all optimizers, not an actual optimizer\n",
                "    that can be used for training models.\n",
                "\n",
                "    All Keras optimizers support the following keyword arguments:\n",
                "\n",
                "        clipnorm: float >= 0. Gradients will be clipped\n",
                "            when their L2 norm exceeds this value.\n",
                "        clipvalue: float >= 0. Gradients will be clipped\n",
                "            when their absolute value exceeds this value.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, **kwargs):\n",
                "        allowed_kwargs = {\"clipnorm\", \"clipvalue\"}\n",
                "        for k in kwargs:\n",
                "            if k not in allowed_kwargs:\n",
                "                raise TypeError(\n",
                "                    \"Unexpected keyword argument \"\n",
                "                    \"passed to optimizer: \" + str(k)\n",
                "                )\n",
                "            # checks that clipnorm >= 0 and clipvalue >= 0\n",
                "            if kwargs[k] < 0:\n",
                "                raise ValueError(f\"Expected {k} >= 0, received: {kwargs[k]}\")\n",
                "        self.__dict__.update(kwargs)\n",
                "        self.updates = []\n",
                "        self.weights = []\n",
                "\n",
                "    # Set this to False, indicating `apply_gradients` does not take the\n",
                "    # `experimental_aggregate_gradients` argument.\n",
                "    _HAS_AGGREGATE_GRAD = False\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        \"\"\"Creates and sets all optimizer weights.\n",
                "\n",
                "        Args:\n",
                "          params: list or tuple of `Variable` objects that will be minimized\n",
                "            using this optimizer.\n",
                "\n",
                "        Returns:\n",
                "          Specific weight values that are used in `get_updates`\n",
                "        \"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        raise NotImplementedError\n",
                "\n",
                "    def get_gradients(self, loss, params):\n",
                "        \"\"\"Returns gradients of `loss` with respect to `params`.\n",
                "\n",
                "        Args:\n",
                "            loss: Loss tensor.\n",
                "            params: List of variables.\n",
                "\n",
                "        Returns:\n",
                "            List of gradient tensors.\n",
                "\n",
                "        Raises:\n",
                "            ValueError: In case any gradient cannot be computed (e.g. if\n",
                "              gradient function not implemented).\n",
                "        \"\"\"\n",
                "        grads = backend.gradients(loss, params)\n",
                "        if any(g is None for g in grads):\n",
                "            raise ValueError(\n",
                "                \"An operation has `None` for gradient. \"\n",
                "                \"Please make sure that all of your ops have a \"\n",
                "                \"gradient defined (i.e. are differentiable). \"\n",
                "                \"Common ops without gradient: \"\n",
                "                \"backend.argmax, backend.round, backend.eval.\"\n",
                "            )\n",
                "        if hasattr(self, \"clipnorm\"):\n",
                "            grads = [tf.clip_by_norm(g, self.clipnorm) for g in grads]\n",
                "        if hasattr(self, \"clipvalue\"):\n",
                "            grads = [\n",
                "                tf.clip_by_value(g, -self.clipvalue, self.clipvalue)\n",
                "                for g in grads\n",
                "            ]\n",
                "        return grads\n",
                "\n",
                "    def set_weights(self, weights):\n",
                "        \"\"\"Sets the weights of the optimizer, from Numpy arrays.\n",
                "\n",
                "        Should only be called after computing the gradients\n",
                "        (otherwise the optimizer has no weights).\n",
                "\n",
                "        Args:\n",
                "            weights: a list of Numpy arrays. The number of arrays and their\n",
                "              shape must match number of the dimensions of the weights of the\n",
                "              optimizer (i.e. it should match the output of `get_weights`).\n",
                "\n",
                "        Raises:\n",
                "            ValueError: in case of incompatible weight shapes.\n",
                "        \"\"\"\n",
                "        params = self.weights\n",
                "        if len(params) != len(weights):\n",
                "            raise ValueError(\n",
                "                \"Length of the specified weight list (\"\n",
                "                + str(len(weights))\n",
                "                + \") does not match the number of weights \"\n",
                "                \"of the optimizer (\" + str(len(params)) + \")\"\n",
                "            )\n",
                "        weight_value_tuples = []\n",
                "        param_values = backend.batch_get_value(params)\n",
                "        for pv, p, w in zip(param_values, params, weights):\n",
                "            if pv.shape != w.shape:\n",
                "                raise ValueError(\n",
                "                    \"Optimizer weight shape \"\n",
                "                    + str(pv.shape)\n",
                "                    + \" not compatible with \"\n",
                "                    \"provided weight shape \" + str(w.shape)\n",
                "                )\n",
                "            weight_value_tuples.append((p, w))\n",
                "        backend.batch_set_value(weight_value_tuples)\n",
                "\n",
                "    def get_weights(self):\n",
                "        \"\"\"Returns the current value of the weights of the optimizer.\n",
                "\n",
                "        Returns:\n",
                "            A list of numpy arrays.\n",
                "        \"\"\"\n",
                "        return backend.batch_get_value(self.weights)\n",
                "\n",
                "    def get_config(self):\n"
            ],
            {
                "type": "replace",
                "before": [
                    "        config = {}\n"
                ],
                "after": [
                    "        config = {\"is_legacy_optimizer\": True}\n"
                ],
                "parent_version_range": {
                    "start": 150,
                    "end": 151
                },
                "child_version_range": {
                    "start": 150,
                    "end": 151
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "Optimizer",
                        "signature": "class Optimizer:",
                        "at_line": 26
                    },
                    {
                        "type": "function",
                        "name": "get_config",
                        "signature": "def get_config(self):",
                        "at_line": 149
                    }
                ],
                "idx": 7,
                "hunk_diff": "File: keras/optimizers/optimizer_v1.py\nCode:\n           class Optimizer:\n               ...\n147 147            return backend.batch_get_value(self.weights)\n148 148    \n149 149        def get_config(self):\n150      -         config = {}\n    150  +         config = {\"is_legacy_optimizer\": True}\n151 151            if hasattr(self, \"clipnorm\"):\n152 152                config[\"clipnorm\"] = self.clipnorm\n153 153            if hasattr(self, \"clipvalue\"):\n         ...\n",
                "file_path": "keras/optimizers/optimizer_v1.py",
                "identifiers_before": [
                    "config"
                ],
                "identifiers_after": [
                    "config"
                ],
                "prefix": [
                    "        return backend.batch_get_value(self.weights)\n",
                    "\n",
                    "    def get_config(self):\n"
                ],
                "suffix": [
                    "        if hasattr(self, \"clipnorm\"):\n",
                    "            config[\"clipnorm\"] = self.clipnorm\n",
                    "        if hasattr(self, \"clipvalue\"):\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "        if hasattr(self, \"clipnorm\"):\n",
                "            config[\"clipnorm\"] = self.clipnorm\n",
                "        if hasattr(self, \"clipvalue\"):\n",
                "            config[\"clipvalue\"] = self.clipvalue\n",
                "        return config\n",
                "\n",
                "    @classmethod\n",
                "    def from_config(cls, config):\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "        if \"is_legacy_optimizer\" in config:\n",
                    "            del config[\"is_legacy_optimizer\"]\n"
                ],
                "parent_version_range": {
                    "start": 159,
                    "end": 159
                },
                "child_version_range": {
                    "start": 159,
                    "end": 161
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "Optimizer",
                        "signature": "class Optimizer:",
                        "at_line": 26
                    },
                    {
                        "type": "function",
                        "name": "from_config",
                        "signature": "def from_config(cls, config):",
                        "at_line": 158
                    }
                ],
                "idx": 8,
                "hunk_diff": "File: keras/optimizers/optimizer_v1.py\nCode:\n           class Optimizer:\n               ...\n156 156    \n157 157        @classmethod\n158 158        def from_config(cls, config):\n    159  +         if \"is_legacy_optimizer\" in config:\n    160  +             del config[\"is_legacy_optimizer\"]\n159 161            return cls(**config)\n160 162    \n161 163    \n         ...\n",
                "file_path": "keras/optimizers/optimizer_v1.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "config"
                ],
                "prefix": [
                    "\n",
                    "    @classmethod\n",
                    "    def from_config(cls, config):\n"
                ],
                "suffix": [
                    "        return cls(**config)\n",
                    "\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    5,
                    9,
                    11
                ]
            },
            [
                "        return cls(**config)\n",
                "\n",
                "\n",
                "class SGD(Optimizer):\n",
                "    \"\"\"Stochastic gradient descent optimizer.\n",
                "\n",
                "    Includes support for momentum,\n",
                "    learning rate decay, and Nesterov momentum.\n",
                "\n",
                "    Args:\n",
                "        lr: float >= 0. Learning rate.\n",
                "        momentum: float >= 0. Parameter that accelerates SGD in the relevant\n",
                "          direction and dampens oscillations.\n",
                "        decay: float >= 0. Learning rate decay over each update.\n",
                "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self, lr=0.01, momentum=0.0, decay=0.0, nesterov=False, **kwargs\n",
                "    ):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.momentum = backend.variable(momentum, name=\"momentum\")\n",
                "            self.decay = backend.variable(decay, name=\"decay\")\n",
                "        self.initial_decay = decay\n",
                "        self.nesterov = nesterov\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        shapes = [backend.int_shape(p) for p in params]\n",
                "        moments = [backend.zeros(shape) for shape in shapes]\n",
                "        self.weights = [self.iterations] + moments\n",
                "        return moments\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        self.updates = [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "\n",
                "        lr = self.lr\n",
                "        if self.initial_decay > 0:\n",
                "            lr = lr * (\n",
                "                1.0\n",
                "                / (\n",
                "                    1.0\n",
                "                    + self.decay\n",
                "                    * tf.cast(self.iterations, backend.dtype(self.decay))\n",
                "                )\n",
                "            )\n",
                "        # momentum\n",
                "        moments = self._create_all_weights(params)\n",
                "        for p, g, m in zip(params, grads, moments):\n",
                "            v = self.momentum * m - lr * g  # velocity\n",
                "            self.updates.append(tf.compat.v1.assign(m, v))\n",
                "\n",
                "            if self.nesterov:\n",
                "                new_p = p + self.momentum * v - lr * g\n",
                "            else:\n",
                "                new_p = p + v\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"momentum\": float(backend.get_value(self.momentum)),\n",
                "            \"decay\": float(backend.get_value(self.decay)),\n",
                "            \"nesterov\": self.nesterov,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class RMSprop(Optimizer):\n",
                "    \"\"\"RMSProp optimizer.\n",
                "\n",
                "    It is recommended to leave the parameters of this optimizer\n",
                "    at their default values\n",
                "    (except the learning rate, which can be freely tuned).\n",
                "\n",
                "    Args:\n",
                "      lr: float >= 0. Learning rate.\n",
                "      rho: float >= 0.\n",
                "      epsilon: float >= 0. Fuzz factor.\n",
                "        If `None`, defaults to `backend.epsilon()`.\n",
                "      decay: float >= 0. Learning rate decay over each update.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.0, **kwargs):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.rho = backend.variable(rho, name=\"rho\")\n",
                "            self.decay = backend.variable(decay, name=\"decay\")\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "        if epsilon is None:\n",
                "            epsilon = backend.epsilon()\n",
                "        self.epsilon = epsilon\n",
                "        self.initial_decay = decay\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        accumulators = [\n",
                "            backend.zeros(backend.int_shape(p), dtype=backend.dtype(p))\n",
                "            for p in params\n",
                "        ]\n",
                "        self.weights = accumulators\n",
                "        return accumulators\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        accumulators = self._create_all_weights(params)\n",
                "        self.updates = [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "\n",
                "        lr = self.lr\n",
                "        if self.initial_decay > 0:\n",
                "            lr = lr * (\n",
                "                1.0\n",
                "                / (\n",
                "                    1.0\n",
                "                    + self.decay\n",
                "                    * tf.cast(self.iterations, backend.dtype(self.decay))\n",
                "                )\n",
                "            )\n",
                "\n",
                "        for p, g, a in zip(params, grads, accumulators):\n",
                "            # update accumulator\n",
                "            new_a = self.rho * a + (1.0 - self.rho) * tf.square(g)\n",
                "            self.updates.append(tf.compat.v1.assign(a, new_a))\n",
                "            new_p = p - lr * g / (backend.sqrt(new_a) + self.epsilon)\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"rho\": float(backend.get_value(self.rho)),\n",
                "            \"decay\": float(backend.get_value(self.decay)),\n",
                "            \"epsilon\": self.epsilon,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class Adagrad(Optimizer):\n",
                "    \"\"\"Adagrad optimizer.\n",
                "\n",
                "    Adagrad is an optimizer with parameter-specific learning rates,\n",
                "    which are adapted relative to how frequently a parameter gets\n",
                "    updated during training. The more updates a parameter receives,\n",
                "    the smaller the updates.\n",
                "\n",
                "    It is recommended to leave the parameters of this optimizer\n",
                "    at their default values.\n",
                "\n",
                "    # Arguments\n",
                "        lr: float >= 0. Initial learning rate.\n",
                "        epsilon: float >= 0. If `None`, defaults to `backend.epsilon()`.\n",
                "        decay: float >= 0. Learning rate decay over each update.\n",
                "\n",
                "    # References\n",
                "        - [Adaptive Subgradient Methods for Online Learning and Stochastic\n",
                "        Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, lr=0.01, epsilon=None, decay=0.0, **kwargs):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.decay = backend.variable(decay, name=\"decay\")\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "        if epsilon is None:\n",
                "            epsilon = backend.epsilon()\n",
                "        self.epsilon = epsilon\n",
                "        self.initial_decay = decay\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        shapes = [backend.int_shape(p) for p in params]\n",
                "        accumulators = [backend.zeros(shape) for shape in shapes]\n",
                "        self.weights = accumulators\n",
                "        return accumulators\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        accumulators = self._create_all_weights(params)\n",
                "\n",
                "        self.updates = [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "\n",
                "        lr = self.lr\n",
                "        if self.initial_decay > 0:\n",
                "            lr = lr * (\n",
                "                1.0\n",
                "                / (\n",
                "                    1.0\n",
                "                    + self.decay\n",
                "                    * tf.cast(self.iterations, backend.dtype(self.decay))\n",
                "                )\n",
                "            )\n",
                "\n",
                "        for p, g, a in zip(params, grads, accumulators):\n",
                "            new_a = a + tf.square(g)  # update accumulator\n",
                "            self.updates.append(tf.compat.v1.assign(a, new_a))\n",
                "            new_p = p - lr * g / (backend.sqrt(new_a) + self.epsilon)\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"decay\": float(backend.get_value(self.decay)),\n",
                "            \"epsilon\": self.epsilon,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class Adadelta(Optimizer):\n",
                "    \"\"\"Adadelta optimizer.\n",
                "\n",
                "    Adadelta is a more robust extension of Adagrad\n",
                "    that adapts learning rates based on a moving window of gradient updates,\n",
                "    instead of accumulating all past gradients. This way, Adadelta continues\n",
                "    learning even when many updates have been done. Compared to Adagrad, in the\n",
                "    original version of Adadelta you don't have to set an initial learning\n",
                "    rate. In this version, initial learning rate and decay factor can\n",
                "    be set, as in most other Keras optimizers.\n",
                "\n",
                "    It is recommended to leave the parameters of this optimizer\n",
                "    at their default values.\n",
                "\n",
                "    Arguments:\n",
                "      lr: float >= 0. Initial learning rate, defaults to 1.\n",
                "          It is recommended to leave it at the default value.\n",
                "      rho: float >= 0. Adadelta decay factor, corresponding to fraction of\n",
                "          gradient to keep at each time step.\n",
                "      epsilon: float >= 0. Fuzz factor.\n",
                "        If `None`, defaults to `backend.epsilon()`.\n",
                "      decay: float >= 0. Initial learning rate decay.\n",
                "\n",
                "    References:\n",
                "        - [Adadelta - an adaptive learning rate\n",
                "        method](http://arxiv.org/abs/1212.5701)\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0.0, **kwargs):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.decay = backend.variable(decay, name=\"decay\")\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "        if epsilon is None:\n",
                "            epsilon = backend.epsilon()\n",
                "        self.rho = rho\n",
                "        self.epsilon = epsilon\n",
                "        self.initial_decay = decay\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        shapes = [backend.int_shape(p) for p in params]\n",
                "        accumulators = [backend.zeros(shape) for shape in shapes]\n",
                "        delta_accumulators = [backend.zeros(shape) for shape in shapes]\n",
                "        self.weights = accumulators + delta_accumulators\n",
                "        return accumulators, delta_accumulators\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        self.updates = [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "        accumulators, delta_accumulators = self._create_all_weights(params)\n",
                "\n",
                "        lr = self.lr\n",
                "        if self.initial_decay > 0:\n",
                "            lr = lr * (\n",
                "                1.0\n",
                "                / (\n",
                "                    1.0\n",
                "                    + self.decay\n",
                "                    * tf.cast(self.iterations, backend.dtype(self.decay))\n",
                "                )\n",
                "            )\n",
                "\n",
                "        for p, g, a, d_a in zip(\n",
                "            params, grads, accumulators, delta_accumulators\n",
                "        ):\n",
                "            # update accumulator\n",
                "            new_a = self.rho * a + (1.0 - self.rho) * tf.square(g)\n",
                "            self.updates.append(tf.compat.v1.assign(a, new_a))\n",
                "\n",
                "            # use the new accumulator and the *old* delta_accumulator\n",
                "            update = (\n",
                "                g\n",
                "                * backend.sqrt(d_a + self.epsilon)\n",
                "                / backend.sqrt(new_a + self.epsilon)\n",
                "            )\n",
                "            new_p = p - lr * update\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "\n",
                "            # update delta_accumulator\n",
                "            new_d_a = self.rho * d_a + (1 - self.rho) * tf.square(update)\n",
                "            self.updates.append(tf.compat.v1.assign(d_a, new_d_a))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"rho\": self.rho,\n",
                "            \"decay\": float(backend.get_value(self.decay)),\n",
                "            \"epsilon\": self.epsilon,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class Adam(Optimizer):\n",
                "    \"\"\"Adam optimizer.\n",
                "\n",
                "    Default parameters follow those provided in the original paper.\n",
                "\n",
                "    Args:\n",
                "      lr: float >= 0. Learning rate.\n",
                "      beta_1: float, 0 < beta < 1. Generally close to 1.\n",
                "      beta_2: float, 0 < beta < 1. Generally close to 1.\n",
                "      epsilon: float >= 0. Fuzz factor.\n",
                "        If `None`, defaults to `backend.epsilon()`.\n",
                "      decay: float >= 0. Learning rate decay over each update.\n",
                "      amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm\n",
                "        from the paper \"On the Convergence of Adam and Beyond\".\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        lr=0.001,\n",
                "        beta_1=0.9,\n",
                "        beta_2=0.999,\n",
                "        epsilon=None,\n",
                "        decay=0.0,\n",
                "        amsgrad=False,\n",
                "        **kwargs,\n",
                "    ):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.beta_1 = backend.variable(beta_1, name=\"beta_1\")\n",
                "            self.beta_2 = backend.variable(beta_2, name=\"beta_2\")\n",
                "            self.decay = backend.variable(decay, name=\"decay\")\n",
                "        if epsilon is None:\n",
                "            epsilon = backend.epsilon()\n",
                "        self.epsilon = epsilon\n",
                "        self.initial_decay = decay\n",
                "        self.amsgrad = amsgrad\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        ms = [\n",
                "            backend.zeros(backend.int_shape(p), dtype=backend.dtype(p))\n",
                "            for p in params\n",
                "        ]\n",
                "        vs = [\n",
                "            backend.zeros(backend.int_shape(p), dtype=backend.dtype(p))\n",
                "            for p in params\n",
                "        ]\n",
                "        if self.amsgrad:\n",
                "            vhats = [\n",
                "                backend.zeros(backend.int_shape(p), dtype=backend.dtype(p))\n",
                "                for p in params\n",
                "            ]\n",
                "        else:\n",
                "            vhats = [backend.zeros(1) for _ in params]\n",
                "        self.weights = [self.iterations] + ms + vs + vhats\n",
                "        return ms, vs, vhats\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        self.updates = []\n",
                "\n",
                "        lr = self.lr\n",
                "        if self.initial_decay > 0:\n",
                "            lr = lr * (\n",
                "                1.0\n",
                "                / (\n",
                "                    1.0\n",
                "                    + self.decay\n",
                "                    * tf.cast(self.iterations, backend.dtype(self.decay))\n",
                "                )\n",
                "            )\n",
                "\n",
                "        with tf.control_dependencies(\n",
                "            [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "        ):\n",
                "            t = tf.cast(self.iterations, backend.floatx())\n",
                "        lr_t = lr * (\n",
                "            backend.sqrt(1.0 - tf.pow(self.beta_2, t))\n",
                "            / (1.0 - tf.pow(self.beta_1, t))\n",
                "        )\n",
                "\n",
                "        ms, vs, vhats = self._create_all_weights(params)\n",
                "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
                "            m_t = (self.beta_1 * m) + (1.0 - self.beta_1) * g\n",
                "            v_t = (self.beta_2 * v) + (1.0 - self.beta_2) * tf.square(g)\n",
                "            if self.amsgrad:\n",
                "                vhat_t = tf.maximum(vhat, v_t)\n",
                "                p_t = p - lr_t * m_t / (backend.sqrt(vhat_t) + self.epsilon)\n",
                "                self.updates.append(tf.compat.v1.assign(vhat, vhat_t))\n",
                "            else:\n",
                "                p_t = p - lr_t * m_t / (backend.sqrt(v_t) + self.epsilon)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(m, m_t))\n",
                "            self.updates.append(tf.compat.v1.assign(v, v_t))\n",
                "            new_p = p_t\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"beta_1\": float(backend.get_value(self.beta_1)),\n",
                "            \"beta_2\": float(backend.get_value(self.beta_2)),\n",
                "            \"decay\": float(backend.get_value(self.decay)),\n",
                "            \"epsilon\": self.epsilon,\n",
                "            \"amsgrad\": self.amsgrad,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class Adamax(Optimizer):\n",
                "    \"\"\"Adamax optimizer from Adam paper's Section 7.\n",
                "\n",
                "    It is a variant of Adam based on the infinity norm.\n",
                "    Default parameters follow those provided in the paper.\n",
                "\n",
                "    Args:\n",
                "      lr: float >= 0. Learning rate.\n",
                "      beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n",
                "      epsilon: float >= 0. Fuzz factor.\n",
                "        If `None`, defaults to `backend.epsilon()`.\n",
                "      decay: float >= 0. Learning rate decay over each update.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        lr=0.002,\n",
                "        beta_1=0.9,\n",
                "        beta_2=0.999,\n",
                "        epsilon=None,\n",
                "        decay=0.0,\n",
                "        **kwargs,\n",
                "    ):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.beta_1 = backend.variable(beta_1, name=\"beta_1\")\n",
                "            self.beta_2 = backend.variable(beta_2, name=\"beta_2\")\n",
                "            self.decay = backend.variable(decay, name=\"decay\")\n",
                "        if epsilon is None:\n",
                "            epsilon = backend.epsilon()\n",
                "        self.epsilon = epsilon\n",
                "        self.initial_decay = decay\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "\n",
                "        shapes = [backend.int_shape(p) for p in params]\n",
                "        # zero init of 1st moment\n",
                "        ms = [backend.zeros(shape) for shape in shapes]\n",
                "        # zero init of exponentially weighted infinity norm\n",
                "        us = [backend.zeros(shape) for shape in shapes]\n",
                "        self.weights = [self.iterations] + ms + us\n",
                "        return ms, us\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        self.updates = []\n",
                "\n",
                "        lr = self.lr\n",
                "        if self.initial_decay > 0:\n",
                "            lr = lr * (\n",
                "                1.0\n",
                "                / (\n",
                "                    1.0\n",
                "                    + self.decay\n",
                "                    * tf.cast(self.iterations, backend.dtype(self.decay))\n",
                "                )\n",
                "            )\n",
                "\n",
                "        with tf.control_dependencies(\n",
                "            [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "        ):\n",
                "            t = tf.cast(self.iterations, backend.floatx())\n",
                "        lr_t = lr / (1.0 - tf.pow(self.beta_1, t))\n",
                "\n",
                "        ms, us = self._create_all_weights(params)\n",
                "\n",
                "        for p, g, m, u in zip(params, grads, ms, us):\n",
                "\n",
                "            m_t = (self.beta_1 * m) + (1.0 - self.beta_1) * g\n",
                "            u_t = tf.maximum(self.beta_2 * u, tf.abs(g))\n",
                "            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(m, m_t))\n",
                "            self.updates.append(tf.compat.v1.assign(u, u_t))\n",
                "            new_p = p_t\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"beta_1\": float(backend.get_value(self.beta_1)),\n",
                "            \"beta_2\": float(backend.get_value(self.beta_2)),\n",
                "            \"decay\": float(backend.get_value(self.decay)),\n",
                "            \"epsilon\": self.epsilon,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class Nadam(Optimizer):\n",
                "    \"\"\"Nesterov Adam optimizer.\n",
                "\n",
                "    Much like Adam is essentially RMSprop with momentum,\n",
                "    Nadam is Adam RMSprop with Nesterov momentum.\n",
                "\n",
                "    Default parameters follow those provided in the paper.\n",
                "    It is recommended to leave the parameters of this optimizer\n",
                "    at their default values.\n",
                "\n",
                "    Args:\n",
                "      lr: float >= 0. Learning rate.\n",
                "      beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n",
                "      epsilon: float >= 0. Fuzz factor.\n",
                "        If `None`, defaults to `backend.epsilon()`.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        lr=0.002,\n",
                "        beta_1=0.9,\n",
                "        beta_2=0.999,\n",
                "        epsilon=None,\n",
                "        schedule_decay=0.004,\n",
                "        **kwargs,\n",
                "    ):\n",
                "        super().__init__(**kwargs)\n",
                "        with backend.name_scope(self.__class__.__name__):\n",
                "            self.iterations = backend.variable(\n",
                "                0, dtype=\"int64\", name=\"iterations\"\n",
                "            )\n",
                "            self.m_schedule = backend.variable(1.0, name=\"m_schedule\")\n",
                "            self.lr = backend.variable(lr, name=\"lr\")\n",
                "            self.beta_1 = backend.variable(beta_1, name=\"beta_1\")\n",
                "            self.beta_2 = backend.variable(beta_2, name=\"beta_2\")\n",
                "        if epsilon is None:\n",
                "            epsilon = backend.epsilon()\n",
                "        self.epsilon = epsilon\n",
                "        self.schedule_decay = schedule_decay\n",
                "\n",
                "    def _create_all_weights(self, params):\n",
                "        shapes = [backend.int_shape(p) for p in params]\n",
                "        ms = [backend.zeros(shape) for shape in shapes]\n",
                "        vs = [backend.zeros(shape) for shape in shapes]\n",
                "\n",
                "        self.weights = [self.iterations, self.m_schedule] + ms + vs\n",
                "        return ms, vs\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        self.updates = []\n",
                "\n",
                "        with tf.control_dependencies(\n",
                "            [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "        ):\n",
                "            t = tf.cast(self.iterations, backend.floatx())\n",
                "\n",
                "        # Due to the recommendations in [2], i.e. warming momentum schedule\n",
                "        momentum_cache_t = self.beta_1 * (\n",
                "            1.0\n",
                "            - 0.5\n",
                "            * (tf.pow(backend.cast_to_floatx(0.96), t * self.schedule_decay))\n",
                "        )\n",
                "        momentum_cache_t_1 = self.beta_1 * (\n",
                "            1.0\n",
                "            - 0.5\n",
                "            * (\n",
                "                tf.pow(\n",
                "                    backend.cast_to_floatx(0.96), (t + 1) * self.schedule_decay\n",
                "                )\n",
                "            )\n",
                "        )\n",
                "        m_schedule_new = self.m_schedule * momentum_cache_t\n",
                "        m_schedule_next = (\n",
                "            self.m_schedule * momentum_cache_t * momentum_cache_t_1\n",
                "        )\n",
                "        self.updates.append((self.m_schedule, m_schedule_new))\n",
                "\n",
                "        ms, vs = self._create_all_weights(params)\n",
                "\n",
                "        for p, g, m, v in zip(params, grads, ms, vs):\n",
                "            # the following equations given in [1]\n",
                "            g_prime = g / (1.0 - m_schedule_new)\n",
                "            m_t = self.beta_1 * m + (1.0 - self.beta_1) * g\n",
                "            m_t_prime = m_t / (1.0 - m_schedule_next)\n",
                "            v_t = self.beta_2 * v + (1.0 - self.beta_2) * tf.square(g)\n",
                "            v_t_prime = v_t / (1.0 - tf.pow(self.beta_2, t))\n",
                "            m_t_bar = (\n",
                "                1.0 - momentum_cache_t\n",
                "            ) * g_prime + momentum_cache_t_1 * m_t_prime\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(m, m_t))\n",
                "            self.updates.append(tf.compat.v1.assign(v, v_t))\n",
                "\n",
                "            p_t = p - self.lr * m_t_bar / (\n",
                "                backend.sqrt(v_t_prime) + self.epsilon\n",
                "            )\n",
                "            new_p = p_t\n",
                "\n",
                "            # Apply constraints.\n",
                "            if getattr(p, \"constraint\", None) is not None:\n",
                "                new_p = p.constraint(new_p)\n",
                "\n",
                "            self.updates.append(tf.compat.v1.assign(p, new_p))\n",
                "        return self.updates\n",
                "\n",
                "    def get_config(self):\n",
                "        config = {\n",
                "            \"lr\": float(backend.get_value(self.lr)),\n",
                "            \"beta_1\": float(backend.get_value(self.beta_1)),\n",
                "            \"beta_2\": float(backend.get_value(self.beta_2)),\n",
                "            \"epsilon\": self.epsilon,\n",
                "            \"schedule_decay\": self.schedule_decay,\n",
                "        }\n",
                "        base_config = super().get_config()\n",
                "        return dict(list(base_config.items()) + list(config.items()))\n",
                "\n",
                "\n",
                "class TFOptimizer(Optimizer, tf.__internal__.tracking.Trackable):\n",
                "    \"\"\"Wrapper class for native TensorFlow optimizers.\"\"\"\n",
                "\n",
                "    def __init__(self, optimizer, iterations=None):\n",
                "        self.optimizer = optimizer\n",
                "        self._track_trackable(optimizer, name=\"optimizer\")\n",
                "        if iterations is None:\n",
                "            with backend.name_scope(self.__class__.__name__):\n",
                "                self.iterations = backend.variable(\n",
                "                    0, dtype=\"int64\", name=\"iterations\"\n",
                "                )\n",
                "        else:\n",
                "            self.iterations = iterations\n",
                "        self._track_trackable(self.iterations, name=\"global_step\")\n",
                "\n",
                "    def _clip_gradients(self, grads):\n",
                "        \"\"\"Clip gradients according to the clipnorm and clipvalue attributes.\"\"\"\n",
                "        # TFOptimizer wrapper has no gradient clipping options.\n",
                "        return grads\n",
                "\n",
                "    def minimize(self, loss, var_list, grad_loss=None, tape=None):\n",
                "        \"\"\"Mimics the `OptimizerV2.minimize` API.\"\"\"\n",
                "        if not callable(loss) and tape is None:\n",
                "            raise ValueError(\n",
                "                \"`tape` is required when a `Tensor` loss is passed.\"\n",
                "            )\n",
                "        tape = tape if tape is not None else tf.GradientTape()\n",
                "\n",
                "        if callable(loss):\n",
                "            with tape:\n",
                "                if not callable(var_list):\n",
                "                    tape.watch(var_list)\n",
                "                loss = loss()\n",
                "                if callable(var_list):\n",
                "                    var_list = var_list()\n",
                "\n",
                "        var_list = tf.nest.flatten(var_list)\n",
                "        if var_list:\n",
                "            grads = tape.gradient(loss, var_list, grad_loss)\n",
                "            grads_and_vars = list(zip(grads, var_list))\n",
                "            self.apply_gradients(grads_and_vars)\n",
                "\n",
                "    def apply_gradients(self, grads_and_vars):\n",
                "        self.optimizer.apply_gradients(\n",
                "            grads_and_vars, global_step=self.iterations\n",
                "        )\n",
                "\n",
                "    def get_grads(self, loss, params):\n",
                "        return self.optimizer.compute_gradients(loss, params)\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        if tf.distribute.has_strategy():\n",
                "            self.updates = []\n",
                "\n",
                "            if not params:\n",
                "                # After the model vars have been created, the second call to\n",
                "                # get_updates is called with params as an empty list. This\n",
                "                # ensures that we call compute_gradients with params=None.\n",
                "                grads = self.optimizer.compute_gradients(loss)\n",
                "            else:\n",
                "                grads = self.optimizer.compute_gradients(loss, params)\n",
                "            global_step = tf.compat.v1.train.get_global_step()\n",
                "            opt_update = self.optimizer.apply_gradients(grads, global_step)\n",
                "        else:\n",
                "            if not params:\n",
                "                self.updates = [tf.compat.v1.assign_add(self.iterations, 1)]\n",
                "                return self.updates\n",
                "\n",
                "            # Updates list starts out empty because the iterations variable is\n",
                "            # incremented in optimizer.apply_gradients()\n",
                "            self.updates = []\n",
                "            grads = self.optimizer.compute_gradients(loss, params)\n",
                "            opt_update = self.optimizer.apply_gradients(\n",
                "                grads, global_step=self.iterations\n",
                "            )\n",
                "\n",
                "        self.updates.append(opt_update)\n",
                "        return self.updates\n",
                "\n",
                "    @property\n",
                "    def weights(self):\n",
                "        raise NotImplementedError\n",
                "\n",
                "    def get_config(self):\n",
                "        raise NotImplementedError\n",
                "\n",
                "    def from_config(self, config):\n",
                "        raise NotImplementedError\n",
                "\n",
                "\n",
                "# Aliases.\n",
                "\n",
                "sgd = SGD\n",
                "rmsprop = RMSprop\n",
                "adagrad = Adagrad\n",
                "adadelta = Adadelta\n",
                "adam = Adam\n",
                "adamax = Adamax\n",
                "nadam = Nadam"
            ]
        ],
        "keras/optimizers/optimizer_v2/adagrad.py": [
            [
                "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\"\"\"Adagrad optimizer implementation.\"\"\"\n",
                "\n",
                "import numpy as np\n",
                "import tensorflow.compat.v2 as tf\n",
                "\n",
                "from keras import backend_config\n",
                "from keras.optimizers.optimizer_v2 import optimizer_v2\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.util.tf_export import keras_export\n",
                "\n",
                "\n",
                "@keras_export(\"keras.optimizers.Adagrad\")\n",
                "class Adagrad(optimizer_v2.OptimizerV2):\n",
                "    r\"\"\"Optimizer that implements the Adagrad algorithm.\n",
                "\n",
                "    Adagrad is an optimizer with parameter-specific learning rates,\n",
                "    which are adapted relative to how frequently a parameter gets\n",
                "    updated during training. The more updates a parameter receives,\n",
                "    the smaller the updates.\n",
                "\n",
                "    Args:\n",
                "      learning_rate: Initial value for the learning rate:\n",
                "        either a floating point value,\n",
                "        or a `tf.keras.optimizers.schedules.LearningRateSchedule` instance.\n",
                "        Defaults to 0.001.\n",
                "        Note that `Adagrad` tends to benefit from higher initial learning rate\n",
                "        values compared to other optimizers.\n",
                "        To match the exact form in the original paper, use 1.0.\n",
                "      initial_accumulator_value: Floating point value.\n",
                "        Starting value for the accumulators (per-parameter momentum values).\n",
                "        Must be non-negative.\n",
                "      epsilon: Small floating point value used to maintain numerical stability.\n",
                "      name: Optional name prefix for the operations created when applying\n",
                "        gradients.  Defaults to `\"Adagrad\"`.\n",
                "      **kwargs: keyword arguments. Allowed arguments are `clipvalue`,\n",
                "        `clipnorm`, `global_clipnorm`.\n",
                "        If `clipvalue` (float) is set, the gradient of each weight\n",
                "        is clipped to be no higher than this value.\n",
                "        If `clipnorm` (float) is set, the gradient of each weight\n",
                "        is individually clipped so that its norm is no higher than this value.\n",
                "        If `global_clipnorm` (float) is set the gradient of all weights is\n",
                "        clipped so that their global norm is no higher than this value..\n",
                "\n",
                "    Reference:\n",
                "      - [Duchi et al., 2011](\n",
                "        http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf).\n",
                "    \"\"\"\n",
                "\n",
                "    _HAS_AGGREGATE_GRAD = True\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        learning_rate=0.001,\n",
                "        initial_accumulator_value=0.1,\n",
                "        epsilon=1e-7,\n",
                "        name=\"Adagrad\",\n",
                "        **kwargs\n",
                "    ):\n",
                "        if initial_accumulator_value < 0.0:\n",
                "            raise ValueError(\n",
                "                \"initial_accumulator_value must be non-negative: %s\"\n",
                "                % initial_accumulator_value\n",
                "            )\n",
                "        if epsilon is None:\n",
                "            epsilon = backend_config.epsilon()\n",
                "        super().__init__(name, **kwargs)\n",
                "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n",
                "        self._set_hyper(\"decay\", self._initial_decay)\n",
                "        self._initial_accumulator_value = initial_accumulator_value\n",
                "        self.epsilon = epsilon or backend_config.epsilon()\n",
                "\n",
                "    def _create_slots(self, var_list):\n",
                "        for var in var_list:\n",
                "            dtype = var.dtype.base_dtype\n",
                "            init = tf.compat.v1.constant_initializer(\n",
                "                self._initial_accumulator_value, dtype=dtype\n",
                "            )\n",
                "            self.add_slot(var, \"accumulator\", init)\n",
                "\n",
                "    def _prepare_local(self, var_device, var_dtype, apply_state):\n",
                "        super()._prepare_local(var_device, var_dtype, apply_state)\n",
                "        apply_state[(var_device, var_dtype)].update(\n",
                "            dict(\n",
                "                epsilon=tf.convert_to_tensor(self.epsilon, var_dtype),\n",
                "                neg_lr_t=-apply_state[(var_device, var_dtype)][\"lr_t\"],\n",
                "                zero=tf.zeros((), dtype=tf.int64),\n",
                "            )\n",
                "        )\n",
                "\n",
                "    def set_weights(self, weights):\n",
                "        params = self.weights\n",
                "        # Override set_weights for backward compatibility of Keras V1 optimizer\n",
                "        # since it does not include iteration at head of the weight list. Set\n",
                "        # iteration to 0.\n",
                "        if len(params) == len(weights) + 1:\n",
                "            weights = [np.array(0)] + weights\n",
                "        super().set_weights(weights)\n",
                "\n",
                "    @classmethod\n",
                "    def from_config(cls, config, custom_objects=None):\n",
                "        \"\"\"Creates an optimizer from its config.\n",
                "\n",
                "        This method is the reverse of `get_config`,\n",
                "        capable of instantiating the same optimizer from the config\n",
                "        dictionary.\n",
                "\n",
                "        Args:\n",
                "            config: A Python dictionary, typically the output of get_config.\n",
                "            custom_objects: A Python dictionary mapping names to additional\n",
                "              Python objects used to create this optimizer, such as a function\n",
                "              used for a hyperparameter.\n",
                "\n",
                "        Returns:\n",
                "            An optimizer instance.\n",
                "        \"\"\"\n",
                "        if \"initial_accumulator_value\" not in config:\n",
                "            config[\"initial_accumulator_value\"] = 0.1\n",
                "        if \"lr\" in config:\n",
                "            config[\"learning_rate\"] = config.pop(\"lr\")\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "        if \"is_legacy_optimizer\" in config:\n",
                    "            del config[\"is_legacy_optimizer\"]\n"
                ],
                "parent_version_range": {
                    "start": 134,
                    "end": 134
                },
                "child_version_range": {
                    "start": 134,
                    "end": 136
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if \"lr\" in config:",
                        "start_line": 132,
                        "end_line": 133
                    }
                ],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "Adagrad",
                        "signature": "class Adagrad(optimizer_v2.OptimizerV2):",
                        "at_line": 27
                    },
                    {
                        "type": "function",
                        "name": "from_config",
                        "signature": "def from_config(cls, config, custom_objects=None):",
                        "at_line": 114
                    }
                ],
                "idx": 9,
                "hunk_diff": "File: keras/optimizers/optimizer_v2/adagrad.py\nCode:\n           class Adagrad(optimizer_v2.OptimizerV2):\n               ...\n               def from_config(cls, config, custom_objects=None):\n                   ...\n131 131                config[\"initial_accumulator_value\"] = 0.1\n132 132            if \"lr\" in config:\n133 133                config[\"learning_rate\"] = config.pop(\"lr\")\n    134  +         if \"is_legacy_optimizer\" in config:\n    135  +             del config[\"is_legacy_optimizer\"]\n134 136            return cls(**config)\n135 137    \n136 138        def _resource_apply_dense(self, grad, var, apply_state=None):\n         ...\n",
                "file_path": "keras/optimizers/optimizer_v2/adagrad.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "config"
                ],
                "prefix": [
                    "            config[\"initial_accumulator_value\"] = 0.1\n",
                    "        if \"lr\" in config:\n",
                    "            config[\"learning_rate\"] = config.pop(\"lr\")\n"
                ],
                "suffix": [
                    "        return cls(**config)\n",
                    "\n",
                    "    def _resource_apply_dense(self, grad, var, apply_state=None):\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    5,
                    8,
                    11
                ]
            },
            [
                "        return cls(**config)\n",
                "\n",
                "    def _resource_apply_dense(self, grad, var, apply_state=None):\n",
                "        var_device, var_dtype = var.device, var.dtype.base_dtype\n",
                "        coefficients = (apply_state or {}).get(\n",
                "            (var_device, var_dtype)\n",
                "        ) or self._fallback_apply_state(var_device, var_dtype)\n",
                "\n",
                "        acc = self.get_slot(var, \"accumulator\")\n",
                "        return tf.raw_ops.ResourceApplyAdagradV2(\n",
                "            var=var.handle,\n",
                "            accum=acc.handle,\n",
                "            lr=coefficients[\"lr_t\"],\n",
                "            epsilon=coefficients[\"epsilon\"],\n",
                "            grad=grad,\n",
                "            use_locking=self._use_locking,\n",
                "        )\n",
                "\n",
                "    def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
                "        var_device, var_dtype = var.device, var.dtype.base_dtype\n",
                "        coefficients = (apply_state or {}).get(\n",
                "            (var_device, var_dtype)\n",
                "        ) or self._fallback_apply_state(var_device, var_dtype)\n",
                "\n",
                "        acc = self.get_slot(var, \"accumulator\")\n",
                "        return tf.raw_ops.ResourceSparseApplyAdagradV2(\n",
                "            var=var.handle,\n",
                "            accum=acc.handle,\n",
                "            lr=coefficients[\"lr_t\"],\n",
                "            epsilon=coefficients[\"epsilon\"],\n",
                "            grad=grad,\n",
                "            indices=indices,\n",
                "            use_locking=self._use_locking,\n",
                "        )\n",
                "\n",
                "    def get_config(self):\n",
                "        config = super().get_config()\n",
                "        config.update(\n",
                "            {\n",
                "                \"learning_rate\": self._serialize_hyperparameter(\n",
                "                    \"learning_rate\"\n",
                "                ),\n",
                "                \"decay\": self._initial_decay,\n",
                "                \"initial_accumulator_value\": self._initial_accumulator_value,\n",
                "                \"epsilon\": self.epsilon,\n",
                "            }\n",
                "        )\n",
                "        return config"
            ]
        ],
        "keras/optimizers/optimizer_v2/optimizer_v2.py": [
            [
                "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\"\"\"Version 2 of class Optimizer.\"\"\"\n",
                "\n",
                "\n",
                "import abc\n",
                "import contextlib\n",
                "import functools\n",
                "import warnings\n",
                "\n",
                "import tensorflow.compat.v2 as tf\n",
                "\n",
                "from keras import backend\n",
                "from keras import initializers\n",
                "from keras.engine import base_layer_utils\n",
                "from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n",
                "from keras.optimizers.schedules import learning_rate_schedule\n",
                "from keras.utils import generic_utils\n",
                "from keras.utils import layer_utils\n",
                "from keras.utils import tf_inspect\n",
                "from keras.utils import tf_utils\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.util.tf_export import keras_export\n",
                "\n",
                "keras_optimizers_gauge = tf.__internal__.monitoring.BoolGauge(\n",
                "    \"/tensorflow/api/keras/optimizers\", \"keras optimizer usage\", \"method\"\n",
                ")\n",
                "\n",
                "_DEFAULT_VALID_DTYPES = frozenset(\n",
                "    [\n",
                "        tf.float16,\n",
                "        tf.bfloat16,\n",
                "        tf.float32,\n",
                "        tf.float64,\n",
                "        tf.complex64,\n",
                "        tf.complex128,\n",
                "    ]\n",
                ")\n",
                "\n",
                "\n",
                "def _deduplicate_indexed_slices(values, indices):\n",
                "    \"\"\"Sums `values` associated with any non-unique `indices`.\n",
                "\n",
                "    Args:\n",
                "      values: A `Tensor` with rank >= 1.\n",
                "      indices: A one-dimensional integer `Tensor`, indexing into the first\n",
                "        dimension of `values` (as in an IndexedSlices object).\n",
                "\n",
                "    Returns:\n",
                "      A tuple of (`summed_values`, `unique_indices`) where `unique_indices` is a\n",
                "      de-duplicated version of `indices` and `summed_values` contains the sum of\n",
                "      `values` slices associated with each unique index.\n",
                "    \"\"\"\n",
                "    unique_indices, new_index_positions = tf.unique(indices)\n",
                "    summed_values = tf.math.unsorted_segment_sum(\n",
                "        values, new_index_positions, tf.shape(unique_indices)[0]\n",
                "    )\n",
                "    return (summed_values, unique_indices)\n",
                "\n",
                "\n",
                "class NullContextmanager:\n",
                "    def __init__(self, *args, **kwargs):\n",
                "        pass\n",
                "\n",
                "    def __enter__(self):\n",
                "        pass\n",
                "\n",
                "    def __exit__(self, type_arg, value_arg, traceback_arg):\n",
                "        return False  # False values do not suppress exceptions\n",
                "\n",
                "\n",
                "def name_scope_only_in_function_or_graph(name):\n",
                "    \"\"\"Internal-only entry point for `name_scope*`.\n",
                "\n",
                "    Enters a compat.v1.name_scope only when in a function or graph,\n",
                "    not when running fully eagerly.\n",
                "\n",
                "    Args:\n",
                "      name: The name argument that is passed to the op function.\n",
                "\n",
                "    Returns:\n",
                "      `name_scope*` context manager.\n",
                "    \"\"\"\n",
                "    if not tf.executing_eagerly():\n",
                "        return tf.name_scope(name)\n",
                "    else:\n",
                "        return NullContextmanager()\n",
                "\n",
                "\n",
                "@keras_export(\"keras.optimizers.Optimizer\", metaclass=abc.ABCMeta)\n",
                "class OptimizerV2(tf.__internal__.tracking.Trackable):\n",
                "    \"\"\"Base class for Keras optimizers.\n",
                "\n",
                "    You should not use this class directly, but instead instantiate one of its\n",
                "    subclasses such as `tf.keras.optimizers.SGD`, `tf.keras.optimizers.Adam`,\n",
                "    etc.\n",
                "\n",
                "    ### Usage\n",
                "\n",
                "    ```python\n",
                "    # Create an optimizer with the desired parameters.\n",
                "    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
                "    # `loss` is a callable that takes no argument and returns the value\n",
                "    # to minimize.\n",
                "    var1 = tf.Variable(2.0)\n",
                "    var2 = tf.Variable(5.0)\n",
                "    loss = lambda: 3 * var1 * var1 + 2 * var2 * var2\n",
                "    # In graph mode, returns op that minimizes the loss by updating the listed\n",
                "    # variables.\n",
                "    opt_op = opt.minimize(loss, var_list=[var1, var2])\n",
                "    opt_op.run()\n",
                "    # In eager mode, simply call minimize to update the list of variables.\n",
                "    opt.minimize(loss, var_list=[var1, var2])\n",
                "    ```\n",
                "\n",
                "    ### Usage in custom training loops\n",
                "\n",
                "    In Keras models, sometimes variables are created when the model is first\n",
                "    called, instead of construction time. Examples include 1) sequential models\n",
                "    without input shape pre-defined, or 2) subclassed models. Pass var_list as\n",
                "    callable in these cases.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    ```python\n",
                "    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
                "    model = tf.keras.Sequential()\n",
                "    model.add(tf.keras.layers.Dense(num_hidden, activation='relu'))\n",
                "    model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
                "    loss_fn = lambda: tf.keras.losses.mse(model(input), output)\n",
                "    var_list_fn = lambda: model.trainable_weights\n",
                "    for input, output in data:\n",
                "      opt.minimize(loss_fn, var_list_fn)\n",
                "    ```\n",
                "\n",
                "    ### Processing gradients before applying them\n",
                "\n",
                "    Calling `minimize()` takes care of both computing the gradients and\n",
                "    applying them to the variables.  If you want to process the gradients\n",
                "    before applying them you can instead use the optimizer in three steps:\n",
                "\n",
                "    1.  Compute the gradients with `tf.GradientTape`.\n",
                "    2.  Process the gradients as you wish.\n",
                "    3.  Apply the processed gradients with `apply_gradients()`.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    ```python\n",
                "    # Create an optimizer.\n",
                "    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
                "\n",
                "    # Compute the gradients for a list of variables.\n",
                "    with tf.GradientTape() as tape:\n",
                "      loss = <call_loss_function>\n",
                "    vars = <list_of_variables>\n",
                "    grads = tape.gradient(loss, vars)\n",
                "\n",
                "    # Process the gradients, for example cap them, etc.\n",
                "    # capped_grads = [MyCapper(g) for g in grads]\n",
                "    processed_grads = [process_gradient(g) for g in grads]\n",
                "\n",
                "    # Ask the optimizer to apply the processed gradients.\n",
                "    opt.apply_gradients(zip(processed_grads, var_list))\n",
                "    ```\n",
                "\n",
                "    ### Use with `tf.distribute.Strategy`\n",
                "\n",
                "    This optimizer class is `tf.distribute.Strategy` aware, which means it\n",
                "    automatically sums gradients across all replicas. To average gradients,\n",
                "    you divide your loss by the global batch size, which is done\n",
                "    automatically if you use `tf.keras` built-in training or evaluation loops.\n",
                "    See the `reduction` argument of your loss which should be set to\n",
                "    `tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE` for averaging or\n",
                "    `tf.keras.losses.Reduction.SUM` for not.\n",
                "\n",
                "    To aggregate gradients yourself, call `apply_gradients` with\n",
                "    `experimental_aggregate_gradients` set to False. This is useful if you need\n",
                "    to process aggregated gradients.\n",
                "\n",
                "    If you are not using these and you want to average gradients, you should use\n",
                "    `tf.math.reduce_sum` to add up your per-example losses and then divide by\n",
                "    the global batch size. Note that when using `tf.distribute.Strategy`, the\n",
                "    first component of a tensor's shape is the *replica-local* batch size, which\n",
                "    is off by a factor equal to the number of replicas being used to compute a\n",
                "    single step. As a result, using `tf.math.reduce_mean` will give the wrong\n",
                "    answer, resulting in gradients that can be many times too big.\n",
                "\n",
                "    ### Variable Constraints\n",
                "\n",
                "    All Keras optimizers respect variable constraints. If constraint function is\n",
                "    passed to any variable, the constraint will be applied to the variable after\n",
                "    the gradient has been applied to the variable.\n",
                "    Important: If gradient is sparse tensor, variable constraint is not\n",
                "    supported.\n",
                "\n",
                "    ### Thread Compatibility\n",
                "\n",
                "    The entire optimizer is currently thread compatible, not thread-safe. The\n",
                "    user needs to perform synchronization if necessary.\n",
                "\n",
                "    ### Slots\n",
                "\n",
                "    Many optimizer subclasses, such as `Adam` and `Adagrad` allocate and manage\n",
                "    additional variables associated with the variables to train.  These are\n",
                "    called <i>Slots</i>.  Slots have names and you can ask the optimizer for the\n",
                "    names of the slots that it uses.  Once you have a slot name you can ask the\n",
                "    optimizer for the variable it created to hold the slot value.\n",
                "\n",
                "    This can be useful if you want to log debug a training algorithm, report\n",
                "    stats about the slots, etc.\n",
                "\n",
                "    ### Hyperparameters\n",
                "\n",
                "    These are arguments passed to the optimizer subclass constructor\n",
                "    (the `__init__` method), and then passed to `self._set_hyper()`.\n",
                "    They can be either regular Python values (like 1.0), tensors, or\n",
                "    callables. If they are callable, the callable will be called during\n",
                "    `apply_gradients()` to get the value for the hyper parameter.\n",
                "\n",
                "    Hyperparameters can be overwritten through user code:\n",
                "\n",
                "    Example:\n",
                "\n",
                "    ```python\n",
                "    # Create an optimizer with the desired parameters.\n",
                "    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
                "    # `loss` is a callable that takes no argument and returns the value\n",
                "    # to minimize.\n",
                "    loss = lambda: 3 * var1 + 2 * var2\n",
                "    # In eager mode, simply call minimize to update the list of variables.\n",
                "    opt.minimize(loss, var_list=[var1, var2])\n",
                "    # update learning rate\n",
                "    opt.learning_rate = 0.05\n",
                "    opt.minimize(loss, var_list=[var1, var2])\n",
                "    ```\n",
                "\n",
                "    ### Callable learning rate\n",
                "\n",
                "    Optimizer accepts a callable learning rate in two ways. The first way is\n",
                "    through built-in or customized\n",
                "    `tf.keras.optimizers.schedules.LearningRateSchedule`. The schedule will be\n",
                "    called on each iteration with `schedule(iteration)`, a `tf.Variable`\n",
                "    owned by the optimizer.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    >>> var = tf.Variable(np.random.random(size=(1,)))\n",
                "    >>> learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
                "    ... initial_learning_rate=.01, decay_steps=20, decay_rate=.1)\n",
                "    >>> opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
                "    >>> loss = lambda: 3 * var\n",
                "    >>> opt.minimize(loss, var_list=[var])\n",
                "    <tf.Variable...\n",
                "\n",
                "    The second way is through a callable function that\n",
                "    does not accept any arguments.\n",
                "\n",
                "    Example:\n",
                "\n",
                "    >>> var = tf.Variable(np.random.random(size=(1,)))\n",
                "    >>> def lr_callable():\n",
                "    ...   return .1\n",
                "    >>> opt = tf.keras.optimizers.SGD(learning_rate=lr_callable)\n",
                "    >>> loss = lambda: 3 * var\n",
                "    >>> opt.minimize(loss, var_list=[var])\n",
                "    <tf.Variable...\n",
                "\n",
                "    ### Creating a custom optimizer\n",
                "\n",
                "    If you intend to create your own optimization algorithm, simply inherit from\n",
                "    this class and override the following methods:\n",
                "\n",
                "      - `_resource_apply_dense` (update variable given gradient tensor is a\n",
                "        dense `tf.Tensor`)\n",
                "      - `_resource_apply_sparse` (update variable given gradient tensor is a\n",
                "        sparse `tf.IndexedSlices`. The most common way for this to happen\n",
                "        is if you are taking the gradient through a `tf.gather`.)\n",
                "      - `_create_slots`\n",
                "        (if your optimizer algorithm requires additional variables)\n",
                "      - `get_config`\n",
                "        (serialization of the optimizer, include all hyper parameters)\n",
                "    \"\"\"\n",
                "\n",
                "    # Subclasses should set this to True unless they override `apply_gradients`\n",
                "    # with a version that does not have the `experimental_aggregate_gradients`\n",
                "    # argument.  Older versions of Keras did not have this argument so custom\n",
                "    # optimizers may have overridden `apply_gradients` without the\n",
                "    # `experimental_aggregate_gradients` argument. Keras only passes\n",
                "    # `experimental_aggregate_gradients` if this attribute is True.\n",
                "    # Note: This attribute will likely be removed in an upcoming release.\n",
                "    _HAS_AGGREGATE_GRAD = False\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        name,\n",
                "        gradient_aggregator=None,\n",
                "        gradient_transformers=None,\n",
                "        **kwargs,\n",
                "    ):\n",
                "        \"\"\"Create a new Optimizer.\n",
                "\n",
                "        This must be called by the constructors of subclasses.\n",
                "        Note that Optimizer instances should not bind to a single graph,\n",
                "        and so shouldn't keep Tensors as member variables. Generally\n",
                "        you should be able to use the _set_hyper()/state.get_hyper()\n",
                "        facility instead.\n",
                "\n",
                "        This class is stateful and thread-compatible.\n",
                "\n",
                "        Example of custom gradient transformations:\n",
                "\n",
                "        ```python\n",
                "        def my_gradient_transformer(grads_and_vars):\n",
                "          # Simple example, double the gradients.\n",
                "          return [(2. * g, v) for g, v in grads_and_vars]\n",
                "\n",
                "        optimizer = tf.keras.optimizers.SGD(\n",
                "            1e-3, gradient_transformers=[my_gradient_transformer])\n",
                "        ```\n",
                "\n",
                "        Args:\n",
                "          name: String. The name to use for momentum accumulator weights created\n",
                "            by the optimizer.\n",
                "          gradient_aggregator: The function to use to aggregate gradients across\n",
                "            devices (when using `tf.distribute.Strategy`). If `None`, defaults\n",
                "            to summing the gradients across devices. The function should accept\n",
                "            and return a list of `(gradient, variable)` tuples.\n",
                "          gradient_transformers: Optional. List of functions to use to transform\n",
                "            gradients before applying updates to Variables. The functions are\n",
                "            applied after `gradient_aggregator`. The functions should accept and\n",
                "            return a list of `(gradient, variable)` tuples.\n",
                "          **kwargs: keyword arguments. Allowed arguments are `clipvalue`,\n",
                "            `clipnorm`, `global_clipnorm`.\n",
                "            If `clipvalue` (float) is set, the gradient of each weight\n",
                "            is clipped to be no higher than this value.\n",
                "            If `clipnorm` (float) is set, the gradient of each weight\n",
                "            is individually clipped so that its norm is no higher than this\n",
                "            value. If `global_clipnorm` (float) is set the gradient of all\n",
                "            weights is clipped so that their global norm is no higher than this\n",
                "            value.\n",
                "\n",
                "        Raises:\n",
                "          ValueError: in case of any invalid argument.\n",
                "        \"\"\"\n",
                "        # Instrument optimizer usages\n",
                "        keras_optimizers_gauge.get_cell(self.__class__.__name__).set(True)\n",
                "\n",
                "        allowed_kwargs = {\n",
                "            \"clipnorm\",\n",
                "            \"clipvalue\",\n",
                "            \"lr\",\n",
                "            \"decay\",\n",
                "            \"global_clipnorm\",\n",
                "        }\n",
                "        for k in kwargs:\n",
                "            if k not in allowed_kwargs:\n",
                "                raise TypeError(\n",
                "                    \"Unexpected keyword argument \"\n",
                "                    f\"passed to optimizer: {str(k)}. Allowed kwargs are \"\n",
                "                    f\"{allowed_kwargs}.\"\n",
                "                )\n",
                "            # checks that all keyword arguments are non-negative.\n",
                "            if kwargs[k] is not None and kwargs[k] < 0:\n",
                "                raise ValueError(f\"Expected {k} >= 0, received: {kwargs[k]}\")\n",
                "            if k == \"lr\":\n",
                "                warnings.warn(\n",
                "                    \"The `lr` argument is deprecated, \"\n",
                "                    \"use `learning_rate` instead.\",\n",
                "                    stacklevel=2,\n",
                "                )\n",
                "\n",
                "        self._use_locking = True\n",
                "        self._init_set_name(name)\n",
                "        self._hyper = {}\n",
                "        # dict: {variable name : {slot name : variable}}\n",
                "        self._slots = {}\n",
                "        self._slot_names = []\n",
                "        self._weights = []\n",
                "        self._iterations = None\n",
                "\n",
                "        # For implementing Trackable. Stores information about how to restore\n",
                "        # slot variables which have not yet been created\n",
                "        # (trackable._CheckpointPosition objects).\n",
                "        #  {slot_name :\n",
                "        #      {_var_key(variable_to_train): [checkpoint_position, ... ], ... },\n",
                "        #   ... }\n",
                "        self._deferred_slot_restorations = {}\n",
                "\n",
                "        decay = kwargs.pop(\"decay\", 0.0)\n",
                "        if decay < 0.0:\n",
                "            raise ValueError(\n",
                "                f\"decay cannot be less than 0. Received: decay={decay}.\"\n",
                "            )\n",
                "        self._initial_decay = decay\n",
                "\n",
                "        self._hypers_created = False\n",
                "        # Store the distribution strategy object if the optimizer is created\n",
                "        # inside strategy scope, so it could be used to create variables later.\n",
                "        if tf.distribute.has_strategy():\n",
                "            self._distribution_strategy = tf.distribute.get_strategy()\n",
                "        else:\n",
                "            self._distribution_strategy = None\n",
                "\n",
                "        # Configure gradient transformations.\n",
                "        if gradient_aggregator is None:\n",
                "            gradient_aggregator = optimizer_utils.all_reduce_sum_gradients\n",
                "        self.gradient_aggregator = gradient_aggregator\n",
                "        if gradient_transformers is None:\n",
                "            gradient_transformers = []\n",
                "        self.gradient_transformers = gradient_transformers\n",
                "        self.clipnorm = kwargs.pop(\"clipnorm\", None)\n",
                "        self.global_clipnorm = kwargs.pop(\"global_clipnorm\", None)\n",
                "        if self.clipnorm is not None and self.global_clipnorm is not None:\n",
                "            raise ValueError(\n",
                "                \"Cannot accept both `clipnorm` and `global_clipnorm`. \"\n",
                "                \"Received: `clipnorm`={}, `global_clipnorm`={}.\".format(\n",
                "                    self.clipnorm, self.global_clipnorm\n",
                "                )\n",
                "            )\n",
                "        self.clipvalue = kwargs.pop(\"clipvalue\", None)\n",
                "\n",
                "    @property\n",
                "    def clipnorm(self):\n",
                "        \"\"\"`float` or `None`. If set, clips gradients to a maximum norm.\"\"\"\n",
                "        return self._clipnorm\n",
                "\n",
                "    @property\n",
                "    def global_clipnorm(self):\n",
                "        \"\"\"`float` or `None`.\n",
                "\n",
                "        If set, clips gradients to a maximum norm.\n",
                "\n",
                "        Check `tf.clip_by_global_norm` for more details.\n",
                "        \"\"\"\n",
                "        return self._global_clipnorm\n",
                "\n",
                "    @clipnorm.setter\n",
                "    def clipnorm(self, val):\n",
                "        if val is not None and self.gradient_transformers:\n",
                "            raise ValueError(\n",
                "                \"`clipnorm` cannot be set when `gradient_transformers` \"\n",
                "                \"is set. Instead, use the `gradient_transformers` to \"\n",
                "                \"specify clipping and other transformations. Received: \"\n",
                "                f\"val={val}, \"\n",
                "                f\"gradient_transformers={self.gradient_transformers}.\"\n",
                "            )\n",
                "        self._clipnorm = val\n",
                "        self._clipnorm_fn = optimizer_utils.make_gradient_clipnorm_fn(\n",
                "            self._clipnorm\n",
                "        )\n",
                "\n",
                "    @global_clipnorm.setter\n",
                "    def global_clipnorm(self, val):\n",
                "        if val is not None and self.gradient_transformers:\n",
                "            raise ValueError(\n",
                "                \"`global_clipnorm` cannot be set when \"\n",
                "                \"`gradient_transformers` \"\n",
                "                \"is set. Instead, use the `gradient_transformers` to \"\n",
                "                \"specify clipping and other transformations. Received: \"\n",
                "                f\"val={val}, \"\n",
                "                f\"gradient_transformers={self.gradient_transformers}.\"\n",
                "            )\n",
                "        self._global_clipnorm = val\n",
                "        self._global_clipnorm_fn = (\n",
                "            optimizer_utils.make_global_gradient_clipnorm_fn(\n",
                "                self._global_clipnorm\n",
                "            )\n",
                "        )\n",
                "\n",
                "    @property\n",
                "    def clipvalue(self):\n",
                "        \"\"\"`float` or `None`. If set, clips gradients to a maximum value.\"\"\"\n",
                "        return self._clipvalue\n",
                "\n",
                "    @clipvalue.setter\n",
                "    def clipvalue(self, val):\n",
                "        if val is not None and self.gradient_transformers:\n",
                "            raise ValueError(\n",
                "                \"`clipvalue` cannot be set when `gradient_transformers` \"\n",
                "                \"is set. Instead, use the `gradient_transformers` to \"\n",
                "                \"specify clipping and other transformations. Received: \"\n",
                "                f\"val={val}, \"\n",
                "                f\"gradient_transformers={self.gradient_transformers}.\"\n",
                "            )\n",
                "        self._clipvalue = val\n",
                "        self._clipvalue_fn = optimizer_utils.make_gradient_clipvalue_fn(\n",
                "            self._clipvalue\n",
                "        )\n",
                "\n",
                "    def _transform_loss(self, loss):\n",
                "        \"\"\"Called in `.minimize` to transform loss before computing\n",
                "        gradients.\"\"\"\n",
                "        return loss\n",
                "\n",
                "    def _get_gradients(self, tape, loss, var_list, grad_loss=None):\n",
                "        \"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\n",
                "        grads = tape.gradient(loss, var_list, grad_loss)\n",
                "        return list(zip(grads, var_list))\n",
                "\n",
                "    def _transform_unaggregated_gradients(self, grads_and_vars):\n",
                "        \"\"\"Called in `apply_gradients` before gradient aggregation.\"\"\"\n",
                "        return grads_and_vars\n",
                "\n",
                "    def _aggregate_gradients(self, grads_and_vars):\n",
                "        \"\"\"Called in `apply_gradients` to aggregate gradients across devices.\n",
                "\n",
                "        Note that user subclasses may override this, so the interface should not\n",
                "        be changed.\n",
                "\n",
                "        Args:\n",
                "          grads_and_vars: List of (gradient, variable) pairs.\n",
                "\n",
                "        Returns:\n",
                "          A list of (aggregrated_gradient, variable) pairs. By default, this\n",
                "          calls `self.gradient_aggregator`.\n",
                "        \"\"\"\n",
                "        return self.gradient_aggregator(grads_and_vars)\n",
                "\n",
                "    def _transform_gradients(self, grads_and_vars):\n",
                "        \"\"\"Called in `apply_gradients` after aggregation.\"\"\"\n",
                "        if self._clipvalue is not None:\n",
                "            grads_and_vars = self._clipvalue_fn(grads_and_vars)\n",
                "        if self._clipnorm is not None:\n",
                "            grads_and_vars = self._clipnorm_fn(grads_and_vars)\n",
                "        if self._global_clipnorm is not None:\n",
                "            grads_and_vars = self._global_clipnorm_fn(grads_and_vars)\n",
                "\n",
                "        for fn in self.gradient_transformers:\n",
                "            grads_and_vars = fn(grads_and_vars)\n",
                "        return grads_and_vars\n",
                "\n",
                "    def minimize(self, loss, var_list, grad_loss=None, name=None, tape=None):\n",
                "        \"\"\"Minimize `loss` by updating `var_list`.\n",
                "\n",
                "        This method simply computes gradient using `tf.GradientTape` and calls\n",
                "        `apply_gradients()`. If you want to process the gradient before applying\n",
                "        then call `tf.GradientTape` and `apply_gradients()` explicitly instead\n",
                "        of using this function.\n",
                "\n",
                "        Args:\n",
                "          loss: `Tensor` or callable. If a callable, `loss` should take no\n",
                "            arguments and return the value to minimize. If a `Tensor`, the\n",
                "            `tape` argument must be passed.\n",
                "          var_list: list or tuple of `Variable` objects to update to minimize\n",
                "            `loss`, or a callable returning the list or tuple of `Variable`\n",
                "            objects.  Use callable when the variable list would otherwise be\n",
                "            incomplete before `minimize` since the variables are created at the\n",
                "            first time `loss` is called.\n",
                "          grad_loss: (Optional). A `Tensor` holding the gradient computed for\n",
                "            `loss`.\n",
                "          name: (Optional) str. Name for the returned operation.\n",
                "          tape: (Optional) `tf.GradientTape`. If `loss` is provided as a\n",
                "            `Tensor`, the tape that computed the `loss` must be provided.\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` that updates the variables in `var_list`. The\n",
                "          `iterations` will be automatically increased by 1.\n",
                "\n",
                "        Raises:\n",
                "          ValueError: If some of the variables are not `Variable` objects.\n",
                "\n",
                "        \"\"\"\n",
                "        grads_and_vars = self._compute_gradients(\n",
                "            loss, var_list=var_list, grad_loss=grad_loss, tape=tape\n",
                "        )\n",
                "        return self.apply_gradients(grads_and_vars, name=name)\n",
                "\n",
                "    def _compute_gradients(self, loss, var_list, grad_loss=None, tape=None):\n",
                "        \"\"\"Compute gradients of `loss` for the variables in `var_list`.\n",
                "\n",
                "        This is the first part of `minimize()`.  It returns a list\n",
                "        of (gradient, variable) pairs where \"gradient\" is the gradient\n",
                "        for \"variable\".  Note that \"gradient\" can be a `Tensor`, an\n",
                "        `IndexedSlices`, or `None` if there is no gradient for the\n",
                "        given variable.\n",
                "\n",
                "        Args:\n",
                "          loss: `Tensor` or callable. If a callable, `loss` should take no\n",
                "            arguments and return the value to minimize. If a `Tensor`, the\n",
                "            `tape` argument must be passed.\n",
                "          var_list: list or tuple of `Variable` objects to update to minimize\n",
                "            `loss`, or a callable returning the list or tuple of `Variable`\n",
                "            objects.  Use callable when the variable list would otherwise be\n",
                "            incomplete before `minimize` and the variables are created at the\n",
                "            first time when `loss` is called.\n",
                "          grad_loss: Optional. A `Tensor` holding the gradient computed for\n",
                "            `loss`.\n",
                "          tape: (Optional) `tf.GradientTape`. If `loss` is provided as a\n",
                "            `Tensor`, the tape that computed the `loss` must be provided.\n",
                "\n",
                "        Returns:\n",
                "          A list of (gradient, variable) pairs. Variable is always present, but\n",
                "          gradient can be `None`.\n",
                "\n",
                "        Raises:\n",
                "          TypeError: If `var_list` contains anything else than `Variable`\n",
                "            objects.\n",
                "          ValueError: If some arguments are invalid, or var_list is None.\n",
                "        \"\"\"\n",
                "        # TODO(joshl): Test that we handle weight decay in a reasonable way.\n",
                "        if not callable(loss) and tape is None:\n",
                "            raise ValueError(\n",
                "                \"`tape` is required when a `Tensor` loss is passed. \"\n",
                "                f\"Received: loss={loss}, tape={tape}.\"\n",
                "            )\n",
                "        tape = tape if tape is not None else tf.GradientTape()\n",
                "\n",
                "        if callable(loss):\n",
                "            with tape:\n",
                "                if not callable(var_list):\n",
                "                    tape.watch(var_list)\n",
                "                loss = loss()\n",
                "                if callable(var_list):\n",
                "                    var_list = var_list()\n",
                "\n",
                "        with tape:\n",
                "            loss = self._transform_loss(loss)\n",
                "\n",
                "        var_list = tf.nest.flatten(var_list)\n",
                "        with tf.name_scope(self._name + \"/gradients\"):\n",
                "            grads_and_vars = self._get_gradients(\n",
                "                tape, loss, var_list, grad_loss\n",
                "            )\n",
                "\n",
                "        self._assert_valid_dtypes(\n",
                "            [\n",
                "                v\n",
                "                for g, v in grads_and_vars\n",
                "                if g is not None and v.dtype != tf.resource\n",
                "            ]\n",
                "        )\n",
                "\n",
                "        return grads_and_vars\n",
                "\n",
                "    def apply_gradients(\n",
                "        self, grads_and_vars, name=None, experimental_aggregate_gradients=True\n",
                "    ):\n",
                "        \"\"\"Apply gradients to variables.\n",
                "\n",
                "        This is the second part of `minimize()`. It returns an `Operation` that\n",
                "        applies gradients.\n",
                "\n",
                "        The method sums gradients from all replicas in the presence of\n",
                "        `tf.distribute.Strategy` by default. You can aggregate gradients\n",
                "        yourself by passing `experimental_aggregate_gradients=False`.\n",
                "\n",
                "        Example:\n",
                "\n",
                "        ```python\n",
                "        grads = tape.gradient(loss, vars)\n",
                "        grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n",
                "        # Processing aggregated gradients.\n",
                "        optimizer.apply_gradients(zip(grads, vars),\n",
                "            experimental_aggregate_gradients=False)\n",
                "\n",
                "        ```\n",
                "\n",
                "        Args:\n",
                "          grads_and_vars: List of (gradient, variable) pairs.\n",
                "          name: Optional name for the returned operation. Default to the name\n",
                "            passed to the `Optimizer` constructor.\n",
                "          experimental_aggregate_gradients: Whether to sum gradients from\n",
                "            different replicas in the presence of `tf.distribute.Strategy`. If\n",
                "            False, it's user responsibility to aggregate the gradients. Default\n",
                "            to True.\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` that applies the specified gradients. The `iterations`\n",
                "          will be automatically increased by 1.\n",
                "\n",
                "        Raises:\n",
                "          TypeError: If `grads_and_vars` is malformed.\n",
                "          ValueError: If none of the variables have gradients.\n",
                "          RuntimeError: If called in a cross-replica context.\n",
                "        \"\"\"\n",
                "        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n",
                "        var_list = [v for (_, v) in grads_and_vars]\n",
                "\n",
                "        with tf.name_scope(self._name):\n",
                "            # Create iteration if necessary.\n",
                "            with tf.init_scope():\n",
                "                self._create_all_weights(var_list)\n",
                "\n",
                "            if not grads_and_vars:\n",
                "                # Distribution strategy does not support reducing an empty list\n",
                "                # of gradients\n",
                "                return tf.no_op()\n",
                "\n",
                "            if tf.distribute.in_cross_replica_context():\n",
                "                raise RuntimeError(\n",
                "                    \"`apply_gradients() cannot be called in cross-replica \"\n",
                "                    \"context. Use `tf.distribute.Strategy.run` to enter \"\n",
                "                    \"replica context. For more information, please see the \"\n",
                "                    \"docstring of `tf.distribute.get_replica_context`.\"\n",
                "                )\n",
                "\n",
                "            strategy = tf.distribute.get_strategy()\n",
                "            if (\n",
                "                not experimental_aggregate_gradients\n",
                "                and strategy\n",
                "                and isinstance(\n",
                "                    strategy,\n",
                "                    (\n",
                "                        tf.compat.v1.distribute.experimental.ParameterServerStrategy,  # noqa: E501\n",
                "                        tf.distribute.experimental.ParameterServerStrategy,\n",
                "                        tf.distribute.experimental.CentralStorageStrategy,\n",
                "                        tf.compat.v1.distribute.experimental.CentralStorageStrategy,  # noqa: E501\n",
                "                    ),\n",
                "                )\n",
                "            ):\n",
                "                raise NotImplementedError(\n",
                "                    \"`experimental_aggregate_gradients=False is not supported \"\n",
                "                    \"for ParameterServerStrategy and CentralStorageStrategy. \"\n",
                "                    f\"Used: strategy={strategy}.\"\n",
                "                )\n",
                "\n",
                "            apply_state = self._prepare(var_list)\n",
                "            if experimental_aggregate_gradients:\n",
                "                grads_and_vars = self._transform_unaggregated_gradients(\n",
                "                    grads_and_vars\n",
                "                )\n",
                "                grads_and_vars = self._aggregate_gradients(grads_and_vars)\n",
                "            grads_and_vars = self._transform_gradients(grads_and_vars)\n",
                "\n",
                "            return tf.__internal__.distribute.interim.maybe_merge_call(\n",
                "                functools.partial(\n",
                "                    self._distributed_apply, apply_state=apply_state\n",
                "                ),\n",
                "                strategy,\n",
                "                grads_and_vars,\n",
                "                name=name,\n",
                "            )\n",
                "\n",
                "    def _distributed_apply(\n",
                "        self, distribution, grads_and_vars, apply_state, name\n",
                "    ):\n",
                "        \"\"\"`apply_gradients` using a `DistributionStrategy`.\"\"\"\n",
                "\n",
                "        def apply_grad_to_update_var(var, grad):\n",
                "            \"\"\"Apply gradient to variable.\"\"\"\n",
                "            if isinstance(var, tf.Tensor):\n",
                "                raise NotImplementedError(\n",
                "                    f\"Updating a `Tensor` is not implemented. \"\n",
                "                    f\"Received: var={var}.\"\n",
                "                )\n",
                "\n",
                "            apply_kwargs = {}\n",
                "            if isinstance(grad, tf.IndexedSlices):\n",
                "                if var.constraint is not None:\n",
                "                    raise RuntimeError(\n",
                "                        \"Cannot use a constraint function on a sparse \"\n",
                "                        f\"variable. Received: grad={grad}, \"\n",
                "                        f\"var.constraint={var.constraint}.\"\n",
                "                    )\n",
                "                if \"apply_state\" in self._sparse_apply_args:\n",
                "                    apply_kwargs[\"apply_state\"] = apply_state\n",
                "                return self._resource_apply_sparse_duplicate_indices(\n",
                "                    grad.values, var, grad.indices, **apply_kwargs\n",
                "                )\n",
                "\n",
                "            if \"apply_state\" in self._dense_apply_args:\n",
                "                apply_kwargs[\"apply_state\"] = apply_state\n",
                "            update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n",
                "            if var.constraint is not None:\n",
                "                with tf.control_dependencies([update_op]):\n",
                "                    return var.assign(var.constraint(var))\n",
                "            else:\n",
                "                return update_op\n",
                "\n",
                "        eagerly_outside_functions = (\n",
                "            tf.compat.v1.executing_eagerly_outside_functions()\n",
                "        )\n",
                "        update_ops = []\n",
                "        with name_scope_only_in_function_or_graph(name or self._name):\n",
                "            for grad, var in grads_and_vars:\n",
                "                # Colocate the update with variables to avoid unnecessary\n",
                "                # communication delays. See b/136304694.\n",
                "                with distribution.extended.colocate_vars_with(var):\n",
                "                    with name_scope_only_in_function_or_graph(\n",
                "                        \"update\"\n",
                "                        if eagerly_outside_functions\n",
                "                        else \"update_\" + var.op.name\n",
                "                    ):\n",
                "                        update_op = distribution.extended.update(\n",
                "                            var,\n",
                "                            apply_grad_to_update_var,\n",
                "                            args=(grad,),\n",
                "                            group=False,\n",
                "                        )\n",
                "                        if tf.distribute.in_cross_replica_context():\n",
                "                            # In cross-replica context, extended.update returns\n",
                "                            # a list of update ops from all replicas\n",
                "                            # (group=False).\n",
                "                            update_ops.extend(update_op)\n",
                "                        else:\n",
                "                            # In replica context, extended.update return the\n",
                "                            # single update op of current replica.\n",
                "                            update_ops.append(update_op)\n",
                "\n",
                "            any_symbolic = any(\n",
                "                isinstance(i, tf.Operation) or tf_utils.is_symbolic_tensor(i)\n",
                "                for i in update_ops\n",
                "            )\n",
                "            if not tf.executing_eagerly() or any_symbolic:\n",
                "                # If the current context is graph mode or any of the update ops\n",
                "                # are symbolic then the step update should be carried out under\n",
                "                # a graph context. (eager updates execute immediately)\n",
                "                with backend._current_graph(update_ops).as_default():\n",
                "                    with tf.control_dependencies([tf.group(update_ops)]):\n",
                "                        return self.iterations.assign_add(1, read_value=False)\n",
                "\n",
                "            return self.iterations.assign_add(1)\n",
                "\n",
                "    def get_gradients(self, loss, params):\n",
                "        \"\"\"Returns gradients of `loss` with respect to `params`.\n",
                "\n",
                "        Should be used only in legacy v1 graph mode.\n",
                "\n",
                "        Args:\n",
                "          loss: Loss tensor.\n",
                "          params: List of variables.\n",
                "\n",
                "        Returns:\n",
                "          List of gradient tensors.\n",
                "\n",
                "        Raises:\n",
                "          ValueError: In case any gradient cannot be computed (e.g. if gradient\n",
                "            function not implemented).\n",
                "        \"\"\"\n",
                "        params = tf.nest.flatten(params)\n",
                "        with backend.get_graph().as_default(), backend.name_scope(\n",
                "            self._name + \"/gradients\"\n",
                "        ):\n",
                "            grads = tf.compat.v1.gradients(loss, params)\n",
                "            for grad, param in zip(grads, params):\n",
                "                if grad is None:\n",
                "                    raise ValueError(\n",
                "                        \"Variable {} has `None` for gradient. \"\n",
                "                        \"Please make sure that all of your ops have a \"\n",
                "                        \"gradient defined (i.e. are differentiable). \"\n",
                "                        \"Common ops without gradient: \"\n",
                "                        \"K.argmax, K.round, K.eval.\".format(param)\n",
                "                    )\n",
                "        return grads\n",
                "\n",
                "    def get_updates(self, loss, params):\n",
                "        grads = self.get_gradients(loss, params)\n",
                "        grads_and_vars = list(zip(grads, params))\n",
                "        self._assert_valid_dtypes(\n",
                "            [\n",
                "                v\n",
                "                for g, v in grads_and_vars\n",
                "                if g is not None and v.dtype != tf.resource\n",
                "            ]\n",
                "        )\n",
                "        return [self.apply_gradients(grads_and_vars)]\n",
                "\n",
                "    def _set_hyper(self, name, value):\n",
                "        \"\"\"set hyper `name` to value. value can be callable, tensor, numeric.\"\"\"\n",
                "        if isinstance(value, tf.__internal__.tracking.Trackable):\n",
                "            self._track_trackable(value, name, overwrite=True)\n",
                "        if name not in self._hyper:\n",
                "            self._hyper[name] = value\n",
                "        else:\n",
                "            prev_value = self._hyper[name]\n",
                "            if (\n",
                "                callable(prev_value)\n",
                "                or isinstance(\n",
                "                    prev_value,\n",
                "                    (\n",
                "                        tf.Tensor,\n",
                "                        int,\n",
                "                        float,\n",
                "                        learning_rate_schedule.LearningRateSchedule,\n",
                "                    ),\n",
                "                )\n",
                "                or isinstance(\n",
                "                    value, learning_rate_schedule.LearningRateSchedule\n",
                "                )\n",
                "            ):\n",
                "                self._hyper[name] = value\n",
                "            else:\n",
                "                backend.set_value(self._hyper[name], value)\n",
                "\n",
                "    def _get_hyper(self, name, dtype=None):\n",
                "        if not self._hypers_created:\n",
                "            self._create_hypers()\n",
                "        value = self._hyper[name]\n",
                "        if isinstance(value, learning_rate_schedule.LearningRateSchedule):\n",
                "            return value\n",
                "        if callable(value):\n",
                "            value = value()\n",
                "        if dtype:\n",
                "            return tf.cast(value, dtype)\n",
                "        else:\n",
                "            return value\n",
                "\n",
                "    def _create_slots(self, var_list):\n",
                "        pass\n",
                "\n",
                "    def _create_slots_for_sharded_variables(self, var_list):\n",
                "        \"\"\"Add ShardedVariables to slots to later reconstruct for checkpointing.\n",
                "\n",
                "        ShardedVariables don't have slot variables created for them; their\n",
                "        shards do. This function allows users to call get_slot with a\n",
                "        ShardedVariable input and receive a ShardedVariable output containing\n",
                "        the appropriate slot vars.\n",
                "\n",
                "        Iterate over the variables to find shards, and aggregate the sharded\n",
                "        containers in a set. Add these ShardedVariables to _slots so that\n",
                "        get_slot can retrieve the proper slot variables for their component\n",
                "        shards, and reconstruct those into a ShardedVariable.\n",
                "\n",
                "        Args:\n",
                "          var_list: list or tuple of `Variable` objects that will be minimized\n",
                "            using this optimizer.\n",
                "        \"\"\"\n",
                "        sharded_vars = set()\n",
                "        for var in var_list:\n",
                "            if getattr(var, \"_sharded_container\", False):\n",
                "                sharded_vars.add(var._sharded_container())\n",
                "\n",
                "        for sharded_var in sharded_vars:\n",
                "            sharded_key = _var_key(sharded_var)\n",
                "            slot_dict = {}\n",
                "            for slot in self.get_slot_names():\n",
                "                slot_dict[slot] = sharded_var\n",
                "            self._slots[sharded_key] = slot_dict\n",
                "\n",
                "    def _create_all_weights(self, var_list):\n",
                "        \"\"\"Creates all weights, including iterations, hyperparameters and slot\n",
                "        vars.\n",
                "\n",
                "        This will add newly created variables to `optimizer.weights`.\n",
                "\n",
                "        New variables are only created when this method is called the first\n",
                "        time, or when called with different variables in the var_list.\n",
                "\n",
                "        Args:\n",
                "          var_list: list or tuple of `Variable` objects that will be minimized\n",
                "            using this optimizer.\n",
                "        \"\"\"\n",
                "\n",
                "        _ = self.iterations\n",
                "        self._create_hypers()\n",
                "        self._create_slots(var_list)\n",
                "        self._create_slots_for_sharded_variables(var_list)\n",
                "\n",
                "    def __getattribute__(self, name):\n",
                "        \"\"\"Overridden to support hyperparameter access.\"\"\"\n",
                "        try:\n",
                "            return super().__getattribute__(name)\n",
                "        except AttributeError as e:\n",
                "            # Needed to avoid infinite recursion with __setattr__.\n",
                "            if name == \"_hyper\":\n",
                "                raise e\n",
                "            # Backwards compatibility with Keras optimizers.\n",
                "            if name == \"lr\":\n",
                "                name = \"learning_rate\"\n",
                "            if name in self._hyper:\n",
                "                return self._get_hyper(name)\n",
                "            raise e\n",
                "\n",
                "    def __dir__(self):\n",
                "        result = set(super().__dir__())\n",
                "        if \"_hyper\" in result:\n",
                "            result |= self._hyper.keys()\n",
                "            if \"learning_rate\" in self._hyper.keys():\n",
                "                result.add(\"lr\")\n",
                "        return list(result)\n",
                "\n",
                "    def __setattr__(self, name, value):\n",
                "        \"\"\"Override setattr to support dynamic hyperparameter setting.\"\"\"\n",
                "        # Backwards compatibility with Keras optimizers.\n",
                "        if name == \"lr\":\n",
                "            name = \"learning_rate\"\n",
                "        if hasattr(self, \"_hyper\") and name in self._hyper:\n",
                "            self._set_hyper(name, value)\n",
                "        else:\n",
                "            super().__setattr__(name, value)\n",
                "\n",
                "    def get_slot_names(self):\n",
                "        \"\"\"A list of names for this optimizer's slots.\"\"\"\n",
                "        return self._slot_names\n",
                "\n",
                "    def add_slot(self, var, slot_name, initializer=\"zeros\", shape=None):\n",
                "        \"\"\"Add a new slot variable for `var`.\n",
                "\n",
                "        A slot variable is an additional variable associated with `var` to\n",
                "        train.  It is allocated and managed by optimizers, e.g. `Adam`.\n",
                "\n",
                "        Args:\n",
                "          var: a `Variable` object.\n",
                "          slot_name: name of the slot variable.\n",
                "          initializer: initializer of the slot variable\n",
                "          shape: (Optional) shape of the slot variable. If not set, it will\n",
                "            default to the shape of `var`.\n",
                "\n",
                "        Returns:\n",
                "          A slot variable.\n",
                "        \"\"\"\n",
                "        if slot_name not in self._slot_names:\n",
                "            self._slot_names.append(slot_name)\n",
                "        var_key = _var_key(var)\n",
                "        slot_dict = self._slots.setdefault(var_key, {})\n",
                "        weight = slot_dict.get(slot_name, None)\n",
                "        if weight is None:\n",
                "            if isinstance(initializer, str) or callable(initializer):\n",
                "                initializer = initializers.get(initializer)\n",
                "                if isinstance(\n",
                "                    initializer,\n",
                "                    tf.__internal__.tracking.CheckpointInitialValueCallable,\n",
                "                ) or (shape is not None):\n",
                "                    slot_shape = shape\n",
                "                else:\n",
                "                    slot_shape = var.shape\n",
                "                initial_value = functools.partial(\n",
                "                    initializer, shape=slot_shape, dtype=var.dtype\n",
                "                )\n",
                "            else:\n",
                "                initial_value = initializer\n",
                "\n",
                "            with self._distribution_strategy_scope():\n",
                "                strategy = tf.distribute.get_strategy()\n",
                "                if not strategy.extended.variable_created_in_scope(var):\n",
                "                    raise ValueError(\n",
                "                        \"Trying to create optimizer slot variable under the \"\n",
                "                        \"scope for tf.distribute.Strategy ({}), which is \"\n",
                "                        \"different from the scope used for the original \"\n",
                "                        \"variable ({}). Make sure the slot variables are \"\n",
                "                        \"created under the same strategy scope. This may \"\n",
                "                        \"happen if you're restoring from a checkpoint \"\n",
                "                        \"outside the scope.\".format(strategy, var)\n",
                "                    )\n",
                "\n",
                "                with strategy.extended.colocate_vars_with(var):\n",
                "                    weight = tf.Variable(\n",
                "                        name=f\"{var._shared_name}/{slot_name}\",\n",
                "                        dtype=var.dtype,\n",
                "                        trainable=False,\n",
                "                        initial_value=initial_value,\n",
                "                    )\n",
                "            backend.track_variable(weight)\n",
                "            slot_dict[slot_name] = weight\n",
                "            self._restore_slot_variable(\n",
                "                slot_name=slot_name, variable=var, slot_variable=weight\n",
                "            )\n",
                "            self._weights.append(weight)\n",
                "        return weight\n",
                "\n",
                "    def get_slot(self, var, slot_name):\n",
                "        var_key = _var_key(var)\n",
                "        slot_dict = self._slots[var_key]\n",
                "        slot_variable = slot_dict[slot_name]\n",
                "        if isinstance(\n",
                "            slot_variable, tf.__internal__.distribute.ShardedVariable\n",
                "        ):\n",
                "            # Construct a ShardedVariable that points to the input\n",
                "            # ShardedVariable's component shard's slot variables.\n",
                "            shard_vars = []\n",
                "            for shard in slot_variable.variables:\n",
                "                slot_shard = self.get_slot(shard, slot_name)\n",
                "                shard_vars.append(slot_shard)\n",
                "            slot_variable = tf.__internal__.distribute.ShardedVariable(\n",
                "                shard_vars, name=slot_variable.name\n",
                "            )\n",
                "        return slot_variable\n",
                "\n",
                "    def _prepare(self, var_list):\n",
                "        keys = set()\n",
                "        for var in var_list:\n",
                "            if isinstance(var, tf.distribute.DistributedValues):\n",
                "                var_devices = var._devices\n",
                "            else:\n",
                "                var_devices = [var.device]\n",
                "            var_dtype = var.dtype.base_dtype\n",
                "            for var_device in var_devices:\n",
                "                keys.add((var_device, var_dtype))\n",
                "\n",
                "        apply_state = {}\n",
                "        for var_device, var_dtype in keys:\n",
                "            apply_state[(var_device, var_dtype)] = {}\n",
                "            with tf.device(var_device):\n",
                "                self._prepare_local(var_device, var_dtype, apply_state)\n",
                "\n",
                "        return apply_state\n",
                "\n",
                "    def _prepare_local(self, var_device, var_dtype, apply_state):\n",
                "        if \"learning_rate\" in self._hyper:\n",
                "            lr_t = tf.identity(self._decayed_lr(var_dtype))\n",
                "            apply_state[(var_device, var_dtype)][\"lr_t\"] = lr_t\n",
                "\n",
                "    def _fallback_apply_state(self, var_device, var_dtype):\n",
                "        \"\"\"Compatibility for subclasses that don't pass apply_state through.\"\"\"\n",
                "        apply_state = {(var_device, var_dtype): {}}\n",
                "        self._prepare_local(var_device, var_dtype, apply_state)\n",
                "        return apply_state[(var_device, var_dtype)]\n",
                "\n",
                "    def _create_hypers(self):\n",
                "        if self._hypers_created:\n",
                "            return\n",
                "        with self._distribution_strategy_scope():\n",
                "            # Iterate hyper values deterministically.\n",
                "            for name, value in sorted(self._hyper.items()):\n",
                "                if isinstance(value, (tf.Tensor, tf.Variable)) or callable(\n",
                "                    value\n",
                "                ):\n",
                "                    # The check for `callable` covers the usage when `value` is\n",
                "                    # a `LearningRateSchedule`, in which case it does not need\n",
                "                    # to create a variable.\n",
                "                    continue\n",
                "                else:\n",
                "                    self._hyper[name] = self.add_weight(\n",
                "                        name,\n",
                "                        shape=[],\n",
                "                        trainable=False,\n",
                "                        initializer=value,\n",
                "                        aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,\n",
                "                    )\n",
                "        self._hypers_created = True\n",
                "\n",
                "    @property\n",
                "    def iterations(self):\n",
                "        \"\"\"Variable. The number of training steps this Optimizer has run.\"\"\"\n",
                "        if self._iterations is None:\n",
                "            with self._distribution_strategy_scope():\n",
                "                self._iterations = self.add_weight(\n",
                "                    \"iter\",\n",
                "                    shape=[],\n",
                "                    dtype=tf.int64,\n",
                "                    trainable=False,\n",
                "                    aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,\n",
                "                )\n",
                "            self._weights.append(self._iterations)\n",
                "        return self._iterations\n",
                "\n",
                "    @iterations.setter\n",
                "    def iterations(self, variable):\n",
                "        if self._iterations is not None:\n",
                "            raise RuntimeError(\n",
                "                \"Cannot set `iterations` to a new Variable after \"\n",
                "                \"the Optimizer weights have been created. Here it is \"\n",
                "                f\"attempting to set `iterations` to {variable}.\"\n",
                "            )\n",
                "        self._iterations = variable\n",
                "        self._weights.append(self._iterations)\n",
                "\n",
                "    def _decayed_lr(self, var_dtype):\n",
                "        \"\"\"Get decayed learning rate as a Tensor with dtype=var_dtype.\"\"\"\n",
                "        lr_t = self._get_hyper(\"learning_rate\", var_dtype)\n",
                "        if isinstance(lr_t, learning_rate_schedule.LearningRateSchedule):\n",
                "            local_step = tf.cast(self.iterations, var_dtype)\n",
                "            lr_t = tf.cast(lr_t(local_step), var_dtype)\n",
                "        if self._initial_decay > 0.0:\n",
                "            local_step = tf.cast(self.iterations, var_dtype)\n",
                "            decay_t = tf.cast(self._initial_decay, var_dtype)\n",
                "            lr_t = lr_t / (1.0 + decay_t * local_step)\n",
                "        return lr_t\n",
                "\n",
                "    @abc.abstractmethod\n",
                "    def get_config(self):\n",
                "        \"\"\"Returns the config of the optimizer.\n",
                "\n",
                "        An optimizer config is a Python dictionary (serializable)\n",
                "        containing the configuration of an optimizer.\n",
                "        The same optimizer can be reinstantiated later\n",
                "        (without any saved state) from this configuration.\n",
                "\n",
                "        Returns:\n",
                "            Python dictionary.\n",
                "        \"\"\"\n"
            ],
            {
                "type": "replace",
                "before": [
                    "        config = {\"name\": self._name}\n"
                ],
                "after": [
                    "        config = {\n",
                    "            \"name\": self._name,\n",
                    "            \"is_legacy_optimizer\": True,\n",
                    "        }\n"
                ],
                "parent_version_range": {
                    "start": 1184,
                    "end": 1185
                },
                "child_version_range": {
                    "start": 1184,
                    "end": 1188
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "OptimizerV2",
                        "signature": "class OptimizerV2(tf.__internal__.tracking.Trackable):",
                        "at_line": 103
                    },
                    {
                        "type": "function",
                        "name": "get_config",
                        "signature": "def get_config(self):",
                        "at_line": 1173
                    }
                ],
                "idx": 10,
                "hunk_diff": "File: keras/optimizers/optimizer_v2/optimizer_v2.py\nCode:\n             class OptimizerV2(tf.__internal__.tracking.Trackable):\n                 ...\n                 def get_config(self):\n                     ...\n1181 1181            Returns:\n1182 1182                Python dictionary.\n1183 1183            \"\"\"\n1184       -         config = {\"name\": self._name}\n     1184  +         config = {\n     1185  +             \"name\": self._name,\n     1186  +             \"is_legacy_optimizer\": True,\n     1187  +         }\n1185 1188            if self.clipnorm is not None:\n1186 1189                config[\"clipnorm\"] = self.clipnorm\n1187 1190            if self.clipvalue is not None:\n           ...\n",
                "file_path": "keras/optimizers/optimizer_v2/optimizer_v2.py",
                "identifiers_before": [
                    "_name",
                    "config",
                    "self"
                ],
                "identifiers_after": [
                    "_name",
                    "config",
                    "self"
                ],
                "prefix": [
                    "        Returns:\n",
                    "            Python dictionary.\n",
                    "        \"\"\"\n"
                ],
                "suffix": [
                    "        if self.clipnorm is not None:\n",
                    "            config[\"clipnorm\"] = self.clipnorm\n",
                    "        if self.clipvalue is not None:\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "        if self.clipnorm is not None:\n",
                "            config[\"clipnorm\"] = self.clipnorm\n",
                "        if self.clipvalue is not None:\n",
                "            config[\"clipvalue\"] = self.clipvalue\n",
                "        if self.global_clipnorm is not None:\n",
                "            config[\"global_clipnorm\"] = self.global_clipnorm\n",
                "        return config\n",
                "\n",
                "    @classmethod\n",
                "    def from_config(cls, config, custom_objects=None):\n",
                "        \"\"\"Creates an optimizer from its config.\n",
                "\n",
                "        This method is the reverse of `get_config`,\n",
                "        capable of instantiating the same optimizer from the config\n",
                "        dictionary.\n",
                "\n",
                "        Args:\n",
                "            config: A Python dictionary, typically the output of get_config.\n",
                "            custom_objects: A Python dictionary mapping names to additional\n",
                "              Python objects used to create this optimizer, such as a function\n",
                "              used for a hyperparameter.\n",
                "\n",
                "        Returns:\n",
                "            An optimizer instance.\n",
                "        \"\"\"\n",
                "        if \"lr\" in config:\n",
                "            config[\"learning_rate\"] = config.pop(\"lr\")\n",
                "        if \"learning_rate\" in config:\n",
                "            if isinstance(config[\"learning_rate\"], dict):\n",
                "                config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n",
                "                    config[\"learning_rate\"], custom_objects=custom_objects\n",
                "                )\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "        if \"is_legacy_optimizer\" in config:\n",
                    "            del config[\"is_legacy_optimizer\"]\n"
                ],
                "parent_version_range": {
                    "start": 1217,
                    "end": 1217
                },
                "child_version_range": {
                    "start": 1220,
                    "end": 1222
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if \"learning_rate\" in config:",
                        "start_line": 1212,
                        "end_line": 1216
                    },
                    {
                        "type": "if_statement",
                        "statement": "if isinstance(config[\"learning_rate\"], dict):",
                        "start_line": 1213,
                        "end_line": 1216
                    }
                ],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "OptimizerV2",
                        "signature": "class OptimizerV2(tf.__internal__.tracking.Trackable):",
                        "at_line": 103
                    },
                    {
                        "type": "function",
                        "name": "from_config",
                        "signature": "def from_config(cls, config, custom_objects=None):",
                        "at_line": 1194
                    },
                    {
                        "type": "call",
                        "name": "learning_rate_schedule.deserialize",
                        "signature": "learning_rate_schedule.deserialize(\n                    config[\"learning_rate\"], custom_objects=custom_objects\n                )",
                        "at_line": 1214
                    }
                ],
                "idx": 11,
                "hunk_diff": "File: keras/optimizers/optimizer_v2/optimizer_v2.py\nCode:\n             class OptimizerV2(tf.__internal__.tracking.Trackable):\n                 ...\n                 def from_config(cls, config, custom_objects=None):\n                     ...\n1214 1217                    config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n1215 1218                        config[\"learning_rate\"], custom_objects=custom_objects\n1216 1219                    )\n     1220  +         if \"is_legacy_optimizer\" in config:\n     1221  +             del config[\"is_legacy_optimizer\"]\n1217 1222            return cls(**config)\n1218 1223    \n1219 1224        def _serialize_hyperparameter(self, hyperparameter_name):\n           ...\n",
                "file_path": "keras/optimizers/optimizer_v2/optimizer_v2.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "config"
                ],
                "prefix": [
                    "                config[\"learning_rate\"] = learning_rate_schedule.deserialize(\n",
                    "                    config[\"learning_rate\"], custom_objects=custom_objects\n",
                    "                )\n"
                ],
                "suffix": [
                    "        return cls(**config)\n",
                    "\n",
                    "    def _serialize_hyperparameter(self, hyperparameter_name):\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    5,
                    8,
                    9
                ]
            },
            [
                "        return cls(**config)\n",
                "\n",
                "    def _serialize_hyperparameter(self, hyperparameter_name):\n",
                "        \"\"\"Serialize a hyperparameter that can be a float, callable, or\n",
                "        Tensor.\"\"\"\n",
                "        value = self._hyper[hyperparameter_name]\n",
                "        if isinstance(value, learning_rate_schedule.LearningRateSchedule):\n",
                "            return learning_rate_schedule.serialize(value)\n",
                "        if callable(value):\n",
                "            return value()\n",
                "        if tf.is_tensor(value):\n",
                "            return backend.get_value(value)\n",
                "        return value\n",
                "\n",
                "    def variables(self):\n",
                "        \"\"\"Returns variables of this Optimizer based on the order created.\"\"\"\n",
                "        return self._weights\n",
                "\n",
                "    @property\n",
                "    def weights(self):\n",
                "        \"\"\"Returns variables of this Optimizer based on the order created.\"\"\"\n",
                "        return self._weights\n",
                "\n",
                "    def get_weights(self):\n",
                "        \"\"\"Returns the current weights of the optimizer.\n",
                "\n",
                "        The weights of an optimizer are its state (ie, variables).\n",
                "        This function returns the weight values associated with this\n",
                "        optimizer as a list of Numpy arrays. The first value is always the\n",
                "        iterations count of the optimizer, followed by the optimizer's state\n",
                "        variables in the order they were created. The returned list can in turn\n",
                "        be used to load state into similarly parameterized optimizers.\n",
                "\n",
                "        For example, the RMSprop optimizer for this simple model returns a list\n",
                "        of three values-- the iteration count, followed by the root-mean-square\n",
                "        value of the kernel and bias of the single Dense layer:\n",
                "\n",
                "        >>> opt = tf.keras.optimizers.RMSprop()\n",
                "        >>> m = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
                "        >>> m.compile(opt, loss='mse')\n",
                "        >>> data = np.arange(100).reshape(5, 20)\n",
                "        >>> labels = np.zeros(5)\n",
                "        >>> results = m.fit(data, labels)  # Training.\n",
                "        >>> len(opt.get_weights())\n",
                "        3\n",
                "\n",
                "        Returns:\n",
                "            Weights values as a list of numpy arrays.\n",
                "        \"\"\"\n",
                "        params = self.weights\n",
                "        return backend.batch_get_value(params)\n",
                "\n",
                "    # TODO(tanzheny): Maybe share this logic with base_layer.\n",
                "    def set_weights(self, weights):\n",
                "        \"\"\"Set the weights of the optimizer.\n",
                "\n",
                "        The weights of an optimizer are its state (ie, variables).\n",
                "        This function takes the weight values associated with this\n",
                "        optimizer as a list of Numpy arrays. The first value is always the\n",
                "        iterations count of the optimizer, followed by the optimizer's state\n",
                "        variables in the order they are created. The passed values are used to\n",
                "        set the new state of the optimizer.\n",
                "\n",
                "        For example, the RMSprop optimizer for this simple model takes a list of\n",
                "        three values-- the iteration count, followed by the root-mean-square\n",
                "        value of the kernel and bias of the single Dense layer:\n",
                "\n",
                "        >>> opt = tf.keras.optimizers.RMSprop()\n",
                "        >>> m = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
                "        >>> m.compile(opt, loss='mse')\n",
                "        >>> data = np.arange(100).reshape(5, 20)\n",
                "        >>> labels = np.zeros(5)\n",
                "        >>> results = m.fit(data, labels)  # Training.\n",
                "        >>> new_weights = [np.array(10), np.ones([20, 10]), np.zeros([10])]\n",
                "        >>> opt.set_weights(new_weights)\n",
                "        >>> opt.iterations\n",
                "        <tf.Variable 'RMSprop/iter:0' shape=() dtype=int64, numpy=10>\n",
                "\n",
                "        Args:\n",
                "            weights: weight values as a list of numpy arrays.\n",
                "        \"\"\"\n",
                "        params = self.weights\n",
                "        if len(params) != len(weights):\n",
                "            raise ValueError(\n",
                "                f\"You called `set_weights(weights)` on optimizer {self._name} \"\n",
                "                f\"with a  weight list of length {str(len(weights))}, \"\n",
                "                f\"but the optimizer was expecting {str(len(params))} \"\n",
                "                f\"weights. Provided weights: {str(weights)[:50]}...\"\n",
                "            )\n",
                "        if not params:\n",
                "            return\n",
                "        weight_value_tuples = []\n",
                "        param_values = backend.batch_get_value(params)\n",
                "        for pv, p, w in zip(param_values, params, weights):\n",
                "            if pv.shape != w.shape:\n",
                "                raise ValueError(\n",
                "                    f\"Optimizer weight shape {str(pv.shape)} \"\n",
                "                    \"not compatible with \"\n",
                "                    f\"provided weight shape {str(w.shape)}.\"\n",
                "                )\n",
                "            weight_value_tuples.append((p, w))\n",
                "        backend.batch_set_value(weight_value_tuples)\n",
                "\n",
                "    def add_weight(\n",
                "        self,\n",
                "        name,\n",
                "        shape,\n",
                "        dtype=None,\n",
                "        initializer=\"zeros\",\n",
                "        trainable=None,\n",
                "        synchronization=tf.VariableSynchronization.AUTO,\n",
                "        aggregation=tf.VariableAggregation.NONE,\n",
                "    ):\n",
                "\n",
                "        if dtype is None:\n",
                "            dtype = tf.float32\n",
                "        if isinstance(initializer, str) or callable(initializer):\n",
                "            initializer = initializers.get(initializer)\n",
                "\n",
                "        if synchronization == tf.VariableSynchronization.ON_READ:\n",
                "            if trainable:\n",
                "                raise ValueError(\n",
                "                    \"Synchronization value can be set to \"\n",
                "                    \"VariableSynchronization.ON_READ only for non-trainable \"\n",
                "                    \"variables. You have specified trainable=True and \"\n",
                "                    \"synchronization=VariableSynchronization.ON_READ.\"\n",
                "                )\n",
                "            else:\n",
                "                # Set trainable to be false when variable is to be synced on\n",
                "                # read.\n",
                "                trainable = False\n",
                "        elif trainable is None:\n",
                "            trainable = True\n",
                "\n",
                "        variable = self._add_variable_with_custom_getter(\n",
                "            name=name,\n",
                "            shape=shape,\n",
                "            getter=base_layer_utils.make_variable,\n",
                "            overwrite=True,\n",
                "            initializer=initializer,\n",
                "            dtype=dtype,\n",
                "            trainable=trainable,\n",
                "            use_resource=True,\n",
                "            synchronization=synchronization,\n",
                "            aggregation=aggregation,\n",
                "        )\n",
                "        backend.track_variable(variable)\n",
                "\n",
                "        return variable\n",
                "\n",
                "    def _init_set_name(self, name, zero_based=True):\n",
                "        if not name:\n",
                "            self._name = backend.unique_object_name(\n",
                "                generic_utils.to_snake_case(self.__class__.__name__),\n",
                "                zero_based=zero_based,\n",
                "            )\n",
                "        else:\n",
                "            self._name = name\n",
                "\n",
                "    def _assert_valid_dtypes(self, tensors):\n",
                "        \"\"\"Asserts tensors are all valid types (see `_valid_dtypes`).\n",
                "\n",
                "        Args:\n",
                "          tensors: Tensors to check.\n",
                "\n",
                "        Raises:\n",
                "          ValueError: If any tensor is not a valid type.\n",
                "        \"\"\"\n",
                "        valid_dtypes = self._valid_dtypes()\n",
                "        for t in tensors:\n",
                "            dtype = t.dtype.base_dtype\n",
                "            if dtype not in valid_dtypes:\n",
                "                raise ValueError(\n",
                "                    \"Invalid type {} for {}, expected: {}.\".format(\n",
                "                        dtype, t.name, [v for v in valid_dtypes]\n",
                "                    )\n",
                "                )\n",
                "\n",
                "    def _valid_dtypes(self):\n",
                "        \"\"\"Valid types for loss, variables and gradients.\n",
                "\n",
                "        Subclasses should override to allow other float types.\n",
                "\n",
                "        Returns:\n",
                "          Valid types for loss, variables and gradients.\n",
                "        \"\"\"\n",
                "        return _DEFAULT_VALID_DTYPES\n",
                "\n",
                "    def _call_if_callable(self, param):\n",
                "        \"\"\"Call the function if param is callable.\"\"\"\n",
                "        return param() if callable(param) else param\n",
                "\n",
                "    def _resource_apply_dense(self, grad, handle, apply_state):\n",
                "        \"\"\"Add ops to apply dense gradients to the variable `handle`.\n",
                "\n",
                "        Args:\n",
                "          grad: a `Tensor` representing the gradient.\n",
                "          handle: a `Tensor` of dtype `resource` which points to the variable to\n",
                "            be updated.\n",
                "          apply_state: A dict which is used across multiple apply calls.\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` which updates the value of the variable.\n",
                "        \"\"\"\n",
                "        raise NotImplementedError(\n",
                "            \"`_resource_apply_dense` must be implemented in \" \"subclasses.\"\n",
                "        )\n",
                "\n",
                "    def _resource_apply_sparse_duplicate_indices(\n",
                "        self, grad, handle, indices, **kwargs\n",
                "    ):\n",
                "        \"\"\"Add ops to apply sparse gradients to `handle`, with repeated indices.\n",
                "\n",
                "        Optimizers which override this method must deal with repeated indices.\n",
                "        See the docstring of `_apply_sparse_duplicate_indices` for details. By\n",
                "        default the correct behavior, to sum non-unique indices and their\n",
                "        associated gradients, is enforced by first pre-processing `grad` and\n",
                "        `indices` and passing them on to `_resource_apply_sparse`. Optimizers\n",
                "        which deal correctly with duplicate indices may instead override this\n",
                "        method to avoid the overhead of summing.\n",
                "\n",
                "        Args:\n",
                "          grad: a `Tensor` representing the gradient for the affected indices.\n",
                "          handle: a `Tensor` of dtype `resource` which points to the variable to\n",
                "            be updated.\n",
                "          indices: a `Tensor` of integral type representing the indices for\n",
                "            which the gradient is nonzero. Indices may be repeated.\n",
                "          **kwargs: May optionally contain `apply_state`\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` which updates the value of the variable.\n",
                "        \"\"\"\n",
                "        summed_grad, unique_indices = _deduplicate_indexed_slices(\n",
                "            values=grad, indices=indices\n",
                "        )\n",
                "        return self._resource_apply_sparse(\n",
                "            summed_grad, handle, unique_indices, **kwargs\n",
                "        )\n",
                "\n",
                "    def _resource_apply_sparse(self, grad, handle, indices, apply_state):\n",
                "        \"\"\"Add ops to apply sparse gradients to the variable `handle`.\n",
                "\n",
                "        Similar to `_apply_sparse`, the `indices` argument to this method has\n",
                "        been de-duplicated. Optimizers which deal correctly with non-unique\n",
                "        indices may instead override `_resource_apply_sparse_duplicate_indices`\n",
                "        to avoid this overhead.\n",
                "\n",
                "        Args:\n",
                "          grad: a `Tensor` representing the gradient for the affected indices.\n",
                "          handle: a `Tensor` of dtype `resource` which points to the variable to\n",
                "            be updated.\n",
                "          indices: a `Tensor` of integral type representing the indices for\n",
                "            which the gradient is nonzero. Indices are unique.\n",
                "          apply_state: A dict which is used across multiple apply calls.\n",
                "\n",
                "        Returns:\n",
                "          An `Operation` which updates the value of the variable.\n",
                "        \"\"\"\n",
                "        raise NotImplementedError(\n",
                "            \"`_resource_apply_sparse` Must be implemented in \" \"subclasses.\"\n",
                "        )\n",
                "\n",
                "    def _resource_scatter_add(self, x, i, v):\n",
                "        with tf.control_dependencies(\n",
                "            [\n",
                "                tf.raw_ops.ResourceScatterAdd(\n",
                "                    resource=x.handle, indices=i, updates=v\n",
                "                )\n",
                "            ]\n",
                "        ):\n",
                "            return x.value()\n",
                "\n",
                "    def _resource_scatter_update(self, x, i, v):\n",
                "        with tf.control_dependencies(\n",
                "            [\n",
                "                tf.raw_ops.ResourceScatterUpdate(\n",
                "                    resource=x.handle, indices=i, updates=v\n",
                "                )\n",
                "            ]\n",
                "        ):\n",
                "            return x.value()\n",
                "\n",
                "    @property\n",
                "    @layer_utils.cached_per_instance\n",
                "    def _dense_apply_args(self):\n",
                "        return tf_inspect.getfullargspec(self._resource_apply_dense).args\n",
                "\n",
                "    @property\n",
                "    @layer_utils.cached_per_instance\n",
                "    def _sparse_apply_args(self):\n",
                "        return tf_inspect.getfullargspec(self._resource_apply_sparse).args\n",
                "\n",
                "    # ---------------\n",
                "    # For implementing the trackable interface\n",
                "    # ---------------\n",
                "\n",
                "    def _restore_slot_variable(self, slot_name, variable, slot_variable):\n",
                "        \"\"\"Restore a newly created slot variable's value.\"\"\"\n",
                "        variable_key = _var_key(variable)\n",
                "        deferred_restorations = self._deferred_slot_restorations.get(\n",
                "            slot_name, {}\n",
                "        ).pop(variable_key, [])\n",
                "        # Iterate over restores, highest restore UID first to minimize the\n",
                "        # number of assignments.\n",
                "        deferred_restorations.sort(\n",
                "            key=lambda position: position.restore_uid, reverse=True\n",
                "        )\n",
                "        for checkpoint_position in deferred_restorations:\n",
                "            checkpoint_position.restore(slot_variable)\n",
                "\n",
                "    def _create_or_restore_slot_variable(\n",
                "        self, slot_variable_position, slot_name, variable\n",
                "    ):\n",
                "        \"\"\"Returns the slot variable that should have a value restored into it.\n",
                "\n",
                "        It is up to the caller to restore the value into the slot variable if a\n",
                "        valid slot variable is returned.\n",
                "\n",
                "        Called when a variable which has an associated slot variable is created\n",
                "        or restored. When executing eagerly, we create the slot variable with a\n",
                "        restoring initializer.\n",
                "\n",
                "        No new variables are created when graph building. Instead,\n",
                "        _restore_slot_variable catches these after normal creation and adds\n",
                "        restore ops to the graph. This method is nonetheless important when\n",
                "        graph building for the case when a slot variable has already been\n",
                "        created but `variable` has just been added to a dependency graph\n",
                "        (causing us to realize that the slot variable needs to be restored).\n",
                "\n",
                "        Args:\n",
                "          slot_variable_position: A `trackable._CheckpointPosition` object\n",
                "            indicating the slot variable `Trackable` object to be restored.\n",
                "          slot_name: The name of this `Optimizer`'s slot to restore into.\n",
                "          variable: The variable object this slot is being created for.\n",
                "\n",
                "        Returns:\n",
                "          A slot variable that should have a value restored into it, or None if\n",
                "          a slot variable should not be restored at this time.\n",
                "        \"\"\"\n",
                "        variable_key = _var_key(variable)\n",
                "        slot_dict = self._slots.get(variable_key, {})\n",
                "        slot_variable = slot_dict.get(slot_name, None)\n",
                "        if (\n",
                "            slot_variable is None\n",
                "            and tf.executing_eagerly()\n",
                "            and slot_variable_position.is_simple_variable()\n",
                "            # Defer slot variable creation if there is an active variable\n",
                "            # creator scope. Generally we'd like to eagerly create/restore slot\n",
                "            # variables when possible, but this may mean that scopes intended to\n",
                "            # catch `variable` also catch its eagerly created slot variable\n",
                "            # unintentionally (specifically make_template would add a dependency\n",
                "            # on a slot variable if not for this case). Deferring is mostly\n",
                "            # harmless (aside from double initialization), and makes variable\n",
                "            # creator scopes behave the same way they do when graph building.\n",
                "            #\n",
                "            # One notable case is with distribution strategy, which uses\n",
                "            # variable creator scope but always desires the `variable` and the\n",
                "            # slot to use the same scope, thus we can safely eagerly\n",
                "            # create/restore slot variables.\n",
                "            and (\n",
                "                not tf.compat.v1.get_default_graph()._variable_creator_stack\n",
                "                or self._distribution_strategy\n",
                "            )\n",
                "        ):\n",
                "            initializer = (\n",
                "                tf.__internal__.tracking.CheckpointInitialValueCallable(\n",
                "                    checkpoint_position=slot_variable_position\n",
                "                )\n",
                "            )\n",
                "            slot_variable = self.add_slot(\n",
                "                var=variable,\n",
                "                initializer=initializer,\n",
                "                slot_name=slot_name,\n",
                "                shape=slot_variable_position.value_shape(),\n",
                "            )\n",
                "            # Slot variables are not owned by any one object (because we don't\n",
                "            # want to save the slot variable if the optimizer is saved without\n",
                "            # the non-slot variable, or if the non-slot variable is saved\n",
                "            # without the optimizer; it's a dependency hypergraph with edges of\n",
                "            # the form (optimizer, non-slot variable, variable)). So we don't\n",
                "            # _track_ slot variables anywhere, and instead special-case this\n",
                "            # dependency and otherwise pretend it's a normal graph.\n",
                "        if slot_variable is not None:\n",
                "            # For sharded variables, we need the logic in get_slot to combine\n",
                "            # slot variables for its shards\n",
                "            if (slot_variable is variable) and (\n",
                "                isinstance(variable, tf.__internal__.distribute.ShardedVariable)\n",
                "            ):\n",
                "                return self.get_slot(variable, slot_name)\n",
                "            # If we've either made this slot variable, or if we've pulled out an\n",
                "            # existing slot variable, we should restore it.\n",
                "            return slot_variable\n",
                "        else:\n",
                "            # We didn't make the slot variable. Defer restoring until it gets\n",
                "            # created normally. We keep a list rather than the one with the\n",
                "            # highest restore UID in case slot variables have their own\n",
                "            # dependencies, in which case those could differ between restores.\n",
                "            self._deferred_slot_restorations.setdefault(\n",
                "                slot_name, {}\n",
                "            ).setdefault(variable_key, []).append(slot_variable_position)\n",
                "        return None\n",
                "\n",
                "    @contextlib.contextmanager\n",
                "    def _distribution_strategy_scope(self):\n",
                "        \"\"\"Returns the `tf.distribute.Strategy` this optimizer was created\n",
                "        under.\"\"\"\n",
                "        if self._distribution_strategy and not tf.distribute.has_strategy():\n",
                "            with self._distribution_strategy.scope():\n",
                "                yield self._distribution_strategy.scope()\n",
                "        else:\n",
                "            yield\n",
                "\n",
                "\n",
                "def _var_key(var):\n",
                "    \"\"\"Key for representing a primary variable, for looking up slots.\n",
                "\n",
                "    In graph mode the name is derived from the var shared name.\n",
                "    In eager mode the name is derived from the var unique id.\n",
                "    If distribution strategy exists, get the primary variable first.\n",
                "\n",
                "    Args:\n",
                "      var: the variable.\n",
                "\n",
                "    Returns:\n",
                "      the unique name of the variable.\n",
                "    \"\"\"\n",
                "\n",
                "    # Get the distributed variable if it exists.\n",
                "    if hasattr(var, \"_distributed_container\"):\n",
                "        var = var._distributed_container()\n",
                "    if getattr(var, \"_in_graph_mode\", False):\n",
                "        return var._shared_name\n",
                "    return var._unique_id\n",
                "\n",
                "\n",
                "def _get_slot_key_from_var(var, slot_name):\n",
                "    \"\"\"Get the slot key for the variable: var_name/slot_name.\"\"\"\n",
                "\n",
                "    name = _var_key(var)\n",
                "    return name + \"/\" + slot_name\n",
                "\n",
                "\n",
                "class RestoredOptimizer(OptimizerV2):\n",
                "    \"\"\"A non-functional Optimizer implementation for checkpoint compatibility.\n",
                "\n",
                "    Holds slot variables and hyperparameters when an optimizer is restored from\n",
                "    a SavedModel. These variables may be referenced in functions along with ops\n",
                "    created by the original optimizer, but currently we do not support using the\n",
                "    optimizer object itself (e.g. through `apply_gradients`).\n",
                "    \"\"\"\n",
                "\n",
                "    # TODO(allenl): Make the restored optimizer functional by tracing its apply\n",
                "    # methods.\n",
                "\n",
                "    def __init__(self):\n",
                "        super().__init__(\"RestoredOptimizer\")\n",
                "        self._hypers_created = True\n",
                "\n",
                "    def get_config(self):\n",
                "        # TODO(allenl): Save and restore the Optimizer's config\n",
                "        raise NotImplementedError(\n",
                "            \"Restoring functional Optimizers from SavedModels is not currently \"\n",
                "            \"supported. Please file a feature request if this limitation \"\n",
                "            \"bothers you.\"\n",
                "        )\n",
                "\n",
                "\n",
                "tf.__internal__.saved_model.load.register_revived_type(\n",
                "    \"optimizer\",\n",
                "    lambda obj: isinstance(obj, OptimizerV2),\n",
                "    versions=[\n",
                "        tf.__internal__.saved_model.load.VersionedTypeRegistration(\n",
                "            object_factory=lambda proto: RestoredOptimizer(),\n",
                "            version=2,\n",
                "            min_producer_version=1,\n",
                "            min_consumer_version=1,\n",
                "            setter=RestoredOptimizer._set_hyper,\n",
                "        )\n",
                "    ],\n",
                ")"
            ]
        ],
        "keras/optimizers/optimizer_v2/optimizer_v2_test.py": [
            [
                "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\"\"\"Functional test for OptimizerV2.\"\"\"\n",
                "\n",
                "import collections\n",
                "\n",
                "import numpy as np\n",
                "import tensorflow.compat.v2 as tf\n",
                "from absl.testing import parameterized\n",
                "\n",
                "import keras\n",
                "from keras import backend\n",
                "from keras import callbacks\n",
                "from keras import losses\n",
                "from keras.engine import input_layer\n",
                "from keras.engine import sequential\n",
                "from keras.engine import training\n",
                "from keras.layers import core\n",
                "from keras.layers import regularization\n",
                "from keras.optimizers import optimizer_v1\n",
                "from keras.optimizers.optimizer_v2 import adadelta\n",
                "from keras.optimizers.optimizer_v2 import adagrad\n",
                "from keras.optimizers.optimizer_v2 import adam\n",
                "from keras.optimizers.optimizer_v2 import adamax\n",
                "from keras.optimizers.optimizer_v2 import ftrl\n",
                "from keras.optimizers.optimizer_v2 import gradient_descent\n",
                "from keras.optimizers.optimizer_v2 import nadam\n",
                "from keras.optimizers.optimizer_v2 import optimizer_v2\n",
                "from keras.optimizers.optimizer_v2 import rmsprop\n",
                "from keras.optimizers.schedules import learning_rate_schedule\n",
                "from keras.testing_infra import test_combinations\n",
                "from keras.testing_infra import test_utils\n",
                "from keras.utils import np_utils\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.framework import (\n",
                "    test_util as tf_test_utils,\n",
                ")\n",
                "\n",
                "_DATA_TYPES = [tf.half, tf.float32, tf.float64]\n",
                "# TODO(b/141710709): complex support in NVCC and ROCM.\n",
                "if not tf_test_utils.IsBuiltWithNvcc() and not tf.test.is_built_with_rocm():\n",
                "    _DATA_TYPES += [tf.complex64, tf.complex128]\n",
                "\n",
                "\n",
                "class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testBasic(self):\n",
                "        for dtype in _DATA_TYPES:\n",
                "            with test_utils.use_gpu():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "                loss = lambda: 5 * var0 + 3 * var1\n",
                "                sgd = gradient_descent.SGD(3.0)\n",
                "\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                # Fetch params to validate initial values\n",
                "                self.assertAllClose([1.0, 2.0], self.evaluate(var0))\n",
                "                self.assertAllClose([3.0, 4.0], self.evaluate(var1))\n",
                "                # Run 1 step of sgd through optimizer\n",
                "                opt_op = sgd.minimize(loss, var_list=[var0, var1])\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                self.evaluate(opt_op)\n",
                "                # Validate updated params\n",
                "                self.assertAllClose([-14.0, -13.0], self.evaluate(var0))\n",
                "                self.assertAllClose([-6.0, -5.0], self.evaluate(var1))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testAdaptiveLearningRate(self):\n",
                "        for dtype in _DATA_TYPES:\n",
                "            with self.test_session():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "\n",
                "                def loss():\n",
                "                    return 5 * var0 + 3 * var1\n",
                "\n",
                "                sgd = gradient_descent.SGD(1.0)\n",
                "\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                # Fetch params to validate initial values\n",
                "                self.assertAllClose([1.0, 2.0], self.evaluate(var0))\n",
                "                self.assertAllClose([3.0, 4.0], self.evaluate(var1))\n",
                "                # Run 1 step of sgd through optimizer\n",
                "                opt_op = sgd.minimize(loss, [var0, var1])\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                self.evaluate(opt_op)\n",
                "                # Validate updated params\n",
                "                # var0 = [1., 2.] - 1.0 * [5, 5]\n",
                "                self.assertAllClose([-4.0, -3.0], self.evaluate(var0))\n",
                "                # var1 = [3., 4.] - 1.0 * [3, 3]\n",
                "                self.assertAllClose([0.0, 1.0], self.evaluate(var1))\n",
                "\n",
                "                sgd.learning_rate = 0.5\n",
                "                if tf.executing_eagerly():\n",
                "                    sgd.minimize(loss, [var0, var1])\n",
                "                else:\n",
                "                    self.evaluate(opt_op)\n",
                "                # Validate updated params\n",
                "                # var0 = [-4., -3.] - 0.5 * [5, 5]\n",
                "                self.assertAllClose([-6.5, -5.5], self.evaluate(var0))\n",
                "                # var1 = [0., 1.] - 0.5 * [3, 3]\n",
                "                self.assertAllClose([-1.5, -0.5], self.evaluate(var1))\n",
                "\n",
                "                sgd.learning_rate = learning_rate_schedule.InverseTimeDecay(\n",
                "                    0.5, decay_steps=1.0, decay_rate=0.5\n",
                "                )\n",
                "                if tf.executing_eagerly():\n",
                "                    sgd.minimize(loss, [var0, var1])\n",
                "                else:\n",
                "                    self.evaluate(opt_op)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testPrecomputedGradient(self):\n",
                "        for dtype in _DATA_TYPES:\n",
                "            with test_utils.use_gpu():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "                loss = lambda: 5 * var0 + 3 * var1\n",
                "                grad_loss = tf.constant([42, -42], dtype=dtype)\n",
                "                sgd = gradient_descent.SGD(3.0)\n",
                "\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                # Fetch params to validate initial values\n",
                "                self.assertAllClose([1.0, 2.0], self.evaluate(var0))\n",
                "                self.assertAllClose([3.0, 4.0], self.evaluate(var1))\n",
                "                # Run 1 step of sgd through optimizer\n",
                "                opt_op = sgd.minimize(\n",
                "                    loss, var_list=[var0, var1], grad_loss=grad_loss\n",
                "                )\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                self.evaluate(opt_op)\n",
                "                # Validate updated params\n",
                "                self.assertAllClose(\n",
                "                    [1.0 - 3 * 5 * 42.0, 2.0 - 3 * 5 * (-42.0)],\n",
                "                    self.evaluate(var0),\n",
                "                )\n",
                "                self.assertAllClose(\n",
                "                    [3.0 - 3 * 3 * 42.0, 4.0 - 3 * 3 * (-42.0)],\n",
                "                    self.evaluate(var1),\n",
                "                )\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testNoGradients(self):\n",
                "        for dtype in _DATA_TYPES:\n",
                "            with test_utils.use_gpu():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "                loss = lambda: 5 * var0\n",
                "                sgd_op = gradient_descent.SGD(3.0)\n",
                "                with self.assertRaisesRegex(ValueError, \"No gradients\"):\n",
                "                    # var1 has no gradient\n",
                "                    sgd_op.minimize(loss, var_list=[var1])\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testNoGradientsForAnyVariables_Minimize(self):\n",
                "        for dtype in _DATA_TYPES:\n",
                "            with test_utils.use_gpu():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "                loss = lambda: tf.constant(5.0)\n",
                "\n",
                "                sgd_op = gradient_descent.SGD(3.0)\n",
                "                with self.assertRaisesRegex(\n",
                "                    ValueError, \"No gradients provided for any variable\"\n",
                "                ):\n",
                "                    sgd_op.minimize(loss, var_list=[var0, var1])\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testNoGradientsForAnyVariables_ApplyGradients(self):\n",
                "        for dtype in _DATA_TYPES:\n",
                "            with test_utils.use_gpu():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "                sgd_op = gradient_descent.SGD(3.0)\n",
                "                with self.assertRaisesRegex(\n",
                "                    ValueError, \"No gradients provided for any variable\"\n",
                "                ):\n",
                "                    sgd_op.apply_gradients([(None, var0), (None, var1)])\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testGradientsAsVariables(self):\n",
                "        for i, dtype in enumerate(_DATA_TYPES):\n",
                "            with test_utils.use_gpu():\n",
                "                var0 = tf.Variable([1.0, 2.0], dtype=dtype)\n",
                "                var1 = tf.Variable([3.0, 4.0], dtype=dtype)\n",
                "                loss = lambda: 5 * var0 + 3 * var1\n",
                "\n",
                "                sgd = gradient_descent.SGD(3.0)\n",
                "                grads_and_vars = sgd._compute_gradients(loss, [var0, var1])\n",
                "                # Convert gradients to tf.Variables\n",
                "                converted_grads = [\n",
                "                    tf.Variable(tf.zeros([2], dtype), name=\"c_%d_%d\" % (i, j))\n",
                "                    for j, gv in enumerate(grads_and_vars)\n",
                "                ]\n",
                "                convert_ops = [\n",
                "                    tf.compat.v1.assign(converted_grads[j], gv[0])\n",
                "                    for j, gv in enumerate(grads_and_vars)\n",
                "                ]\n",
                "\n",
                "                # Run convert_ops to achieve the gradients converting\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                self.evaluate(convert_ops)\n",
                "                # Fetch params to validate initial values\n",
                "                self.assertAllClose([1.0, 2.0], self.evaluate(var0))\n",
                "                self.assertAllClose([3.0, 4.0], self.evaluate(var1))\n",
                "\n",
                "                # Run 1 step of sgd through optimizer\n",
                "                converted_grads_and_vars = list(\n",
                "                    zip(converted_grads, [var0, var1])\n",
                "                )\n",
                "                opt_op = sgd.apply_gradients(converted_grads_and_vars)\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                self.evaluate(convert_ops)\n",
                "                self.evaluate(opt_op)\n",
                "\n",
                "                # Validate updated params\n",
                "                self.assertAllClose([-14.0, -13.0], self.evaluate(var0))\n",
                "                self.assertAllClose([-6.0, -5.0], self.evaluate(var1))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testComputeGradientsWithTensors(self):\n",
                "        with test_utils.use_gpu():\n",
                "            x = tf.convert_to_tensor(1.0)\n",
                "\n",
                "            def f():\n",
                "                return x * x\n",
                "\n",
                "            sgd = gradient_descent.SGD(3.0)\n",
                "            grads_and_vars = sgd._compute_gradients(f, [x])\n",
                "            self.assertLen(grads_and_vars, 1)\n",
                "            grad, x_as_var = grads_and_vars[0]\n",
                "            self.assertIs(x, x_as_var)\n",
                "            self.assertEqual(2.0, self.evaluate(grad))\n",
                "\n",
                "            with self.assertRaises(NotImplementedError):\n",
                "                sgd.apply_gradients(grads_and_vars)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testConstraint(self):\n",
                "        constraint_01 = lambda x: tf.clip_by_value(x, -0.1, 0.0)\n",
                "        constraint_0 = lambda x: tf.clip_by_value(x, 0.0, 1.0)\n",
                "        with test_utils.use_gpu():\n",
                "            var0 = tf.Variable([1.0, 2.0], constraint=constraint_01)\n",
                "            var1 = tf.Variable([3.0, 4.0], constraint=constraint_0)\n",
                "            loss = lambda: 5 * var0 + 3 * var1\n",
                "            sgd = gradient_descent.SGD(3.0)\n",
                "\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            # Fetch params to validate initial values\n",
                "            self.assertAllClose([1.0, 2.0], self.evaluate(var0))\n",
                "            self.assertAllClose([3.0, 4.0], self.evaluate(var1))\n",
                "            # Run 1 step of sgd through optimizer\n",
                "            opt_op = sgd.minimize(loss, var_list=[var0, var1])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.evaluate(opt_op)\n",
                "            # Validate updated params\n",
                "            self.assertAllClose([-0.1, -0.1], self.evaluate(var0))\n",
                "            self.assertAllClose([0.0, 0.0], self.evaluate(var1))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testIterationWithoutMinimize(self):\n",
                "        with test_utils.use_gpu():\n",
                "            sgd = gradient_descent.SGD(3.0)\n",
                "            self.evaluate(sgd.iterations.initializer)\n",
                "            self.assertEqual(0, self.evaluate(sgd.iterations))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testConfig(self):\n",
                "        with test_utils.use_gpu():\n",
                "            opt = gradient_descent.SGD(learning_rate=1.0)\n",
                "            config = opt.get_config()\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "            self.assertEqual(config[\"is_legacy_optimizer\"], True)\n"
                ],
                "parent_version_range": {
                    "start": 306,
                    "end": 306
                },
                "child_version_range": {
                    "start": 306,
                    "end": 307
                },
                "control_flow": [
                    {
                        "type": "with_statement",
                        "statement": "with test_utils.use_gpu():",
                        "start_line": 303,
                        "end_line": 319
                    }
                ],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "OptimizerTest",
                        "signature": "class OptimizerTest(tf.test.TestCase, parameterized.TestCase):",
                        "at_line": 57
                    },
                    {
                        "type": "function",
                        "name": "testConfig",
                        "signature": "def testConfig(self):",
                        "at_line": 302
                    }
                ],
                "idx": 12,
                "hunk_diff": "File: keras/optimizers/optimizer_v2/optimizer_v2_test.py\nCode:\n           class OptimizerTest(tf.test.TestCase, parameterized.TestCase):\n               ...\n               def testConfig(self):\n                   ...\n303 303            with test_utils.use_gpu():\n304 304                opt = gradient_descent.SGD(learning_rate=1.0)\n305 305                config = opt.get_config()\n    306  +             self.assertEqual(config[\"is_legacy_optimizer\"], True)\n306 307                opt2 = gradient_descent.SGD.from_config(config)\n307 308                lr = opt._get_hyper(\"learning_rate\")\n308 309                lr2 = opt2._get_hyper(\"learning_rate\")\n         ...\n",
                "file_path": "keras/optimizers/optimizer_v2/optimizer_v2_test.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "assertEqual",
                    "config",
                    "self"
                ],
                "prefix": [
                    "        with test_utils.use_gpu():\n",
                    "            opt = gradient_descent.SGD(learning_rate=1.0)\n",
                    "            config = opt.get_config()\n"
                ],
                "suffix": [
                    "            opt2 = gradient_descent.SGD.from_config(config)\n",
                    "            lr = opt._get_hyper(\"learning_rate\")\n",
                    "            lr2 = opt2._get_hyper(\"learning_rate\")\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "            opt2 = gradient_descent.SGD.from_config(config)\n",
                "            lr = opt._get_hyper(\"learning_rate\")\n",
                "            lr2 = opt2._get_hyper(\"learning_rate\")\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            # assert both are equal float values.\n",
                "            self.assertEqual(self.evaluate(lr), self.evaluate(lr2))\n",
                "            var0 = tf.Variable([[1.0], [2.0]], dtype=tf.float32)\n",
                "            loss = lambda: 3 * var0\n",
                "            # learning rate variable created when calling minimize.\n",
                "            opt.minimize(loss, [var0])\n",
                "            opt3 = gradient_descent.SGD.from_config(config)\n",
                "            lr3 = opt3._get_hyper(\"learning_rate\")\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.assertEqual(self.evaluate(lr), self.evaluate(lr3))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testConfigWithLearningRateDecay(self):\n",
                "        with test_utils.use_gpu():\n",
                "            var0 = tf.Variable([[1.0], [2.0]], dtype=tf.float32)\n",
                "            for decay_schedule in [\n",
                "                learning_rate_schedule.InverseTimeDecay(\n",
                "                    0.5, decay_steps=1.0, decay_rate=0.1\n",
                "                ),\n",
                "                learning_rate_schedule.PiecewiseConstantDecay([5], [1.0, 0.5]),\n",
                "            ]:\n",
                "                step = 10\n",
                "                opt = gradient_descent.SGD(decay_schedule)\n",
                "                config = opt.get_config()\n",
                "                opt2 = gradient_descent.SGD.from_config(config)\n",
                "                # assert both are equal float values.\n",
                "                self.assertAllEqual(\n",
                "                    decay_schedule(step), opt._get_hyper(\"learning_rate\")(step)\n",
                "                )\n",
                "                self.assertAllEqual(\n",
                "                    decay_schedule(step), opt2._get_hyper(\"learning_rate\")(step)\n",
                "                )\n",
                "                loss = lambda: 3 * var0\n",
                "                # learning rate variable is created when calling minimize.\n",
                "                opt.minimize(loss, [var0])\n",
                "                self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "                config = opt.get_config()\n",
                "                opt3 = gradient_descent.SGD.from_config(config)\n",
                "                self.assertAllEqual(\n",
                "                    self.evaluate(opt._get_hyper(\"learning_rate\")(step)),\n",
                "                    opt3._get_hyper(\"learning_rate\")(step),\n",
                "                )\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testGradClipValue(self):\n",
                "        with test_utils.use_gpu():\n",
                "            var = tf.Variable([1.0, 2.0])\n",
                "            loss = lambda: 3 * var\n",
                "            opt = gradient_descent.SGD(learning_rate=1.0, clipvalue=1.0)\n",
                "            opt_op = opt.minimize(loss, [var])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.evaluate(opt_op)\n",
                "            self.assertAllClose([0.0, 1.0], self.evaluate(var))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testGradClipNorm(self):\n",
                "        with test_utils.use_gpu():\n",
                "            var = tf.Variable([1.0])\n",
                "            loss = lambda: 3 * var\n",
                "            opt = gradient_descent.SGD(learning_rate=1.0, clipnorm=1.0)\n",
                "            opt_op = opt.minimize(loss, [var])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.evaluate(opt_op)\n",
                "            self.assertAllClose([0.0], self.evaluate(var))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testGradGlobalClipNorm(self):\n",
                "        with test_utils.use_gpu():\n",
                "            # l2 norm is 5.0\n",
                "            var1 = tf.Variable([1.0])\n",
                "            var2 = tf.Variable([2.0])\n",
                "            loss = lambda: 3 * var1 + 4 * var2\n",
                "            opt = gradient_descent.SGD(learning_rate=1.0, global_clipnorm=2.0)\n",
                "            opt_op = opt.minimize(loss, [var1, var2])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.evaluate(opt_op)\n",
                "            # grad1 = 3.0 * 2.0 / 5.0 = 1.2\n",
                "            self.assertAllClose([-0.2], self.evaluate(var1))\n",
                "            # grad2 = 4.0 * 2.0 / 5.0 = 1.6\n",
                "            self.assertAllClose([0.4], self.evaluate(var2))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testInvalidClipNorm(self):\n",
                "        with self.assertRaisesRegex(ValueError, \">= 0\"):\n",
                "            gradient_descent.SGD(learning_rate=1.0, clipnorm=-1.0)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(\n",
                "            mode=[\"graph\", \"eager\"],\n",
                "            clip_type=[\"clipnorm\", \"global_clipnorm\", \"clipvalue\"],\n",
                "        )\n",
                "    )\n",
                "    def testConfigWithCliping(self, clip_type):\n",
                "        opt = gradient_descent.SGD(learning_rate=1.0, **{clip_type: 2.0})\n",
                "        config = opt.get_config()\n",
                "        opt = gradient_descent.SGD.from_config(config)\n",
                "        self.assertEqual(getattr(opt, clip_type), 2.0)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testInvalidKwargs(self):\n",
                "        with self.assertRaisesRegex(TypeError, \"Unexpected keyword argument\"):\n",
                "            gradient_descent.SGD(learning_rate=1.0, invalidkwargs=1.0)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testWeights(self):\n",
                "        with test_utils.use_gpu():\n",
                "            opt1 = adam.Adam(learning_rate=1.0)\n",
                "            var1 = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "            loss1 = lambda: 3 * var1\n",
                "            opt_op_1 = opt1.minimize(loss1, [var1])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            config = opt1.get_config()\n",
                "            opt2 = adam.Adam.from_config(config)\n",
                "            var2 = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "            loss2 = lambda: 3 * var2\n",
                "            opt_op_2 = opt2.minimize(loss2, [var2])\n",
                "            weights = opt1.get_weights()\n",
                "\n",
                "            # Assert set_weights and both variables get updated to same value.\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            opt2.set_weights(weights)\n",
                "            self.evaluate([opt_op_1, opt_op_2])\n",
                "            self.assertAllClose(self.evaluate(var1), self.evaluate(var2))\n",
                "            self.assertEqual(1, self.evaluate(opt1.iterations))\n",
                "            self.assertEqual(1, self.evaluate(opt2.iterations))\n",
                "\n",
                "            var3 = tf.Variable([1.0, 2.0, 3.0], dtype=tf.float32)\n",
                "            var4 = tf.Variable([4.0, 5.0, 6.0], dtype=tf.float32)\n",
                "            loss3 = lambda: 3 * var3 + 5 * var4\n",
                "            opt_op_3 = opt1.minimize(loss3, [var3, var4])\n",
                "\n",
                "            # Assert set_weights with ValueError since weight list does not\n",
                "            # match.\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            weights = opt1.get_weights()\n",
                "            with self.assertRaisesRegex(ValueError, \"but the optimizer was\"):\n",
                "                opt2.set_weights(weights)\n",
                "\n",
                "            # Assert set_weights and variables get updated to same value.\n",
                "            var5 = tf.Variable([1.0, 2.0, 3.0], dtype=tf.float32)\n",
                "            var6 = tf.Variable([4.0, 5.0, 6.0], dtype=tf.float32)\n",
                "            loss4 = lambda: 3 * var5 + 5 * var6\n",
                "            opt_op_4 = opt2.minimize(loss4, [var5, var6])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            opt2.set_weights(weights)\n",
                "            self.evaluate([opt_op_3, opt_op_4])\n",
                "            self.assertAllClose(\n",
                "                self.evaluate([var3, var4]), self.evaluate([var5, var6])\n",
                "            )\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testGettingHyperParameters(self):\n",
                "        with self.test_session():\n",
                "            opt = adam.Adam(learning_rate=1.0)\n",
                "            var = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "            loss = lambda: 3 * var\n",
                "            opt_op = opt.minimize(loss, [var])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.evaluate(opt_op)\n",
                "\n",
                "            lr = self.evaluate(opt.lr)\n",
                "            self.assertEqual(1.0, lr)\n",
                "\n",
                "            opt.lr = 2.0\n",
                "            lr = self.evaluate(opt.lr)\n",
                "            self.assertEqual(2.0, lr)\n",
                "\n",
                "            self.evaluate(opt.lr.assign(3.0))\n",
                "            lr = self.evaluate(opt.lr)\n",
                "            self.assertEqual(3.0, lr)\n",
                "\n",
                "            with self.assertRaises(AttributeError):\n",
                "                opt.not_an_attr += 3\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testGettingHyperParametersWithLrInConstructor(self):\n",
                "        with self.test_session():\n",
                "            opt = gradient_descent.SGD(lr=3.0)\n",
                "            var = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "            loss = lambda: 3 * var\n",
                "            opt_op = opt.minimize(loss, [var])\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.evaluate(opt_op)\n",
                "\n",
                "            self.assertIsInstance(opt.lr, tf.Variable)\n",
                "            self.assertIsInstance(opt.learning_rate, tf.Variable)\n",
                "\n",
                "            lr = self.evaluate(opt.lr)\n",
                "            self.assertEqual(3.0, lr)\n",
                "\n",
                "            opt.lr = 2.0\n",
                "            lr = self.evaluate(opt.lr)\n",
                "            self.assertEqual(2.0, lr)\n",
                "\n",
                "            self.evaluate(opt.lr.assign(4.0))\n",
                "            lr = self.evaluate(opt.lr)\n",
                "            self.assertEqual(4.0, lr)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testDir(self):\n",
                "        opt = gradient_descent.SGD(learning_rate=1.0, momentum=0.1)\n",
                "        dir_result = set(dir(opt))\n",
                "        self.assertIn(\"learning_rate\", dir_result)  # Hyperparameter\n",
                "        self.assertIn(\"lr\", dir_result)  # Hyperparameter\n",
                "        self.assertIn(\"momentum\", dir_result)  # Hyperparameter\n",
                "        self.assertIn(\"nesterov\", dir_result)  # Attribute\n",
                "        self.assertIn(\"minimize\", dir_result)  # Attribute\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testOptimizerWithKerasModel(self):\n",
                "        a = input_layer.Input(shape=(3,), name=\"input_a\")\n",
                "        b = input_layer.Input(shape=(3,), name=\"input_b\")\n",
                "\n",
                "        dense = core.Dense(4, name=\"dense\")\n",
                "        c = dense(a)\n",
                "        d = dense(b)\n",
                "        e = regularization.Dropout(0.5, name=\"dropout\")(c)\n",
                "\n",
                "        model = training.Model([a, b], [d, e])\n",
                "\n",
                "        optimizer = gradient_descent.SGD(learning_rate=0.001)\n",
                "        loss = \"mse\"\n",
                "        model.compile(optimizer, loss, metrics=[\"mae\"])\n",
                "\n",
                "        input_a_np = np.random.random((10, 3))\n",
                "        input_b_np = np.random.random((10, 3))\n",
                "\n",
                "        output_d_np = np.random.random((10, 4))\n",
                "        output_e_np = np.random.random((10, 4))\n",
                "\n",
                "        model.fit(\n",
                "            [input_a_np, input_b_np],\n",
                "            [output_d_np, output_e_np],\n",
                "            epochs=1,\n",
                "            batch_size=5,\n",
                "        )\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testOptimizerWithCallbacks(self):\n",
                "        np.random.seed(1331)\n",
                "        input_np = np.random.random((10, 3))\n",
                "        output_np = np.random.random((10, 4))\n",
                "        a = input_layer.Input(shape=(3,), name=\"input_a\")\n",
                "        model = sequential.Sequential()\n",
                "        model.add(core.Dense(4, kernel_initializer=\"zeros\", name=\"dense\"))\n",
                "        model.add(regularization.Dropout(0.5, name=\"dropout\"))\n",
                "        model(a)\n",
                "        optimizer = gradient_descent.SGD(learning_rate=0.1)\n",
                "        model.compile(optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
                "        # This does not reduce the LR after the first epoch (due to low delta).\n",
                "        cbks = [\n",
                "            callbacks.ReduceLROnPlateau(\n",
                "                monitor=\"val_loss\",\n",
                "                factor=0.1,\n",
                "                min_delta=0,\n",
                "                patience=1,\n",
                "                cooldown=5,\n",
                "            )\n",
                "        ]\n",
                "        model.fit(\n",
                "            input_np,\n",
                "            output_np,\n",
                "            batch_size=10,\n",
                "            validation_data=(input_np, output_np),\n",
                "            callbacks=cbks,\n",
                "            epochs=2,\n",
                "            verbose=0,\n",
                "        )\n",
                "        self.assertAllClose(\n",
                "            float(backend.get_value(model.optimizer.lr)), 0.1, atol=1e-4\n",
                "        )\n",
                "\n",
                "        # This should reduce the LR after the first epoch (due to high delta).\n",
                "        cbks = [\n",
                "            callbacks.ReduceLROnPlateau(\n",
                "                monitor=\"val_loss\",\n",
                "                factor=0.1,\n",
                "                min_delta=10,\n",
                "                patience=1,\n",
                "                cooldown=5,\n",
                "            )\n",
                "        ]\n",
                "        model.fit(\n",
                "            input_np,\n",
                "            output_np,\n",
                "            batch_size=10,\n",
                "            validation_data=(input_np, output_np),\n",
                "            callbacks=cbks,\n",
                "            epochs=2,\n",
                "            verbose=2,\n",
                "        )\n",
                "        self.assertAllClose(\n",
                "            float(backend.get_value(model.optimizer.lr)), 0.01, atol=1e-4\n",
                "        )\n",
                "\n",
                "    def testOptimizerSetIterations(self):\n",
                "        global_step = tf.compat.v1.train.get_or_create_global_step()\n",
                "        opt = adam.Adam(learning_rate=1.0)\n",
                "        opt.iterations = global_step\n",
                "        var = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        init_step_value = self.evaluate(global_step)\n",
                "        loss = lambda: 3 * var\n",
                "        opt_op = opt.minimize(loss, [var])\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.evaluate(opt_op)\n",
                "        new_step_value = self.evaluate(global_step)\n",
                "        self.assertEqual(new_step_value, init_step_value + 1)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testOptimizerWithCallableVarList(self):\n",
                "        train_samples = 20\n",
                "        input_dim = 1\n",
                "        num_classes = 2\n",
                "        (x, y), _ = test_utils.get_test_data(\n",
                "            train_samples=train_samples,\n",
                "            test_samples=10,\n",
                "            input_shape=(input_dim,),\n",
                "            num_classes=num_classes,\n",
                "        )\n",
                "        y = np_utils.to_categorical(y)\n",
                "\n",
                "        num_hidden = 1\n",
                "        model = test_utils.get_small_sequential_mlp(\n",
                "            num_hidden=num_hidden, num_classes=num_classes\n",
                "        )\n",
                "        opt = adam.Adam()\n",
                "\n",
                "        loss = lambda: losses.mean_squared_error(model(x), y)\n",
                "        var_list = lambda: model.trainable_weights\n",
                "\n",
                "        with self.assertRaisesRegex(\n",
                "            ValueError, \"Weights for model .* have not yet been created\"\n",
                "        ):\n",
                "            var_list()\n",
                "        train_op = opt.minimize(loss, var_list)\n",
                "        if not tf.executing_eagerly():\n",
                "            self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "            self.assertEqual(\n",
                "                [[0.0]], self.evaluate(opt.get_slot(var_list()[0], \"m\"))\n",
                "            )\n",
                "            self.evaluate(train_op)\n",
                "        self.assertNotEqual(\n",
                "            [[0.0]], self.evaluate(opt.get_slot(var_list()[0], \"m\"))\n",
                "        )\n",
                "        self.assertLen(var_list(), 4)\n",
                "\n",
                "    def testVarKey(self):\n",
                "        with tf.compat.v1.get_default_graph().as_default():\n",
                "            a = tf.Variable([1.0, 2.0], name=\"var\")\n",
                "            b = tf.Variable([1.0], name=\"var\")\n",
                "            self.assertTrue(a._in_graph_mode)\n",
                "            self.assertTrue(b._in_graph_mode)\n",
                "            var_key = optimizer_v2._var_key(a)\n",
                "            self.assertEqual(\"var\", var_key)\n",
                "            var_key = optimizer_v2._var_key(b)\n",
                "            self.assertEqual(\"var_1\", var_key)\n",
                "\n",
                "    def testVarName(self):\n",
                "        with tf.compat.v1.get_default_graph().as_default():\n",
                "            var = tf.Variable([1.0, 2.0], name=\"var\")\n",
                "            loss = var + 1.0\n",
                "            opt = adam.Adam()\n",
                "            opt.get_updates(loss, [var])\n",
                "            opt_vars = opt.variables()\n",
                "            self.assertLen(opt_vars, 3)\n",
                "            self.assertEqual(\"Adam/iter:0\", opt_vars[0].name)\n",
                "            self.assertEqual(\"Adam/var/m:0\", opt_vars[1].name)\n",
                "            var_2 = tf.Variable([1.0, 2.0], name=\"var_2\")\n",
                "            loss = var_2 + 1.0\n",
                "            with backend.name_scope(\"outter\"):\n",
                "                opt.get_updates(loss, [var_2])\n",
                "            opt_vars = opt.variables()\n",
                "            self.assertLen(opt_vars, 5)\n",
                "            self.assertEqual(\"outter/Adam/var_2/m:0\", opt_vars[3].name)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testEmptyVarList(self):\n",
                "        opt = gradient_descent.SGD(1.0)\n",
                "        opt.minimize(lambda: tf.constant(1.0), [])\n",
                "        opt.apply_gradients([])\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testAggregationTrue(self):\n",
                "        # Test that experimental_aggregate_gradients=True works without\n",
                "        # distributed strategy.\n",
                "        var = tf.Variable([1.0, 2.0])\n",
                "        opt = gradient_descent.SGD(3.0)\n",
                "\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.assertAllClose([1.0, 2.0], self.evaluate(var))\n",
                "        opt_op = opt.apply_gradients(\n",
                "            [([0.1, 0.1], var)], experimental_aggregate_gradients=True\n",
                "        )\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.evaluate(opt_op)\n",
                "        self.assertAllClose([0.7, 1.7], self.evaluate(var))\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def testAggregationFalse(self):\n",
                "        # Test that experimental_aggregate_gradients=False works without\n",
                "        # distributed strategy.\n",
                "        var = tf.Variable([1.0, 2.0])\n",
                "        opt = gradient_descent.SGD(3.0)\n",
                "\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.assertAllClose([1.0, 2.0], self.evaluate(var))\n",
                "        opt_op = opt.apply_gradients(\n",
                "            [([0.1, 0.1], var)], experimental_aggregate_gradients=False\n",
                "        )\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.evaluate(opt_op)\n",
                "        self.assertAllClose([0.7, 1.7], self.evaluate(var))\n",
                "\n",
                "    @test_combinations.generate(test_combinations.combine(mode=[\"eager\"]))\n",
                "    def testRestoringIterationsWithoutAnOptimizer(self):\n",
                "        opt = gradient_descent.SGD(3.0)\n",
                "        opt.iterations.assign(5)\n",
                "        checkpoint = tf.train.Checkpoint(optimizer=opt)\n",
                "        path = checkpoint.save(self.get_temp_dir())\n",
                "\n",
                "        # Following verifies that the `iterations` can be restored with the\n",
                "        # absence of an `Optimizer` object (using a `Checkpoint` as a\n",
                "        # placeholder).\n",
                "        iterations_var = tf.Variable(0, dtype=tf.int64)\n",
                "        optimizer_checkpoint = tf.train.Checkpoint(iter=iterations_var)\n",
                "        checkpoint_to_restore = tf.train.Checkpoint(\n",
                "            optimizer=optimizer_checkpoint\n",
                "        )\n",
                "        checkpoint_to_restore.restore(path)\n",
                "\n",
                "        self.assertEqual(5, self.evaluate(iterations_var))\n",
                "\n",
                "    @test_combinations.generate(test_combinations.combine(mode=[\"eager\"]))\n",
                "    def testSlotWithNonstandardShapeRestoresBasedOnCheckpoint(self):\n",
                "        # First create an optimizer and a slot variable with a non-standard\n",
                "        # shape.\n",
                "        x = tf.Variable([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n",
                "        slot_shape = [2, 1]\n",
                "        optimizer_1 = optimizer_v2.OptimizerV2(name=\"test\")\n",
                "        optimizer_1.add_slot(x, \"test_slot\", \"ones\", shape=slot_shape)\n",
                "\n",
                "        # Then save the variable and optimizer to a checkpoint.\n",
                "        checkpoint_1 = tf.train.Checkpoint(var=x, optimizer=optimizer_1)\n",
                "        checkpoint_path = checkpoint_1.save(self.get_temp_dir())\n",
                "\n",
                "        # Create a new optimizer and call restore on it (and x)\n",
                "        optimizer_2 = optimizer_v2.OptimizerV2(name=\"test\")\n",
                "        checkpoint_2 = tf.train.Checkpoint(var=x, optimizer=optimizer_2)\n",
                "        checkpoint_2.restore(checkpoint_path)\n",
                "\n",
                "        self.assertEqual(\n",
                "            slot_shape, optimizer_2.get_slot(x, \"test_slot\").shape.as_list()\n",
                "        )\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def test_gradient_aggregator(self):\n",
                "        def gradient_aggregator(grads_and_vars):\n",
                "            # Simulate an all-reduce where the other replica has zeros for\n",
                "            # gradients, by dividing each gradient by 2.\n",
                "            grads = [g for g, _ in grads_and_vars]\n",
                "            vars = [v for _, v in grads_and_vars]\n",
                "            all_reduced_grads = [g / 2 for g in grads]\n",
                "            return list(zip(all_reduced_grads, vars))\n",
                "\n",
                "        var = tf.Variable(2.0)\n",
                "        sgd = gradient_descent.SGD(1.0, gradient_aggregator=gradient_aggregator)\n",
                "        loss = lambda: 2 * var\n",
                "        opt_op = sgd.minimize(loss, var_list=[var])\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.evaluate(opt_op)\n",
                "        self.assertEqual(self.evaluate(var), 1.0)\n",
                "\n",
                "    @test_combinations.generate(\n",
                "        test_combinations.combine(mode=[\"graph\", \"eager\"])\n",
                "    )\n",
                "    def test_override_aggregate_gradients(self):\n",
                "        class MyOptimizer(gradient_descent.SGD):\n",
                "            def _aggregate_gradients(self, grads_and_vars):\n",
                "                # Simulate an all-reduce where the other replica has zeros for\n",
                "                # gradients, by dividing each gradient by 2.\n",
                "                grads = [g for g, _ in grads_and_vars]\n",
                "                vars = [v for _, v in grads_and_vars]\n",
                "                all_reduced_grads = [g / 2 for g in grads]\n",
                "                return list(zip(all_reduced_grads, vars))\n",
                "\n",
                "        var = tf.Variable(2.0)\n",
                "        sgd = MyOptimizer(1.0)\n",
                "        loss = lambda: 2 * var\n",
                "        opt_op = sgd.minimize(loss, var_list=[var])\n",
                "        self.evaluate(tf.compat.v1.global_variables_initializer())\n",
                "        self.evaluate(opt_op)\n",
                "        self.assertEqual(self.evaluate(var), 1.0)\n",
                "\n",
                "    @test_combinations.generate(test_combinations.combine(mode=[\"eager\"]))\n",
                "    def test_create_slots_for_sharded_variables(self):\n",
                "        # set names so that ShardedVariable is well-named for slot variable\n",
                "        # keying.\n",
                "        var_a = tf.Variable([1.0], name=\"part_0\")\n",
                "        var_b = tf.Variable([2.0], name=\"part_1\")\n",
                "        sharded_var = tf.__internal__.distribute.ShardedVariable([var_a, var_b])\n",
                "\n",
                "        opt = adagrad.Adagrad()\n",
                "        opt._create_slots(sharded_var.variables)\n",
                "        opt._create_slots_for_sharded_variables(sharded_var.variables)\n",
                "\n",
                "        sharded_slot = opt.get_slot(sharded_var, \"accumulator\")\n",
                "        self.assertIsInstance(\n",
                "            sharded_slot, tf.__internal__.distribute.ShardedVariable\n",
                "        )\n",
                "\n",
                "        slot_a = opt.get_slot(var_a, \"accumulator\")\n",
                "        self.assertAllClose(sharded_slot.variables[0], slot_a)\n",
                "        slot_b = opt.get_slot(var_b, \"accumulator\")\n",
                "        self.assertAllClose(sharded_slot.variables[1], slot_b)\n",
                "\n",
                "\n",
                "@test_combinations.run_all_keras_modes\n",
                "class OptimizersCompatibilityTest(test_combinations.TestCase):\n",
                "    def _testOptimizersCompatibility(self, opt_v1, opt_v2, test_weights=True):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        np.random.seed(1331)\n",
                "        with test_utils.use_gpu():\n",
                "            train_samples = 20\n",
                "            input_dim = 3\n",
                "            num_classes = 2\n",
                "            (x, y), _ = test_utils.get_test_data(\n",
                "                train_samples=train_samples,\n",
                "                test_samples=10,\n",
                "                input_shape=(input_dim,),\n",
                "                num_classes=num_classes,\n",
                "            )\n",
                "            y = np_utils.to_categorical(y)\n",
                "\n",
                "            num_hidden = 5\n",
                "            model_v1 = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_v1.compile(\n",
                "                opt_v1,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "            model_v1.fit(x, y, batch_size=5, epochs=1)\n",
                "\n",
                "            model_v2 = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_v2.set_weights(model_v1.get_weights())\n",
                "            model_v2.compile(\n",
                "                opt_v2,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "            if not tf.compat.v1.executing_eagerly_outside_functions():\n",
                "                model_v2._make_train_function()\n",
                "            if test_weights:\n",
                "                opt_v2.set_weights(opt_v1.get_weights())\n",
                "\n",
                "            hist_1 = model_v1.fit(x, y, batch_size=5, epochs=1, shuffle=False)\n",
                "            hist_2 = model_v2.fit(x, y, batch_size=5, epochs=1, shuffle=False)\n",
                "            self.assertAllClose(\n",
                "                model_v1.get_weights(),\n",
                "                model_v2.get_weights(),\n",
                "                rtol=1e-5,\n",
                "                atol=1e-5,\n",
                "            )\n",
                "            self.assertAllClose(\n",
                "                hist_1.history[\"loss\"],\n",
                "                hist_2.history[\"loss\"],\n",
                "                rtol=1e-5,\n",
                "                atol=1e-5,\n",
                "            )\n",
                "\n",
                "    def testAdadeltaCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.Adadelta(lr=0.01)\n",
                "        opt_v2 = adadelta.Adadelta(learning_rate=0.01)\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testAdagradCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.Adagrad(lr=0.01)\n",
                "        opt_v2 = adagrad.Adagrad(learning_rate=0.01)\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testAdamCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.Adam()\n",
                "        opt_v2 = adam.Adam()\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testAdamaxCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.Adamax(lr=0.01)\n",
                "        opt_v2 = adamax.Adamax(learning_rate=0.01)\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testNadamCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.Nadam(lr=0.001)\n",
                "        opt_v2 = nadam.Nadam(learning_rate=0.001)\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testMomentumCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.SGD(lr=0.01, momentum=0.9)\n",
                "        opt_v2 = gradient_descent.SGD(learning_rate=0.01, momentum=0.9)\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testRMSpropCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.RMSprop()\n",
                "        opt_v2 = rmsprop.RMSprop()\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2)\n",
                "\n",
                "    def testSGDCompatibility(self):\n",
                "        opt_v1 = optimizer_v1.SGD(lr=0.01)\n",
                "        opt_v2 = gradient_descent.SGD(learning_rate=0.01)\n",
                "        self._testOptimizersCompatibility(opt_v1, opt_v2, False)\n",
                "\n",
                "    def testNumericEquivalenceForNesterovMomentum(self):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        np.random.seed(1331)\n",
                "        with test_utils.use_gpu():\n",
                "            train_samples = 20\n",
                "            input_dim = 3\n",
                "            num_classes = 2\n",
                "            (x, y), _ = test_utils.get_test_data(\n",
                "                train_samples=train_samples,\n",
                "                test_samples=10,\n",
                "                input_shape=(input_dim,),\n",
                "                num_classes=num_classes,\n",
                "            )\n",
                "            y = np_utils.to_categorical(y)\n",
                "\n",
                "            num_hidden = 5\n",
                "            model_k_v1 = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_k_v2 = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_k_v2.set_weights(model_k_v1.get_weights())\n",
                "            model_tf = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_tf.set_weights(model_k_v2.get_weights())\n",
                "\n",
                "            opt_k_v1 = optimizer_v1.SGD(momentum=0.9, nesterov=True)\n",
                "            opt_k_v2 = gradient_descent.SGD(momentum=0.9, nesterov=True)\n",
                "            opt_tf = tf.compat.v1.train.MomentumOptimizer(\n",
                "                learning_rate=0.01, momentum=0.9, use_nesterov=True\n",
                "            )\n",
                "\n",
                "            model_k_v1.compile(\n",
                "                opt_k_v1,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "            model_k_v2.compile(\n",
                "                opt_k_v2,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "            model_tf.compile(\n",
                "                opt_tf,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "\n",
                "            hist_k_v1 = model_k_v1.fit(\n",
                "                x, y, batch_size=5, epochs=10, shuffle=False\n",
                "            )\n",
                "            hist_k_v2 = model_k_v2.fit(\n",
                "                x, y, batch_size=5, epochs=10, shuffle=False\n",
                "            )\n",
                "            hist_tf = model_tf.fit(x, y, batch_size=5, epochs=10, shuffle=False)\n",
                "\n",
                "            self.assertAllClose(\n",
                "                model_k_v1.get_weights(), model_tf.get_weights()\n",
                "            )\n",
                "            self.assertAllClose(\n",
                "                model_k_v1.get_weights(), model_k_v2.get_weights()\n",
                "            )\n",
                "            self.assertAllClose(opt_k_v1.get_weights(), opt_k_v2.get_weights())\n",
                "            self.assertAllClose(\n",
                "                hist_k_v1.history[\"loss\"], hist_tf.history[\"loss\"]\n",
                "            )\n",
                "            self.assertAllClose(\n",
                "                hist_k_v1.history[\"loss\"], hist_k_v2.history[\"loss\"]\n",
                "            )\n",
                "\n",
                "    def testNumericEquivalenceForAmsgrad(self):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        np.random.seed(1331)\n",
                "        with test_utils.use_gpu():\n",
                "            train_samples = 20\n",
                "            input_dim = 3\n",
                "            num_classes = 2\n",
                "            (x, y), _ = test_utils.get_test_data(\n",
                "                train_samples=train_samples,\n",
                "                test_samples=10,\n",
                "                input_shape=(input_dim,),\n",
                "                num_classes=num_classes,\n",
                "            )\n",
                "            y = np_utils.to_categorical(y)\n",
                "\n",
                "            num_hidden = 5\n",
                "            model_k_v1 = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_k_v2 = test_utils.get_small_sequential_mlp(\n",
                "                num_hidden=num_hidden,\n",
                "                num_classes=num_classes,\n",
                "                input_dim=input_dim,\n",
                "            )\n",
                "            model_k_v2.set_weights(model_k_v1.get_weights())\n",
                "\n",
                "            opt_k_v1 = optimizer_v1.Adam(amsgrad=True)\n",
                "            opt_k_v2 = adam.Adam(amsgrad=True)\n",
                "\n",
                "            model_k_v1.compile(\n",
                "                opt_k_v1,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "            model_k_v2.compile(\n",
                "                opt_k_v2,\n",
                "                loss=\"categorical_crossentropy\",\n",
                "                metrics=[],\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "\n",
                "            hist_k_v1 = model_k_v1.fit(\n",
                "                x, y, batch_size=5, epochs=10, shuffle=False\n",
                "            )\n",
                "            hist_k_v2 = model_k_v2.fit(\n",
                "                x, y, batch_size=5, epochs=10, shuffle=False\n",
                "            )\n",
                "\n",
                "            self.assertAllClose(\n",
                "                model_k_v1.get_weights(), model_k_v2.get_weights()\n",
                "            )\n",
                "            self.assertAllClose(opt_k_v1.get_weights(), opt_k_v2.get_weights())\n",
                "            self.assertAllClose(\n",
                "                hist_k_v1.history[\"loss\"], hist_k_v2.history[\"loss\"]\n",
                "            )\n",
                "\n",
                "\n",
                "# Note: These tests are kept in a separate class to avoid bugs in some\n",
                "# distributions of Python that break AutoGraph which is used by tf.function.\n",
                "@test_combinations.generate(test_combinations.combine(mode=[\"eager\"]))\n",
                "class OptimizerWithFunctionTest(tf.test.TestCase, parameterized.TestCase):\n",
                "    def testBasic(self):\n",
                "        var = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "        loss = lambda: 3 * var\n",
                "        opt = adam.Adam(learning_rate=1.0)\n",
                "\n",
                "        @tf.function\n",
                "        def fn():\n",
                "            opt.minimize(loss, [var])\n",
                "            return var\n",
                "\n",
                "        self.assertAllClose([0.0, 1.0], fn(), atol=1e-4)\n",
                "        self.assertAllClose([-1, 0.0], fn(), atol=1e-4)\n",
                "\n",
                "    def testBasicWithConstantDecay(self):\n",
                "        var = tf.Variable([1.0, 2.0], dtype=tf.float32)\n",
                "        loss = lambda: 3 * var\n",
                "        opt = adam.Adam(learning_rate=1.0)\n",
                "\n",
                "        @tf.function\n",
                "        def fn():\n",
                "            opt.minimize(loss, [var])\n",
                "            return var\n",
                "\n",
                "        self.assertAllClose([0.0, 1.0], fn(), atol=1e-4)\n",
                "        self.assertAllClose([-1, 0.0], fn(), atol=1e-4)\n",
                "\n",
                "    def testVarKeyWithVarCreatedInEager(self):\n",
                "        a = tf.Variable([1.0, 2.0], name=\"var\")\n",
                "        b = tf.Variable([1.0], name=\"var\")\n",
                "\n",
                "        @tf_test_utils.also_run_as_tf_function\n",
                "        def var_key_test():\n",
                "            self.assertFalse(a._in_graph_mode)\n",
                "            self.assertFalse(b._in_graph_mode)\n",
                "            var_key_a = optimizer_v2._var_key(a)\n",
                "            self.assertStartsWith(var_key_a, \"var_\")\n",
                "            var_key_b = optimizer_v2._var_key(b)\n",
                "            self.assertStartsWith(var_key_b, \"var_\")\n",
                "            self.assertNotEqual(var_key_a, var_key_b)\n",
                "\n",
                "        var_key_test()\n",
                "\n",
                "    def testLearningRateDecayUsedInTwoFunctions(self):\n",
                "        a = tf.Variable([1.0, 2.0], name=\"var\")\n",
                "        b = tf.Variable([1.0], name=\"var\")\n",
                "\n",
                "        learning_rate_decay = learning_rate_schedule.InverseTimeDecay(\n",
                "            0.5, decay_steps=1.0, decay_rate=0.5\n",
                "        )\n",
                "        opt = adam.Adam(learning_rate=learning_rate_decay)\n",
                "        loss_a = lambda: 3 * a\n",
                "        loss_b = lambda: 2 * b\n",
                "\n",
                "        @tf.function\n",
                "        def fn_a():\n",
                "            opt.minimize(loss_a, [a])\n",
                "            return a\n",
                "\n",
                "        @tf.function\n",
                "        def fn_b():\n",
                "            opt.minimize(loss_b, [b])\n",
                "            return b\n",
                "\n",
                "        fn_a()\n",
                "        fn_b()\n",
                "\n",
                "\n",
                "_NUM_LEARNERS = 50\n",
                "APPLY_SCOPE = \"debug_apply\"\n",
                "ALLOWLIST = [\n",
                "    # optimizer_v2._deduplicate_indexed_slices contains an indexed slice:\n",
                "    #   array_ops.shape(unique_indices)[0]\n",
                "    # which winds up expanding to [0:1:1] thereby creating three constants\n",
                "    # to represent the indices.\n",
                "    (\"embeddings/strided_slice/stack\", \"Const\"),\n",
                "]\n",
                "\n",
                "\n",
                "def get_inputs(op):\n",
                "    op_inputs = list(op.inputs) + op.control_inputs\n",
                "    names = [i.name for i in op_inputs]\n",
                "    op_inputs = [getattr(i, \"op\", i) for i in op_inputs]\n",
                "    return op_inputs, names\n",
                "\n",
                "\n",
                "def strip_name(node):\n",
                "    if \"Placeholder\" in node.op:\n",
                "        return\n",
                "    node.name = \"\"\n",
                "\n",
                "\n",
                "def topological_sort(graph):\n",
                "    graph_ops = graph.get_operations()\n",
                "\n",
                "    sources = []\n",
                "    result = []\n",
                "\n",
                "    inputs = {}\n",
                "    outputs = collections.defaultdict(set)\n",
                "    for op in graph_ops:\n",
                "        op_inputs = get_inputs(op)[0]\n",
                "        if not op_inputs:\n",
                "            sources.append(op)\n",
                "\n",
                "        inputs[op] = set(op_inputs)\n",
                "        for i in op_inputs:\n",
                "            outputs[i].add(op)\n",
                "\n",
                "    while sources:\n",
                "        op = sources.pop()\n",
                "        for op_output in outputs[op]:\n",
                "            inputs[op_output].remove(op)\n",
                "            if not inputs[op_output]:\n",
                "                sources.append(op_output)\n",
                "\n",
                "        result.append(op)\n",
                "\n",
                "    # Check correctness.\n",
                "    if len(result) != len(graph_ops):\n",
                "        raise ValueError(\n",
                "            f\"Sort result has {len(result)} ops, \"\n",
                "            f\"source graph has {len(graph_ops)}.\"\n",
                "        )\n",
                "\n",
                "    sort_check_seen = set()\n",
                "    for op in result:\n",
                "        sort_check_seen.add(op)\n",
                "        for i in get_inputs(op)[0]:\n",
                "            assert i in sort_check_seen\n",
                "\n",
                "    return result\n",
                "\n",
                "\n",
                "def identify_redundant_ops(graph):\n",
                "    \"\"\"Implements basic common subexpression elimination.\n",
                "\n",
                "    This is not intended to replicate the graph semantics of TensorFlow Graphs\n",
                "    (for instance it does not handle stateful op ordering), nor is it intended\n",
                "    to replace the common subexpression elimination Grappler pass. Rather, it\n",
                "    provides a high level sanity check that clearly redundant ops are not being\n",
                "    created.\n",
                "\n",
                "    Args:\n",
                "      graph: The graph to be analyzed.\n",
                "\n",
                "    Returns:\n",
                "      A count of the duplicate ops and a description of the structure of each.\n",
                "    \"\"\"\n",
                "    sorted_ops = topological_sort(graph)\n",
                "    duplicates = collections.defaultdict(list)\n",
                "    unified_node_defs = {}\n",
                "    name_map = {}\n",
                "\n",
                "    for op in sorted_ops:\n",
                "        input_names = []\n",
                "        for op_input, name in zip(*get_inputs(op)):\n",
                "            input_def = op_input.node_def\n",
                "\n",
                "            # Operations can have multiple outputs. We track which is used to\n",
                "            # prevent overzealous elimination.\n",
                "            input_def.name = name\n",
                "\n",
                "            input_def.input[:] = [name_map.get(i, i) for i in input_def.input]\n",
                "            strip_name(input_def)\n",
                "\n",
                "            # NodeDef.SerializeToString() does not provide identical serialized\n",
                "            # representations for identical NodeDefs, so we instead use string\n",
                "            # representation as a dict key.\n",
                "            key = repr(input_def)\n",
                "\n",
                "            if key in unified_node_defs:\n",
                "                input_names.append(unified_node_defs[key])\n",
                "\n",
                "            else:\n",
                "                unified_node_defs[key] = op_input.name\n",
                "                input_names.append(name)\n",
                "\n",
                "        node_def = op.node_def\n",
                "        node_def.input[:] = input_names\n",
                "        strip_name(node_def)\n",
                "\n",
                "        key = repr(node_def)\n",
                "        duplicates[key].append(op)\n",
                "        name_map[op.name] = duplicates[key][0].name\n",
                "\n",
                "    num_duplicates = 0\n",
                "    duplicate_types = []\n",
                "    for standard_def, op_defs in duplicates.items():\n",
                "        # We are only interested in testing the apply method of the optimizer\n",
                "        op_defs = [i for i in op_defs if APPLY_SCOPE in i.name]\n",
                "\n",
                "        # We only check for per-apply redundant ops.\n",
                "        if len(op_defs) < _NUM_LEARNERS:\n",
                "            continue\n",
                "\n",
                "        # Certain ops are simply not worth eliminating, and are instead simply\n",
                "        # ignored.\n",
                "        name, op_type = op_defs[0].name, op_defs[0].type\n",
                "        if any(\n",
                "            allowlisted_scope in name and op_type == allowlisted_type\n",
                "            for allowlisted_scope, allowlisted_type in ALLOWLIST\n",
                "        ):\n",
                "            continue\n",
                "\n",
                "        num_duplicates += len(op_defs)\n",
                "        traceback = []\n",
                "        for level in op_defs[0].traceback:\n",
                "            traceback.append(f\"  {level[0]} {level[2]}:{level[1]}\")\n",
                "\n",
                "        duplicate_types.append(\n",
                "            \"# Example name: {}\\n# Op creation stack:\\n{}\\n{}\".format(\n",
                "                op_defs[0].name, \"\\n\".join(traceback), standard_def\n",
                "            )\n",
                "        )\n",
                "\n",
                "    return num_duplicates, duplicate_types\n",
                "\n",
                "\n",
                "def make_model():\n",
                "    r\"\"\"Constructs a simple ensemble of weak learners model.\n",
                "\n",
                "    ---------    ---------             ---------    ---------\n",
                "    | Input |    | Input |     ...     | Input |    | Input |\n",
                "    ---------    ---------             ---------    ---------\n",
                "        |            |                     |            |\n",
                "        V            V                     V            V\n",
                "    ---------    ---------             ---------    ---------\n",
                "    | Embed |    | Embed |     ...     | Embed |    | Embed |\n",
                "    ---------    ---------             ---------    ---------\n",
                "        |            |                     |            |\n",
                "        V            V                     V            V\n",
                "    ---------    ---------             ---------    ---------\n",
                "    | Dense |    | Dense |     ...     | Dense |    | Dense |\n",
                "    ---------    ---------             ---------    ---------\n",
                "        \\            |                     |            /\n",
                "         \\           |                     |           /\n",
                "          ---------------------------------------------\n",
                "                                |\n",
                "                            ---------\n",
                "                            | Dense |\n",
                "                            ---------\n",
                "\n",
                "    This topology is chosen because it exercises both dense and sparse update\n",
                "    paths.\n",
                "\n",
                "    Returns:\n",
                "      A model for testing optimizer coefficient reuse.\n",
                "    \"\"\"\n",
                "    inputs = []\n",
                "    intermediates = []\n",
                "    for _ in range(_NUM_LEARNERS):\n",
                "        inp = keras.layers.Input(shape=(1,), dtype=tf.int32)\n",
                "        layer = keras.layers.Embedding(1, 4)(inp)\n",
                "        layer = keras.layers.Dense(1)(layer)\n",
                "\n",
                "        inputs.append(inp)\n",
                "        intermediates.append(layer)\n",
                "\n",
                "    layer = keras.layers.Concatenate(axis=-1)(intermediates)\n",
                "    layer = keras.layers.Dense(1)(layer)\n",
                "\n",
                "    return keras.models.Model(inputs, layer)\n",
                "\n",
                "\n",
                "COEFFICIENT_PARAMS = (\n",
                "    (\"Adadelta\", adadelta.Adadelta, None),\n",
                "    (\"Adagrad\", adagrad.Adagrad, None),\n",
                "    (\"Adam\", adam.Adam, None),\n",
                "    (\"Adam_amdgrad\", adam.Adam, dict(amsgrad=True)),\n",
                "    (\"Adamax\", adamax.Adamax, None),\n",
                "    (\"Ftrl\", ftrl.Ftrl, None),\n",
                "    (\n",
                "        \"Ftrl_l2_shrinkage\",\n",
                "        ftrl.Ftrl,\n",
                "        dict(l2_shrinkage_regularization_strength=0.1),\n",
                "    ),\n",
                "    (\"SGD\", gradient_descent.SGD, None),\n",
                "    (\"SGD_momentum\", gradient_descent.SGD, dict(momentum=0.5)),\n",
                "    (\"Nadam\", nadam.Nadam, None),\n",
                "    (\"RMSprop\", rmsprop.RMSprop, None),\n",
                "    (\"RMSprop_centered\", rmsprop.RMSprop, dict(centered=True)),\n",
                "    (\"RMSprop_momentum\", rmsprop.RMSprop, dict(momentum=0.5)),\n",
                "    (\n",
                "        \"RMSprop_momentum_centered\",\n",
                "        rmsprop.RMSprop,\n",
                "        dict(momentum=0.5, centered=True),\n",
                "    ),\n",
                ")\n",
                "\n",
                "\n",
                "class OptimizerCoefficientTest(test_combinations.TestCase):\n",
                "    @parameterized.named_parameters(*COEFFICIENT_PARAMS)\n",
                "    def test_duplicate_ops(self, optimizer_class, init_kwargs=None):\n",
                "        init_kwargs = init_kwargs or {}\n",
                "        optimizer = optimizer_class(**init_kwargs)\n",
                "\n",
                "        graph = tf.Graph()\n",
                "        with graph.as_default():\n",
                "            model = make_model()\n",
                "            trainable_variables = model.trainable_variables\n",
                "            grads = optimizer.get_gradients(\n",
                "                model.outputs[0], trainable_variables\n",
                "            )\n",
                "\n",
                "            with backend.name_scope(APPLY_SCOPE):\n",
                "                optimizer.apply_gradients(zip(grads, trainable_variables))\n",
                "\n",
                "        num_duplicates, duplicate_types = identify_redundant_ops(graph)\n",
                "        if num_duplicates:\n",
                "            # Avoid spamming logs.\n",
                "            if len(duplicate_types) > 3:\n",
                "                duplicate_types = duplicate_types[:3] + [\"...\"]\n",
                "\n",
                "            num_total = len(graph.get_operations())\n",
                "            raise ValueError(\n",
                "                \"{} of {} ({:.1f}%) ops were duplicates:\\n\\n{}\".format(\n",
                "                    num_duplicates,\n",
                "                    num_total,\n",
                "                    num_duplicates / num_total * 100,\n",
                "                    \"\\n\".join(duplicate_types),\n",
                "                )\n",
                "            )\n",
                "\n",
                "    @parameterized.named_parameters(*COEFFICIENT_PARAMS)\n",
                "    def test_subclass_compat(self, optimizer_class, init_kwargs=None):\n",
                "        \"\"\"Ensure that subclassed optimizers without apply_state still work.\"\"\"\n",
                "\n",
                "        class SubclassedOptimizer(optimizer_class):\n",
                "            def _resource_apply_dense(self, grad, var):\n",
                "                return super()._resource_apply_dense(grad, var)\n",
                "\n",
                "            def _resource_apply_sparse(self, grad, var, indices):\n",
                "                return super()._resource_apply_sparse(grad, var, indices)\n",
                "\n",
                "        init_kwargs = init_kwargs or {}\n",
                "        optimizer = SubclassedOptimizer(**init_kwargs)\n",
                "\n",
                "        graph = tf.Graph()\n",
                "        with graph.as_default():\n",
                "            model = make_model()\n",
                "            trainable_variables = model.trainable_variables\n",
                "            grads = optimizer.get_gradients(\n",
                "                model.outputs[0], trainable_variables\n",
                "            )\n",
                "\n",
                "            with backend.name_scope(APPLY_SCOPE):\n",
                "                optimizer.apply_gradients(zip(grads, trainable_variables))\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    tf.test.main()"
            ]
        ],
        "keras/optimizers/optimizers_test.py": [
            [
                "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
                "#\n",
                "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                "# you may not use this file except in compliance with the License.\n",
                "# You may obtain a copy of the License at\n",
                "#\n",
                "#     http://www.apache.org/licenses/LICENSE-2.0\n",
                "#\n",
                "# Unless required by applicable law or agreed to in writing, software\n",
                "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "# See the License for the specific language governing permissions and\n",
                "# limitations under the License.\n",
                "# ==============================================================================\n",
                "\"\"\"Tests for Keras optimizers.\"\"\"\n",
                "\n",
                "import gc\n",
                "import weakref\n",
                "\n",
                "import numpy as np\n",
                "import tensorflow.compat.v2 as tf\n",
                "\n",
                "import keras\n",
                "from keras.optimizers import optimizer_v1\n",
                "from keras.testing_infra import test_combinations\n",
                "from keras.testing_infra import test_utils\n",
                "from keras.utils import np_utils\n",
                "\n",
                "# isort: off\n",
                "from tensorflow.python.training.adam import AdamOptimizer\n",
                "from tensorflow.python.training.experimental.loss_scale_optimizer import (  # noqa: E501\n",
                "    MixedPrecisionLossScaleOptimizer,\n",
                ")\n",
                "\n",
                "\n",
                "def _get_model(input_dim, num_hidden, output_dim):\n",
                "    model = keras.models.Sequential()\n",
                "    model.add(\n",
                "        keras.layers.Dense(\n",
                "            num_hidden, activation=\"relu\", input_shape=(input_dim,)\n",
                "        )\n",
                "    )\n",
                "    model.add(keras.layers.Dense(output_dim, activation=\"softmax\"))\n",
                "    return model\n",
                "\n",
                "\n",
                "@test_combinations.run_all_keras_modes\n",
                "class KerasOptimizersTest(test_combinations.TestCase):\n",
                "    def _test_optimizer(self, optimizer, target=0.75):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        np.random.seed(1337)\n",
                "        (x_train, y_train), _ = test_utils.get_test_data(\n",
                "            train_samples=1000,\n",
                "            test_samples=200,\n",
                "            input_shape=(10,),\n",
                "            num_classes=2,\n",
                "        )\n",
                "        y_train = np_utils.to_categorical(y_train)\n",
                "        model = _get_model(x_train.shape[1], 20, y_train.shape[1])\n",
                "        model.compile(\n",
                "            loss=\"categorical_crossentropy\",\n",
                "            optimizer=optimizer,\n",
                "            metrics=[\"acc\"],\n",
                "            run_eagerly=test_utils.should_run_eagerly(),\n",
                "        )\n",
                "        np.testing.assert_equal(\n",
                "            keras.backend.get_value(model.optimizer.iterations), 0\n",
                "        )\n",
                "        history = model.fit(\n",
                "            x_train, y_train, epochs=2, batch_size=16, verbose=0\n",
                "        )\n",
                "        np.testing.assert_equal(\n",
                "            keras.backend.get_value(model.optimizer.iterations), 126\n",
                "        )  # 63 steps per epoch\n",
                "        self.assertGreaterEqual(history.history[\"acc\"][-1], target)\n",
                "        config = keras.optimizers.serialize(optimizer)\n",
                "        optim = keras.optimizers.deserialize(config)\n",
                "        new_config = keras.optimizers.serialize(optim)\n",
                "        new_config[\"class_name\"] = new_config[\"class_name\"].lower()\n",
                "        new_config[\"config\"].pop(\"name\", None)\n",
                "        if \"amsgrad\" not in config[\"config\"]:\n",
                "            new_config[\"config\"].pop(\"amsgrad\", None)\n",
                "        if (\n",
                "            \"decay\" in new_config[\"config\"]\n",
                "            and \"schedule_decay\" in config[\"config\"]\n",
                "        ):\n",
                "            new_config[\"config\"][\"schedule_decay\"] = new_config[\"config\"].pop(\n",
                "                \"decay\"\n",
                "            )\n",
                "        if \"momentum\" not in config[\"config\"]:\n",
                "            new_config[\"config\"].pop(\"momentum\", None)\n",
                "        if \"centered\" not in config[\"config\"]:\n",
                "            new_config[\"config\"].pop(\"centered\", None)\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "        if \"is_legacy_optimizer\" not in config[\"config\"]:\n",
                    "            new_config[\"config\"].pop(\"is_legacy_optimizer\", None)\n"
                ],
                "parent_version_range": {
                    "start": 94,
                    "end": 94
                },
                "child_version_range": {
                    "start": 94,
                    "end": 96
                },
                "control_flow": [
                    {
                        "type": "if_statement",
                        "statement": "if \"centered\" not in config[\"config\"]:",
                        "start_line": 92,
                        "end_line": 93
                    }
                ],
                "structural_path": [
                    {
                        "type": "class",
                        "name": "KerasOptimizersTest",
                        "signature": "class KerasOptimizersTest(test_combinations.TestCase):",
                        "at_line": 47
                    },
                    {
                        "type": "function",
                        "name": "_test_optimizer",
                        "signature": "def _test_optimizer(self, optimizer, target=0.75):",
                        "at_line": 48
                    },
                    {
                        "type": "call",
                        "name": "new_config[\"config\"].pop",
                        "signature": "new_config[\"config\"].pop(\"centered\", None)",
                        "at_line": 93,
                        "argument": "\"centered\""
                    }
                ],
                "idx": 13,
                "hunk_diff": "File: keras/optimizers/optimizers_test.py\nCode:\n         class KerasOptimizersTest(test_combinations.TestCase):\n             ...\n             def _test_optimizer(self, optimizer, target=0.75):\n                 ...\n91 91                new_config[\"config\"].pop(\"momentum\", None)\n92 92            if \"centered\" not in config[\"config\"]:\n93 93                new_config[\"config\"].pop(\"centered\", None)\n   94  +         if \"is_legacy_optimizer\" not in config[\"config\"]:\n   95  +             new_config[\"config\"].pop(\"is_legacy_optimizer\", None)\n94 96            self.assertDictEqual(config, new_config)\n95 97    \n96 98            # Test constraints.\n       ...\n",
                "file_path": "keras/optimizers/optimizers_test.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "config",
                    "new_config",
                    "pop"
                ],
                "prefix": [
                    "            new_config[\"config\"].pop(\"momentum\", None)\n",
                    "        if \"centered\" not in config[\"config\"]:\n",
                    "            new_config[\"config\"].pop(\"centered\", None)\n"
                ],
                "suffix": [
                    "        self.assertDictEqual(config, new_config)\n",
                    "\n",
                    "        # Test constraints.\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "        self.assertDictEqual(config, new_config)\n",
                "\n",
                "        # Test constraints.\n",
                "        model = keras.models.Sequential()\n",
                "        dense = keras.layers.Dense(\n",
                "            10,\n",
                "            input_shape=(x_train.shape[1],),\n",
                "            kernel_constraint=lambda x: 0.0 * x + 1.0,\n",
                "            bias_constraint=lambda x: 0.0 * x + 2.0,\n",
                "            activation=\"relu\",\n",
                "        )\n",
                "        model.add(dense)\n",
                "        model.add(keras.layers.Dense(y_train.shape[1], activation=\"softmax\"))\n",
                "        model.compile(\n",
                "            loss=\"categorical_crossentropy\",\n",
                "            optimizer=optimizer,\n",
                "            metrics=[\"accuracy\"],\n",
                "            run_eagerly=test_utils.should_run_eagerly(),\n",
                "        )\n",
                "        np.testing.assert_equal(\n",
                "            keras.backend.get_value(model.optimizer.iterations), 126\n",
                "        )  # Using same optimizer from before\n",
                "        model.train_on_batch(x_train[:10], y_train[:10])\n",
                "        np.testing.assert_equal(\n",
                "            keras.backend.get_value(model.optimizer.iterations), 127\n",
                "        )\n",
                "        kernel, bias = dense.get_weights()\n",
                "        np.testing.assert_allclose(kernel, 1.0, atol=1e-3)\n",
                "        np.testing.assert_allclose(bias, 2.0, atol=1e-3)\n",
                "\n",
                "    def test_sgd(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.SGD())\n",
                "\n",
                "    def test_momentum(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(\n",
                "                optimizer_v1.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
                "            )\n",
                "\n",
                "    def test_rmsprop(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.RMSprop())\n",
                "            self._test_optimizer(optimizer_v1.RMSprop(decay=1e-3))\n",
                "\n",
                "    def test_adagrad(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.Adagrad())\n",
                "            self._test_optimizer(optimizer_v1.Adagrad(decay=1e-3))\n",
                "\n",
                "    def test_adadelta(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.Adadelta(), target=0.6)\n",
                "            # Accuracy seems dependent on the initialization. Even adding\n",
                "            # tf.compat.v1.Print nodes in the graph seemed to affect the\n",
                "            # initialization seed, and hence the accuracy.\n",
                "            self._test_optimizer(optimizer_v1.Adadelta(decay=1e-3), target=0.4)\n",
                "\n",
                "    def test_adam(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.Adam())\n",
                "            # Accuracy seems dependent on the seed initialization.\n",
                "            # TODO(b/121051441): fix test flakiness.\n",
                "            self._test_optimizer(optimizer_v1.Adam(decay=1e-3), target=0.73)\n",
                "            self._test_optimizer(optimizer_v1.Adam(amsgrad=True))\n",
                "\n",
                "    def test_adamax(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.Adamax())\n",
                "            self._test_optimizer(optimizer_v1.Adamax(decay=1e-3))\n",
                "\n",
                "    def test_nadam(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(optimizer_v1.Nadam())\n",
                "\n",
                "    def test_clipnorm(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(\n",
                "                optimizer_v1.SGD(lr=0.01, momentum=0.9, clipnorm=0.5)\n",
                "            )\n",
                "\n",
                "    def test_clipvalue(self):\n",
                "        with self.cached_session():\n",
                "            self._test_optimizer(\n",
                "                optimizer_v1.SGD(lr=0.01, momentum=0.9, clipvalue=0.5)\n",
                "            )\n",
                "\n",
                "    def test_tf_optimizer(self):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        optimizer = optimizer_v1.TFOptimizer(AdamOptimizer(0.01))\n",
                "        model = keras.models.Sequential()\n",
                "        model.add(\n",
                "            keras.layers.Dense(\n",
                "                2,\n",
                "                input_shape=(3,),\n",
                "                kernel_constraint=keras.constraints.MaxNorm(1),\n",
                "            )\n",
                "        )\n",
                "        # This is possible\n",
                "        model.compile(\n",
                "            loss=\"mean_squared_error\",\n",
                "            optimizer=optimizer,\n",
                "            run_eagerly=test_utils.should_run_eagerly(),\n",
                "        )\n",
                "        keras.backend.track_tf_optimizer(optimizer)\n",
                "        model.fit(\n",
                "            np.random.random((5, 3)),\n",
                "            np.random.random((5, 2)),\n",
                "            epochs=1,\n",
                "            batch_size=5,\n",
                "            verbose=0,\n",
                "        )\n",
                "        # not supported\n",
                "        with self.assertRaises(NotImplementedError):\n",
                "            _ = optimizer.weights\n",
                "        with self.assertRaises(NotImplementedError):\n",
                "            optimizer.get_config()\n",
                "        with self.assertRaises(NotImplementedError):\n",
                "            optimizer.from_config(None)\n",
                "\n",
                "    def test_optimizer_garbage_collection(self):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        graph = tf.Graph()\n",
                "        with graph.as_default():\n",
                "            optimizer = optimizer_v1.TFOptimizer(AdamOptimizer(0.01))\n",
                "            keras.backend.track_tf_optimizer(optimizer)\n",
                "            optimizer_weak = weakref.ref(optimizer)\n",
                "        graph_weak = weakref.ref(graph)\n",
                "        del graph, optimizer\n",
                "        gc.collect()\n",
                "        # Check that the weak references are dead now.\n",
                "        self.assertIs(graph_weak(), None)\n",
                "        self.assertIs(optimizer_weak(), None)\n",
                "\n",
                "    def test_tf_optimizer_iterations(self):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        with self.cached_session():\n",
                "            optimizer = optimizer_v1.TFOptimizer(AdamOptimizer(0.01))\n",
                "            model = keras.models.Sequential()\n",
                "            model.add(\n",
                "                keras.layers.Dense(\n",
                "                    2,\n",
                "                    input_shape=(3,),\n",
                "                    kernel_constraint=keras.constraints.MaxNorm(1),\n",
                "                )\n",
                "            )\n",
                "            model.compile(\n",
                "                loss=\"mean_squared_error\",\n",
                "                optimizer=optimizer,\n",
                "                run_eagerly=test_utils.should_run_eagerly(),\n",
                "            )\n",
                "            keras.backend.track_tf_optimizer(optimizer)\n",
                "            self.assertEqual(\n",
                "                keras.backend.get_value(model.optimizer.iterations), 0\n",
                "            )\n",
                "\n",
                "            model.fit(\n",
                "                np.random.random((55, 3)),\n",
                "                np.random.random((55, 2)),\n",
                "                epochs=1,\n",
                "                batch_size=5,\n",
                "                verbose=0,\n",
                "            )\n",
                "            self.assertEqual(\n",
                "                keras.backend.get_value(model.optimizer.iterations), 11\n",
                "            )\n",
                "\n",
                "    def test_negative_clipvalue_or_clipnorm(self):\n",
                "        with self.assertRaises(ValueError):\n",
                "            _ = optimizer_v1.SGD(lr=0.01, clipvalue=-0.5)\n",
                "        with self.assertRaises(ValueError):\n",
                "            _ = optimizer_v1.Adam(clipnorm=-2.0)\n",
                "\n",
                "    def test_mixed_precision_loss_scale_optimizer(self):\n",
                "        if tf.executing_eagerly():\n",
                "            self.skipTest(\"v1 optimizer does not run in eager mode\")\n",
                "        optimizer = MixedPrecisionLossScaleOptimizer(AdamOptimizer(), \"dynamic\")\n",
                "        model = keras.models.Sequential()\n",
                "        model.add(\n",
                "            keras.layers.Dense(\n",
                "                2,\n",
                "                input_shape=(3,),\n",
                "                kernel_constraint=keras.constraints.MaxNorm(1),\n",
                "            )\n",
                "        )\n",
                "        model.compile(\n",
                "            loss=\"mean_squared_error\",\n",
                "            optimizer=optimizer,\n",
                "            run_eagerly=test_utils.should_run_eagerly(),\n",
                "        )\n",
                "        model.fit(\n",
                "            np.random.random((5, 3)),\n",
                "            np.random.random((5, 2)),\n",
                "            epochs=1,\n",
                "            batch_size=5,\n",
                "            verbose=0,\n",
                "        )\n",
                "\n",
                "    def test_deserialization_error(self):\n",
                "        with self.assertRaisesRegex(\n",
                "            ValueError, \"Could not interpret optimizer\"\n",
                "        ):\n",
                "            keras.optimizers.get(0)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    tf.test.main()"
            ]
        ]
    },
    "partial_orders": [
        {
            "edit_hunk_pair": [
                0,
                1
            ],
            "edit_order": "bi-directional",
            "reason": "clone"
        },
        {
            "edit_hunk_pair": [
                0,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "use and implement"
        },
        {
            "edit_hunk_pair": [
                1,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "use and implement"
        },
        {
            "edit_hunk_pair": [
                2,
                3
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                2,
                4
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                2,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                2,
                7
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                2,
                8
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                2,
                9
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                2,
                10
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                3,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                3,
                8
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                3,
                9
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                3,
                11
            ],
            "edit_order": "bi-directional",
            "reason": "sync"
        },
        {
            "edit_hunk_pair": [
                4,
                5
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        },
        {
            "edit_hunk_pair": [
                4,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                5,
                8
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                5,
                9
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                5,
                11
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                7,
                8
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        },
        {
            "edit_hunk_pair": [
                8,
                9
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                8,
                11
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                9,
                11
            ],
            "edit_order": "bi-directional",
            "reason": "copy code"
        },
        {
            "edit_hunk_pair": [
                10,
                11
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        },
        {
            "edit_hunk_pair": [
                10,
                12
            ],
            "edit_order": "bi-directional",
            "reason": "def and use"
        }
    ]
}