{
    "language": "python",
    "commit_url": "https://github.com/numpy/numpy/commit/cad9171f9ec3b5ddd79a51077196a57a22380b3b",
    "commit_message": "TST: skip limited API test on nogil python build (#26229)",
    "commit_snapshots": {
        "numpy/_core/tests/test_limited_api.py": [
            [
                "import os\n",
                "import shutil\n",
                "import subprocess\n",
                "import sys\n",
                "import sysconfig\n",
                "import pytest\n",
                "\n"
            ],
            {
                "type": "replace",
                "before": [
                    "from numpy.testing import IS_WASM, IS_PYPY\n"
                ],
                "after": [
                    "from numpy.testing import IS_WASM, IS_PYPY, NOGIL_BUILD\n"
                ],
                "parent_version_range": {
                    "start": 7,
                    "end": 8
                },
                "child_version_range": {
                    "start": 7,
                    "end": 8
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 0,
                "hunk_diff": "File: numpy/_core/tests/test_limited_api.py\nCode:\n  ...\n 4  4    import sysconfig\n 5  5    import pytest\n 6  6    \n 7     - from numpy.testing import IS_WASM, IS_PYPY\n    7  + from numpy.testing import IS_WASM, IS_PYPY, NOGIL_BUILD\n 8  8    \n 9  9    # This import is copied from random.tests.test_extending\n10 10    try:\n       ...\n",
                "file_path": "numpy/_core/tests/test_limited_api.py",
                "identifiers_before": [
                    "IS_PYPY",
                    "IS_WASM",
                    "numpy",
                    "testing"
                ],
                "identifiers_after": [
                    "IS_PYPY",
                    "IS_WASM",
                    "NOGIL_BUILD",
                    "numpy",
                    "testing"
                ],
                "prefix": [
                    "import sysconfig\n",
                    "import pytest\n",
                    "\n"
                ],
                "suffix": [
                    "\n",
                    "# This import is copied from random.tests.test_extending\n",
                    "try:\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    3
                ]
            },
            [
                "\n",
                "# This import is copied from random.tests.test_extending\n",
                "try:\n",
                "    import cython\n",
                "    from Cython.Compiler.Version import version as cython_version\n",
                "except ImportError:\n",
                "    cython = None\n",
                "else:\n",
                "    from numpy._utils import _pep440\n",
                "\n",
                "    # Note: keep in sync with the one in pyproject.toml\n",
                "    required_version = \"3.0.6\"\n",
                "    if _pep440.parse(cython_version) < _pep440.Version(required_version):\n",
                "        # too old or wrong cython, skip the test\n",
                "        cython = None\n",
                "\n",
                "pytestmark = pytest.mark.skipif(cython is None, reason=\"requires cython\")\n",
                "\n",
                "\n",
                "@pytest.fixture(scope='module')\n",
                "def install_temp(tmpdir_factory):\n",
                "    # Based in part on test_cython from random.tests.test_extending\n",
                "    if IS_WASM:\n",
                "        pytest.skip(\"No subprocess\")\n",
                "\n",
                "    srcdir = os.path.join(os.path.dirname(__file__), 'examples', 'limited_api')\n",
                "    build_dir = tmpdir_factory.mktemp(\"limited_api\") / \"build\"\n",
                "    os.makedirs(build_dir, exist_ok=True)\n",
                "    try:\n",
                "        subprocess.check_call([\"meson\", \"--version\"])\n",
                "    except FileNotFoundError:\n",
                "        pytest.skip(\"No usable 'meson' found\")\n",
                "    if sys.platform == \"win32\":\n",
                "        subprocess.check_call([\"meson\", \"setup\",\n",
                "                               \"--buildtype=release\",\n",
                "                               \"--vsenv\", str(srcdir)],\n",
                "                              cwd=build_dir,\n",
                "                              )\n",
                "    else:\n",
                "        subprocess.check_call([\"meson\", \"setup\", str(srcdir)],\n",
                "                              cwd=build_dir\n",
                "                              )\n",
                "    try:\n",
                "        subprocess.check_call([\"meson\", \"compile\", \"-vv\"], cwd=build_dir)\n",
                "    except subprocess.CalledProcessError as p:\n",
                "        print(f\"{p.stdout=}\")\n",
                "        print(f\"{p.stderr=}\")\n",
                "        raise\n",
                "\n",
                "    sys.path.append(str(build_dir))\n",
                "\n",
                "\n",
                "\n",
                "@pytest.mark.skipif(IS_WASM, reason=\"Can't start subprocess\")\n",
                "@pytest.mark.xfail(\n",
                "    sysconfig.get_config_var(\"Py_DEBUG\"),\n",
                "    reason=(\n",
                "        \"Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, \"\n",
                "        \"and Py_REF_DEBUG\"\n",
                "    ),\n",
                ")\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "@pytest.mark.xfail(\n",
                    "    NOGIL_BUILD,\n",
                    "    reason=\"Py_GIL_DISABLED builds do not currently support the limited API\",\n",
                    ")\n"
                ],
                "parent_version_range": {
                    "start": 69,
                    "end": 69
                },
                "child_version_range": {
                    "start": 69,
                    "end": 73
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "call",
                        "name": "pytest.mark.xfail",
                        "signature": "pytest.mark.xfail(\n    sysconfig.get_config_var(\"Py_DEBUG\"),\n    reason=(\n        \"Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, \"\n        \"and Py_REF_DEBUG\"\n    ),\n)",
                        "at_line": 62
                    }
                ],
                "idx": 1,
                "hunk_diff": "File: numpy/_core/tests/test_limited_api.py\nCode:\n         pytest.mark.xfail(\n    sysconfig.get_config_var(\"Py_DEBUG\"),\n    reason=(\n        \"Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, \"\n        \"and Py_REF_DEBUG\"\n    ),\n)\n             ...\n66 66            \"and Py_REF_DEBUG\"\n67 67        ),\n68 68    )\n   69  + @pytest.mark.xfail(\n   70  +     NOGIL_BUILD,\n   71  +     reason=\"Py_GIL_DISABLED builds do not currently support the limited API\",\n   72  + )\n69 73    @pytest.mark.skipif(IS_PYPY, reason=\"no support for limited API in PyPy\")\n70 74    def test_limited_api(install_temp):\n71 75        \"\"\"Test building a third-party C extension with the limited API\n       ...\n",
                "file_path": "numpy/_core/tests/test_limited_api.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "NOGIL_BUILD",
                    "mark",
                    "pytest",
                    "reason",
                    "xfail"
                ],
                "prefix": [
                    "        \"and Py_REF_DEBUG\"\n",
                    "    ),\n",
                    ")\n"
                ],
                "suffix": [
                    "@pytest.mark.skipif(IS_PYPY, reason=\"no support for limited API in PyPy\")\n",
                    "def test_limited_api(install_temp):\n",
                    "    \"\"\"Test building a third-party C extension with the limited API\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "@pytest.mark.skipif(IS_PYPY, reason=\"no support for limited API in PyPy\")\n",
                "def test_limited_api(install_temp):\n",
                "    \"\"\"Test building a third-party C extension with the limited API\n",
                "    and building a cython extension with the limited API\n",
                "    \"\"\"\n",
                "\n",
                "    import limited_api1\n",
                "    import limited_api2"
            ]
        ],
        "numpy/_core/tests/test_nditer.py": [
            [
                "import sys\n"
            ],
            {
                "type": "delete",
                "before": [
                    "import sysconfig\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 1,
                    "end": 2
                },
                "child_version_range": {
                    "start": 1,
                    "end": 1
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 2,
                "hunk_diff": "File: numpy/_core/tests/test_nditer.py\nCode:\n  ...\n0 0    import sys\n1    - import sysconfig\n2 1    import pytest\n3 2    \n4 3    import textwrap\n     ...\n",
                "file_path": "numpy/_core/tests/test_nditer.py",
                "identifiers_before": [
                    "sysconfig"
                ],
                "identifiers_after": [],
                "prefix": [
                    "import sys\n"
                ],
                "suffix": [
                    "import pytest\n",
                    "\n",
                    "import textwrap\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [
                    {
                        "to_hunk_idx": 4,
                        "detail": {
                            "identifier": "sysconfig",
                            "position": {
                                "start": {
                                    "line": 1,
                                    "column": 7
                                },
                                "end": {
                                    "line": 1,
                                    "column": 16
                                }
                            },
                            "type": "identifier",
                            "kind": "import",
                            "abs_file_path": "/data2/chenyan/repos/numpy/numpy/_core/tests/test_nditer.py",
                            "hunk_idx": 2,
                            "dependency_checked": true
                        }
                    }
                ],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "import pytest\n",
                "\n",
                "import textwrap\n",
                "import subprocess\n",
                "\n",
                "import numpy as np\n",
                "import numpy._core.umath as ncu\n",
                "import numpy._core._multiarray_tests as _multiarray_tests\n",
                "from numpy import array, arange, nditer, all\n",
                "from numpy.testing import (\n",
                "    assert_, assert_equal, assert_array_equal, assert_raises,\n"
            ],
            {
                "type": "replace",
                "before": [
                    "    IS_WASM, HAS_REFCOUNT, suppress_warnings, break_cycles\n"
                ],
                "after": [
                    "    IS_WASM, HAS_REFCOUNT, suppress_warnings, break_cycles,\n",
                    "    NOGIL_BUILD\n"
                ],
                "parent_version_range": {
                    "start": 13,
                    "end": 14
                },
                "child_version_range": {
                    "start": 12,
                    "end": 14
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 3,
                "hunk_diff": "File: numpy/_core/tests/test_nditer.py\nCode:\n  ...\n10  9    from numpy import array, arange, nditer, all\n11 10    from numpy.testing import (\n12 11        assert_, assert_equal, assert_array_equal, assert_raises,\n13     -     IS_WASM, HAS_REFCOUNT, suppress_warnings, break_cycles\n   12  +     IS_WASM, HAS_REFCOUNT, suppress_warnings, break_cycles,\n   13  +     NOGIL_BUILD\n14 14        )\n15 15    \n       ...\n",
                "file_path": "numpy/_core/tests/test_nditer.py",
                "identifiers_before": [
                    "HAS_REFCOUNT",
                    "IS_WASM",
                    "break_cycles",
                    "suppress_warnings"
                ],
                "identifiers_after": [
                    "HAS_REFCOUNT",
                    "IS_WASM",
                    "NOGIL_BUILD",
                    "break_cycles",
                    "suppress_warnings"
                ],
                "prefix": [
                    "from numpy import array, arange, nditer, all\n",
                    "from numpy.testing import (\n",
                    "    assert_, assert_equal, assert_array_equal, assert_raises,\n"
                ],
                "suffix": [
                    "    )\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": [
                    0
                ]
            },
            [
                "    )\n",
                "\n"
            ],
            {
                "type": "delete",
                "before": [
                    "NOGIL_BUILD = bool(sysconfig.get_config_var('Py_GIL_DISABLED'))\n",
                    "\n"
                ],
                "after": [],
                "parent_version_range": {
                    "start": 16,
                    "end": 18
                },
                "child_version_range": {
                    "start": 16,
                    "end": 16
                },
                "control_flow": [],
                "structural_path": [
                    {
                        "type": "call",
                        "name": "bool",
                        "signature": "bool(sysconfig.get_config_var('Py_GIL_DISABLED'))",
                        "at_line": 16,
                        "argument": "sysconfig.get_config_var('Py_G..."
                    }
                ],
                "idx": 4,
                "hunk_diff": "File: numpy/_core/tests/test_nditer.py\nCode:\n14 14        )\n15 15    \n16     - NOGIL_BUILD = bool(sysconfig.get_config_var('Py_GIL_DISABLED'))\n17     - \n18 16    def iter_multi_index(i):\n19 17        ret = []\n20 18        while not i.finished:\n       ...\n",
                "file_path": "numpy/_core/tests/test_nditer.py",
                "identifiers_before": [
                    "NOGIL_BUILD",
                    "bool",
                    "get_config_var",
                    "sysconfig"
                ],
                "identifiers_after": [],
                "prefix": [
                    "    )\n",
                    "\n"
                ],
                "suffix": [
                    "def iter_multi_index(i):\n",
                    "    ret = []\n",
                    "    while not i.finished:\n"
                ],
                "base_dependency_callee": [
                    {
                        "to_hunk_idx": 2,
                        "detail": {
                            "identifier": "sysconfig",
                            "position": {
                                "start": {
                                    "line": 16,
                                    "column": 19
                                },
                                "end": {
                                    "line": 16,
                                    "column": 28
                                }
                            },
                            "type": "identifier",
                            "kind": "unknown",
                            "abs_file_path": "/data2/chenyan/repos/numpy/numpy/_core/tests/test_nditer.py",
                            "hunk_idx": 4,
                            "dependency_checked": true
                        }
                    }
                ],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "def iter_multi_index(i):\n",
                "    ret = []\n",
                "    while not i.finished:\n",
                "        ret.append(i.multi_index)\n",
                "        i.iternext()\n",
                "    return ret\n",
                "\n",
                "def iter_indices(i):\n",
                "    ret = []\n",
                "    while not i.finished:\n",
                "        ret.append(i.index)\n",
                "        i.iternext()\n",
                "    return ret\n",
                "\n",
                "def iter_iterindices(i):\n",
                "    ret = []\n",
                "    while not i.finished:\n",
                "        ret.append(i.iterindex)\n",
                "        i.iternext()\n",
                "    return ret\n",
                "\n",
                "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")\n",
                "def test_iter_refcount():\n",
                "    # Make sure the iterator doesn't leak\n",
                "\n",
                "    # Basic\n",
                "    a = arange(6)\n",
                "    dt = np.dtype('f4').newbyteorder()\n",
                "    rc_a = sys.getrefcount(a)\n",
                "    rc_dt = sys.getrefcount(dt)\n",
                "    with nditer(a, [],\n",
                "                [['readwrite', 'updateifcopy']],\n",
                "                casting='unsafe',\n",
                "                op_dtypes=[dt]) as it:\n",
                "        assert_(not it.iterationneedsapi)\n",
                "        assert_(sys.getrefcount(a) > rc_a)\n",
                "        assert_(sys.getrefcount(dt) > rc_dt)\n",
                "    # del 'it'\n",
                "    it = None\n",
                "    assert_equal(sys.getrefcount(a), rc_a)\n",
                "    assert_equal(sys.getrefcount(dt), rc_dt)\n",
                "\n",
                "    # With a copy\n",
                "    a = arange(6, dtype='f4')\n",
                "    dt = np.dtype('f4')\n",
                "    rc_a = sys.getrefcount(a)\n",
                "    rc_dt = sys.getrefcount(dt)\n",
                "    it = nditer(a, [],\n",
                "                [['readwrite']],\n",
                "                op_dtypes=[dt])\n",
                "    rc2_a = sys.getrefcount(a)\n",
                "    rc2_dt = sys.getrefcount(dt)\n",
                "    it2 = it.copy()\n",
                "    assert_(sys.getrefcount(a) > rc2_a)\n",
                "    if not NOGIL_BUILD:\n",
                "        # np.dtype('f4') is immortal in the nogil build\n",
                "        assert_(sys.getrefcount(dt) > rc2_dt)\n",
                "    it = None\n",
                "    assert_equal(sys.getrefcount(a), rc2_a)\n",
                "    assert_equal(sys.getrefcount(dt), rc2_dt)\n",
                "    it2 = None\n",
                "    assert_equal(sys.getrefcount(a), rc_a)\n",
                "    assert_equal(sys.getrefcount(dt), rc_dt)\n",
                "\n",
                "    del it2  # avoid pyflakes unused variable warning\n",
                "\n",
                "def test_iter_best_order():\n",
                "    # The iterator should always find the iteration order\n",
                "    # with increasing memory addresses\n",
                "\n",
                "    # Test the ordering for 1-D to 5-D shapes\n",
                "    for shape in [(5,), (3, 4), (2, 3, 4), (2, 3, 4, 3), (2, 3, 2, 2, 3)]:\n",
                "        a = arange(np.prod(shape))\n",
                "        # Test each combination of positive and negative strides\n",
                "        for dirs in range(2**len(shape)):\n",
                "            dirs_index = [slice(None)]*len(shape)\n",
                "            for bit in range(len(shape)):\n",
                "                if ((2**bit) & dirs):\n",
                "                    dirs_index[bit] = slice(None, None, -1)\n",
                "            dirs_index = tuple(dirs_index)\n",
                "\n",
                "            aview = a.reshape(shape)[dirs_index]\n",
                "            # C-order\n",
                "            i = nditer(aview, [], [['readonly']])\n",
                "            assert_equal([x for x in i], a)\n",
                "            # Fortran-order\n",
                "            i = nditer(aview.T, [], [['readonly']])\n",
                "            assert_equal([x for x in i], a)\n",
                "            # Other order\n",
                "            if len(shape) > 2:\n",
                "                i = nditer(aview.swapaxes(0, 1), [], [['readonly']])\n",
                "                assert_equal([x for x in i], a)\n",
                "\n",
                "def test_iter_c_order():\n",
                "    # Test forcing C order\n",
                "\n",
                "    # Test the ordering for 1-D to 5-D shapes\n",
                "    for shape in [(5,), (3, 4), (2, 3, 4), (2, 3, 4, 3), (2, 3, 2, 2, 3)]:\n",
                "        a = arange(np.prod(shape))\n",
                "        # Test each combination of positive and negative strides\n",
                "        for dirs in range(2**len(shape)):\n",
                "            dirs_index = [slice(None)]*len(shape)\n",
                "            for bit in range(len(shape)):\n",
                "                if ((2**bit) & dirs):\n",
                "                    dirs_index[bit] = slice(None, None, -1)\n",
                "            dirs_index = tuple(dirs_index)\n",
                "\n",
                "            aview = a.reshape(shape)[dirs_index]\n",
                "            # C-order\n",
                "            i = nditer(aview, order='C')\n",
                "            assert_equal([x for x in i], aview.ravel(order='C'))\n",
                "            # Fortran-order\n",
                "            i = nditer(aview.T, order='C')\n",
                "            assert_equal([x for x in i], aview.T.ravel(order='C'))\n",
                "            # Other order\n",
                "            if len(shape) > 2:\n",
                "                i = nditer(aview.swapaxes(0, 1), order='C')\n",
                "                assert_equal([x for x in i],\n",
                "                                    aview.swapaxes(0, 1).ravel(order='C'))\n",
                "\n",
                "def test_iter_f_order():\n",
                "    # Test forcing F order\n",
                "\n",
                "    # Test the ordering for 1-D to 5-D shapes\n",
                "    for shape in [(5,), (3, 4), (2, 3, 4), (2, 3, 4, 3), (2, 3, 2, 2, 3)]:\n",
                "        a = arange(np.prod(shape))\n",
                "        # Test each combination of positive and negative strides\n",
                "        for dirs in range(2**len(shape)):\n",
                "            dirs_index = [slice(None)]*len(shape)\n",
                "            for bit in range(len(shape)):\n",
                "                if ((2**bit) & dirs):\n",
                "                    dirs_index[bit] = slice(None, None, -1)\n",
                "            dirs_index = tuple(dirs_index)\n",
                "\n",
                "            aview = a.reshape(shape)[dirs_index]\n",
                "            # C-order\n",
                "            i = nditer(aview, order='F')\n",
                "            assert_equal([x for x in i], aview.ravel(order='F'))\n",
                "            # Fortran-order\n",
                "            i = nditer(aview.T, order='F')\n",
                "            assert_equal([x for x in i], aview.T.ravel(order='F'))\n",
                "            # Other order\n",
                "            if len(shape) > 2:\n",
                "                i = nditer(aview.swapaxes(0, 1), order='F')\n",
                "                assert_equal([x for x in i],\n",
                "                                    aview.swapaxes(0, 1).ravel(order='F'))\n",
                "\n",
                "def test_iter_c_or_f_order():\n",
                "    # Test forcing any contiguous (C or F) order\n",
                "\n",
                "    # Test the ordering for 1-D to 5-D shapes\n",
                "    for shape in [(5,), (3, 4), (2, 3, 4), (2, 3, 4, 3), (2, 3, 2, 2, 3)]:\n",
                "        a = arange(np.prod(shape))\n",
                "        # Test each combination of positive and negative strides\n",
                "        for dirs in range(2**len(shape)):\n",
                "            dirs_index = [slice(None)]*len(shape)\n",
                "            for bit in range(len(shape)):\n",
                "                if ((2**bit) & dirs):\n",
                "                    dirs_index[bit] = slice(None, None, -1)\n",
                "            dirs_index = tuple(dirs_index)\n",
                "\n",
                "            aview = a.reshape(shape)[dirs_index]\n",
                "            # C-order\n",
                "            i = nditer(aview, order='A')\n",
                "            assert_equal([x for x in i], aview.ravel(order='A'))\n",
                "            # Fortran-order\n",
                "            i = nditer(aview.T, order='A')\n",
                "            assert_equal([x for x in i], aview.T.ravel(order='A'))\n",
                "            # Other order\n",
                "            if len(shape) > 2:\n",
                "                i = nditer(aview.swapaxes(0, 1), order='A')\n",
                "                assert_equal([x for x in i],\n",
                "                                    aview.swapaxes(0, 1).ravel(order='A'))\n",
                "\n",
                "def test_nditer_multi_index_set():\n",
                "    # Test the multi_index set\n",
                "    a = np.arange(6).reshape(2, 3)\n",
                "    it = np.nditer(a, flags=['multi_index'])\n",
                "\n",
                "    # Removes the iteration on two first elements of a[0]\n",
                "    it.multi_index = (0, 2,)\n",
                "\n",
                "    assert_equal([i for i in it], [2, 3, 4, 5])\n",
                "\n",
                "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")\n",
                "def test_nditer_multi_index_set_refcount():\n",
                "    # Test if the reference count on index variable is decreased\n",
                "\n",
                "    index = 0\n",
                "    i = np.nditer(np.array([111, 222, 333, 444]), flags=['multi_index'])\n",
                "\n",
                "    start_count = sys.getrefcount(index)\n",
                "    i.multi_index = (index,)\n",
                "    end_count = sys.getrefcount(index)\n",
                "\n",
                "    assert_equal(start_count, end_count)\n",
                "\n",
                "def test_iter_best_order_multi_index_1d():\n",
                "    # The multi-indices should be correct with any reordering\n",
                "\n",
                "    a = arange(4)\n",
                "    # 1D order\n",
                "    i = nditer(a, ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(0,), (1,), (2,), (3,)])\n",
                "    # 1D reversed order\n",
                "    i = nditer(a[::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(3,), (2,), (1,), (0,)])\n",
                "\n",
                "def test_iter_best_order_multi_index_2d():\n",
                "    # The multi-indices should be correct with any reordering\n",
                "\n",
                "    a = arange(6)\n",
                "    # 2D C-order\n",
                "    i = nditer(a.reshape(2, 3), ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)])\n",
                "    # 2D Fortran-order\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F'), ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(0, 0), (1, 0), (0, 1), (1, 1), (0, 2), (1, 2)])\n",
                "    # 2D reversed C-order\n",
                "    i = nditer(a.reshape(2, 3)[::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(1, 0), (1, 1), (1, 2), (0, 0), (0, 1), (0, 2)])\n",
                "    i = nditer(a.reshape(2, 3)[:, ::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(0, 2), (0, 1), (0, 0), (1, 2), (1, 1), (1, 0)])\n",
                "    i = nditer(a.reshape(2, 3)[::-1, ::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(1, 2), (1, 1), (1, 0), (0, 2), (0, 1), (0, 0)])\n",
                "    # 2D reversed Fortran-order\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(1, 0), (0, 0), (1, 1), (0, 1), (1, 2), (0, 2)])\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[:, ::-1],\n",
                "                                                   ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(0, 2), (1, 2), (0, 1), (1, 1), (0, 0), (1, 0)])\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[::-1, ::-1],\n",
                "                                                   ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i), [(1, 2), (0, 2), (1, 1), (0, 1), (1, 0), (0, 0)])\n",
                "\n",
                "def test_iter_best_order_multi_index_3d():\n",
                "    # The multi-indices should be correct with any reordering\n",
                "\n",
                "    a = arange(12)\n",
                "    # 3D C-order\n",
                "    i = nditer(a.reshape(2, 3, 2), ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (0, 2, 0), (0, 2, 1),\n",
                "                             (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1), (1, 2, 0), (1, 2, 1)])\n",
                "    # 3D Fortran-order\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F'), ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(0, 0, 0), (1, 0, 0), (0, 1, 0), (1, 1, 0), (0, 2, 0), (1, 2, 0),\n",
                "                             (0, 0, 1), (1, 0, 1), (0, 1, 1), (1, 1, 1), (0, 2, 1), (1, 2, 1)])\n",
                "    # 3D reversed C-order\n",
                "    i = nditer(a.reshape(2, 3, 2)[::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1), (1, 2, 0), (1, 2, 1),\n",
                "                             (0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (0, 2, 0), (0, 2, 1)])\n",
                "    i = nditer(a.reshape(2, 3, 2)[:, ::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(0, 2, 0), (0, 2, 1), (0, 1, 0), (0, 1, 1), (0, 0, 0), (0, 0, 1),\n",
                "                             (1, 2, 0), (1, 2, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)])\n",
                "    i = nditer(a.reshape(2, 3, 2)[:,:, ::-1], ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(0, 0, 1), (0, 0, 0), (0, 1, 1), (0, 1, 0), (0, 2, 1), (0, 2, 0),\n",
                "                             (1, 0, 1), (1, 0, 0), (1, 1, 1), (1, 1, 0), (1, 2, 1), (1, 2, 0)])\n",
                "    # 3D reversed Fortran-order\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[::-1],\n",
                "                                                    ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(1, 0, 0), (0, 0, 0), (1, 1, 0), (0, 1, 0), (1, 2, 0), (0, 2, 0),\n",
                "                             (1, 0, 1), (0, 0, 1), (1, 1, 1), (0, 1, 1), (1, 2, 1), (0, 2, 1)])\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[:, ::-1],\n",
                "                                                    ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(0, 2, 0), (1, 2, 0), (0, 1, 0), (1, 1, 0), (0, 0, 0), (1, 0, 0),\n",
                "                             (0, 2, 1), (1, 2, 1), (0, 1, 1), (1, 1, 1), (0, 0, 1), (1, 0, 1)])\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[:,:, ::-1],\n",
                "                                                    ['multi_index'], [['readonly']])\n",
                "    assert_equal(iter_multi_index(i),\n",
                "                            [(0, 0, 1), (1, 0, 1), (0, 1, 1), (1, 1, 1), (0, 2, 1), (1, 2, 1),\n",
                "                             (0, 0, 0), (1, 0, 0), (0, 1, 0), (1, 1, 0), (0, 2, 0), (1, 2, 0)])\n",
                "\n",
                "def test_iter_best_order_c_index_1d():\n",
                "    # The C index should be correct with any reordering\n",
                "\n",
                "    a = arange(4)\n",
                "    # 1D order\n",
                "    i = nditer(a, ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [0, 1, 2, 3])\n",
                "    # 1D reversed order\n",
                "    i = nditer(a[::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [3, 2, 1, 0])\n",
                "\n",
                "def test_iter_best_order_c_index_2d():\n",
                "    # The C index should be correct with any reordering\n",
                "\n",
                "    a = arange(6)\n",
                "    # 2D C-order\n",
                "    i = nditer(a.reshape(2, 3), ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [0, 1, 2, 3, 4, 5])\n",
                "    # 2D Fortran-order\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F'),\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [0, 3, 1, 4, 2, 5])\n",
                "    # 2D reversed C-order\n",
                "    i = nditer(a.reshape(2, 3)[::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [3, 4, 5, 0, 1, 2])\n",
                "    i = nditer(a.reshape(2, 3)[:, ::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [2, 1, 0, 5, 4, 3])\n",
                "    i = nditer(a.reshape(2, 3)[::-1, ::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [5, 4, 3, 2, 1, 0])\n",
                "    # 2D reversed Fortran-order\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[::-1],\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [3, 0, 4, 1, 5, 2])\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[:, ::-1],\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [2, 5, 1, 4, 0, 3])\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[::-1, ::-1],\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [5, 2, 4, 1, 3, 0])\n",
                "\n",
                "def test_iter_best_order_c_index_3d():\n",
                "    # The C index should be correct with any reordering\n",
                "\n",
                "    a = arange(12)\n",
                "    # 3D C-order\n",
                "    i = nditer(a.reshape(2, 3, 2), ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
                "    # 3D Fortran-order\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F'),\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [0, 6, 2, 8, 4, 10, 1, 7, 3, 9, 5, 11])\n",
                "    # 3D reversed C-order\n",
                "    i = nditer(a.reshape(2, 3, 2)[::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5])\n",
                "    i = nditer(a.reshape(2, 3, 2)[:, ::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [4, 5, 2, 3, 0, 1, 10, 11, 8, 9, 6, 7])\n",
                "    i = nditer(a.reshape(2, 3, 2)[:,:, ::-1], ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10])\n",
                "    # 3D reversed Fortran-order\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[::-1],\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [6, 0, 8, 2, 10, 4, 7, 1, 9, 3, 11, 5])\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[:, ::-1],\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [4, 10, 2, 8, 0, 6, 5, 11, 3, 9, 1, 7])\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[:,:, ::-1],\n",
                "                                    ['c_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [1, 7, 3, 9, 5, 11, 0, 6, 2, 8, 4, 10])\n",
                "\n",
                "def test_iter_best_order_f_index_1d():\n",
                "    # The Fortran index should be correct with any reordering\n",
                "\n",
                "    a = arange(4)\n",
                "    # 1D order\n",
                "    i = nditer(a, ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [0, 1, 2, 3])\n",
                "    # 1D reversed order\n",
                "    i = nditer(a[::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [3, 2, 1, 0])\n",
                "\n",
                "def test_iter_best_order_f_index_2d():\n",
                "    # The Fortran index should be correct with any reordering\n",
                "\n",
                "    a = arange(6)\n",
                "    # 2D C-order\n",
                "    i = nditer(a.reshape(2, 3), ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [0, 2, 4, 1, 3, 5])\n",
                "    # 2D Fortran-order\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F'),\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [0, 1, 2, 3, 4, 5])\n",
                "    # 2D reversed C-order\n",
                "    i = nditer(a.reshape(2, 3)[::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [1, 3, 5, 0, 2, 4])\n",
                "    i = nditer(a.reshape(2, 3)[:, ::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [4, 2, 0, 5, 3, 1])\n",
                "    i = nditer(a.reshape(2, 3)[::-1, ::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [5, 3, 1, 4, 2, 0])\n",
                "    # 2D reversed Fortran-order\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[::-1],\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [1, 0, 3, 2, 5, 4])\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[:, ::-1],\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [4, 5, 2, 3, 0, 1])\n",
                "    i = nditer(a.reshape(2, 3).copy(order='F')[::-1, ::-1],\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i), [5, 4, 3, 2, 1, 0])\n",
                "\n",
                "def test_iter_best_order_f_index_3d():\n",
                "    # The Fortran index should be correct with any reordering\n",
                "\n",
                "    a = arange(12)\n",
                "    # 3D C-order\n",
                "    i = nditer(a.reshape(2, 3, 2), ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [0, 6, 2, 8, 4, 10, 1, 7, 3, 9, 5, 11])\n",
                "    # 3D Fortran-order\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F'),\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
                "    # 3D reversed C-order\n",
                "    i = nditer(a.reshape(2, 3, 2)[::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [1, 7, 3, 9, 5, 11, 0, 6, 2, 8, 4, 10])\n",
                "    i = nditer(a.reshape(2, 3, 2)[:, ::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [4, 10, 2, 8, 0, 6, 5, 11, 3, 9, 1, 7])\n",
                "    i = nditer(a.reshape(2, 3, 2)[:,:, ::-1], ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [6, 0, 8, 2, 10, 4, 7, 1, 9, 3, 11, 5])\n",
                "    # 3D reversed Fortran-order\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[::-1],\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10])\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[:, ::-1],\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [4, 5, 2, 3, 0, 1, 10, 11, 8, 9, 6, 7])\n",
                "    i = nditer(a.reshape(2, 3, 2).copy(order='F')[:,:, ::-1],\n",
                "                                    ['f_index'], [['readonly']])\n",
                "    assert_equal(iter_indices(i),\n",
                "                            [6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5])\n",
                "\n",
                "def test_iter_no_inner_full_coalesce():\n",
                "    # Check no_inner iterators which coalesce into a single inner loop\n",
                "\n",
                "    for shape in [(5,), (3, 4), (2, 3, 4), (2, 3, 4, 3), (2, 3, 2, 2, 3)]:\n",
                "        size = np.prod(shape)\n",
                "        a = arange(size)\n",
                "        # Test each combination of forward and backwards indexing\n",
                "        for dirs in range(2**len(shape)):\n",
                "            dirs_index = [slice(None)]*len(shape)\n",
                "            for bit in range(len(shape)):\n",
                "                if ((2**bit) & dirs):\n",
                "                    dirs_index[bit] = slice(None, None, -1)\n",
                "            dirs_index = tuple(dirs_index)\n",
                "\n",
                "            aview = a.reshape(shape)[dirs_index]\n",
                "            # C-order\n",
                "            i = nditer(aview, ['external_loop'], [['readonly']])\n",
                "            assert_equal(i.ndim, 1)\n",
                "            assert_equal(i[0].shape, (size,))\n",
                "            # Fortran-order\n",
                "            i = nditer(aview.T, ['external_loop'], [['readonly']])\n",
                "            assert_equal(i.ndim, 1)\n",
                "            assert_equal(i[0].shape, (size,))\n",
                "            # Other order\n",
                "            if len(shape) > 2:\n",
                "                i = nditer(aview.swapaxes(0, 1),\n",
                "                                    ['external_loop'], [['readonly']])\n",
                "                assert_equal(i.ndim, 1)\n",
                "                assert_equal(i[0].shape, (size,))\n",
                "\n",
                "def test_iter_no_inner_dim_coalescing():\n",
                "    # Check no_inner iterators whose dimensions may not coalesce completely\n",
                "\n",
                "    # Skipping the last element in a dimension prevents coalescing\n",
                "    # with the next-bigger dimension\n",
                "    a = arange(24).reshape(2, 3, 4)[:,:, :-1]\n",
                "    i = nditer(a, ['external_loop'], [['readonly']])\n",
                "    assert_equal(i.ndim, 2)\n",
                "    assert_equal(i[0].shape, (3,))\n",
                "    a = arange(24).reshape(2, 3, 4)[:, :-1,:]\n",
                "    i = nditer(a, ['external_loop'], [['readonly']])\n",
                "    assert_equal(i.ndim, 2)\n",
                "    assert_equal(i[0].shape, (8,))\n",
                "    a = arange(24).reshape(2, 3, 4)[:-1,:,:]\n",
                "    i = nditer(a, ['external_loop'], [['readonly']])\n",
                "    assert_equal(i.ndim, 1)\n",
                "    assert_equal(i[0].shape, (12,))\n",
                "\n",
                "    # Even with lots of 1-sized dimensions, should still coalesce\n",
                "    a = arange(24).reshape(1, 1, 2, 1, 1, 3, 1, 1, 4, 1, 1)\n",
                "    i = nditer(a, ['external_loop'], [['readonly']])\n",
                "    assert_equal(i.ndim, 1)\n",
                "    assert_equal(i[0].shape, (24,))\n",
                "\n",
                "def test_iter_dim_coalescing():\n",
                "    # Check that the correct number of dimensions are coalesced\n",
                "\n",
                "    # Tracking a multi-index disables coalescing\n",
                "    a = arange(24).reshape(2, 3, 4)\n",
                "    i = nditer(a, ['multi_index'], [['readonly']])\n",
                "    assert_equal(i.ndim, 3)\n",
                "\n",
                "    # A tracked index can allow coalescing if it's compatible with the array\n",
                "    a3d = arange(24).reshape(2, 3, 4)\n",
                "    i = nditer(a3d, ['c_index'], [['readonly']])\n",
                "    assert_equal(i.ndim, 1)\n",
                "    i = nditer(a3d.swapaxes(0, 1), ['c_index'], [['readonly']])\n",
                "    assert_equal(i.ndim, 3)\n",
                "    i = nditer(a3d.T, ['c_index'], [['readonly']])\n",
                "    assert_equal(i.ndim, 3)\n",
                "    i = nditer(a3d.T, ['f_index'], [['readonly']])\n",
                "    assert_equal(i.ndim, 1)\n",
                "    i = nditer(a3d.T.swapaxes(0, 1), ['f_index'], [['readonly']])\n",
                "    assert_equal(i.ndim, 3)\n",
                "\n",
                "    # When C or F order is forced, coalescing may still occur\n",
                "    a3d = arange(24).reshape(2, 3, 4)\n",
                "    i = nditer(a3d, order='C')\n",
                "    assert_equal(i.ndim, 1)\n",
                "    i = nditer(a3d.T, order='C')\n",
                "    assert_equal(i.ndim, 3)\n",
                "    i = nditer(a3d, order='F')\n",
                "    assert_equal(i.ndim, 3)\n",
                "    i = nditer(a3d.T, order='F')\n",
                "    assert_equal(i.ndim, 1)\n",
                "    i = nditer(a3d, order='A')\n",
                "    assert_equal(i.ndim, 1)\n",
                "    i = nditer(a3d.T, order='A')\n",
                "    assert_equal(i.ndim, 1)\n",
                "\n",
                "def test_iter_broadcasting():\n",
                "    # Standard NumPy broadcasting rules\n",
                "\n",
                "    # 1D with scalar\n",
                "    i = nditer([arange(6), np.int32(2)], ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 6)\n",
                "    assert_equal(i.shape, (6,))\n",
                "\n",
                "    # 2D with scalar\n",
                "    i = nditer([arange(6).reshape(2, 3), np.int32(2)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 6)\n",
                "    assert_equal(i.shape, (2, 3))\n",
                "    # 2D with 1D\n",
                "    i = nditer([arange(6).reshape(2, 3), arange(3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 6)\n",
                "    assert_equal(i.shape, (2, 3))\n",
                "    i = nditer([arange(2).reshape(2, 1), arange(3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 6)\n",
                "    assert_equal(i.shape, (2, 3))\n",
                "    # 2D with 2D\n",
                "    i = nditer([arange(2).reshape(2, 1), arange(3).reshape(1, 3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 6)\n",
                "    assert_equal(i.shape, (2, 3))\n",
                "\n",
                "    # 3D with scalar\n",
                "    i = nditer([np.int32(2), arange(24).reshape(4, 2, 3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    # 3D with 1D\n",
                "    i = nditer([arange(3), arange(24).reshape(4, 2, 3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    i = nditer([arange(3), arange(8).reshape(4, 2, 1)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    # 3D with 2D\n",
                "    i = nditer([arange(6).reshape(2, 3), arange(24).reshape(4, 2, 3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    i = nditer([arange(2).reshape(2, 1), arange(24).reshape(4, 2, 3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    i = nditer([arange(3).reshape(1, 3), arange(8).reshape(4, 2, 1)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    # 3D with 3D\n",
                "    i = nditer([arange(2).reshape(1, 2, 1), arange(3).reshape(1, 1, 3),\n",
                "                        arange(4).reshape(4, 1, 1)],\n",
                "                        ['multi_index'], [['readonly']]*3)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    i = nditer([arange(6).reshape(1, 2, 3), arange(4).reshape(4, 1, 1)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "    i = nditer([arange(24).reshape(4, 2, 3), arange(12).reshape(4, 1, 3)],\n",
                "                        ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i.shape, (4, 2, 3))\n",
                "\n",
                "def test_iter_itershape():\n",
                "    # Check that allocated outputs work with a specified shape\n",
                "    a = np.arange(6, dtype='i2').reshape(2, 3)\n",
                "    i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],\n",
                "                            op_axes=[[0, 1, None], None],\n",
                "                            itershape=(-1, -1, 4))\n",
                "    assert_equal(i.operands[1].shape, (2, 3, 4))\n",
                "    assert_equal(i.operands[1].strides, (24, 8, 2))\n",
                "\n",
                "    i = nditer([a.T, None], [], [['readonly'], ['writeonly', 'allocate']],\n",
                "                            op_axes=[[0, 1, None], None],\n",
                "                            itershape=(-1, -1, 4))\n",
                "    assert_equal(i.operands[1].shape, (3, 2, 4))\n",
                "    assert_equal(i.operands[1].strides, (8, 24, 2))\n",
                "\n",
                "    i = nditer([a.T, None], [], [['readonly'], ['writeonly', 'allocate']],\n",
                "                            order='F',\n",
                "                            op_axes=[[0, 1, None], None],\n",
                "                            itershape=(-1, -1, 4))\n",
                "    assert_equal(i.operands[1].shape, (3, 2, 4))\n",
                "    assert_equal(i.operands[1].strides, (2, 6, 12))\n",
                "\n",
                "    # If we specify 1 in the itershape, it shouldn't allow broadcasting\n",
                "    # of that dimension to a bigger value\n",
                "    assert_raises(ValueError, nditer, [a, None], [],\n",
                "                            [['readonly'], ['writeonly', 'allocate']],\n",
                "                            op_axes=[[0, 1, None], None],\n",
                "                            itershape=(-1, 1, 4))\n",
                "    # Test bug that for no op_axes but itershape, they are NULLed correctly\n",
                "    i = np.nditer([np.ones(2), None, None], itershape=(2,))\n",
                "\n",
                "def test_iter_broadcasting_errors():\n",
                "    # Check that errors are thrown for bad broadcasting shapes\n",
                "\n",
                "    # 1D with 1D\n",
                "    assert_raises(ValueError, nditer, [arange(2), arange(3)],\n",
                "                    [], [['readonly']]*2)\n",
                "    # 2D with 1D\n",
                "    assert_raises(ValueError, nditer,\n",
                "                    [arange(6).reshape(2, 3), arange(2)],\n",
                "                    [], [['readonly']]*2)\n",
                "    # 2D with 2D\n",
                "    assert_raises(ValueError, nditer,\n",
                "                    [arange(6).reshape(2, 3), arange(9).reshape(3, 3)],\n",
                "                    [], [['readonly']]*2)\n",
                "    assert_raises(ValueError, nditer,\n",
                "                    [arange(6).reshape(2, 3), arange(4).reshape(2, 2)],\n",
                "                    [], [['readonly']]*2)\n",
                "    # 3D with 3D\n",
                "    assert_raises(ValueError, nditer,\n",
                "                    [arange(36).reshape(3, 3, 4), arange(24).reshape(2, 3, 4)],\n",
                "                    [], [['readonly']]*2)\n",
                "    assert_raises(ValueError, nditer,\n",
                "                    [arange(8).reshape(2, 4, 1), arange(24).reshape(2, 3, 4)],\n",
                "                    [], [['readonly']]*2)\n",
                "\n",
                "    # Verify that the error message mentions the right shapes\n",
                "    try:\n",
                "        nditer([arange(2).reshape(1, 2, 1),\n",
                "                arange(3).reshape(1, 3),\n",
                "                arange(6).reshape(2, 3)],\n",
                "               [],\n",
                "               [['readonly'], ['readonly'], ['writeonly', 'no_broadcast']])\n",
                "        raise AssertionError('Should have raised a broadcast error')\n",
                "    except ValueError as e:\n",
                "        msg = str(e)\n",
                "        # The message should contain the shape of the 3rd operand\n",
                "        assert_(msg.find('(2,3)') >= 0,\n",
                "                'Message \"%s\" doesn\\'t contain operand shape (2,3)' % msg)\n",
                "        # The message should contain the broadcast shape\n",
                "        assert_(msg.find('(1,2,3)') >= 0,\n",
                "                'Message \"%s\" doesn\\'t contain broadcast shape (1,2,3)' % msg)\n",
                "\n",
                "    try:\n",
                "        nditer([arange(6).reshape(2, 3), arange(2)],\n",
                "               [],\n",
                "               [['readonly'], ['readonly']],\n",
                "               op_axes=[[0, 1], [0, np.newaxis]],\n",
                "               itershape=(4, 3))\n",
                "        raise AssertionError('Should have raised a broadcast error')\n",
                "    except ValueError as e:\n",
                "        msg = str(e)\n",
                "        # The message should contain \"shape->remappedshape\" for each operand\n",
                "        assert_(msg.find('(2,3)->(2,3)') >= 0,\n",
                "            'Message \"%s\" doesn\\'t contain operand shape (2,3)->(2,3)' % msg)\n",
                "        assert_(msg.find('(2,)->(2,newaxis)') >= 0,\n",
                "                ('Message \"%s\" doesn\\'t contain remapped operand shape' +\n",
                "                '(2,)->(2,newaxis)') % msg)\n",
                "        # The message should contain the itershape parameter\n",
                "        assert_(msg.find('(4,3)') >= 0,\n",
                "                'Message \"%s\" doesn\\'t contain itershape parameter (4,3)' % msg)\n",
                "\n",
                "    try:\n",
                "        nditer([np.zeros((2, 1, 1)), np.zeros((2,))],\n",
                "               [],\n",
                "               [['writeonly', 'no_broadcast'], ['readonly']])\n",
                "        raise AssertionError('Should have raised a broadcast error')\n",
                "    except ValueError as e:\n",
                "        msg = str(e)\n",
                "        # The message should contain the shape of the bad operand\n",
                "        assert_(msg.find('(2,1,1)') >= 0,\n",
                "            'Message \"%s\" doesn\\'t contain operand shape (2,1,1)' % msg)\n",
                "        # The message should contain the broadcast shape\n",
                "        assert_(msg.find('(2,1,2)') >= 0,\n",
                "                'Message \"%s\" doesn\\'t contain the broadcast shape (2,1,2)' % msg)\n",
                "\n",
                "def test_iter_flags_errors():\n",
                "    # Check that bad combinations of flags produce errors\n",
                "\n",
                "    a = arange(6)\n",
                "\n",
                "    # Not enough operands\n",
                "    assert_raises(ValueError, nditer, [], [], [])\n",
                "    # Too many operands\n",
                "    assert_raises(ValueError, nditer, [a]*100, [], [['readonly']]*100)\n",
                "    # Bad global flag\n",
                "    assert_raises(ValueError, nditer, [a], ['bad flag'], [['readonly']])\n",
                "    # Bad op flag\n",
                "    assert_raises(ValueError, nditer, [a], [], [['readonly', 'bad flag']])\n",
                "    # Bad order parameter\n",
                "    assert_raises(ValueError, nditer, [a], [], [['readonly']], order='G')\n",
                "    # Bad casting parameter\n",
                "    assert_raises(ValueError, nditer, [a], [], [['readonly']], casting='noon')\n",
                "    # op_flags must match ops\n",
                "    assert_raises(ValueError, nditer, [a]*3, [], [['readonly']]*2)\n",
                "    # Cannot track both a C and an F index\n",
                "    assert_raises(ValueError, nditer, a,\n",
                "                ['c_index', 'f_index'], [['readonly']])\n",
                "    # Inner iteration and multi-indices/indices are incompatible\n",
                "    assert_raises(ValueError, nditer, a,\n",
                "                ['external_loop', 'multi_index'], [['readonly']])\n",
                "    assert_raises(ValueError, nditer, a,\n",
                "                ['external_loop', 'c_index'], [['readonly']])\n",
                "    assert_raises(ValueError, nditer, a,\n",
                "                ['external_loop', 'f_index'], [['readonly']])\n",
                "    # Must specify exactly one of readwrite/readonly/writeonly per operand\n",
                "    assert_raises(ValueError, nditer, a, [], [[]])\n",
                "    assert_raises(ValueError, nditer, a, [], [['readonly', 'writeonly']])\n",
                "    assert_raises(ValueError, nditer, a, [], [['readonly', 'readwrite']])\n",
                "    assert_raises(ValueError, nditer, a, [], [['writeonly', 'readwrite']])\n",
                "    assert_raises(ValueError, nditer, a,\n",
                "                [], [['readonly', 'writeonly', 'readwrite']])\n",
                "    # Python scalars are always readonly\n",
                "    assert_raises(TypeError, nditer, 1.5, [], [['writeonly']])\n",
                "    assert_raises(TypeError, nditer, 1.5, [], [['readwrite']])\n",
                "    # Array scalars are always readonly\n",
                "    assert_raises(TypeError, nditer, np.int32(1), [], [['writeonly']])\n",
                "    assert_raises(TypeError, nditer, np.int32(1), [], [['readwrite']])\n",
                "    # Check readonly array\n",
                "    a.flags.writeable = False\n",
                "    assert_raises(ValueError, nditer, a, [], [['writeonly']])\n",
                "    assert_raises(ValueError, nditer, a, [], [['readwrite']])\n",
                "    a.flags.writeable = True\n",
                "    # Multi-indices available only with the multi_index flag\n",
                "    i = nditer(arange(6), [], [['readonly']])\n",
                "    assert_raises(ValueError, lambda i:i.multi_index, i)\n",
                "    # Index available only with an index flag\n",
                "    assert_raises(ValueError, lambda i:i.index, i)\n",
                "    # GotoCoords and GotoIndex incompatible with buffering or no_inner\n",
                "\n",
                "    def assign_multi_index(i):\n",
                "        i.multi_index = (0,)\n",
                "\n",
                "    def assign_index(i):\n",
                "        i.index = 0\n",
                "\n",
                "    def assign_iterindex(i):\n",
                "        i.iterindex = 0\n",
                "\n",
                "    def assign_iterrange(i):\n",
                "        i.iterrange = (0, 1)\n",
                "    i = nditer(arange(6), ['external_loop'])\n",
                "    assert_raises(ValueError, assign_multi_index, i)\n",
                "    assert_raises(ValueError, assign_index, i)\n",
                "    assert_raises(ValueError, assign_iterindex, i)\n",
                "    assert_raises(ValueError, assign_iterrange, i)\n",
                "    i = nditer(arange(6), ['buffered'])\n",
                "    assert_raises(ValueError, assign_multi_index, i)\n",
                "    assert_raises(ValueError, assign_index, i)\n",
                "    assert_raises(ValueError, assign_iterrange, i)\n",
                "    # Can't iterate if size is zero\n",
                "    assert_raises(ValueError, nditer, np.array([]))\n",
                "\n",
                "def test_iter_slice():\n",
                "    a, b, c = np.arange(3), np.arange(3), np.arange(3.)\n",
                "    i = nditer([a, b, c], [], ['readwrite'])\n",
                "    with i:\n",
                "        i[0:2] = (3, 3)\n",
                "        assert_equal(a, [3, 1, 2])\n",
                "        assert_equal(b, [3, 1, 2])\n",
                "        assert_equal(c, [0, 1, 2])\n",
                "        i[1] = 12\n",
                "        assert_equal(i[0:2], [3, 12])\n",
                "\n",
                "def test_iter_assign_mapping():\n",
                "    a = np.arange(24, dtype='f8').reshape(2, 3, 4).T\n",
                "    it = np.nditer(a, [], [['readwrite', 'updateifcopy']],\n",
                "                       casting='same_kind', op_dtypes=[np.dtype('f4')])\n",
                "    with it:\n",
                "        it.operands[0][...] = 3\n",
                "        it.operands[0][...] = 14\n",
                "    assert_equal(a, 14)\n",
                "    it = np.nditer(a, [], [['readwrite', 'updateifcopy']],\n",
                "                       casting='same_kind', op_dtypes=[np.dtype('f4')])\n",
                "    with it:\n",
                "        x = it.operands[0][-1:1]\n",
                "        x[...] = 14\n",
                "        it.operands[0][...] = -1234\n",
                "    assert_equal(a, -1234)\n",
                "    # check for no warnings on dealloc\n",
                "    x = None\n",
                "    it = None\n",
                "\n",
                "def test_iter_nbo_align_contig():\n",
                "    # Check that byte order, alignment, and contig changes work\n",
                "\n",
                "    # Byte order change by requesting a specific dtype\n",
                "    a = np.arange(6, dtype='f4')\n",
                "    au = a.byteswap()\n",
                "    au = au.view(au.dtype.newbyteorder())\n",
                "    assert_(a.dtype.byteorder != au.dtype.byteorder)\n",
                "    i = nditer(au, [], [['readwrite', 'updateifcopy']],\n",
                "                        casting='equiv',\n",
                "                        op_dtypes=[np.dtype('f4')])\n",
                "    with i:\n",
                "        # context manager triggers WRITEBACKIFCOPY on i at exit\n",
                "        assert_equal(i.dtypes[0].byteorder, a.dtype.byteorder)\n",
                "        assert_equal(i.operands[0].dtype.byteorder, a.dtype.byteorder)\n",
                "        assert_equal(i.operands[0], a)\n",
                "        i.operands[0][:] = 2\n",
                "    assert_equal(au, [2]*6)\n",
                "    del i  # should not raise a warning\n",
                "    # Byte order change by requesting NBO\n",
                "    a = np.arange(6, dtype='f4')\n",
                "    au = a.byteswap()\n",
                "    au = au.view(au.dtype.newbyteorder())\n",
                "    assert_(a.dtype.byteorder != au.dtype.byteorder)\n",
                "    with nditer(au, [], [['readwrite', 'updateifcopy', 'nbo']],\n",
                "                        casting='equiv') as i:\n",
                "        # context manager triggers UPDATEIFCOPY on i at exit\n",
                "        assert_equal(i.dtypes[0].byteorder, a.dtype.byteorder)\n",
                "        assert_equal(i.operands[0].dtype.byteorder, a.dtype.byteorder)\n",
                "        assert_equal(i.operands[0], a)\n",
                "        i.operands[0][:] = 12345\n",
                "        i.operands[0][:] = 2\n",
                "    assert_equal(au, [2]*6)\n",
                "\n",
                "    # Unaligned input\n",
                "    a = np.zeros((6*4+1,), dtype='i1')[1:]\n",
                "    a.dtype = 'f4'\n",
                "    a[:] = np.arange(6, dtype='f4')\n",
                "    assert_(not a.flags.aligned)\n",
                "    # Without 'aligned', shouldn't copy\n",
                "    i = nditer(a, [], [['readonly']])\n",
                "    assert_(not i.operands[0].flags.aligned)\n",
                "    assert_equal(i.operands[0], a)\n",
                "    # With 'aligned', should make a copy\n",
                "    with nditer(a, [], [['readwrite', 'updateifcopy', 'aligned']]) as i:\n",
                "        assert_(i.operands[0].flags.aligned)\n",
                "        # context manager triggers UPDATEIFCOPY on i at exit\n",
                "        assert_equal(i.operands[0], a)\n",
                "        i.operands[0][:] = 3\n",
                "    assert_equal(a, [3]*6)\n",
                "\n",
                "    # Discontiguous input\n",
                "    a = arange(12)\n",
                "    # If it is contiguous, shouldn't copy\n",
                "    i = nditer(a[:6], [], [['readonly']])\n",
                "    assert_(i.operands[0].flags.contiguous)\n",
                "    assert_equal(i.operands[0], a[:6])\n",
                "    # If it isn't contiguous, should buffer\n",
                "    i = nditer(a[::2], ['buffered', 'external_loop'],\n",
                "                        [['readonly', 'contig']],\n",
                "                        buffersize=10)\n",
                "    assert_(i[0].flags.contiguous)\n",
                "    assert_equal(i[0], a[::2])\n",
                "\n",
                "def test_iter_array_cast():\n",
                "    # Check that arrays are cast as requested\n",
                "\n",
                "    # No cast 'f4' -> 'f4'\n",
                "    a = np.arange(6, dtype='f4').reshape(2, 3)\n",
                "    i = nditer(a, [], [['readwrite']], op_dtypes=[np.dtype('f4')])\n",
                "    with i:\n",
                "        assert_equal(i.operands[0], a)\n",
                "        assert_equal(i.operands[0].dtype, np.dtype('f4'))\n",
                "\n",
                "    # Byte-order cast '<f4' -> '>f4'\n",
                "    a = np.arange(6, dtype='<f4').reshape(2, 3)\n",
                "    with nditer(a, [], [['readwrite', 'updateifcopy']],\n",
                "            casting='equiv',\n",
                "            op_dtypes=[np.dtype('>f4')]) as i:\n",
                "        assert_equal(i.operands[0], a)\n",
                "        assert_equal(i.operands[0].dtype, np.dtype('>f4'))\n",
                "\n",
                "    # Safe case 'f4' -> 'f8'\n",
                "    a = np.arange(24, dtype='f4').reshape(2, 3, 4).swapaxes(1, 2)\n",
                "    i = nditer(a, [], [['readonly', 'copy']],\n",
                "            casting='safe',\n",
                "            op_dtypes=[np.dtype('f8')])\n",
                "    assert_equal(i.operands[0], a)\n",
                "    assert_equal(i.operands[0].dtype, np.dtype('f8'))\n",
                "    # The memory layout of the temporary should match a (a is (48,4,16))\n",
                "    # except negative strides get flipped to positive strides.\n",
                "    assert_equal(i.operands[0].strides, (96, 8, 32))\n",
                "    a = a[::-1,:, ::-1]\n",
                "    i = nditer(a, [], [['readonly', 'copy']],\n",
                "            casting='safe',\n",
                "            op_dtypes=[np.dtype('f8')])\n",
                "    assert_equal(i.operands[0], a)\n",
                "    assert_equal(i.operands[0].dtype, np.dtype('f8'))\n",
                "    assert_equal(i.operands[0].strides, (96, 8, 32))\n",
                "\n",
                "    # Same-kind cast 'f8' -> 'f4' -> 'f8'\n",
                "    a = np.arange(24, dtype='f8').reshape(2, 3, 4).T\n",
                "    with nditer(a, [],\n",
                "            [['readwrite', 'updateifcopy']],\n",
                "            casting='same_kind',\n",
                "            op_dtypes=[np.dtype('f4')]) as i:\n",
                "        assert_equal(i.operands[0], a)\n",
                "        assert_equal(i.operands[0].dtype, np.dtype('f4'))\n",
                "        assert_equal(i.operands[0].strides, (4, 16, 48))\n",
                "        # Check that WRITEBACKIFCOPY is activated at exit\n",
                "        i.operands[0][2, 1, 1] = -12.5\n",
                "        assert_(a[2, 1, 1] != -12.5)\n",
                "    assert_equal(a[2, 1, 1], -12.5)\n",
                "\n",
                "    a = np.arange(6, dtype='i4')[::-2]\n",
                "    with nditer(a, [],\n",
                "            [['writeonly', 'updateifcopy']],\n",
                "            casting='unsafe',\n",
                "            op_dtypes=[np.dtype('f4')]) as i:\n",
                "        assert_equal(i.operands[0].dtype, np.dtype('f4'))\n",
                "        # Even though the stride was negative in 'a', it\n",
                "        # becomes positive in the temporary\n",
                "        assert_equal(i.operands[0].strides, (4,))\n",
                "        i.operands[0][:] = [1, 2, 3]\n",
                "    assert_equal(a, [1, 2, 3])\n",
                "\n",
                "def test_iter_array_cast_errors():\n",
                "    # Check that invalid casts are caught\n",
                "\n",
                "    # Need to enable copying for casts to occur\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f4'), [],\n",
                "                [['readonly']], op_dtypes=[np.dtype('f8')])\n",
                "    # Also need to allow casting for casts to occur\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f4'), [],\n",
                "                [['readonly', 'copy']], casting='no',\n",
                "                op_dtypes=[np.dtype('f8')])\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f4'), [],\n",
                "                [['readonly', 'copy']], casting='equiv',\n",
                "                op_dtypes=[np.dtype('f8')])\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f8'), [],\n",
                "                [['writeonly', 'updateifcopy']],\n",
                "                casting='no',\n",
                "                op_dtypes=[np.dtype('f4')])\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f8'), [],\n",
                "                [['writeonly', 'updateifcopy']],\n",
                "                casting='equiv',\n",
                "                op_dtypes=[np.dtype('f4')])\n",
                "    # '<f4' -> '>f4' should not work with casting='no'\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='<f4'), [],\n",
                "                [['readonly', 'copy']], casting='no',\n",
                "                op_dtypes=[np.dtype('>f4')])\n",
                "    # 'f4' -> 'f8' is a safe cast, but 'f8' -> 'f4' isn't\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f4'), [],\n",
                "                [['readwrite', 'updateifcopy']],\n",
                "                casting='safe',\n",
                "                op_dtypes=[np.dtype('f8')])\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f8'), [],\n",
                "                [['readwrite', 'updateifcopy']],\n",
                "                casting='safe',\n",
                "                op_dtypes=[np.dtype('f4')])\n",
                "    # 'f4' -> 'i4' is neither a safe nor a same-kind cast\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='f4'), [],\n",
                "                [['readonly', 'copy']],\n",
                "                casting='same_kind',\n",
                "                op_dtypes=[np.dtype('i4')])\n",
                "    assert_raises(TypeError, nditer, arange(2, dtype='i4'), [],\n",
                "                [['writeonly', 'updateifcopy']],\n",
                "                casting='same_kind',\n",
                "                op_dtypes=[np.dtype('f4')])\n",
                "\n",
                "def test_iter_scalar_cast():\n",
                "    # Check that scalars are cast as requested\n",
                "\n",
                "    # No cast 'f4' -> 'f4'\n",
                "    i = nditer(np.float32(2.5), [], [['readonly']],\n",
                "                    op_dtypes=[np.dtype('f4')])\n",
                "    assert_equal(i.dtypes[0], np.dtype('f4'))\n",
                "    assert_equal(i.value.dtype, np.dtype('f4'))\n",
                "    assert_equal(i.value, 2.5)\n",
                "    # Safe cast 'f4' -> 'f8'\n",
                "    i = nditer(np.float32(2.5), [],\n",
                "                    [['readonly', 'copy']],\n",
                "                    casting='safe',\n",
                "                    op_dtypes=[np.dtype('f8')])\n",
                "    assert_equal(i.dtypes[0], np.dtype('f8'))\n",
                "    assert_equal(i.value.dtype, np.dtype('f8'))\n",
                "    assert_equal(i.value, 2.5)\n",
                "    # Same-kind cast 'f8' -> 'f4'\n",
                "    i = nditer(np.float64(2.5), [],\n",
                "                    [['readonly', 'copy']],\n",
                "                    casting='same_kind',\n",
                "                    op_dtypes=[np.dtype('f4')])\n",
                "    assert_equal(i.dtypes[0], np.dtype('f4'))\n",
                "    assert_equal(i.value.dtype, np.dtype('f4'))\n",
                "    assert_equal(i.value, 2.5)\n",
                "    # Unsafe cast 'f8' -> 'i4'\n",
                "    i = nditer(np.float64(3.0), [],\n",
                "                    [['readonly', 'copy']],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=[np.dtype('i4')])\n",
                "    assert_equal(i.dtypes[0], np.dtype('i4'))\n",
                "    assert_equal(i.value.dtype, np.dtype('i4'))\n",
                "    assert_equal(i.value, 3)\n",
                "    # Readonly scalars may be cast even without setting COPY or BUFFERED\n",
                "    i = nditer(3, [], [['readonly']], op_dtypes=[np.dtype('f8')])\n",
                "    assert_equal(i[0].dtype, np.dtype('f8'))\n",
                "    assert_equal(i[0], 3.)\n",
                "\n",
                "def test_iter_scalar_cast_errors():\n",
                "    # Check that invalid casts are caught\n",
                "\n",
                "    # Need to allow copying/buffering for write casts of scalars to occur\n",
                "    assert_raises(TypeError, nditer, np.float32(2), [],\n",
                "                [['readwrite']], op_dtypes=[np.dtype('f8')])\n",
                "    assert_raises(TypeError, nditer, 2.5, [],\n",
                "                [['readwrite']], op_dtypes=[np.dtype('f4')])\n",
                "    # 'f8' -> 'f4' isn't a safe cast if the value would overflow\n",
                "    assert_raises(TypeError, nditer, np.float64(1e60), [],\n",
                "                [['readonly']],\n",
                "                casting='safe',\n",
                "                op_dtypes=[np.dtype('f4')])\n",
                "    # 'f4' -> 'i4' is neither a safe nor a same-kind cast\n",
                "    assert_raises(TypeError, nditer, np.float32(2), [],\n",
                "                [['readonly']],\n",
                "                casting='same_kind',\n",
                "                op_dtypes=[np.dtype('i4')])\n",
                "\n",
                "def test_iter_object_arrays_basic():\n",
                "    # Check that object arrays work\n",
                "\n",
                "    obj = {'a':3,'b':'d'}\n",
                "    a = np.array([[1, 2, 3], None, obj, None], dtype='O')\n",
                "    if HAS_REFCOUNT:\n",
                "        rc = sys.getrefcount(obj)\n",
                "\n",
                "    # Need to allow references for object arrays\n",
                "    assert_raises(TypeError, nditer, a)\n",
                "    if HAS_REFCOUNT:\n",
                "        assert_equal(sys.getrefcount(obj), rc)\n",
                "\n",
                "    i = nditer(a, ['refs_ok'], ['readonly'])\n",
                "    vals = [x_[()] for x_ in i]\n",
                "    assert_equal(np.array(vals, dtype='O'), a)\n",
                "    vals, i, x = [None]*3\n",
                "    if HAS_REFCOUNT:\n",
                "        assert_equal(sys.getrefcount(obj), rc)\n",
                "\n",
                "    i = nditer(a.reshape(2, 2).T, ['refs_ok', 'buffered'],\n",
                "                        ['readonly'], order='C')\n",
                "    assert_(i.iterationneedsapi)\n",
                "    vals = [x_[()] for x_ in i]\n",
                "    assert_equal(np.array(vals, dtype='O'), a.reshape(2, 2).ravel(order='F'))\n",
                "    vals, i, x = [None]*3\n",
                "    if HAS_REFCOUNT:\n",
                "        assert_equal(sys.getrefcount(obj), rc)\n",
                "\n",
                "    i = nditer(a.reshape(2, 2).T, ['refs_ok', 'buffered'],\n",
                "                        ['readwrite'], order='C')\n",
                "    with i:\n",
                "        for x in i:\n",
                "            x[...] = None\n",
                "        vals, i, x = [None]*3\n",
                "    if HAS_REFCOUNT:\n",
                "        assert_(sys.getrefcount(obj) == rc-1)\n",
                "    assert_equal(a, np.array([None]*4, dtype='O'))\n",
                "\n",
                "def test_iter_object_arrays_conversions():\n",
                "    # Conversions to/from objects\n",
                "    a = np.arange(6, dtype='O')\n",
                "    i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],\n",
                "                    casting='unsafe', op_dtypes='i4')\n",
                "    with i:\n",
                "        for x in i:\n",
                "            x[...] += 1\n",
                "    assert_equal(a, np.arange(6)+1)\n",
                "\n",
                "    a = np.arange(6, dtype='i4')\n",
                "    i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],\n",
                "                    casting='unsafe', op_dtypes='O')\n",
                "    with i:\n",
                "        for x in i:\n",
                "            x[...] += 1\n",
                "    assert_equal(a, np.arange(6)+1)\n",
                "\n",
                "    # Non-contiguous object array\n",
                "    a = np.zeros((6,), dtype=[('p', 'i1'), ('a', 'O')])\n",
                "    a = a['a']\n",
                "    a[:] = np.arange(6)\n",
                "    i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],\n",
                "                    casting='unsafe', op_dtypes='i4')\n",
                "    with i:\n",
                "        for x in i:\n",
                "            x[...] += 1\n",
                "    assert_equal(a, np.arange(6)+1)\n",
                "\n",
                "    #Non-contiguous value array\n",
                "    a = np.zeros((6,), dtype=[('p', 'i1'), ('a', 'i4')])\n",
                "    a = a['a']\n",
                "    a[:] = np.arange(6) + 98172488\n",
                "    i = nditer(a, ['refs_ok', 'buffered'], ['readwrite'],\n",
                "                    casting='unsafe', op_dtypes='O')\n",
                "    with i:\n",
                "        ob = i[0][()]\n",
                "        if HAS_REFCOUNT:\n",
                "            rc = sys.getrefcount(ob)\n",
                "        for x in i:\n",
                "            x[...] += 1\n",
                "    if HAS_REFCOUNT:\n",
                "        assert_(sys.getrefcount(ob) == rc-1)\n",
                "    assert_equal(a, np.arange(6)+98172489)\n",
                "\n",
                "def test_iter_common_dtype():\n",
                "    # Check that the iterator finds a common data type correctly\n",
                "    # (some checks are somewhat duplicate after adopting NEP 50)\n",
                "\n",
                "    i = nditer([array([3], dtype='f4'), array([0], dtype='f8')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy']]*2,\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('f8'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('f8'))\n",
                "    i = nditer([array([3], dtype='i4'), array([0], dtype='f4')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy']]*2,\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('f8'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('f8'))\n",
                "    i = nditer([array([3], dtype='f4'), array(0, dtype='f8')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy']]*2,\n",
                "                    casting='same_kind')\n",
                "    assert_equal(i.dtypes[0], np.dtype('f8'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('f8'))\n",
                "    i = nditer([array([3], dtype='u4'), array(0, dtype='i4')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy']]*2,\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('i8'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('i8'))\n",
                "    i = nditer([array([3], dtype='u4'), array(-12, dtype='i4')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy']]*2,\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('i8'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('i8'))\n",
                "    i = nditer([array([3], dtype='u4'), array(-12, dtype='i4'),\n",
                "                 array([2j], dtype='c8'), array([9], dtype='f8')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy']]*4,\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('c16'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('c16'))\n",
                "    assert_equal(i.dtypes[2], np.dtype('c16'))\n",
                "    assert_equal(i.dtypes[3], np.dtype('c16'))\n",
                "    assert_equal(i.value, (3, -12, 2j, 9))\n",
                "\n",
                "    # When allocating outputs, other outputs aren't factored in\n",
                "    i = nditer([array([3], dtype='i4'), None, array([2j], dtype='c16')], [],\n",
                "                    [['readonly', 'copy'],\n",
                "                     ['writeonly', 'allocate'],\n",
                "                     ['writeonly']],\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('i4'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('i4'))\n",
                "    assert_equal(i.dtypes[2], np.dtype('c16'))\n",
                "    # But, if common data types are requested, they are\n",
                "    i = nditer([array([3], dtype='i4'), None, array([2j], dtype='c16')],\n",
                "                    ['common_dtype'],\n",
                "                    [['readonly', 'copy'],\n",
                "                     ['writeonly', 'allocate'],\n",
                "                     ['writeonly']],\n",
                "                    casting='safe')\n",
                "    assert_equal(i.dtypes[0], np.dtype('c16'))\n",
                "    assert_equal(i.dtypes[1], np.dtype('c16'))\n",
                "    assert_equal(i.dtypes[2], np.dtype('c16'))\n",
                "\n",
                "def test_iter_copy_if_overlap():\n",
                "    # Ensure the iterator makes copies on read/write overlap, if requested\n",
                "\n",
                "    # Copy not needed, 1 op\n",
                "    for flag in ['readonly', 'writeonly', 'readwrite']:\n",
                "        a = arange(10)\n",
                "        i = nditer([a], ['copy_if_overlap'], [[flag]])\n",
                "        with i:\n",
                "            assert_(i.operands[0] is a)\n",
                "\n",
                "    # Copy needed, 2 ops, read-write overlap\n",
                "    x = arange(10)\n",
                "    a = x[1:]\n",
                "    b = x[:-1]\n",
                "    with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['readwrite']]) as i:\n",
                "        assert_(not np.shares_memory(*i.operands))\n",
                "\n",
                "    # Copy not needed with elementwise, 2 ops, exactly same arrays\n",
                "    x = arange(10)\n",
                "    a = x\n",
                "    b = x\n",
                "    i = nditer([a, b], ['copy_if_overlap'], [['readonly', 'overlap_assume_elementwise'],\n",
                "                                             ['readwrite', 'overlap_assume_elementwise']])\n",
                "    with i:\n",
                "        assert_(i.operands[0] is a and i.operands[1] is b)\n",
                "    with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['readwrite']]) as i:\n",
                "        assert_(i.operands[0] is a and not np.shares_memory(i.operands[1], b))\n",
                "\n",
                "    # Copy not needed, 2 ops, no overlap\n",
                "    x = arange(10)\n",
                "    a = x[::2]\n",
                "    b = x[1::2]\n",
                "    i = nditer([a, b], ['copy_if_overlap'], [['readonly'], ['writeonly']])\n",
                "    assert_(i.operands[0] is a and i.operands[1] is b)\n",
                "\n",
                "    # Copy needed, 2 ops, read-write overlap\n",
                "    x = arange(4, dtype=np.int8)\n",
                "    a = x[3:]\n",
                "    b = x.view(np.int32)[:1]\n",
                "    with nditer([a, b], ['copy_if_overlap'], [['readonly'], ['writeonly']]) as i:\n",
                "        assert_(not np.shares_memory(*i.operands))\n",
                "\n",
                "    # Copy needed, 3 ops, read-write overlap\n",
                "    for flag in ['writeonly', 'readwrite']:\n",
                "        x = np.ones([10, 10])\n",
                "        a = x\n",
                "        b = x.T\n",
                "        c = x\n",
                "        with nditer([a, b, c], ['copy_if_overlap'],\n",
                "                   [['readonly'], ['readonly'], [flag]]) as i:\n",
                "            a2, b2, c2 = i.operands\n",
                "            assert_(not np.shares_memory(a2, c2))\n",
                "            assert_(not np.shares_memory(b2, c2))\n",
                "\n",
                "    # Copy not needed, 3 ops, read-only overlap\n",
                "    x = np.ones([10, 10])\n",
                "    a = x\n",
                "    b = x.T\n",
                "    c = x\n",
                "    i = nditer([a, b, c], ['copy_if_overlap'],\n",
                "               [['readonly'], ['readonly'], ['readonly']])\n",
                "    a2, b2, c2 = i.operands\n",
                "    assert_(a is a2)\n",
                "    assert_(b is b2)\n",
                "    assert_(c is c2)\n",
                "\n",
                "    # Copy not needed, 3 ops, read-only overlap\n",
                "    x = np.ones([10, 10])\n",
                "    a = x\n",
                "    b = np.ones([10, 10])\n",
                "    c = x.T\n",
                "    i = nditer([a, b, c], ['copy_if_overlap'],\n",
                "               [['readonly'], ['writeonly'], ['readonly']])\n",
                "    a2, b2, c2 = i.operands\n",
                "    assert_(a is a2)\n",
                "    assert_(b is b2)\n",
                "    assert_(c is c2)\n",
                "\n",
                "    # Copy not needed, 3 ops, write-only overlap\n",
                "    x = np.arange(7)\n",
                "    a = x[:3]\n",
                "    b = x[3:6]\n",
                "    c = x[4:7]\n",
                "    i = nditer([a, b, c], ['copy_if_overlap'],\n",
                "               [['readonly'], ['writeonly'], ['writeonly']])\n",
                "    a2, b2, c2 = i.operands\n",
                "    assert_(a is a2)\n",
                "    assert_(b is b2)\n",
                "    assert_(c is c2)\n",
                "\n",
                "def test_iter_op_axes():\n",
                "    # Check that custom axes work\n",
                "\n",
                "    # Reverse the axes\n",
                "    a = arange(6).reshape(2, 3)\n",
                "    i = nditer([a, a.T], [], [['readonly']]*2, op_axes=[[0, 1], [1, 0]])\n",
                "    assert_(all([x == y for (x, y) in i]))\n",
                "    a = arange(24).reshape(2, 3, 4)\n",
                "    i = nditer([a.T, a], [], [['readonly']]*2, op_axes=[[2, 1, 0], None])\n",
                "    assert_(all([x == y for (x, y) in i]))\n",
                "\n",
                "    # Broadcast 1D to any dimension\n",
                "    a = arange(1, 31).reshape(2, 3, 5)\n",
                "    b = arange(1, 3)\n",
                "    i = nditer([a, b], [], [['readonly']]*2, op_axes=[None, [0, -1, -1]])\n",
                "    assert_equal([x*y for (x, y) in i], (a*b.reshape(2, 1, 1)).ravel())\n",
                "    b = arange(1, 4)\n",
                "    i = nditer([a, b], [], [['readonly']]*2, op_axes=[None, [-1, 0, -1]])\n",
                "    assert_equal([x*y for (x, y) in i], (a*b.reshape(1, 3, 1)).ravel())\n",
                "    b = arange(1, 6)\n",
                "    i = nditer([a, b], [], [['readonly']]*2,\n",
                "                            op_axes=[None, [np.newaxis, np.newaxis, 0]])\n",
                "    assert_equal([x*y for (x, y) in i], (a*b.reshape(1, 1, 5)).ravel())\n",
                "\n",
                "    # Inner product-style broadcasting\n",
                "    a = arange(24).reshape(2, 3, 4)\n",
                "    b = arange(40).reshape(5, 2, 4)\n",
                "    i = nditer([a, b], ['multi_index'], [['readonly']]*2,\n",
                "                            op_axes=[[0, 1, -1, -1], [-1, -1, 0, 1]])\n",
                "    assert_equal(i.shape, (2, 3, 5, 2))\n",
                "\n",
                "    # Matrix product-style broadcasting\n",
                "    a = arange(12).reshape(3, 4)\n",
                "    b = arange(20).reshape(4, 5)\n",
                "    i = nditer([a, b], ['multi_index'], [['readonly']]*2,\n",
                "                            op_axes=[[0, -1], [-1, 1]])\n",
                "    assert_equal(i.shape, (3, 5))\n",
                "\n",
                "def test_iter_op_axes_errors():\n",
                "    # Check that custom axes throws errors for bad inputs\n",
                "\n",
                "    # Wrong number of items in op_axes\n",
                "    a = arange(6).reshape(2, 3)\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[0], [1], [0]])\n",
                "    # Out of bounds items in op_axes\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[2, 1], [0, 1]])\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[0, 1], [2, -1]])\n",
                "    # Duplicate items in op_axes\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[0, 0], [0, 1]])\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[0, 1], [1, 1]])\n",
                "\n",
                "    # Different sized arrays in op_axes\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[0, 1], [0, 1, 0]])\n",
                "\n",
                "    # Non-broadcastable dimensions in the result\n",
                "    assert_raises(ValueError, nditer, [a, a], [], [['readonly']]*2,\n",
                "                                    op_axes=[[0, 1], [1, 0]])\n",
                "\n",
                "def test_iter_copy():\n",
                "    # Check that copying the iterator works correctly\n",
                "    a = arange(24).reshape(2, 3, 4)\n",
                "\n",
                "    # Simple iterator\n",
                "    i = nditer(a)\n",
                "    j = i.copy()\n",
                "    assert_equal([x[()] for x in i], [x[()] for x in j])\n",
                "\n",
                "    i.iterindex = 3\n",
                "    j = i.copy()\n",
                "    assert_equal([x[()] for x in i], [x[()] for x in j])\n",
                "\n",
                "    # Buffered iterator\n",
                "    i = nditer(a, ['buffered', 'ranged'], order='F', buffersize=3)\n",
                "    j = i.copy()\n",
                "    assert_equal([x[()] for x in i], [x[()] for x in j])\n",
                "\n",
                "    i.iterindex = 3\n",
                "    j = i.copy()\n",
                "    assert_equal([x[()] for x in i], [x[()] for x in j])\n",
                "\n",
                "    i.iterrange = (3, 9)\n",
                "    j = i.copy()\n",
                "    assert_equal([x[()] for x in i], [x[()] for x in j])\n",
                "\n",
                "    i.iterrange = (2, 18)\n",
                "    next(i)\n",
                "    next(i)\n",
                "    j = i.copy()\n",
                "    assert_equal([x[()] for x in i], [x[()] for x in j])\n",
                "\n",
                "    # Casting iterator\n",
                "    with nditer(a, ['buffered'], order='F', casting='unsafe',\n",
                "                op_dtypes='f8', buffersize=5) as i:\n",
                "        j = i.copy()\n",
                "    assert_equal([x[()] for x in j], a.ravel(order='F'))\n",
                "\n",
                "    a = arange(24, dtype='<i4').reshape(2, 3, 4)\n",
                "    with nditer(a, ['buffered'], order='F', casting='unsafe',\n",
                "                op_dtypes='>f8', buffersize=5) as i:\n",
                "        j = i.copy()\n",
                "    assert_equal([x[()] for x in j], a.ravel(order='F'))\n",
                "\n",
                "\n",
                "@pytest.mark.parametrize(\"dtype\", np.typecodes[\"All\"])\n",
                "@pytest.mark.parametrize(\"loop_dtype\", np.typecodes[\"All\"])\n",
                "@pytest.mark.filterwarnings(\"ignore::numpy.exceptions.ComplexWarning\")\n",
                "def test_iter_copy_casts(dtype, loop_dtype):\n",
                "    # Ensure the dtype is never flexible:\n",
                "    if loop_dtype.lower() == \"m\":\n",
                "        loop_dtype = loop_dtype + \"[ms]\"\n",
                "    elif np.dtype(loop_dtype).itemsize == 0:\n",
                "        loop_dtype = loop_dtype + \"50\"\n",
                "\n",
                "    # Make things a bit more interesting by requiring a byte-swap as well:\n",
                "    arr = np.ones(1000, dtype=np.dtype(dtype).newbyteorder())\n",
                "    try:\n",
                "        expected = arr.astype(loop_dtype)\n",
                "    except Exception:\n",
                "        # Some casts are not possible, do not worry about them\n",
                "        return\n",
                "\n",
                "    it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],\n",
                "                   op_dtypes=[loop_dtype], casting=\"unsafe\")\n",
                "\n",
                "    if np.issubdtype(np.dtype(loop_dtype), np.number):\n",
                "        # Casting to strings may be strange, but for simple dtypes do not rely\n",
                "        # on the cast being correct:\n",
                "        assert_array_equal(expected, np.ones(1000, dtype=loop_dtype))\n",
                "\n",
                "    it_copy = it.copy()\n",
                "    res = next(it)\n",
                "    del it\n",
                "    res_copy = next(it_copy)\n",
                "    del it_copy\n",
                "\n",
                "    assert_array_equal(res, expected)\n",
                "    assert_array_equal(res_copy, expected)\n",
                "\n",
                "\n",
                "def test_iter_copy_casts_structured():\n",
                "    # Test a complicated structured dtype for casting, as it requires\n",
                "    # both multiple steps and a more complex casting setup.\n",
                "    # Includes a structured -> unstructured (any to object), and many other\n",
                "    # casts, which cause this to require all steps in the casting machinery\n",
                "    # one level down as well as the iterator copy (which uses NpyAuxData clone)\n",
                "    in_dtype = np.dtype([(\"a\", np.dtype(\"i,\")),\n",
                "                         (\"b\", np.dtype(\">i,<i,>d,S17,>d,3f,O,i1\"))])\n",
                "    out_dtype = np.dtype([(\"a\", np.dtype(\"O\")),\n",
                "                          (\"b\", np.dtype(\">i,>i,S17,>d,>U3,3d,i1,O\"))])\n",
                "    arr = np.ones(1000, dtype=in_dtype)\n",
                "\n",
                "    it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],\n",
                "                   op_dtypes=[out_dtype], casting=\"unsafe\")\n",
                "    it_copy = it.copy()\n",
                "\n",
                "    res1 = next(it)\n",
                "    del it\n",
                "    res2 = next(it_copy)\n",
                "    del it_copy\n",
                "\n",
                "    expected = arr[\"a\"].astype(out_dtype[\"a\"])\n",
                "    assert_array_equal(res1[\"a\"], expected)\n",
                "    assert_array_equal(res2[\"a\"], expected)\n",
                "\n",
                "    for field in in_dtype[\"b\"].names:\n",
                "        # Note that the .base avoids the subarray field\n",
                "        expected = arr[\"b\"][field].astype(out_dtype[\"b\"][field].base)\n",
                "        assert_array_equal(res1[\"b\"][field], expected)\n",
                "        assert_array_equal(res2[\"b\"][field], expected)\n",
                "\n",
                "\n",
                "def test_iter_copy_casts_structured2():\n",
                "    # Similar to the above, this is a fairly arcane test to cover internals\n",
                "    in_dtype = np.dtype([(\"a\", np.dtype(\"O,O\")),\n",
                "                         (\"b\", np.dtype(\"5O,3O,(1,)O,(1,)i,(1,)O\"))])\n",
                "    out_dtype = np.dtype([(\"a\", np.dtype(\"O\")),\n",
                "                          (\"b\", np.dtype(\"O,3i,4O,4O,4i\"))])\n",
                "\n",
                "    arr = np.ones(1, dtype=in_dtype)\n",
                "    it = np.nditer((arr,), [\"buffered\", \"external_loop\", \"refs_ok\"],\n",
                "                   op_dtypes=[out_dtype], casting=\"unsafe\")\n",
                "    it_copy = it.copy()\n",
                "\n",
                "    res1 = next(it)\n",
                "    del it\n",
                "    res2 = next(it_copy)\n",
                "    del it_copy\n",
                "\n",
                "    # Array of two structured scalars:\n",
                "    for res in res1, res2:\n",
                "        # Cast to tuple by getitem, which may be weird and changeable?:\n",
                "        assert type(res[\"a\"][0]) == tuple\n",
                "        assert res[\"a\"][0] == (1, 1)\n",
                "\n",
                "    for res in res1, res2:\n",
                "        assert_array_equal(res[\"b\"][\"f0\"][0], np.ones(5, dtype=object))\n",
                "        assert_array_equal(res[\"b\"][\"f1\"], np.ones((1, 3), dtype=\"i\"))\n",
                "        assert res[\"b\"][\"f2\"].shape == (1, 4)\n",
                "        assert_array_equal(res[\"b\"][\"f2\"][0], np.ones(4, dtype=object))\n",
                "        assert_array_equal(res[\"b\"][\"f3\"][0], np.ones(4, dtype=object))\n",
                "        assert_array_equal(res[\"b\"][\"f3\"][0], np.ones(4, dtype=\"i\"))\n",
                "\n",
                "\n",
                "def test_iter_allocate_output_simple():\n",
                "    # Check that the iterator will properly allocate outputs\n",
                "\n",
                "    # Simple case\n",
                "    a = arange(6)\n",
                "    i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')])\n",
                "    assert_equal(i.operands[1].shape, a.shape)\n",
                "    assert_equal(i.operands[1].dtype, np.dtype('f4'))\n",
                "\n",
                "def test_iter_allocate_output_buffered_readwrite():\n",
                "    # Allocated output with buffering + delay_bufalloc\n",
                "\n",
                "    a = arange(6)\n",
                "    i = nditer([a, None], ['buffered', 'delay_bufalloc'],\n",
                "                        [['readonly'], ['allocate', 'readwrite']])\n",
                "    with i:\n",
                "        i.operands[1][:] = 1\n",
                "        i.reset()\n",
                "        for x in i:\n",
                "            x[1][...] += x[0][...]\n",
                "        assert_equal(i.operands[1], a+1)\n",
                "\n",
                "def test_iter_allocate_output_itorder():\n",
                "    # The allocated output should match the iteration order\n",
                "\n",
                "    # C-order input, best iteration order\n",
                "    a = arange(6, dtype='i4').reshape(2, 3)\n",
                "    i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')])\n",
                "    assert_equal(i.operands[1].shape, a.shape)\n",
                "    assert_equal(i.operands[1].strides, a.strides)\n",
                "    assert_equal(i.operands[1].dtype, np.dtype('f4'))\n",
                "    # F-order input, best iteration order\n",
                "    a = arange(24, dtype='i4').reshape(2, 3, 4).T\n",
                "    i = nditer([a, None], [], [['readonly'], ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')])\n",
                "    assert_equal(i.operands[1].shape, a.shape)\n",
                "    assert_equal(i.operands[1].strides, a.strides)\n",
                "    assert_equal(i.operands[1].dtype, np.dtype('f4'))\n",
                "    # Non-contiguous input, C iteration order\n",
                "    a = arange(24, dtype='i4').reshape(2, 3, 4).swapaxes(0, 1)\n",
                "    i = nditer([a, None], [],\n",
                "                        [['readonly'], ['writeonly', 'allocate']],\n",
                "                        order='C',\n",
                "                        op_dtypes=[None, np.dtype('f4')])\n",
                "    assert_equal(i.operands[1].shape, a.shape)\n",
                "    assert_equal(i.operands[1].strides, (32, 16, 4))\n",
                "    assert_equal(i.operands[1].dtype, np.dtype('f4'))\n",
                "\n",
                "def test_iter_allocate_output_opaxes():\n",
                "    # Specifying op_axes should work\n",
                "\n",
                "    a = arange(24, dtype='i4').reshape(2, 3, 4)\n",
                "    i = nditer([None, a], [], [['writeonly', 'allocate'], ['readonly']],\n",
                "                        op_dtypes=[np.dtype('u4'), None],\n",
                "                        op_axes=[[1, 2, 0], None])\n",
                "    assert_equal(i.operands[0].shape, (4, 2, 3))\n",
                "    assert_equal(i.operands[0].strides, (4, 48, 16))\n",
                "    assert_equal(i.operands[0].dtype, np.dtype('u4'))\n",
                "\n",
                "def test_iter_allocate_output_types_promotion():\n",
                "    # Check type promotion of automatic outputs (this was more interesting\n",
                "    # before NEP 50...)\n",
                "\n",
                "    i = nditer([array([3], dtype='f4'), array([0], dtype='f8'), None], [],\n",
                "                    [['readonly']]*2+[['writeonly', 'allocate']])\n",
                "    assert_equal(i.dtypes[2], np.dtype('f8'))\n",
                "    i = nditer([array([3], dtype='i4'), array([0], dtype='f4'), None], [],\n",
                "                    [['readonly']]*2+[['writeonly', 'allocate']])\n",
                "    assert_equal(i.dtypes[2], np.dtype('f8'))\n",
                "    i = nditer([array([3], dtype='f4'), array(0, dtype='f8'), None], [],\n",
                "                    [['readonly']]*2+[['writeonly', 'allocate']])\n",
                "    assert_equal(i.dtypes[2], np.dtype('f8'))\n",
                "    i = nditer([array([3], dtype='u4'), array(0, dtype='i4'), None], [],\n",
                "                    [['readonly']]*2+[['writeonly', 'allocate']])\n",
                "    assert_equal(i.dtypes[2], np.dtype('i8'))\n",
                "    i = nditer([array([3], dtype='u4'), array(-12, dtype='i4'), None], [],\n",
                "                    [['readonly']]*2+[['writeonly', 'allocate']])\n",
                "    assert_equal(i.dtypes[2], np.dtype('i8'))\n",
                "\n",
                "def test_iter_allocate_output_types_byte_order():\n",
                "    # Verify the rules for byte order changes\n",
                "\n",
                "    # When there's just one input, the output type exactly matches\n",
                "    a = array([3], dtype='u4')\n",
                "    a = a.view(a.dtype.newbyteorder())\n",
                "    i = nditer([a, None], [],\n",
                "                    [['readonly'], ['writeonly', 'allocate']])\n",
                "    assert_equal(i.dtypes[0], i.dtypes[1])\n",
                "    # With two or more inputs, the output type is in native byte order\n",
                "    i = nditer([a, a, None], [],\n",
                "                    [['readonly'], ['readonly'], ['writeonly', 'allocate']])\n",
                "    assert_(i.dtypes[0] != i.dtypes[2])\n",
                "    assert_equal(i.dtypes[0].newbyteorder('='), i.dtypes[2])\n",
                "\n",
                "def test_iter_allocate_output_types_scalar():\n",
                "    # If the inputs are all scalars, the output should be a scalar\n",
                "\n",
                "    i = nditer([None, 1, 2.3, np.float32(12), np.complex128(3)], [],\n",
                "                [['writeonly', 'allocate']] + [['readonly']]*4)\n",
                "    assert_equal(i.operands[0].dtype, np.dtype('complex128'))\n",
                "    assert_equal(i.operands[0].ndim, 0)\n",
                "\n",
                "def test_iter_allocate_output_subtype():\n",
                "    # Make sure that the subtype with priority wins\n",
                "    class MyNDArray(np.ndarray):\n",
                "        __array_priority__ = 15\n",
                "\n",
                "    # subclass vs ndarray\n",
                "    a = np.array([[1, 2], [3, 4]]).view(MyNDArray)\n",
                "    b = np.arange(4).reshape(2, 2).T\n",
                "    i = nditer([a, b, None], [],\n",
                "               [['readonly'], ['readonly'], ['writeonly', 'allocate']])\n",
                "    assert_equal(type(a), type(i.operands[2]))\n",
                "    assert_(type(b) is not type(i.operands[2]))\n",
                "    assert_equal(i.operands[2].shape, (2, 2))\n",
                "\n",
                "    # If subtypes are disabled, we should get back an ndarray.\n",
                "    i = nditer([a, b, None], [],\n",
                "               [['readonly'], ['readonly'],\n",
                "                ['writeonly', 'allocate', 'no_subtype']])\n",
                "    assert_equal(type(b), type(i.operands[2]))\n",
                "    assert_(type(a) is not type(i.operands[2]))\n",
                "    assert_equal(i.operands[2].shape, (2, 2))\n",
                "\n",
                "def test_iter_allocate_output_errors():\n",
                "    # Check that the iterator will throw errors for bad output allocations\n",
                "\n",
                "    # Need an input if no output data type is specified\n",
                "    a = arange(6)\n",
                "    assert_raises(TypeError, nditer, [a, None], [],\n",
                "                        [['writeonly'], ['writeonly', 'allocate']])\n",
                "    # Allocated output should be flagged for writing\n",
                "    assert_raises(ValueError, nditer, [a, None], [],\n",
                "                        [['readonly'], ['allocate', 'readonly']])\n",
                "    # Allocated output can't have buffering without delayed bufalloc\n",
                "    assert_raises(ValueError, nditer, [a, None], ['buffered'],\n",
                "                                            ['allocate', 'readwrite'])\n",
                "    # Must specify dtype if there are no inputs (cannot promote existing ones;\n",
                "    # maybe this should use the 'f4' here, but it does not historically.)\n",
                "    assert_raises(TypeError, nditer, [None, None], [],\n",
                "                        [['writeonly', 'allocate'],\n",
                "                         ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')])\n",
                "    # If using op_axes, must specify all the axes\n",
                "    a = arange(24, dtype='i4').reshape(2, 3, 4)\n",
                "    assert_raises(ValueError, nditer, [a, None], [],\n",
                "                        [['readonly'], ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')],\n",
                "                        op_axes=[None, [0, np.newaxis, 1]])\n",
                "    # If using op_axes, the axes must be within bounds\n",
                "    assert_raises(ValueError, nditer, [a, None], [],\n",
                "                        [['readonly'], ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')],\n",
                "                        op_axes=[None, [0, 3, 1]])\n",
                "    # If using op_axes, there can't be duplicates\n",
                "    assert_raises(ValueError, nditer, [a, None], [],\n",
                "                        [['readonly'], ['writeonly', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')],\n",
                "                        op_axes=[None, [0, 2, 1, 0]])\n",
                "    # Not all axes may be specified if a reduction. If there is a hole\n",
                "    # in op_axes, this is an error.\n",
                "    a = arange(24, dtype='i4').reshape(2, 3, 4)\n",
                "    assert_raises(ValueError, nditer, [a, None], [\"reduce_ok\"],\n",
                "                        [['readonly'], ['readwrite', 'allocate']],\n",
                "                        op_dtypes=[None, np.dtype('f4')],\n",
                "                        op_axes=[None, [0, np.newaxis, 2]])\n",
                "\n",
                "def test_all_allocated():\n",
                "    # When no output and no shape is given, `()` is used as shape.\n",
                "    i = np.nditer([None], op_dtypes=[\"int64\"])\n",
                "    assert i.operands[0].shape == ()\n",
                "    assert i.dtypes == (np.dtype(\"int64\"),)\n",
                "\n",
                "    i = np.nditer([None], op_dtypes=[\"int64\"], itershape=(2, 3, 4))\n",
                "    assert i.operands[0].shape == (2, 3, 4)\n",
                "\n",
                "def test_iter_remove_axis():\n",
                "    a = arange(24).reshape(2, 3, 4)\n",
                "\n",
                "    i = nditer(a, ['multi_index'])\n",
                "    i.remove_axis(1)\n",
                "    assert_equal([x for x in i], a[:, 0,:].ravel())\n",
                "\n",
                "    a = a[::-1,:,:]\n",
                "    i = nditer(a, ['multi_index'])\n",
                "    i.remove_axis(0)\n",
                "    assert_equal([x for x in i], a[0,:,:].ravel())\n",
                "\n",
                "def test_iter_remove_multi_index_inner_loop():\n",
                "    # Check that removing multi-index support works\n",
                "\n",
                "    a = arange(24).reshape(2, 3, 4)\n",
                "\n",
                "    i = nditer(a, ['multi_index'])\n",
                "    assert_equal(i.ndim, 3)\n",
                "    assert_equal(i.shape, (2, 3, 4))\n",
                "    assert_equal(i.itviews[0].shape, (2, 3, 4))\n",
                "\n",
                "    # Removing the multi-index tracking causes all dimensions to coalesce\n",
                "    before = [x for x in i]\n",
                "    i.remove_multi_index()\n",
                "    after = [x for x in i]\n",
                "\n",
                "    assert_equal(before, after)\n",
                "    assert_equal(i.ndim, 1)\n",
                "    assert_raises(ValueError, lambda i:i.shape, i)\n",
                "    assert_equal(i.itviews[0].shape, (24,))\n",
                "\n",
                "    # Removing the inner loop means there's just one iteration\n",
                "    i.reset()\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i[0].shape, tuple())\n",
                "    i.enable_external_loop()\n",
                "    assert_equal(i.itersize, 24)\n",
                "    assert_equal(i[0].shape, (24,))\n",
                "    assert_equal(i.value, arange(24))\n",
                "\n",
                "def test_iter_iterindex():\n",
                "    # Make sure iterindex works\n",
                "\n",
                "    buffersize = 5\n",
                "    a = arange(24).reshape(4, 3, 2)\n",
                "    for flags in ([], ['buffered']):\n",
                "        i = nditer(a, flags, buffersize=buffersize)\n",
                "        assert_equal(iter_iterindices(i), list(range(24)))\n",
                "        i.iterindex = 2\n",
                "        assert_equal(iter_iterindices(i), list(range(2, 24)))\n",
                "\n",
                "        i = nditer(a, flags, order='F', buffersize=buffersize)\n",
                "        assert_equal(iter_iterindices(i), list(range(24)))\n",
                "        i.iterindex = 5\n",
                "        assert_equal(iter_iterindices(i), list(range(5, 24)))\n",
                "\n",
                "        i = nditer(a[::-1], flags, order='F', buffersize=buffersize)\n",
                "        assert_equal(iter_iterindices(i), list(range(24)))\n",
                "        i.iterindex = 9\n",
                "        assert_equal(iter_iterindices(i), list(range(9, 24)))\n",
                "\n",
                "        i = nditer(a[::-1, ::-1], flags, order='C', buffersize=buffersize)\n",
                "        assert_equal(iter_iterindices(i), list(range(24)))\n",
                "        i.iterindex = 13\n",
                "        assert_equal(iter_iterindices(i), list(range(13, 24)))\n",
                "\n",
                "        i = nditer(a[::1, ::-1], flags, buffersize=buffersize)\n",
                "        assert_equal(iter_iterindices(i), list(range(24)))\n",
                "        i.iterindex = 23\n",
                "        assert_equal(iter_iterindices(i), list(range(23, 24)))\n",
                "        i.reset()\n",
                "        i.iterindex = 2\n",
                "        assert_equal(iter_iterindices(i), list(range(2, 24)))\n",
                "\n",
                "def test_iter_iterrange():\n",
                "    # Make sure getting and resetting the iterrange works\n",
                "\n",
                "    buffersize = 5\n",
                "    a = arange(24, dtype='i4').reshape(4, 3, 2)\n",
                "    a_fort = a.ravel(order='F')\n",
                "\n",
                "    i = nditer(a, ['ranged'], ['readonly'], order='F',\n",
                "                buffersize=buffersize)\n",
                "    assert_equal(i.iterrange, (0, 24))\n",
                "    assert_equal([x[()] for x in i], a_fort)\n",
                "    for r in [(0, 24), (1, 2), (3, 24), (5, 5), (0, 20), (23, 24)]:\n",
                "        i.iterrange = r\n",
                "        assert_equal(i.iterrange, r)\n",
                "        assert_equal([x[()] for x in i], a_fort[r[0]:r[1]])\n",
                "\n",
                "    i = nditer(a, ['ranged', 'buffered'], ['readonly'], order='F',\n",
                "                op_dtypes='f8', buffersize=buffersize)\n",
                "    assert_equal(i.iterrange, (0, 24))\n",
                "    assert_equal([x[()] for x in i], a_fort)\n",
                "    for r in [(0, 24), (1, 2), (3, 24), (5, 5), (0, 20), (23, 24)]:\n",
                "        i.iterrange = r\n",
                "        assert_equal(i.iterrange, r)\n",
                "        assert_equal([x[()] for x in i], a_fort[r[0]:r[1]])\n",
                "\n",
                "    def get_array(i):\n",
                "        val = np.array([], dtype='f8')\n",
                "        for x in i:\n",
                "            val = np.concatenate((val, x))\n",
                "        return val\n",
                "\n",
                "    i = nditer(a, ['ranged', 'buffered', 'external_loop'],\n",
                "                ['readonly'], order='F',\n",
                "                op_dtypes='f8', buffersize=buffersize)\n",
                "    assert_equal(i.iterrange, (0, 24))\n",
                "    assert_equal(get_array(i), a_fort)\n",
                "    for r in [(0, 24), (1, 2), (3, 24), (5, 5), (0, 20), (23, 24)]:\n",
                "        i.iterrange = r\n",
                "        assert_equal(i.iterrange, r)\n",
                "        assert_equal(get_array(i), a_fort[r[0]:r[1]])\n",
                "\n",
                "def test_iter_buffering():\n",
                "    # Test buffering with several buffer sizes and types\n",
                "    arrays = []\n",
                "    # F-order swapped array\n",
                "    _tmp = np.arange(24, dtype='c16').reshape(2, 3, 4).T\n",
                "    _tmp = _tmp.view(_tmp.dtype.newbyteorder()).byteswap()\n",
                "    arrays.append(_tmp)\n",
                "    # Contiguous 1-dimensional array\n",
                "    arrays.append(np.arange(10, dtype='f4'))\n",
                "    # Unaligned array\n",
                "    a = np.zeros((4*16+1,), dtype='i1')[1:]\n",
                "    a.dtype = 'i4'\n",
                "    a[:] = np.arange(16, dtype='i4')\n",
                "    arrays.append(a)\n",
                "    # 4-D F-order array\n",
                "    arrays.append(np.arange(120, dtype='i4').reshape(5, 3, 2, 4).T)\n",
                "    for a in arrays:\n",
                "        for buffersize in (1, 2, 3, 5, 8, 11, 16, 1024):\n",
                "            vals = []\n",
                "            i = nditer(a, ['buffered', 'external_loop'],\n",
                "                           [['readonly', 'nbo', 'aligned']],\n",
                "                           order='C',\n",
                "                           casting='equiv',\n",
                "                           buffersize=buffersize)\n",
                "            while not i.finished:\n",
                "                assert_(i[0].size <= buffersize)\n",
                "                vals.append(i[0].copy())\n",
                "                i.iternext()\n",
                "            assert_equal(np.concatenate(vals), a.ravel(order='C'))\n",
                "\n",
                "def test_iter_write_buffering():\n",
                "    # Test that buffering of writes is working\n",
                "\n",
                "    # F-order swapped array\n",
                "    a = np.arange(24).reshape(2, 3, 4).T\n",
                "    a = a.view(a.dtype.newbyteorder()).byteswap()\n",
                "    i = nditer(a, ['buffered'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='equiv',\n",
                "                   order='C',\n",
                "                   buffersize=16)\n",
                "    x = 0\n",
                "    with i:\n",
                "        while not i.finished:\n",
                "            i[0] = x\n",
                "            x += 1\n",
                "            i.iternext()\n",
                "    assert_equal(a.ravel(order='C'), np.arange(24))\n",
                "\n",
                "def test_iter_buffering_delayed_alloc():\n",
                "    # Test that delaying buffer allocation works\n",
                "\n",
                "    a = np.arange(6)\n",
                "    b = np.arange(1, dtype='f4')\n",
                "    i = nditer([a, b], ['buffered', 'delay_bufalloc', 'multi_index', 'reduce_ok'],\n",
                "                    ['readwrite'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes='f4')\n",
                "    assert_(i.has_delayed_bufalloc)\n",
                "    assert_raises(ValueError, lambda i:i.multi_index, i)\n",
                "    assert_raises(ValueError, lambda i:i[0], i)\n",
                "    assert_raises(ValueError, lambda i:i[0:2], i)\n",
                "\n",
                "    def assign_iter(i):\n",
                "        i[0] = 0\n",
                "    assert_raises(ValueError, assign_iter, i)\n",
                "\n",
                "    i.reset()\n",
                "    assert_(not i.has_delayed_bufalloc)\n",
                "    assert_equal(i.multi_index, (0,))\n",
                "    with i:\n",
                "        assert_equal(i[0], 0)\n",
                "        i[1] = 1\n",
                "        assert_equal(i[0:2], [0, 1])\n",
                "        assert_equal([[x[0][()], x[1][()]] for x in i], list(zip(range(6), [1]*6)))\n",
                "\n",
                "def test_iter_buffered_cast_simple():\n",
                "    # Test that buffering can handle a simple cast\n",
                "\n",
                "    a = np.arange(10, dtype='f4')\n",
                "    i = nditer(a, ['buffered', 'external_loop'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='same_kind',\n",
                "                   op_dtypes=[np.dtype('f8')],\n",
                "                   buffersize=3)\n",
                "    with i:\n",
                "        for v in i:\n",
                "            v[...] *= 2\n",
                "\n",
                "    assert_equal(a, 2*np.arange(10, dtype='f4'))\n",
                "\n",
                "def test_iter_buffered_cast_byteswapped():\n",
                "    # Test that buffering can handle a cast which requires swap->cast->swap\n",
                "\n",
                "    a = np.arange(10, dtype='f4')\n",
                "    a = a.view(a.dtype.newbyteorder()).byteswap()\n",
                "    i = nditer(a, ['buffered', 'external_loop'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='same_kind',\n",
                "                   op_dtypes=[np.dtype('f8').newbyteorder()],\n",
                "                   buffersize=3)\n",
                "    with i:\n",
                "        for v in i:\n",
                "            v[...] *= 2\n",
                "\n",
                "    assert_equal(a, 2*np.arange(10, dtype='f4'))\n",
                "\n",
                "    with suppress_warnings() as sup:\n",
                "        sup.filter(np.exceptions.ComplexWarning)\n",
                "\n",
                "        a = np.arange(10, dtype='f8')\n",
                "        a = a.view(a.dtype.newbyteorder()).byteswap()\n",
                "        i = nditer(a, ['buffered', 'external_loop'],\n",
                "                       [['readwrite', 'nbo', 'aligned']],\n",
                "                       casting='unsafe',\n",
                "                       op_dtypes=[np.dtype('c8').newbyteorder()],\n",
                "                       buffersize=3)\n",
                "        with i:\n",
                "            for v in i:\n",
                "                v[...] *= 2\n",
                "\n",
                "        assert_equal(a, 2*np.arange(10, dtype='f8'))\n",
                "\n",
                "def test_iter_buffered_cast_byteswapped_complex():\n",
                "    # Test that buffering can handle a cast which requires swap->cast->copy\n",
                "\n",
                "    a = np.arange(10, dtype='c8')\n",
                "    a = a.view(a.dtype.newbyteorder()).byteswap()\n",
                "    a += 2j\n",
                "    i = nditer(a, ['buffered', 'external_loop'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='same_kind',\n",
                "                   op_dtypes=[np.dtype('c16')],\n",
                "                   buffersize=3)\n",
                "    with i:\n",
                "        for v in i:\n",
                "            v[...] *= 2\n",
                "    assert_equal(a, 2*np.arange(10, dtype='c8') + 4j)\n",
                "\n",
                "    a = np.arange(10, dtype='c8')\n",
                "    a += 2j\n",
                "    i = nditer(a, ['buffered', 'external_loop'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='same_kind',\n",
                "                   op_dtypes=[np.dtype('c16').newbyteorder()],\n",
                "                   buffersize=3)\n",
                "    with i:\n",
                "        for v in i:\n",
                "            v[...] *= 2\n",
                "    assert_equal(a, 2*np.arange(10, dtype='c8') + 4j)\n",
                "\n",
                "    a = np.arange(10, dtype=np.clongdouble)\n",
                "    a = a.view(a.dtype.newbyteorder()).byteswap()\n",
                "    a += 2j\n",
                "    i = nditer(a, ['buffered', 'external_loop'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='same_kind',\n",
                "                   op_dtypes=[np.dtype('c16')],\n",
                "                   buffersize=3)\n",
                "    with i:\n",
                "        for v in i:\n",
                "            v[...] *= 2\n",
                "    assert_equal(a, 2*np.arange(10, dtype=np.clongdouble) + 4j)\n",
                "\n",
                "    a = np.arange(10, dtype=np.longdouble)\n",
                "    a = a.view(a.dtype.newbyteorder()).byteswap()\n",
                "    i = nditer(a, ['buffered', 'external_loop'],\n",
                "                   [['readwrite', 'nbo', 'aligned']],\n",
                "                   casting='same_kind',\n",
                "                   op_dtypes=[np.dtype('f4')],\n",
                "                   buffersize=7)\n",
                "    with i:\n",
                "        for v in i:\n",
                "            v[...] *= 2\n",
                "    assert_equal(a, 2*np.arange(10, dtype=np.longdouble))\n",
                "\n",
                "def test_iter_buffered_cast_structured_type():\n",
                "    # Tests buffering of structured types\n",
                "\n",
                "    # simple -> struct type (duplicates the value)\n",
                "    sdt = [('a', 'f4'), ('b', 'i8'), ('c', 'c8', (2, 3)), ('d', 'O')]\n",
                "    a = np.arange(3, dtype='f4') + 0.5\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt)\n",
                "    vals = [np.array(x) for x in i]\n",
                "    assert_equal(vals[0]['a'], 0.5)\n",
                "    assert_equal(vals[0]['b'], 0)\n",
                "    assert_equal(vals[0]['c'], [[(0.5)]*3]*2)\n",
                "    assert_equal(vals[0]['d'], 0.5)\n",
                "    assert_equal(vals[1]['a'], 1.5)\n",
                "    assert_equal(vals[1]['b'], 1)\n",
                "    assert_equal(vals[1]['c'], [[(1.5)]*3]*2)\n",
                "    assert_equal(vals[1]['d'], 1.5)\n",
                "    assert_equal(vals[0].dtype, np.dtype(sdt))\n",
                "\n",
                "    # object -> struct type\n",
                "    sdt = [('a', 'f4'), ('b', 'i8'), ('c', 'c8', (2, 3)), ('d', 'O')]\n",
                "    a = np.zeros((3,), dtype='O')\n",
                "    a[0] = (0.5, 0.5, [[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]], 0.5)\n",
                "    a[1] = (1.5, 1.5, [[1.5, 1.5, 1.5], [1.5, 1.5, 1.5]], 1.5)\n",
                "    a[2] = (2.5, 2.5, [[2.5, 2.5, 2.5], [2.5, 2.5, 2.5]], 2.5)\n",
                "    if HAS_REFCOUNT:\n",
                "        rc = sys.getrefcount(a[0])\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt)\n",
                "    vals = [x.copy() for x in i]\n",
                "    assert_equal(vals[0]['a'], 0.5)\n",
                "    assert_equal(vals[0]['b'], 0)\n",
                "    assert_equal(vals[0]['c'], [[(0.5)]*3]*2)\n",
                "    assert_equal(vals[0]['d'], 0.5)\n",
                "    assert_equal(vals[1]['a'], 1.5)\n",
                "    assert_equal(vals[1]['b'], 1)\n",
                "    assert_equal(vals[1]['c'], [[(1.5)]*3]*2)\n",
                "    assert_equal(vals[1]['d'], 1.5)\n",
                "    assert_equal(vals[0].dtype, np.dtype(sdt))\n",
                "    vals, i, x = [None]*3\n",
                "    if HAS_REFCOUNT:\n",
                "        assert_equal(sys.getrefcount(a[0]), rc)\n",
                "\n",
                "    # single-field struct type -> simple\n",
                "    sdt = [('a', 'f4')]\n",
                "    a = np.array([(5.5,), (8,)], dtype=sdt)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes='i4')\n",
                "    assert_equal([x_[()] for x_ in i], [5, 8])\n",
                "\n",
                "    # make sure multi-field struct type -> simple doesn't work\n",
                "    sdt = [('a', 'f4'), ('b', 'i8'), ('d', 'O')]\n",
                "    a = np.array([(5.5, 7, 'test'), (8, 10, 11)], dtype=sdt)\n",
                "    assert_raises(TypeError, lambda: (\n",
                "        nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "               casting='unsafe',\n",
                "               op_dtypes='i4')))\n",
                "\n",
                "    # struct type -> struct type (field-wise copy)\n",
                "    sdt1 = [('a', 'f4'), ('b', 'i8'), ('d', 'O')]\n",
                "    sdt2 = [('d', 'u2'), ('a', 'O'), ('b', 'f8')]\n",
                "    a = np.array([(1, 2, 3), (4, 5, 6)], dtype=sdt1)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    assert_equal([np.array(x_) for x_ in i],\n",
                "                 [np.array((1, 2, 3), dtype=sdt2),\n",
                "                  np.array((4, 5, 6), dtype=sdt2)])\n",
                "\n",
                "\n",
                "def test_iter_buffered_cast_structured_type_failure_with_cleanup():\n",
                "    # make sure struct type -> struct type with different\n",
                "    # number of fields fails\n",
                "    sdt1 = [('a', 'f4'), ('b', 'i8'), ('d', 'O')]\n",
                "    sdt2 = [('b', 'O'), ('a', 'f8')]\n",
                "    a = np.array([(1, 2, 3), (4, 5, 6)], dtype=sdt1)\n",
                "\n",
                "    for intent in [\"readwrite\", \"readonly\", \"writeonly\"]:\n",
                "        # This test was initially designed to test an error at a different\n",
                "        # place, but will now raise earlier to to the cast not being possible:\n",
                "        # `assert np.can_cast(a.dtype, sdt2, casting=\"unsafe\")` fails.\n",
                "        # Without a faulty DType, there is probably no reliable\n",
                "        # way to get the initial tested behaviour.\n",
                "        simple_arr = np.array([1, 2], dtype=\"i,i\")  # requires clean up\n",
                "        with pytest.raises(TypeError):\n",
                "            nditer((simple_arr, a), ['buffered', 'refs_ok'], [intent, intent],\n",
                "                   casting='unsafe', op_dtypes=[\"f,f\", sdt2])\n",
                "\n",
                "\n",
                "def test_buffered_cast_error_paths():\n",
                "    with pytest.raises(ValueError):\n",
                "        # The input is cast into an `S3` buffer\n",
                "        np.nditer((np.array(\"a\", dtype=\"S1\"),), op_dtypes=[\"i\"],\n",
                "                  casting=\"unsafe\", flags=[\"buffered\"])\n",
                "\n",
                "    # The `M8[ns]` is cast into the `S3` output\n",
                "    it = np.nditer((np.array(1, dtype=\"i\"),), op_dtypes=[\"S1\"],\n",
                "                   op_flags=[\"writeonly\"], casting=\"unsafe\", flags=[\"buffered\"])\n",
                "    with pytest.raises(ValueError):\n",
                "        with it:\n",
                "            buf = next(it)\n",
                "            buf[...] = \"a\"  # cannot be converted to int.\n",
                "\n",
                "@pytest.mark.skipif(IS_WASM, reason=\"Cannot start subprocess\")\n",
                "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"PyPy seems to not hit this.\")\n",
                "def test_buffered_cast_error_paths_unraisable():\n",
                "    # The following gives an unraisable error. Pytest sometimes captures that\n",
                "    # (depending python and/or pytest version). So with Python>=3.8 this can\n",
                "    # probably be cleaned out in the future to check for\n",
                "    # pytest.PytestUnraisableExceptionWarning:\n",
                "    code = textwrap.dedent(\"\"\"\n",
                "        import numpy as np\n",
                "\n",
                "        it = np.nditer((np.array(1, dtype=\"i\"),), op_dtypes=[\"S1\"],\n",
                "                       op_flags=[\"writeonly\"], casting=\"unsafe\", flags=[\"buffered\"])\n",
                "        buf = next(it)\n",
                "        buf[...] = \"a\"\n",
                "        del buf, it  # Flushing only happens during deallocate right now.\n",
                "        \"\"\")\n",
                "    res = subprocess.check_output([sys.executable, \"-c\", code],\n",
                "                                  stderr=subprocess.STDOUT, text=True)\n",
                "    assert \"ValueError\" in res\n",
                "\n",
                "\n",
                "def test_iter_buffered_cast_subarray():\n",
                "    # Tests buffering of subarrays\n",
                "\n",
                "    # one element -> many (copies it to all)\n",
                "    sdt1 = [('a', 'f4')]\n",
                "    sdt2 = [('a', 'f8', (3, 2, 2))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    for x, count in zip(i, list(range(6))):\n",
                "        assert_(np.all(x['a'] == count))\n",
                "\n",
                "    # one element -> many -> back (copies it to all)\n",
                "    sdt1 = [('a', 'O', (1, 1))]\n",
                "    sdt2 = [('a', 'O', (3, 2, 2))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'][:, 0, 0] = np.arange(6)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readwrite'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    with i:\n",
                "        assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "        count = 0\n",
                "        for x in i:\n",
                "            assert_(np.all(x['a'] == count))\n",
                "            x['a'][0] += 2\n",
                "            count += 1\n",
                "    assert_equal(a['a'], np.arange(6).reshape(6, 1, 1)+2)\n",
                "\n",
                "    # many -> one element -> back (copies just element 0)\n",
                "    sdt1 = [('a', 'O', (3, 2, 2))]\n",
                "    sdt2 = [('a', 'O', (1,))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'][:, 0, 0, 0] = np.arange(6)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readwrite'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    with i:\n",
                "        assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "        count = 0\n",
                "        for x in i:\n",
                "            assert_equal(x['a'], count)\n",
                "            x['a'] += 2\n",
                "            count += 1\n",
                "    assert_equal(a['a'], np.arange(6).reshape(6, 1, 1, 1)*np.ones((1, 3, 2, 2))+2)\n",
                "\n",
                "    # many -> one element -> back (copies just element 0)\n",
                "    sdt1 = [('a', 'f8', (3, 2, 2))]\n",
                "    sdt2 = [('a', 'O', (1,))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'][:, 0, 0, 0] = np.arange(6)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'], count)\n",
                "        count += 1\n",
                "\n",
                "    # many -> one element (copies just element 0)\n",
                "    sdt1 = [('a', 'O', (3, 2, 2))]\n",
                "    sdt2 = [('a', 'f4', (1,))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'][:, 0, 0, 0] = np.arange(6)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'], count)\n",
                "        count += 1\n",
                "\n",
                "    # many -> matching shape (straightforward copy)\n",
                "    sdt1 = [('a', 'O', (3, 2, 2))]\n",
                "    sdt2 = [('a', 'f4', (3, 2, 2))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6*3*2*2).reshape(6, 3, 2, 2)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'], a[count]['a'])\n",
                "        count += 1\n",
                "\n",
                "    # vector -> smaller vector (truncates)\n",
                "    sdt1 = [('a', 'f8', (6,))]\n",
                "    sdt2 = [('a', 'f4', (2,))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6*6).reshape(6, 6)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'], a[count]['a'][:2])\n",
                "        count += 1\n",
                "\n",
                "    # vector -> bigger vector (pads with zeros)\n",
                "    sdt1 = [('a', 'f8', (2,))]\n",
                "    sdt2 = [('a', 'f4', (6,))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6*2).reshape(6, 2)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'][:2], a[count]['a'])\n",
                "        assert_equal(x['a'][2:], [0, 0, 0, 0])\n",
                "        count += 1\n",
                "\n",
                "    # vector -> matrix (broadcasts)\n",
                "    sdt1 = [('a', 'f8', (2,))]\n",
                "    sdt2 = [('a', 'f4', (2, 2))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6*2).reshape(6, 2)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'][0], a[count]['a'])\n",
                "        assert_equal(x['a'][1], a[count]['a'])\n",
                "        count += 1\n",
                "\n",
                "    # vector -> matrix (broadcasts and zero-pads)\n",
                "    sdt1 = [('a', 'f8', (2, 1))]\n",
                "    sdt2 = [('a', 'f4', (3, 2))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6*2).reshape(6, 2, 1)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'][:2, 0], a[count]['a'][:, 0])\n",
                "        assert_equal(x['a'][:2, 1], a[count]['a'][:, 0])\n",
                "        assert_equal(x['a'][2,:], [0, 0])\n",
                "        count += 1\n",
                "\n",
                "    # matrix -> matrix (truncates and zero-pads)\n",
                "    sdt1 = [('a', 'f8', (2, 3))]\n",
                "    sdt2 = [('a', 'f4', (3, 2))]\n",
                "    a = np.zeros((6,), dtype=sdt1)\n",
                "    a['a'] = np.arange(6*2*3).reshape(6, 2, 3)\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe',\n",
                "                    op_dtypes=sdt2)\n",
                "    assert_equal(i[0].dtype, np.dtype(sdt2))\n",
                "    count = 0\n",
                "    for x in i:\n",
                "        assert_equal(x['a'][:2, 0], a[count]['a'][:, 0])\n",
                "        assert_equal(x['a'][:2, 1], a[count]['a'][:, 1])\n",
                "        assert_equal(x['a'][2,:], [0, 0])\n",
                "        count += 1\n",
                "\n",
                "def test_iter_buffering_badwriteback():\n",
                "    # Writing back from a buffer cannot combine elements\n",
                "\n",
                "    # a needs write buffering, but had a broadcast dimension\n",
                "    a = np.arange(6).reshape(2, 3, 1)\n",
                "    b = np.arange(12).reshape(2, 3, 2)\n",
                "    assert_raises(ValueError, nditer, [a, b],\n",
                "                  ['buffered', 'external_loop'],\n",
                "                  [['readwrite'], ['writeonly']],\n",
                "                  order='C')\n",
                "\n",
                "    # But if a is readonly, it's fine\n",
                "    nditer([a, b], ['buffered', 'external_loop'],\n",
                "           [['readonly'], ['writeonly']],\n",
                "           order='C')\n",
                "\n",
                "    # If a has just one element, it's fine too (constant 0 stride, a reduction)\n",
                "    a = np.arange(1).reshape(1, 1, 1)\n",
                "    nditer([a, b], ['buffered', 'external_loop', 'reduce_ok'],\n",
                "           [['readwrite'], ['writeonly']],\n",
                "           order='C')\n",
                "\n",
                "    # check that it fails on other dimensions too\n",
                "    a = np.arange(6).reshape(1, 3, 2)\n",
                "    assert_raises(ValueError, nditer, [a, b],\n",
                "                  ['buffered', 'external_loop'],\n",
                "                  [['readwrite'], ['writeonly']],\n",
                "                  order='C')\n",
                "    a = np.arange(4).reshape(2, 1, 2)\n",
                "    assert_raises(ValueError, nditer, [a, b],\n",
                "                  ['buffered', 'external_loop'],\n",
                "                  [['readwrite'], ['writeonly']],\n",
                "                  order='C')\n",
                "\n",
                "def test_iter_buffering_string():\n",
                "    # Safe casting disallows shrinking strings\n",
                "    a = np.array(['abc', 'a', 'abcd'], dtype=np.bytes_)\n",
                "    assert_equal(a.dtype, np.dtype('S4'))\n",
                "    assert_raises(TypeError, nditer, a, ['buffered'], ['readonly'],\n",
                "                  op_dtypes='S2')\n",
                "    i = nditer(a, ['buffered'], ['readonly'], op_dtypes='S6')\n",
                "    assert_equal(i[0], b'abc')\n",
                "    assert_equal(i[0].dtype, np.dtype('S6'))\n",
                "\n",
                "    a = np.array(['abc', 'a', 'abcd'], dtype=np.str_)\n",
                "    assert_equal(a.dtype, np.dtype('U4'))\n",
                "    assert_raises(TypeError, nditer, a, ['buffered'], ['readonly'],\n",
                "                    op_dtypes='U2')\n",
                "    i = nditer(a, ['buffered'], ['readonly'], op_dtypes='U6')\n",
                "    assert_equal(i[0], 'abc')\n",
                "    assert_equal(i[0].dtype, np.dtype('U6'))\n",
                "\n",
                "def test_iter_buffering_growinner():\n",
                "    # Test that the inner loop grows when no buffering is needed\n",
                "    a = np.arange(30)\n",
                "    i = nditer(a, ['buffered', 'growinner', 'external_loop'],\n",
                "                           buffersize=5)\n",
                "    # Should end up with just one inner loop here\n",
                "    assert_equal(i[0].size, a.size)\n",
                "\n",
                "\n",
                "@pytest.mark.slow\n",
                "def test_iter_buffered_reduce_reuse():\n",
                "    # large enough array for all views, including negative strides.\n",
                "    a = np.arange(2*3**5)[3**5:3**5+1]\n",
                "    flags = ['buffered', 'delay_bufalloc', 'multi_index', 'reduce_ok', 'refs_ok']\n",
                "    op_flags = [('readonly',), ('readwrite', 'allocate')]\n",
                "    op_axes_list = [[(0, 1, 2), (0, 1, -1)], [(0, 1, 2), (0, -1, -1)]]\n",
                "    # wrong dtype to force buffering\n",
                "    op_dtypes = [float, a.dtype]\n",
                "\n",
                "    def get_params():\n",
                "        for xs in range(-3**2, 3**2 + 1):\n",
                "            for ys in range(xs, 3**2 + 1):\n",
                "                for op_axes in op_axes_list:\n",
                "                    # last stride is reduced and because of that not\n",
                "                    # important for this test, as it is the inner stride.\n",
                "                    strides = (xs * a.itemsize, ys * a.itemsize, a.itemsize)\n",
                "                    arr = np.lib.stride_tricks.as_strided(a, (3, 3, 3), strides)\n",
                "\n",
                "                    for skip in [0, 1]:\n",
                "                        yield arr, op_axes, skip\n",
                "\n",
                "    for arr, op_axes, skip in get_params():\n",
                "        nditer2 = np.nditer([arr.copy(), None],\n",
                "                            op_axes=op_axes, flags=flags, op_flags=op_flags,\n",
                "                            op_dtypes=op_dtypes)\n",
                "        with nditer2:\n",
                "            nditer2.operands[-1][...] = 0\n",
                "            nditer2.reset()\n",
                "            nditer2.iterindex = skip\n",
                "\n",
                "            for (a2_in, b2_in) in nditer2:\n",
                "                b2_in += a2_in.astype(np.int_)\n",
                "\n",
                "            comp_res = nditer2.operands[-1]\n",
                "\n",
                "        for bufsize in range(0, 3**3):\n",
                "            nditer1 = np.nditer([arr, None],\n",
                "                                op_axes=op_axes, flags=flags, op_flags=op_flags,\n",
                "                                buffersize=bufsize, op_dtypes=op_dtypes)\n",
                "            with nditer1:\n",
                "                nditer1.operands[-1][...] = 0\n",
                "                nditer1.reset()\n",
                "                nditer1.iterindex = skip\n",
                "\n",
                "                for (a1_in, b1_in) in nditer1:\n",
                "                    b1_in += a1_in.astype(np.int_)\n",
                "\n",
                "                res = nditer1.operands[-1]\n",
                "            assert_array_equal(res, comp_res)\n",
                "\n",
                "\n",
                "def test_iter_no_broadcast():\n",
                "    # Test that the no_broadcast flag works\n",
                "    a = np.arange(24).reshape(2, 3, 4)\n",
                "    b = np.arange(6).reshape(2, 3, 1)\n",
                "    c = np.arange(12).reshape(3, 4)\n",
                "\n",
                "    nditer([a, b, c], [],\n",
                "           [['readonly', 'no_broadcast'],\n",
                "            ['readonly'], ['readonly']])\n",
                "    assert_raises(ValueError, nditer, [a, b, c], [],\n",
                "                  [['readonly'], ['readonly', 'no_broadcast'], ['readonly']])\n",
                "    assert_raises(ValueError, nditer, [a, b, c], [],\n",
                "                  [['readonly'], ['readonly'], ['readonly', 'no_broadcast']])\n",
                "\n",
                "\n",
                "class TestIterNested:\n",
                "\n",
                "    def test_basic(self):\n",
                "        # Test nested iteration basic usage\n",
                "        a = arange(12).reshape(2, 3, 2)\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0], [1, 2]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0, 1], [2]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0, 2], [1]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 2, 4], [1, 3, 5], [6, 8, 10], [7, 9, 11]])\n",
                "\n",
                "    def test_reorder(self):\n",
                "        # Test nested iteration basic usage\n",
                "        a = arange(12).reshape(2, 3, 2)\n",
                "\n",
                "        # In 'K' order (default), it gets reordered\n",
                "        i, j = np.nested_iters(a, [[0], [2, 1]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[1, 0], [2]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[2, 0], [1]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 2, 4], [1, 3, 5], [6, 8, 10], [7, 9, 11]])\n",
                "\n",
                "        # In 'C' order, it doesn't\n",
                "        i, j = np.nested_iters(a, [[0], [2, 1]], order='C')\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 2, 4, 1, 3, 5], [6, 8, 10, 7, 9, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[1, 0], [2]], order='C')\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1], [6, 7], [2, 3], [8, 9], [4, 5], [10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[2, 0], [1]], order='C')\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 2, 4], [6, 8, 10], [1, 3, 5], [7, 9, 11]])\n",
                "\n",
                "    def test_flip_axes(self):\n",
                "        # Test nested iteration with negative axes\n",
                "        a = arange(12).reshape(2, 3, 2)[::-1, ::-1, ::-1]\n",
                "\n",
                "        # In 'K' order (default), the axes all get flipped\n",
                "        i, j = np.nested_iters(a, [[0], [1, 2]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0, 1], [2]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0, 2], [1]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 2, 4], [1, 3, 5], [6, 8, 10], [7, 9, 11]])\n",
                "\n",
                "        # In 'C' order, flipping axes is disabled\n",
                "        i, j = np.nested_iters(a, [[0], [1, 2]], order='C')\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[11, 10, 9, 8, 7, 6], [5, 4, 3, 2, 1, 0]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0, 1], [2]], order='C')\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[11, 10], [9, 8], [7, 6], [5, 4], [3, 2], [1, 0]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[0, 2], [1]], order='C')\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[11, 9, 7], [10, 8, 6], [5, 3, 1], [4, 2, 0]])\n",
                "\n",
                "    def test_broadcast(self):\n",
                "        # Test nested iteration with broadcasting\n",
                "        a = arange(2).reshape(2, 1)\n",
                "        b = arange(3).reshape(1, 3)\n",
                "\n",
                "        i, j = np.nested_iters([a, b], [[0], [1]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[[0, 0], [0, 1], [0, 2]], [[1, 0], [1, 1], [1, 2]]])\n",
                "\n",
                "        i, j = np.nested_iters([a, b], [[1], [0]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[[0, 0], [1, 0]], [[0, 1], [1, 1]], [[0, 2], [1, 2]]])\n",
                "\n",
                "    def test_dtype_copy(self):\n",
                "        # Test nested iteration with a copy to change dtype\n",
                "\n",
                "        # copy\n",
                "        a = arange(6, dtype='i4').reshape(2, 3)\n",
                "        i, j = np.nested_iters(a, [[0], [1]],\n",
                "                            op_flags=['readonly', 'copy'],\n",
                "                            op_dtypes='f8')\n",
                "        assert_equal(j[0].dtype, np.dtype('f8'))\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1, 2], [3, 4, 5]])\n",
                "        vals = None\n",
                "\n",
                "        # writebackifcopy - using context manager\n",
                "        a = arange(6, dtype='f4').reshape(2, 3)\n",
                "        i, j = np.nested_iters(a, [[0], [1]],\n",
                "                            op_flags=['readwrite', 'updateifcopy'],\n",
                "                            casting='same_kind',\n",
                "                            op_dtypes='f8')\n",
                "        with i, j:\n",
                "            assert_equal(j[0].dtype, np.dtype('f8'))\n",
                "            for x in i:\n",
                "                for y in j:\n",
                "                    y[...] += 1\n",
                "            assert_equal(a, [[0, 1, 2], [3, 4, 5]])\n",
                "        assert_equal(a, [[1, 2, 3], [4, 5, 6]])\n",
                "\n",
                "        # writebackifcopy - using close()\n",
                "        a = arange(6, dtype='f4').reshape(2, 3)\n",
                "        i, j = np.nested_iters(a, [[0], [1]],\n",
                "                            op_flags=['readwrite', 'updateifcopy'],\n",
                "                            casting='same_kind',\n",
                "                            op_dtypes='f8')\n",
                "        assert_equal(j[0].dtype, np.dtype('f8'))\n",
                "        for x in i:\n",
                "            for y in j:\n",
                "                y[...] += 1\n",
                "        assert_equal(a, [[0, 1, 2], [3, 4, 5]])\n",
                "        i.close()\n",
                "        j.close()\n",
                "        assert_equal(a, [[1, 2, 3], [4, 5, 6]])\n",
                "\n",
                "    def test_dtype_buffered(self):\n",
                "        # Test nested iteration with buffering to change dtype\n",
                "\n",
                "        a = arange(6, dtype='f4').reshape(2, 3)\n",
                "        i, j = np.nested_iters(a, [[0], [1]],\n",
                "                            flags=['buffered'],\n",
                "                            op_flags=['readwrite'],\n",
                "                            casting='same_kind',\n",
                "                            op_dtypes='f8')\n",
                "        assert_equal(j[0].dtype, np.dtype('f8'))\n",
                "        for x in i:\n",
                "            for y in j:\n",
                "                y[...] += 1\n",
                "        assert_equal(a, [[1, 2, 3], [4, 5, 6]])\n",
                "\n",
                "    def test_0d(self):\n",
                "        a = np.arange(12).reshape(2, 3, 2)\n",
                "        i, j = np.nested_iters(a, [[], [1, 0, 2]])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]])\n",
                "\n",
                "        i, j = np.nested_iters(a, [[1, 0, 2], []])\n",
                "        vals = [list(j) for _ in i]\n",
                "        assert_equal(vals, [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]])\n",
                "\n",
                "        i, j, k = np.nested_iters(a, [[2, 0], [], [1]])\n",
                "        vals = []\n",
                "        for x in i:\n",
                "            for y in j:\n",
                "                vals.append([z for z in k])\n",
                "        assert_equal(vals, [[0, 2, 4], [1, 3, 5], [6, 8, 10], [7, 9, 11]])\n",
                "\n",
                "    def test_iter_nested_iters_dtype_buffered(self):\n",
                "        # Test nested iteration with buffering to change dtype\n",
                "\n",
                "        a = arange(6, dtype='f4').reshape(2, 3)\n",
                "        i, j = np.nested_iters(a, [[0], [1]],\n",
                "                            flags=['buffered'],\n",
                "                            op_flags=['readwrite'],\n",
                "                            casting='same_kind',\n",
                "                            op_dtypes='f8')\n",
                "        with i, j:\n",
                "            assert_equal(j[0].dtype, np.dtype('f8'))\n",
                "            for x in i:\n",
                "                for y in j:\n",
                "                    y[...] += 1\n",
                "        assert_equal(a, [[1, 2, 3], [4, 5, 6]])\n",
                "\n",
                "def test_iter_reduction_error():\n",
                "\n",
                "    a = np.arange(6)\n",
                "    assert_raises(ValueError, nditer, [a, None], [],\n",
                "                    [['readonly'], ['readwrite', 'allocate']],\n",
                "                    op_axes=[[0], [-1]])\n",
                "\n",
                "    a = np.arange(6).reshape(2, 3)\n",
                "    assert_raises(ValueError, nditer, [a, None], ['external_loop'],\n",
                "                    [['readonly'], ['readwrite', 'allocate']],\n",
                "                    op_axes=[[0, 1], [-1, -1]])\n",
                "\n",
                "def test_iter_reduction():\n",
                "    # Test doing reductions with the iterator\n",
                "\n",
                "    a = np.arange(6)\n",
                "    i = nditer([a, None], ['reduce_ok'],\n",
                "                    [['readonly'], ['readwrite', 'allocate']],\n",
                "                    op_axes=[[0], [-1]])\n",
                "    # Need to initialize the output operand to the addition unit\n",
                "    with i:\n",
                "        i.operands[1][...] = 0\n",
                "        # Do the reduction\n",
                "        for x, y in i:\n",
                "            y[...] += x\n",
                "        # Since no axes were specified, should have allocated a scalar\n",
                "        assert_equal(i.operands[1].ndim, 0)\n",
                "        assert_equal(i.operands[1], np.sum(a))\n",
                "\n",
                "    a = np.arange(6).reshape(2, 3)\n",
                "    i = nditer([a, None], ['reduce_ok', 'external_loop'],\n",
                "                    [['readonly'], ['readwrite', 'allocate']],\n",
                "                    op_axes=[[0, 1], [-1, -1]])\n",
                "    # Need to initialize the output operand to the addition unit\n",
                "    with i:\n",
                "        i.operands[1][...] = 0\n",
                "        # Reduction shape/strides for the output\n",
                "        assert_equal(i[1].shape, (6,))\n",
                "        assert_equal(i[1].strides, (0,))\n",
                "        # Do the reduction\n",
                "        for x, y in i:\n",
                "            # Use a for loop instead of ``y[...] += x``\n",
                "            # (equivalent to ``y[...] = y[...].copy() + x``),\n",
                "            # because y has zero strides we use for the reduction\n",
                "            for j in range(len(y)):\n",
                "                y[j] += x[j]\n",
                "        # Since no axes were specified, should have allocated a scalar\n",
                "        assert_equal(i.operands[1].ndim, 0)\n",
                "        assert_equal(i.operands[1], np.sum(a))\n",
                "\n",
                "    # This is a tricky reduction case for the buffering double loop\n",
                "    # to handle\n",
                "    a = np.ones((2, 3, 5))\n",
                "    it1 = nditer([a, None], ['reduce_ok', 'external_loop'],\n",
                "                    [['readonly'], ['readwrite', 'allocate']],\n",
                "                    op_axes=[None, [0, -1, 1]])\n",
                "    it2 = nditer([a, None], ['reduce_ok', 'external_loop',\n",
                "                            'buffered', 'delay_bufalloc'],\n",
                "                    [['readonly'], ['readwrite', 'allocate']],\n",
                "                    op_axes=[None, [0, -1, 1]], buffersize=10)\n",
                "    with it1, it2:\n",
                "        it1.operands[1].fill(0)\n",
                "        it2.operands[1].fill(0)\n",
                "        it2.reset()\n",
                "        for x in it1:\n",
                "            x[1][...] += x[0]\n",
                "        for x in it2:\n",
                "            x[1][...] += x[0]\n",
                "        assert_equal(it1.operands[1], it2.operands[1])\n",
                "        assert_equal(it2.operands[1].sum(), a.size)\n",
                "\n",
                "def test_iter_buffering_reduction():\n",
                "    # Test doing buffered reductions with the iterator\n",
                "\n",
                "    a = np.arange(6)\n",
                "    b = np.array(0., dtype='f8').byteswap()\n",
                "    b = b.view(b.dtype.newbyteorder())\n",
                "    i = nditer([a, b], ['reduce_ok', 'buffered'],\n",
                "                    [['readonly'], ['readwrite', 'nbo']],\n",
                "                    op_axes=[[0], [-1]])\n",
                "    with i:\n",
                "        assert_equal(i[1].dtype, np.dtype('f8'))\n",
                "        assert_(i[1].dtype != b.dtype)\n",
                "        # Do the reduction\n",
                "        for x, y in i:\n",
                "            y[...] += x\n",
                "    # Since no axes were specified, should have allocated a scalar\n",
                "    assert_equal(b, np.sum(a))\n",
                "\n",
                "    a = np.arange(6).reshape(2, 3)\n",
                "    b = np.array([0, 0], dtype='f8').byteswap()\n",
                "    b = b.view(b.dtype.newbyteorder())\n",
                "    i = nditer([a, b], ['reduce_ok', 'external_loop', 'buffered'],\n",
                "                    [['readonly'], ['readwrite', 'nbo']],\n",
                "                    op_axes=[[0, 1], [0, -1]])\n",
                "    # Reduction shape/strides for the output\n",
                "    with i:\n",
                "        assert_equal(i[1].shape, (3,))\n",
                "        assert_equal(i[1].strides, (0,))\n",
                "        # Do the reduction\n",
                "        for x, y in i:\n",
                "            # Use a for loop instead of ``y[...] += x``\n",
                "            # (equivalent to ``y[...] = y[...].copy() + x``),\n",
                "            # because y has zero strides we use for the reduction\n",
                "            for j in range(len(y)):\n",
                "                y[j] += x[j]\n",
                "    assert_equal(b, np.sum(a, axis=1))\n",
                "\n",
                "    # Iterator inner double loop was wrong on this one\n",
                "    p = np.arange(2) + 1\n",
                "    it = np.nditer([p, None],\n",
                "            ['delay_bufalloc', 'reduce_ok', 'buffered', 'external_loop'],\n",
                "            [['readonly'], ['readwrite', 'allocate']],\n",
                "            op_axes=[[-1, 0], [-1, -1]],\n",
                "            itershape=(2, 2))\n",
                "    with it:\n",
                "        it.operands[1].fill(0)\n",
                "        it.reset()\n",
                "        assert_equal(it[0], [1, 2, 1, 2])\n",
                "\n",
                "    # Iterator inner loop should take argument contiguity into account\n",
                "    x = np.ones((7, 13, 8), np.int8)[4:6,1:11:6,1:5].transpose(1, 2, 0)\n",
                "    x[...] = np.arange(x.size).reshape(x.shape)\n",
                "    y_base = np.arange(4*4, dtype=np.int8).reshape(4, 4)\n",
                "    y_base_copy = y_base.copy()\n",
                "    y = y_base[::2,:,None]\n",
                "\n",
                "    it = np.nditer([y, x],\n",
                "                   ['buffered', 'external_loop', 'reduce_ok'],\n",
                "                   [['readwrite'], ['readonly']])\n",
                "    with it:\n",
                "        for a, b in it:\n",
                "            a.fill(2)\n",
                "\n",
                "    assert_equal(y_base[1::2], y_base_copy[1::2])\n",
                "    assert_equal(y_base[::2], 2)\n",
                "\n",
                "def test_iter_buffering_reduction_reuse_reduce_loops():\n",
                "    # There was a bug triggering reuse of the reduce loop inappropriately,\n",
                "    # which caused processing to happen in unnecessarily small chunks\n",
                "    # and overran the buffer.\n",
                "\n",
                "    a = np.zeros((2, 7))\n",
                "    b = np.zeros((1, 7))\n",
                "    it = np.nditer([a, b], flags=['reduce_ok', 'external_loop', 'buffered'],\n",
                "                    op_flags=[['readonly'], ['readwrite']],\n",
                "                    buffersize=5)\n",
                "\n",
                "    with it:\n",
                "        bufsizes = [x.shape[0] for x, y in it]\n",
                "    assert_equal(bufsizes, [5, 2, 5, 2])\n",
                "    assert_equal(sum(bufsizes), a.size)\n",
                "\n",
                "def test_iter_writemasked_badinput():\n",
                "    a = np.zeros((2, 3))\n",
                "    b = np.zeros((3,))\n",
                "    m = np.array([[True, True, False], [False, True, False]])\n",
                "    m2 = np.array([True, True, False])\n",
                "    m3 = np.array([0, 1, 1], dtype='u1')\n",
                "    mbad1 = np.array([0, 1, 1], dtype='i1')\n",
                "    mbad2 = np.array([0, 1, 1], dtype='f4')\n",
                "\n",
                "    # Need an 'arraymask' if any operand is 'writemasked'\n",
                "    assert_raises(ValueError, nditer, [a, m], [],\n",
                "                    [['readwrite', 'writemasked'], ['readonly']])\n",
                "\n",
                "    # A 'writemasked' operand must not be readonly\n",
                "    assert_raises(ValueError, nditer, [a, m], [],\n",
                "                    [['readonly', 'writemasked'], ['readonly', 'arraymask']])\n",
                "\n",
                "    # 'writemasked' and 'arraymask' may not be used together\n",
                "    assert_raises(ValueError, nditer, [a, m], [],\n",
                "                    [['readonly'], ['readwrite', 'arraymask', 'writemasked']])\n",
                "\n",
                "    # 'arraymask' may only be specified once\n",
                "    assert_raises(ValueError, nditer, [a, m, m2], [],\n",
                "                    [['readwrite', 'writemasked'],\n",
                "                     ['readonly', 'arraymask'],\n",
                "                     ['readonly', 'arraymask']])\n",
                "\n",
                "    # An 'arraymask' with nothing 'writemasked' also doesn't make sense\n",
                "    assert_raises(ValueError, nditer, [a, m], [],\n",
                "                    [['readwrite'], ['readonly', 'arraymask']])\n",
                "\n",
                "    # A writemasked reduction requires a similarly smaller mask\n",
                "    assert_raises(ValueError, nditer, [a, b, m], ['reduce_ok'],\n",
                "                    [['readonly'],\n",
                "                     ['readwrite', 'writemasked'],\n",
                "                     ['readonly', 'arraymask']])\n",
                "    # But this should work with a smaller/equal mask to the reduction operand\n",
                "    np.nditer([a, b, m2], ['reduce_ok'],\n",
                "                    [['readonly'],\n",
                "                     ['readwrite', 'writemasked'],\n",
                "                     ['readonly', 'arraymask']])\n",
                "    # The arraymask itself cannot be a reduction\n",
                "    assert_raises(ValueError, nditer, [a, b, m2], ['reduce_ok'],\n",
                "                    [['readonly'],\n",
                "                     ['readwrite', 'writemasked'],\n",
                "                     ['readwrite', 'arraymask']])\n",
                "\n",
                "    # A uint8 mask is ok too\n",
                "    np.nditer([a, m3], ['buffered'],\n",
                "                    [['readwrite', 'writemasked'],\n",
                "                     ['readonly', 'arraymask']],\n",
                "                    op_dtypes=['f4', None],\n",
                "                    casting='same_kind')\n",
                "    # An int8 mask isn't ok\n",
                "    assert_raises(TypeError, np.nditer, [a, mbad1], ['buffered'],\n",
                "                    [['readwrite', 'writemasked'],\n",
                "                     ['readonly', 'arraymask']],\n",
                "                    op_dtypes=['f4', None],\n",
                "                    casting='same_kind')\n",
                "    # A float32 mask isn't ok\n",
                "    assert_raises(TypeError, np.nditer, [a, mbad2], ['buffered'],\n",
                "                    [['readwrite', 'writemasked'],\n",
                "                     ['readonly', 'arraymask']],\n",
                "                    op_dtypes=['f4', None],\n",
                "                    casting='same_kind')\n",
                "\n",
                "\n",
                "def _is_buffered(iterator):\n",
                "    try:\n",
                "        iterator.itviews\n",
                "    except ValueError:\n",
                "        return True\n",
                "    return False\n",
                "\n",
                "@pytest.mark.parametrize(\"a\",\n",
                "        [np.zeros((3,), dtype='f8'),\n",
                "         np.zeros((9876, 3*5), dtype='f8')[::2, :],\n",
                "         np.zeros((4, 312, 124, 3), dtype='f8')[::2, :, ::2, :],\n",
                "         # Also test with the last dimension strided (so it does not fit if\n",
                "         # there is repeated access)\n",
                "         np.zeros((9,), dtype='f8')[::3],\n",
                "         np.zeros((9876, 3*10), dtype='f8')[::2, ::5],\n",
                "         np.zeros((4, 312, 124, 3), dtype='f8')[::2, :, ::2, ::-1]])\n",
                "def test_iter_writemasked(a):\n",
                "    # Note, the slicing above is to ensure that nditer cannot combine multiple\n",
                "    # axes into one.  The repetition is just to make things a bit more\n",
                "    # interesting.\n",
                "    shape = a.shape\n",
                "    reps = shape[-1] // 3\n",
                "    msk = np.empty(shape, dtype=bool)\n",
                "    msk[...] = [True, True, False] * reps\n",
                "\n",
                "    # When buffering is unused, 'writemasked' effectively does nothing.\n",
                "    # It's up to the user of the iterator to obey the requested semantics.\n",
                "    it = np.nditer([a, msk], [],\n",
                "                [['readwrite', 'writemasked'],\n",
                "                 ['readonly', 'arraymask']])\n",
                "    with it:\n",
                "        for x, m in it:\n",
                "            x[...] = 1\n",
                "    # Because we violated the semantics, all the values became 1\n",
                "    assert_equal(a, np.broadcast_to([1, 1, 1] * reps, shape))\n",
                "\n",
                "    # Even if buffering is enabled, we still may be accessing the array\n",
                "    # directly.\n",
                "    it = np.nditer([a, msk], ['buffered'],\n",
                "                [['readwrite', 'writemasked'],\n",
                "                 ['readonly', 'arraymask']])\n",
                "    # @seberg: I honestly don't currently understand why a \"buffered\" iterator\n",
                "    # would end up not using a buffer for the small array here at least when\n",
                "    # \"writemasked\" is used, that seems confusing...  Check by testing for\n",
                "    # actual memory overlap!\n",
                "    is_buffered = True\n",
                "    with it:\n",
                "        for x, m in it:\n",
                "            x[...] = 2.5\n",
                "            if np.may_share_memory(x, a):\n",
                "                is_buffered = False\n",
                "\n",
                "    if not is_buffered:\n",
                "        # Because we violated the semantics, all the values became 2.5\n",
                "        assert_equal(a, np.broadcast_to([2.5, 2.5, 2.5] * reps, shape))\n",
                "    else:\n",
                "        # For large sizes, the iterator may be buffered:\n",
                "        assert_equal(a, np.broadcast_to([2.5, 2.5, 1] * reps, shape))\n",
                "        a[...] = 2.5\n",
                "\n",
                "    # If buffering will definitely happening, for instance because of\n",
                "    # a cast, only the items selected by the mask will be copied back from\n",
                "    # the buffer.\n",
                "    it = np.nditer([a, msk], ['buffered'],\n",
                "                [['readwrite', 'writemasked'],\n",
                "                 ['readonly', 'arraymask']],\n",
                "                op_dtypes=['i8', None],\n",
                "                casting='unsafe')\n",
                "    with it:\n",
                "        for x, m in it:\n",
                "            x[...] = 3\n",
                "    # Even though we violated the semantics, only the selected values\n",
                "    # were copied back\n",
                "    assert_equal(a, np.broadcast_to([3, 3, 2.5] * reps, shape))\n",
                "\n",
                "\n",
                "@pytest.mark.parametrize([\"mask\", \"mask_axes\"], [\n",
                "        # Allocated operand (only broadcasts with -1)\n",
                "        (None, [-1, 0]),\n",
                "        # Reduction along the first dimension (with and without op_axes)\n",
                "        (np.zeros((1, 4), dtype=\"bool\"), [0, 1]),\n",
                "        (np.zeros((1, 4), dtype=\"bool\"), None),\n",
                "        # Test 0-D and -1 op_axes\n",
                "        (np.zeros(4, dtype=\"bool\"), [-1, 0]),\n",
                "        (np.zeros((), dtype=\"bool\"), [-1, -1]),\n",
                "        (np.zeros((), dtype=\"bool\"), None)])\n",
                "def test_iter_writemasked_broadcast_error(mask, mask_axes):\n",
                "    # This assumes that a readwrite mask makes sense. This is likely not the\n",
                "    # case and should simply be deprecated.\n",
                "    arr = np.zeros((3, 4))\n",
                "    itflags = [\"reduce_ok\"]\n",
                "    mask_flags = [\"arraymask\", \"readwrite\", \"allocate\"]\n",
                "    a_flags = [\"writeonly\", \"writemasked\"]\n",
                "    if mask_axes is None:\n",
                "        op_axes = None\n",
                "    else:\n",
                "        op_axes = [mask_axes, [0, 1]]\n",
                "\n",
                "    with assert_raises(ValueError):\n",
                "        np.nditer((mask, arr), flags=itflags, op_flags=[mask_flags, a_flags],\n",
                "                  op_axes=op_axes)\n",
                "\n",
                "\n",
                "def test_iter_writemasked_decref():\n",
                "    # force casting (to make it interesting) by using a structured dtype.\n",
                "    arr = np.arange(10000).astype(\">i,O\")\n",
                "    original = arr.copy()\n",
                "    mask = np.random.randint(0, 2, size=10000).astype(bool)\n",
                "\n",
                "    it = np.nditer([arr, mask], ['buffered', \"refs_ok\"],\n",
                "                   [['readwrite', 'writemasked'],\n",
                "                    ['readonly', 'arraymask']],\n",
                "                   op_dtypes=[\"<i,O\", \"?\"])\n",
                "    singleton = object()\n",
                "    if HAS_REFCOUNT:\n",
                "        count = sys.getrefcount(singleton)\n",
                "    for buf, mask_buf in it:\n",
                "        buf[...] = (3, singleton)\n",
                "\n",
                "    del buf, mask_buf, it   # delete everything to ensure correct cleanup\n",
                "\n",
                "    if HAS_REFCOUNT:\n",
                "        # The buffer would have included additional items, they must be\n",
                "        # cleared correctly:\n",
                "        assert sys.getrefcount(singleton) - count == np.count_nonzero(mask)\n",
                "\n",
                "    assert_array_equal(arr[~mask], original[~mask])\n",
                "    assert (arr[mask] == np.array((3, singleton), arr.dtype)).all()\n",
                "    del arr\n",
                "\n",
                "    if HAS_REFCOUNT:\n",
                "        assert sys.getrefcount(singleton) == count\n",
                "\n",
                "\n",
                "def test_iter_non_writable_attribute_deletion():\n",
                "    it = np.nditer(np.ones(2))\n",
                "    attr = [\"value\", \"shape\", \"operands\", \"itviews\", \"has_delayed_bufalloc\",\n",
                "            \"iterationneedsapi\", \"has_multi_index\", \"has_index\", \"dtypes\",\n",
                "            \"ndim\", \"nop\", \"itersize\", \"finished\"]\n",
                "\n",
                "    for s in attr:\n",
                "        assert_raises(AttributeError, delattr, it, s)\n",
                "\n",
                "\n",
                "def test_iter_writable_attribute_deletion():\n",
                "    it = np.nditer(np.ones(2))\n",
                "    attr = [ \"multi_index\", \"index\", \"iterrange\", \"iterindex\"]\n",
                "    for s in attr:\n",
                "        assert_raises(AttributeError, delattr, it, s)\n",
                "\n",
                "\n",
                "def test_iter_element_deletion():\n",
                "    it = np.nditer(np.ones(3))\n",
                "    try:\n",
                "        del it[1]\n",
                "        del it[1:2]\n",
                "    except TypeError:\n",
                "        pass\n",
                "    except Exception:\n",
                "        raise AssertionError\n",
                "\n",
                "def test_iter_allocated_array_dtypes():\n",
                "    # If the dtype of an allocated output has a shape, the shape gets\n",
                "    # tacked onto the end of the result.\n",
                "    it = np.nditer(([1, 3, 20], None), op_dtypes=[None, ('i4', (2,))])\n",
                "    for a, b in it:\n",
                "        b[0] = a - 1\n",
                "        b[1] = a + 1\n",
                "    assert_equal(it.operands[1], [[0, 2], [2, 4], [19, 21]])\n",
                "\n",
                "    # Check the same (less sensitive) thing when `op_axes` with -1 is given.\n",
                "    it = np.nditer(([[1, 3, 20]], None), op_dtypes=[None, ('i4', (2,))],\n",
                "                   flags=[\"reduce_ok\"], op_axes=[None, (-1, 0)])\n",
                "    for a, b in it:\n",
                "        b[0] = a - 1\n",
                "        b[1] = a + 1\n",
                "    assert_equal(it.operands[1], [[0, 2], [2, 4], [19, 21]])\n",
                "\n",
                "    # Make sure this works for scalars too\n",
                "    it = np.nditer((10, 2, None), op_dtypes=[None, None, ('i4', (2, 2))])\n",
                "    for a, b, c in it:\n",
                "        c[0, 0] = a - b\n",
                "        c[0, 1] = a + b\n",
                "        c[1, 0] = a * b\n",
                "        c[1, 1] = a / b\n",
                "    assert_equal(it.operands[2], [[8, 12], [20, 5]])\n",
                "\n",
                "\n",
                "def test_0d_iter():\n",
                "    # Basic test for iteration of 0-d arrays:\n",
                "    i = nditer([2, 3], ['multi_index'], [['readonly']]*2)\n",
                "    assert_equal(i.ndim, 0)\n",
                "    assert_equal(next(i), (2, 3))\n",
                "    assert_equal(i.multi_index, ())\n",
                "    assert_equal(i.iterindex, 0)\n",
                "    assert_raises(StopIteration, next, i)\n",
                "    # test reset:\n",
                "    i.reset()\n",
                "    assert_equal(next(i), (2, 3))\n",
                "    assert_raises(StopIteration, next, i)\n",
                "\n",
                "    # test forcing to 0-d\n",
                "    i = nditer(np.arange(5), ['multi_index'], [['readonly']], op_axes=[()])\n",
                "    assert_equal(i.ndim, 0)\n",
                "    assert_equal(len(i), 1)\n",
                "\n",
                "    i = nditer(np.arange(5), ['multi_index'], [['readonly']],\n",
                "               op_axes=[()], itershape=())\n",
                "    assert_equal(i.ndim, 0)\n",
                "    assert_equal(len(i), 1)\n",
                "\n",
                "    # passing an itershape alone is not enough, the op_axes are also needed\n",
                "    with assert_raises(ValueError):\n",
                "        nditer(np.arange(5), ['multi_index'], [['readonly']], itershape=())\n",
                "\n",
                "    # Test a more complex buffered casting case (same as another test above)\n",
                "    sdt = [('a', 'f4'), ('b', 'i8'), ('c', 'c8', (2, 3)), ('d', 'O')]\n",
                "    a = np.array(0.5, dtype='f4')\n",
                "    i = nditer(a, ['buffered', 'refs_ok'], ['readonly'],\n",
                "                    casting='unsafe', op_dtypes=sdt)\n",
                "    vals = next(i)\n",
                "    assert_equal(vals['a'], 0.5)\n",
                "    assert_equal(vals['b'], 0)\n",
                "    assert_equal(vals['c'], [[(0.5)]*3]*2)\n",
                "    assert_equal(vals['d'], 0.5)\n",
                "\n",
                "def test_object_iter_cleanup():\n",
                "    # see gh-18450\n",
                "    # object arrays can raise a python exception in ufunc inner loops using\n",
                "    # nditer, which should cause iteration to stop & cleanup. There were bugs\n",
                "    # in the nditer cleanup when decref'ing object arrays.\n",
                "    # This test would trigger valgrind \"uninitialized read\" before the bugfix.\n",
                "    assert_raises(TypeError, lambda: np.zeros((17000, 2), dtype='f4') * None)\n",
                "\n",
                "    # this more explicit code also triggers the invalid access\n",
                "    arr = np.arange(ncu.BUFSIZE * 10).reshape(10, -1).astype(str)\n",
                "    oarr = arr.astype(object)\n",
                "    oarr[:, -1] = None\n",
                "    assert_raises(TypeError, lambda: np.add(oarr[:, ::-1], arr[:, ::-1]))\n",
                "\n",
                "    # followup: this tests for a bug introduced in the first pass of gh-18450,\n",
                "    # caused by an incorrect fallthrough of the TypeError\n",
                "    class T:\n",
                "        def __bool__(self):\n",
                "            raise TypeError(\"Ambiguous\")\n",
                "    assert_raises(TypeError, np.logical_or.reduce,\n",
                "                             np.array([T(), T()], dtype='O'))\n",
                "\n",
                "def test_object_iter_cleanup_reduce():\n",
                "    # Similar as above, but a complex reduction case that was previously\n",
                "    # missed (see gh-18810).\n",
                "    # The following array is special in that it cannot be flattened:\n",
                "    arr = np.array([[None, 1], [-1, -1], [None, 2], [-1, -1]])[::2]\n",
                "    with pytest.raises(TypeError):\n",
                "        np.sum(arr)\n",
                "\n",
                "@pytest.mark.parametrize(\"arr\", [\n",
                "        np.ones((8000, 4, 2), dtype=object)[:, ::2, :],\n",
                "        np.ones((8000, 4, 2), dtype=object, order=\"F\")[:, ::2, :],\n",
                "        np.ones((8000, 4, 2), dtype=object)[:, ::2, :].copy(\"F\")])\n",
                "def test_object_iter_cleanup_large_reduce(arr):\n",
                "    # More complicated calls are possible for large arrays:\n",
                "    out = np.ones(8000, dtype=np.intp)\n",
                "    # force casting with `dtype=object`\n",
                "    res = np.sum(arr, axis=(1, 2), dtype=object, out=out)\n",
                "    assert_array_equal(res, np.full(8000, 4, dtype=object))\n",
                "\n",
                "def test_iter_too_large():\n",
                "    # The total size of the iterator must not exceed the maximum intp due\n",
                "    # to broadcasting. Dividing by 1024 will keep it small enough to\n",
                "    # give a legal array.\n",
                "    size = np.iinfo(np.intp).max // 1024\n",
                "    arr = np.lib.stride_tricks.as_strided(np.zeros(1), (size,), (0,))\n",
                "    assert_raises(ValueError, nditer, (arr, arr[:, None]))\n",
                "    # test the same for multiindex. That may get more interesting when\n",
                "    # removing 0 dimensional axis is allowed (since an iterator can grow then)\n",
                "    assert_raises(ValueError, nditer,\n",
                "                  (arr, arr[:, None]), flags=['multi_index'])\n",
                "\n",
                "\n",
                "def test_iter_too_large_with_multiindex():\n",
                "    # When a multi index is being tracked, the error is delayed this\n",
                "    # checks the delayed error messages and getting below that by\n",
                "    # removing an axis.\n",
                "    base_size = 2**10\n",
                "    num = 1\n",
                "    while base_size**num < np.iinfo(np.intp).max:\n",
                "        num += 1\n",
                "\n",
                "    shape_template = [1, 1] * num\n",
                "    arrays = []\n",
                "    for i in range(num):\n",
                "        shape = shape_template[:]\n",
                "        shape[i * 2] = 2**10\n",
                "        arrays.append(np.empty(shape))\n",
                "    arrays = tuple(arrays)\n",
                "\n",
                "    # arrays are now too large to be broadcast. The different modes test\n",
                "    # different nditer functionality with or without GIL.\n",
                "    for mode in range(6):\n",
                "        with assert_raises(ValueError):\n",
                "            _multiarray_tests.test_nditer_too_large(arrays, -1, mode)\n",
                "    # but if we do nothing with the nditer, it can be constructed:\n",
                "    _multiarray_tests.test_nditer_too_large(arrays, -1, 7)\n",
                "\n",
                "    # When an axis is removed, things should work again (half the time):\n",
                "    for i in range(num):\n",
                "        for mode in range(6):\n",
                "            # an axis with size 1024 is removed:\n",
                "            _multiarray_tests.test_nditer_too_large(arrays, i*2, mode)\n",
                "            # an axis with size 1 is removed:\n",
                "            with assert_raises(ValueError):\n",
                "                _multiarray_tests.test_nditer_too_large(arrays, i*2 + 1, mode)\n",
                "\n",
                "def test_writebacks():\n",
                "    a = np.arange(6, dtype='f4')\n",
                "    au = a.byteswap()\n",
                "    au = au.view(au.dtype.newbyteorder())\n",
                "    assert_(a.dtype.byteorder != au.dtype.byteorder)\n",
                "    it = nditer(au, [], [['readwrite', 'updateifcopy']],\n",
                "                        casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "    with it:\n",
                "        it.operands[0][:] = 100\n",
                "    assert_equal(au, 100)\n",
                "    # do it again, this time raise an error,\n",
                "    it = nditer(au, [], [['readwrite', 'updateifcopy']],\n",
                "                        casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "    try:\n",
                "        with it:\n",
                "            assert_equal(au.flags.writeable, False)\n",
                "            it.operands[0][:] = 0\n",
                "            raise ValueError('exit context manager on exception')\n",
                "    except:\n",
                "        pass\n",
                "    assert_equal(au, 0)\n",
                "    assert_equal(au.flags.writeable, True)\n",
                "    # cannot reuse i outside context manager\n",
                "    assert_raises(ValueError, getattr, it, 'operands')\n",
                "\n",
                "    it = nditer(au, [], [['readwrite', 'updateifcopy']],\n",
                "                        casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "    with it:\n",
                "        x = it.operands[0]\n",
                "        x[:] = 6\n",
                "        assert_(x.flags.writebackifcopy)\n",
                "    assert_equal(au, 6)\n",
                "    assert_(not x.flags.writebackifcopy)\n",
                "    x[:] = 123 # x.data still valid\n",
                "    assert_equal(au, 6) # but not connected to au\n",
                "\n",
                "    it = nditer(au, [],\n",
                "                 [['readwrite', 'updateifcopy']],\n",
                "                 casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "    # reentering works\n",
                "    with it:\n",
                "        with it:\n",
                "            for x in it:\n",
                "                x[...] = 123\n",
                "\n",
                "    it = nditer(au, [],\n",
                "                 [['readwrite', 'updateifcopy']],\n",
                "                 casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "    # make sure exiting the inner context manager closes the iterator\n",
                "    with it:\n",
                "        with it:\n",
                "            for x in it:\n",
                "                x[...] = 123\n",
                "        assert_raises(ValueError, getattr, it, 'operands')\n",
                "    # do not crash if original data array is decrefed\n",
                "    it = nditer(au, [],\n",
                "                 [['readwrite', 'updateifcopy']],\n",
                "                 casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "    del au\n",
                "    with it:\n",
                "        for x in it:\n",
                "            x[...] = 123\n",
                "    # make sure we cannot reenter the closed iterator\n",
                "    enter = it.__enter__\n",
                "    assert_raises(RuntimeError, enter)\n",
                "\n",
                "def test_close_equivalent():\n",
                "    ''' using a context amanger and using nditer.close are equivalent\n",
                "    '''\n",
                "    def add_close(x, y, out=None):\n",
                "        addop = np.add\n",
                "        it = np.nditer([x, y, out], [],\n",
                "                    [['readonly'], ['readonly'], ['writeonly','allocate']])\n",
                "        for (a, b, c) in it:\n",
                "            addop(a, b, out=c)\n",
                "        ret = it.operands[2]\n",
                "        it.close()\n",
                "        return ret\n",
                "\n",
                "    def add_context(x, y, out=None):\n",
                "        addop = np.add\n",
                "        it = np.nditer([x, y, out], [],\n",
                "                    [['readonly'], ['readonly'], ['writeonly','allocate']])\n",
                "        with it:\n",
                "            for (a, b, c) in it:\n",
                "                addop(a, b, out=c)\n",
                "            return it.operands[2]\n",
                "    z = add_close(range(5), range(5))\n",
                "    assert_equal(z, range(0, 10, 2))\n",
                "    z = add_context(range(5), range(5))\n",
                "    assert_equal(z, range(0, 10, 2))\n",
                "\n",
                "def test_close_raises():\n",
                "    it = np.nditer(np.arange(3))\n",
                "    assert_equal (next(it), 0)\n",
                "    it.close()\n",
                "    assert_raises(StopIteration, next, it)\n",
                "    assert_raises(ValueError, getattr, it, 'operands')\n",
                "\n",
                "def test_close_parameters():\n",
                "    it = np.nditer(np.arange(3))\n",
                "    assert_raises(TypeError, it.close, 1)\n",
                "\n",
                "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")\n",
                "def test_warn_noclose():\n",
                "    a = np.arange(6, dtype='f4')\n",
                "    au = a.byteswap()\n",
                "    au = au.view(au.dtype.newbyteorder())\n",
                "    with suppress_warnings() as sup:\n",
                "        sup.record(RuntimeWarning)\n",
                "        it = np.nditer(au, [], [['readwrite', 'updateifcopy']],\n",
                "                        casting='equiv', op_dtypes=[np.dtype('f4')])\n",
                "        del it\n",
                "        assert len(sup.log) == 1\n",
                "\n",
                "\n",
                "@pytest.mark.skipif(sys.version_info[:2] == (3, 9) and sys.platform == \"win32\",\n",
                "                    reason=\"Errors with Python 3.9 on Windows\")\n",
                "@pytest.mark.parametrize([\"in_dtype\", \"buf_dtype\"],\n",
                "        [(\"i\", \"O\"), (\"O\", \"i\"),  # most simple cases\n",
                "         (\"i,O\", \"O,O\"),  # structured partially only copying O\n",
                "         (\"O,i\", \"i,O\"),  # structured casting to and from O\n",
                "         ])\n",
                "@pytest.mark.parametrize(\"steps\", [1, 2, 3])\n",
                "def test_partial_iteration_cleanup(in_dtype, buf_dtype, steps):\n",
                "    \"\"\"\n",
                "    Checks for reference counting leaks during cleanup.  Using explicit\n",
                "    reference counts lead to occasional false positives (at least in parallel\n",
                "    test setups).  This test now should still test leaks correctly when\n",
                "    run e.g. with pytest-valgrind or pytest-leaks\n",
                "    \"\"\"\n",
                "    value = 2**30 + 1  # just a random value that Python won't intern\n",
                "    arr = np.full(int(ncu.BUFSIZE * 2.5), value).astype(in_dtype)\n",
                "\n",
                "    it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n",
                "            flags=[\"buffered\", \"external_loop\", \"refs_ok\"], casting=\"unsafe\")\n",
                "    for step in range(steps):\n",
                "        # The iteration finishes in 3 steps, the first two are partial\n",
                "        next(it)\n",
                "\n",
                "    del it  # not necessary, but we test the cleanup\n",
                "\n",
                "    # Repeat the test with `iternext`\n",
                "    it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n",
                "                   flags=[\"buffered\", \"external_loop\", \"refs_ok\"], casting=\"unsafe\")\n",
                "    for step in range(steps):\n",
                "        it.iternext()\n",
                "\n",
                "    del it  # not necessary, but we test the cleanup\n",
                "\n",
                "@pytest.mark.skipif(not HAS_REFCOUNT, reason=\"Python lacks refcounts\")\n",
                "@pytest.mark.parametrize([\"in_dtype\", \"buf_dtype\"],\n",
                "         [(\"O\", \"i\"),  # most simple cases\n",
                "          (\"O,i\", \"i,O\"),  # structured casting to and from O\n",
                "          ])\n",
                "def test_partial_iteration_error(in_dtype, buf_dtype):\n",
                "    value = 123  # relies on python cache (leak-check will still find it)\n",
                "    arr = np.full(int(ncu.BUFSIZE * 2.5), value).astype(in_dtype)\n",
                "    if in_dtype == \"O\":\n",
                "        arr[int(ncu.BUFSIZE * 1.5)] = None\n",
                "    else:\n",
                "        arr[int(ncu.BUFSIZE * 1.5)][\"f0\"] = None\n",
                "\n",
                "    count = sys.getrefcount(value)\n",
                "\n",
                "    it = np.nditer(arr, op_dtypes=[np.dtype(buf_dtype)],\n",
                "            flags=[\"buffered\", \"external_loop\", \"refs_ok\"], casting=\"unsafe\")\n",
                "    with pytest.raises(TypeError):\n",
                "        # pytest.raises seems to have issues with the error originating\n",
                "        # in the for loop, so manually unravel:\n",
                "        next(it)\n",
                "        next(it)  # raises TypeError\n",
                "\n",
                "    # Repeat the test with `iternext` after resetting, the buffers should\n",
                "    # already be cleared from any references, so resetting is sufficient.\n",
                "    it.reset()\n",
                "    with pytest.raises(TypeError):\n",
                "        it.iternext()\n",
                "        it.iternext()\n",
                "\n",
                "    assert count == sys.getrefcount(value)\n",
                "\n",
                "\n",
                "def test_debug_print(capfd):\n",
                "    \"\"\"\n",
                "    Matches the expected output of a debug print with the actual output.\n",
                "    Note that the iterator dump should not be considered stable API,\n",
                "    this test is mainly to ensure the print does not crash.\n",
                "\n",
                "    Currently uses a subprocess to avoid dealing with the C level `printf`s.\n",
                "    \"\"\"\n",
                "    # the expected output with all addresses and sizes stripped (they vary\n",
                "    # and/or are platform dependent).\n",
                "    expected = \"\"\"\n",
                "    ------ BEGIN ITERATOR DUMP ------\n",
                "    | Iterator Address:\n",
                "    | ItFlags: BUFFER REDUCE REUSE_REDUCE_LOOPS\n",
                "    | NDim: 2\n",
                "    | NOp: 2\n",
                "    | IterSize: 50\n",
                "    | IterStart: 0\n",
                "    | IterEnd: 50\n",
                "    | IterIndex: 0\n",
                "    | Iterator SizeOf:\n",
                "    | BufferData SizeOf:\n",
                "    | AxisData SizeOf:\n",
                "    |\n",
                "    | Perm: 0 1\n",
                "    | DTypes:\n",
                "    | DTypes: dtype('float64') dtype('int32')\n",
                "    | InitDataPtrs:\n",
                "    | BaseOffsets: 0 0\n",
                "    | Operands:\n",
                "    | Operand DTypes: dtype('int64') dtype('float64')\n",
                "    | OpItFlags:\n",
                "    |   Flags[0]: READ CAST ALIGNED\n",
                "    |   Flags[1]: READ WRITE CAST ALIGNED REDUCE\n",
                "    |\n",
                "    | BufferData:\n",
                "    |   BufferSize: 50\n",
                "    |   Size: 5\n",
                "    |   BufIterEnd: 5\n",
                "    |   REDUCE Pos: 0\n",
                "    |   REDUCE OuterSize: 10\n",
                "    |   REDUCE OuterDim: 1\n",
                "    |   Strides: 8 4\n",
                "    |   Ptrs:\n",
                "    |   REDUCE Outer Strides: 40 0\n",
                "    |   REDUCE Outer Ptrs:\n",
                "    |   ReadTransferFn:\n",
                "    |   ReadTransferData:\n",
                "    |   WriteTransferFn:\n",
                "    |   WriteTransferData:\n",
                "    |   Buffers:\n",
                "    |\n",
                "    | AxisData[0]:\n",
                "    |   Shape: 5\n",
                "    |   Index: 0\n",
                "    |   Strides: 16 8\n",
                "    |   Ptrs:\n",
                "    | AxisData[1]:\n",
                "    |   Shape: 10\n",
                "    |   Index: 0\n",
                "    |   Strides: 80 0\n",
                "    |   Ptrs:\n",
                "    ------- END ITERATOR DUMP -------\n",
                "    \"\"\".strip().splitlines()\n",
                "\n",
                "    arr1 = np.arange(100, dtype=np.int64).reshape(10, 10)[:, ::2]\n",
                "    arr2 = np.arange(5.)\n",
                "    it = np.nditer((arr1, arr2), op_dtypes=[\"d\", \"i4\"], casting=\"unsafe\",\n",
                "                   flags=[\"reduce_ok\", \"buffered\"],\n",
                "                   op_flags=[[\"readonly\"], [\"readwrite\"]])\n",
                "    it.debug_print()\n",
                "    res = capfd.readouterr().out\n",
                "    res = res.strip().splitlines()\n",
                "\n",
                "    assert len(res) == len(expected)\n",
                "    for res_line, expected_line in zip(res, expected):\n",
                "        # The actual output may have additional pointers listed that are\n",
                "        # stripped from the example output:\n",
                "        assert res_line.startswith(expected_line.strip())"
            ]
        ],
        "numpy/testing/_private/utils.py": [
            [
                "\"\"\"\n",
                "Utility function to facilitate testing.\n",
                "\n",
                "\"\"\"\n",
                "import os\n",
                "import sys\n",
                "import platform\n",
                "import re\n",
                "import gc\n",
                "import operator\n",
                "import warnings\n",
                "from functools import partial, wraps\n",
                "import shutil\n",
                "import contextlib\n",
                "from tempfile import mkdtemp, mkstemp\n",
                "from unittest.case import SkipTest\n",
                "from warnings import WarningMessage\n",
                "import pprint\n",
                "import sysconfig\n",
                "\n",
                "import numpy as np\n",
                "from numpy._core import (\n",
                "     intp, float32, empty, arange, array_repr, ndarray, isnat, array)\n",
                "from numpy import isfinite, isnan, isinf\n",
                "import numpy.linalg._umath_linalg\n",
                "from numpy._utils import _rename_parameter\n",
                "\n",
                "from io import StringIO\n",
                "\n",
                "__all__ = [\n",
                "        'assert_equal', 'assert_almost_equal', 'assert_approx_equal',\n",
                "        'assert_array_equal', 'assert_array_less', 'assert_string_equal',\n",
                "        'assert_array_almost_equal', 'assert_raises', 'build_err_msg',\n",
                "        'decorate_methods', 'jiffies', 'memusage', 'print_assert_equal',\n",
                "        'rundocs', 'runstring', 'verbose', 'measure',\n",
                "        'assert_', 'assert_array_almost_equal_nulp', 'assert_raises_regex',\n",
                "        'assert_array_max_ulp', 'assert_warns', 'assert_no_warnings',\n",
                "        'assert_allclose', 'IgnoreException', 'clear_and_catch_warnings',\n",
                "        'SkipTest', 'KnownFailureException', 'temppath', 'tempdir', 'IS_PYPY',\n",
                "        'HAS_REFCOUNT', \"IS_WASM\", 'suppress_warnings', 'assert_array_compare',\n",
                "        'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',\n"
            ],
            {
                "type": "replace",
                "before": [
                    "        '_OLD_PROMOTION', 'IS_MUSL', '_SUPPORTS_SVE'\n"
                ],
                "after": [
                    "        '_OLD_PROMOTION', 'IS_MUSL', '_SUPPORTS_SVE', 'NOGIL_BUILD'\n"
                ],
                "parent_version_range": {
                    "start": 41,
                    "end": 42
                },
                "child_version_range": {
                    "start": 41,
                    "end": 42
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 5,
                "hunk_diff": "File: numpy/testing/_private/utils.py\nCode:\n  ...\n38 38            'SkipTest', 'KnownFailureException', 'temppath', 'tempdir', 'IS_PYPY',\n39 39            'HAS_REFCOUNT', \"IS_WASM\", 'suppress_warnings', 'assert_array_compare',\n40 40            'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',\n41     -         '_OLD_PROMOTION', 'IS_MUSL', '_SUPPORTS_SVE'\n   41  +         '_OLD_PROMOTION', 'IS_MUSL', '_SUPPORTS_SVE', 'NOGIL_BUILD'\n42 42            ]\n43 43    \n44 44    \n       ...\n",
                "file_path": "numpy/testing/_private/utils.py",
                "identifiers_before": [],
                "identifiers_after": [],
                "prefix": [
                    "        'SkipTest', 'KnownFailureException', 'temppath', 'tempdir', 'IS_PYPY',\n",
                    "        'HAS_REFCOUNT', \"IS_WASM\", 'suppress_warnings', 'assert_array_compare',\n",
                    "        'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',\n"
                ],
                "suffix": [
                    "        ]\n",
                    "\n",
                    "\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "        ]\n",
                "\n",
                "\n",
                "class KnownFailureException(Exception):\n",
                "    '''Raise this exception to mark a test as a known failing test.'''\n",
                "    pass\n",
                "\n",
                "\n",
                "KnownFailureTest = KnownFailureException  # backwards compat\n",
                "verbose = 0\n",
                "\n",
                "IS_WASM = platform.machine() in [\"wasm32\", \"wasm64\"]\n",
                "IS_PYPY = sys.implementation.name == 'pypy'\n",
                "IS_PYSTON = hasattr(sys, \"pyston_version_info\")\n",
                "HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON\n",
                "HAS_LAPACK64 = numpy.linalg._umath_linalg._ilp64\n",
                "\n",
                "_OLD_PROMOTION = lambda: np._get_promotion_state() == 'legacy'\n",
                "\n",
                "IS_MUSL = False\n",
                "# alternate way is\n",
                "# from packaging.tags import sys_tags\n",
                "#     _tags = list(sys_tags())\n",
                "#     if 'musllinux' in _tags[0].platform:\n",
                "_v = sysconfig.get_config_var('HOST_GNU_TYPE') or ''\n",
                "if 'musl' in _v:\n",
                "    IS_MUSL = True\n",
                "\n"
            ],
            {
                "type": "insert",
                "before": [],
                "after": [
                    "NOGIL_BUILD = bool(sysconfig.get_config_var(\"Py_GIL_DISABLED\"))\n"
                ],
                "parent_version_range": {
                    "start": 70,
                    "end": 70
                },
                "child_version_range": {
                    "start": 70,
                    "end": 71
                },
                "control_flow": [],
                "structural_path": [],
                "idx": 6,
                "hunk_diff": "File: numpy/testing/_private/utils.py\nCode:\n  ...\n67 67    if 'musl' in _v:\n68 68        IS_MUSL = True\n69 69    \n   70  + NOGIL_BUILD = bool(sysconfig.get_config_var(\"Py_GIL_DISABLED\"))\n70 71    \n71 72    def assert_(val, msg=''):\n72 73        \"\"\"\n       ...\n",
                "file_path": "numpy/testing/_private/utils.py",
                "identifiers_before": [],
                "identifiers_after": [
                    "NOGIL_BUILD",
                    "bool",
                    "get_config_var",
                    "sysconfig"
                ],
                "prefix": [
                    "if 'musl' in _v:\n",
                    "    IS_MUSL = True\n",
                    "\n"
                ],
                "suffix": [
                    "\n",
                    "def assert_(val, msg=''):\n",
                    "    \"\"\"\n"
                ],
                "base_dependency_callee": [],
                "base_dependency_caller": [],
                "head_dependency_callee": [],
                "head_dependency_caller": [],
                "other_clones": []
            },
            [
                "\n",
                "def assert_(val, msg=''):\n",
                "    \"\"\"\n",
                "    Assert that works in release mode.\n",
                "    Accepts callable msg to allow deferring evaluation until failure.\n",
                "\n",
                "    The Python built-in ``assert`` does not work when executing code in\n",
                "    optimized mode (the ``-O`` flag) - no byte-code is generated for it.\n",
                "\n",
                "    For documentation on usage, refer to the Python documentation.\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    if not val:\n",
                "        try:\n",
                "            smsg = msg()\n",
                "        except TypeError:\n",
                "            smsg = msg\n",
                "        raise AssertionError(smsg)\n",
                "\n",
                "\n",
                "if os.name == 'nt':\n",
                "    # Code \"stolen\" from enthought/debug/memusage.py\n",
                "    def GetPerformanceAttributes(object, counter, instance=None,\n",
                "                                 inum=-1, format=None, machine=None):\n",
                "        # NOTE: Many counters require 2 samples to give accurate results,\n",
                "        # including \"% Processor Time\" (as by definition, at any instant, a\n",
                "        # thread's CPU usage is either 0 or 100).  To read counters like this,\n",
                "        # you should copy this function, but keep the counter open, and call\n",
                "        # CollectQueryData() each time you need to know.\n",
                "        # See http://msdn.microsoft.com/library/en-us/dnperfmo/html/perfmonpt2.asp (dead link)\n",
                "        # My older explanation for this was that the \"AddCounter\" process\n",
                "        # forced the CPU to 100%, but the above makes more sense :)\n",
                "        import win32pdh\n",
                "        if format is None:\n",
                "            format = win32pdh.PDH_FMT_LONG\n",
                "        path = win32pdh.MakeCounterPath( (machine, object, instance, None,\n",
                "                                          inum, counter))\n",
                "        hq = win32pdh.OpenQuery()\n",
                "        try:\n",
                "            hc = win32pdh.AddCounter(hq, path)\n",
                "            try:\n",
                "                win32pdh.CollectQueryData(hq)\n",
                "                type, val = win32pdh.GetFormattedCounterValue(hc, format)\n",
                "                return val\n",
                "            finally:\n",
                "                win32pdh.RemoveCounter(hc)\n",
                "        finally:\n",
                "            win32pdh.CloseQuery(hq)\n",
                "\n",
                "    def memusage(processName=\"python\", instance=0):\n",
                "        # from win32pdhutil, part of the win32all package\n",
                "        import win32pdh\n",
                "        return GetPerformanceAttributes(\"Process\", \"Virtual Bytes\",\n",
                "                                        processName, instance,\n",
                "                                        win32pdh.PDH_FMT_LONG, None)\n",
                "elif sys.platform[:5] == 'linux':\n",
                "\n",
                "    def memusage(_proc_pid_stat=f'/proc/{os.getpid()}/stat'):\n",
                "        \"\"\"\n",
                "        Return virtual memory size in bytes of the running python.\n",
                "\n",
                "        \"\"\"\n",
                "        try:\n",
                "            with open(_proc_pid_stat) as f:\n",
                "                l = f.readline().split(' ')\n",
                "            return int(l[22])\n",
                "        except Exception:\n",
                "            return\n",
                "else:\n",
                "    def memusage():\n",
                "        \"\"\"\n",
                "        Return memory usage of running python. [Not implemented]\n",
                "\n",
                "        \"\"\"\n",
                "        raise NotImplementedError\n",
                "\n",
                "\n",
                "if sys.platform[:5] == 'linux':\n",
                "    def jiffies(_proc_pid_stat=f'/proc/{os.getpid()}/stat', _load_time=[]):\n",
                "        \"\"\"\n",
                "        Return number of jiffies elapsed.\n",
                "\n",
                "        Return number of jiffies (1/100ths of a second) that this\n",
                "        process has been scheduled in user mode. See man 5 proc.\n",
                "\n",
                "        \"\"\"\n",
                "        import time\n",
                "        if not _load_time:\n",
                "            _load_time.append(time.time())\n",
                "        try:\n",
                "            with open(_proc_pid_stat) as f:\n",
                "                l = f.readline().split(' ')\n",
                "            return int(l[13])\n",
                "        except Exception:\n",
                "            return int(100*(time.time()-_load_time[0]))\n",
                "else:\n",
                "    # os.getpid is not in all platforms available.\n",
                "    # Using time is safe but inaccurate, especially when process\n",
                "    # was suspended or sleeping.\n",
                "    def jiffies(_load_time=[]):\n",
                "        \"\"\"\n",
                "        Return number of jiffies elapsed.\n",
                "\n",
                "        Return number of jiffies (1/100ths of a second) that this\n",
                "        process has been scheduled in user mode. See man 5 proc.\n",
                "\n",
                "        \"\"\"\n",
                "        import time\n",
                "        if not _load_time:\n",
                "            _load_time.append(time.time())\n",
                "        return int(100*(time.time()-_load_time[0]))\n",
                "\n",
                "\n",
                "def build_err_msg(arrays, err_msg, header='Items are not equal:',\n",
                "                  verbose=True, names=('ACTUAL', 'DESIRED'), precision=8):\n",
                "    msg = ['\\n' + header]\n",
                "    err_msg = str(err_msg)\n",
                "    if err_msg:\n",
                "        if err_msg.find('\\n') == -1 and len(err_msg) < 79-len(header):\n",
                "            msg = [msg[0] + ' ' + err_msg]\n",
                "        else:\n",
                "            msg.append(err_msg)\n",
                "    if verbose:\n",
                "        for i, a in enumerate(arrays):\n",
                "\n",
                "            if isinstance(a, ndarray):\n",
                "                # precision argument is only needed if the objects are ndarrays\n",
                "                r_func = partial(array_repr, precision=precision)\n",
                "            else:\n",
                "                r_func = repr\n",
                "\n",
                "            try:\n",
                "                r = r_func(a)\n",
                "            except Exception as exc:\n",
                "                r = f'[repr failed for <{type(a).__name__}>: {exc}]'\n",
                "            if r.count('\\n') > 3:\n",
                "                r = '\\n'.join(r.splitlines()[:3])\n",
                "                r += '...'\n",
                "            msg.append(f' {names[i]}: {r}')\n",
                "    return '\\n'.join(msg)\n",
                "\n",
                "\n",
                "def assert_equal(actual, desired, err_msg='', verbose=True, *, strict=False):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two objects are not equal.\n",
                "\n",
                "    Given two objects (scalars, lists, tuples, dictionaries or numpy arrays),\n",
                "    check that all elements of these objects are equal. An exception is raised\n",
                "    at the first conflicting values.\n",
                "\n",
                "    This function handles NaN comparisons as if NaN was a \"normal\" number.\n",
                "    That is, AssertionError is not raised if both objects have NaNs in the same\n",
                "    positions.  This is in contrast to the IEEE standard on NaNs, which says\n",
                "    that NaN compared to anything must return False.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : array_like\n",
                "        The object to check.\n",
                "    desired : array_like\n",
                "        The expected object.\n",
                "    err_msg : str, optional\n",
                "        The error message to be printed in case of failure.\n",
                "    verbose : bool, optional\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "    strict : bool, optional\n",
                "        If True and either of the `actual` and `desired` arguments is an array,\n",
                "        raise an ``AssertionError`` when either the shape or the data type of\n",
                "        the arguments does not match. If neither argument is an array, this\n",
                "        parameter has no effect.\n",
                "\n",
                "        .. versionadded:: 2.0.0\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "        If actual and desired are not equal.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_allclose\n",
                "    assert_array_almost_equal_nulp,\n",
                "    assert_array_max_ulp,\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    By default, when one of `actual` and `desired` is a scalar and the other is\n",
                "    an array, the function checks that each element of the array is equal to\n",
                "    the scalar. This behaviour can be disabled by setting ``strict==True``.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> np.testing.assert_equal([4, 5], [4, 6])\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Items are not equal:\n",
                "    item=1\n",
                "     ACTUAL: 5\n",
                "     DESIRED: 6\n",
                "\n",
                "    The following comparison does not raise an exception.  There are NaNs\n",
                "    in the inputs, but they are in the same positions.\n",
                "\n",
                "    >>> np.testing.assert_equal(np.array([1.0, 2.0, np.nan]), [1, 2, np.nan])\n",
                "\n",
                "    As mentioned in the Notes section, `assert_equal` has special\n",
                "    handling for scalars when one of the arguments is an array.\n",
                "    Here, the test checks that each value in `x` is 3:\n",
                "\n",
                "    >>> x = np.full((2, 5), fill_value=3)\n",
                "    >>> np.testing.assert_equal(x, 3)\n",
                "\n",
                "    Use `strict` to raise an AssertionError when comparing a scalar with an\n",
                "    array of a different shape:\n",
                "\n",
                "    >>> np.testing.assert_equal(x, 3, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not equal\n",
                "    <BLANKLINE>\n",
                "    (shapes (2, 5), () mismatch)\n",
                "     ACTUAL: array([[3, 3, 3, 3, 3],\n",
                "           [3, 3, 3, 3, 3]])\n",
                "     DESIRED: array(3)\n",
                "\n",
                "    The `strict` parameter also ensures that the array data types match:\n",
                "\n",
                "    >>> x = np.array([2, 2, 2])\n",
                "    >>> y = np.array([2., 2., 2.], dtype=np.float32)\n",
                "    >>> np.testing.assert_equal(x, y, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not equal\n",
                "    <BLANKLINE>\n",
                "    (dtypes int64, float32 mismatch)\n",
                "     ACTUAL: array([2, 2, 2])\n",
                "     DESIRED: array([2., 2., 2.], dtype=float32)\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    if isinstance(desired, dict):\n",
                "        if not isinstance(actual, dict):\n",
                "            raise AssertionError(repr(type(actual)))\n",
                "        assert_equal(len(actual), len(desired), err_msg, verbose)\n",
                "        for k, i in desired.items():\n",
                "            if k not in actual:\n",
                "                raise AssertionError(repr(k))\n",
                "            assert_equal(actual[k], desired[k], f'key={k!r}\\n{err_msg}',\n",
                "                         verbose)\n",
                "        return\n",
                "    if isinstance(desired, (list, tuple)) and isinstance(actual, (list, tuple)):\n",
                "        assert_equal(len(actual), len(desired), err_msg, verbose)\n",
                "        for k in range(len(desired)):\n",
                "            assert_equal(actual[k], desired[k], f'item={k!r}\\n{err_msg}',\n",
                "                         verbose)\n",
                "        return\n",
                "    from numpy._core import ndarray, isscalar, signbit\n",
                "    from numpy import iscomplexobj, real, imag\n",
                "    if isinstance(actual, ndarray) or isinstance(desired, ndarray):\n",
                "        return assert_array_equal(actual, desired, err_msg, verbose,\n",
                "                                  strict=strict)\n",
                "    msg = build_err_msg([actual, desired], err_msg, verbose=verbose)\n",
                "\n",
                "    # Handle complex numbers: separate into real/imag to handle\n",
                "    # nan/inf/negative zero correctly\n",
                "    # XXX: catch ValueError for subclasses of ndarray where iscomplex fail\n",
                "    try:\n",
                "        usecomplex = iscomplexobj(actual) or iscomplexobj(desired)\n",
                "    except (ValueError, TypeError):\n",
                "        usecomplex = False\n",
                "\n",
                "    if usecomplex:\n",
                "        if iscomplexobj(actual):\n",
                "            actualr = real(actual)\n",
                "            actuali = imag(actual)\n",
                "        else:\n",
                "            actualr = actual\n",
                "            actuali = 0\n",
                "        if iscomplexobj(desired):\n",
                "            desiredr = real(desired)\n",
                "            desiredi = imag(desired)\n",
                "        else:\n",
                "            desiredr = desired\n",
                "            desiredi = 0\n",
                "        try:\n",
                "            assert_equal(actualr, desiredr)\n",
                "            assert_equal(actuali, desiredi)\n",
                "        except AssertionError:\n",
                "            raise AssertionError(msg)\n",
                "\n",
                "    # isscalar test to check cases such as [np.nan] != np.nan\n",
                "    if isscalar(desired) != isscalar(actual):\n",
                "        raise AssertionError(msg)\n",
                "\n",
                "    try:\n",
                "        isdesnat = isnat(desired)\n",
                "        isactnat = isnat(actual)\n",
                "        dtypes_match = (np.asarray(desired).dtype.type ==\n",
                "                        np.asarray(actual).dtype.type)\n",
                "        if isdesnat and isactnat:\n",
                "            # If both are NaT (and have the same dtype -- datetime or\n",
                "            # timedelta) they are considered equal.\n",
                "            if dtypes_match:\n",
                "                return\n",
                "            else:\n",
                "                raise AssertionError(msg)\n",
                "\n",
                "    except (TypeError, ValueError, NotImplementedError):\n",
                "        pass\n",
                "\n",
                "    # Inf/nan/negative zero handling\n",
                "    try:\n",
                "        isdesnan = isnan(desired)\n",
                "        isactnan = isnan(actual)\n",
                "        if isdesnan and isactnan:\n",
                "            return  # both nan, so equal\n",
                "\n",
                "        # handle signed zero specially for floats\n",
                "        array_actual = np.asarray(actual)\n",
                "        array_desired = np.asarray(desired)\n",
                "        if (array_actual.dtype.char in 'Mm' or\n",
                "                array_desired.dtype.char in 'Mm'):\n",
                "            # version 1.18\n",
                "            # until this version, isnan failed for datetime64 and timedelta64.\n",
                "            # Now it succeeds but comparison to scalar with a different type\n",
                "            # emits a DeprecationWarning.\n",
                "            # Avoid that by skipping the next check\n",
                "            raise NotImplementedError('cannot compare to a scalar '\n",
                "                                      'with a different type')\n",
                "\n",
                "        if desired == 0 and actual == 0:\n",
                "            if not signbit(desired) == signbit(actual):\n",
                "                raise AssertionError(msg)\n",
                "\n",
                "    except (TypeError, ValueError, NotImplementedError):\n",
                "        pass\n",
                "\n",
                "    try:\n",
                "        # Explicitly use __eq__ for comparison, gh-2552\n",
                "        if not (desired == actual):\n",
                "            raise AssertionError(msg)\n",
                "\n",
                "    except (DeprecationWarning, FutureWarning) as e:\n",
                "        # this handles the case when the two types are not even comparable\n",
                "        if 'elementwise == comparison' in e.args[0]:\n",
                "            raise AssertionError(msg)\n",
                "        else:\n",
                "            raise\n",
                "\n",
                "\n",
                "def print_assert_equal(test_string, actual, desired):\n",
                "    \"\"\"\n",
                "    Test if two objects are equal, and print an error message if test fails.\n",
                "\n",
                "    The test is performed with ``actual == desired``.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    test_string : str\n",
                "        The message supplied to AssertionError.\n",
                "    actual : object\n",
                "        The object to test for equality against `desired`.\n",
                "    desired : object\n",
                "        The expected result.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> np.testing.print_assert_equal('Test XYZ of func xyz', [0, 1], [0, 1])\n",
                "    >>> np.testing.print_assert_equal('Test XYZ of func xyz', [0, 1], [0, 2])\n",
                "    Traceback (most recent call last):\n",
                "    ...\n",
                "    AssertionError: Test XYZ of func xyz failed\n",
                "    ACTUAL:\n",
                "    [0, 1]\n",
                "    DESIRED:\n",
                "    [0, 2]\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    import pprint\n",
                "\n",
                "    if not (actual == desired):\n",
                "        msg = StringIO()\n",
                "        msg.write(test_string)\n",
                "        msg.write(' failed\\nACTUAL: \\n')\n",
                "        pprint.pprint(actual, msg)\n",
                "        msg.write('DESIRED: \\n')\n",
                "        pprint.pprint(desired, msg)\n",
                "        raise AssertionError(msg.getvalue())\n",
                "\n",
                "\n",
                "@np._no_nep50_warning()\n",
                "def assert_almost_equal(actual, desired, decimal=7, err_msg='', verbose=True):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two items are not equal up to desired\n",
                "    precision.\n",
                "\n",
                "    .. note:: It is recommended to use one of `assert_allclose`,\n",
                "              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`\n",
                "              instead of this function for more consistent floating point\n",
                "              comparisons.\n",
                "\n",
                "    The test verifies that the elements of `actual` and `desired` satisfy::\n",
                "\n",
                "        abs(desired-actual) < float64(1.5 * 10**(-decimal))\n",
                "\n",
                "    That is a looser test than originally documented, but agrees with what the\n",
                "    actual implementation in `assert_array_almost_equal` did up to rounding\n",
                "    vagaries. An exception is raised at conflicting values. For ndarrays this\n",
                "    delegates to assert_array_almost_equal\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : array_like\n",
                "        The object to check.\n",
                "    desired : array_like\n",
                "        The expected object.\n",
                "    decimal : int, optional\n",
                "        Desired precision, default is 7.\n",
                "    err_msg : str, optional\n",
                "        The error message to be printed in case of failure.\n",
                "    verbose : bool, optional\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "      If actual and desired are not equal up to specified precision.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_allclose: Compare two array_like objects for equality with desired\n",
                "                     relative and/or absolute precision.\n",
                "    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> from numpy.testing import assert_almost_equal\n",
                "    >>> assert_almost_equal(2.3333333333333, 2.33333334)\n",
                "    >>> assert_almost_equal(2.3333333333333, 2.33333334, decimal=10)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not almost equal to 10 decimals\n",
                "     ACTUAL: 2.3333333333333\n",
                "     DESIRED: 2.33333334\n",
                "\n",
                "    >>> assert_almost_equal(np.array([1.0,2.3333333333333]),\n",
                "    ...                     np.array([1.0,2.33333334]), decimal=9)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not almost equal to 9 decimals\n",
                "    <BLANKLINE>\n",
                "    Mismatched elements: 1 / 2 (50%)\n",
                "    Max absolute difference among violations: 6.66669964e-09\n",
                "    Max relative difference among violations: 2.85715698e-09\n",
                "     ACTUAL: array([1.         , 2.333333333])\n",
                "     DESIRED: array([1.        , 2.33333334])\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    from numpy._core import ndarray\n",
                "    from numpy import iscomplexobj, real, imag\n",
                "\n",
                "    # Handle complex numbers: separate into real/imag to handle\n",
                "    # nan/inf/negative zero correctly\n",
                "    # XXX: catch ValueError for subclasses of ndarray where iscomplex fail\n",
                "    try:\n",
                "        usecomplex = iscomplexobj(actual) or iscomplexobj(desired)\n",
                "    except ValueError:\n",
                "        usecomplex = False\n",
                "\n",
                "    def _build_err_msg():\n",
                "        header = ('Arrays are not almost equal to %d decimals' % decimal)\n",
                "        return build_err_msg([actual, desired], err_msg, verbose=verbose,\n",
                "                             header=header)\n",
                "\n",
                "    if usecomplex:\n",
                "        if iscomplexobj(actual):\n",
                "            actualr = real(actual)\n",
                "            actuali = imag(actual)\n",
                "        else:\n",
                "            actualr = actual\n",
                "            actuali = 0\n",
                "        if iscomplexobj(desired):\n",
                "            desiredr = real(desired)\n",
                "            desiredi = imag(desired)\n",
                "        else:\n",
                "            desiredr = desired\n",
                "            desiredi = 0\n",
                "        try:\n",
                "            assert_almost_equal(actualr, desiredr, decimal=decimal)\n",
                "            assert_almost_equal(actuali, desiredi, decimal=decimal)\n",
                "        except AssertionError:\n",
                "            raise AssertionError(_build_err_msg())\n",
                "\n",
                "    if isinstance(actual, (ndarray, tuple, list)) \\\n",
                "            or isinstance(desired, (ndarray, tuple, list)):\n",
                "        return assert_array_almost_equal(actual, desired, decimal, err_msg)\n",
                "    try:\n",
                "        # If one of desired/actual is not finite, handle it specially here:\n",
                "        # check that both are nan if any is a nan, and test for equality\n",
                "        # otherwise\n",
                "        if not (isfinite(desired) and isfinite(actual)):\n",
                "            if isnan(desired) or isnan(actual):\n",
                "                if not (isnan(desired) and isnan(actual)):\n",
                "                    raise AssertionError(_build_err_msg())\n",
                "            else:\n",
                "                if not desired == actual:\n",
                "                    raise AssertionError(_build_err_msg())\n",
                "            return\n",
                "    except (NotImplementedError, TypeError):\n",
                "        pass\n",
                "    if abs(desired - actual) >= np.float64(1.5 * 10.0**(-decimal)):\n",
                "        raise AssertionError(_build_err_msg())\n",
                "\n",
                "\n",
                "@np._no_nep50_warning()\n",
                "def assert_approx_equal(actual, desired, significant=7, err_msg='',\n",
                "                        verbose=True):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two items are not equal up to significant\n",
                "    digits.\n",
                "\n",
                "    .. note:: It is recommended to use one of `assert_allclose`,\n",
                "              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`\n",
                "              instead of this function for more consistent floating point\n",
                "              comparisons.\n",
                "\n",
                "    Given two numbers, check that they are approximately equal.\n",
                "    Approximately equal is defined as the number of significant digits\n",
                "    that agree.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : scalar\n",
                "        The object to check.\n",
                "    desired : scalar\n",
                "        The expected object.\n",
                "    significant : int, optional\n",
                "        Desired precision, default is 7.\n",
                "    err_msg : str, optional\n",
                "        The error message to be printed in case of failure.\n",
                "    verbose : bool, optional\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "      If actual and desired are not equal up to specified precision.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_allclose: Compare two array_like objects for equality with desired\n",
                "                     relative and/or absolute precision.\n",
                "    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> np.testing.assert_approx_equal(0.12345677777777e-20, 0.1234567e-20)\n",
                "    >>> np.testing.assert_approx_equal(0.12345670e-20, 0.12345671e-20,\n",
                "    ...                                significant=8)\n",
                "    >>> np.testing.assert_approx_equal(0.12345670e-20, 0.12345672e-20,\n",
                "    ...                                significant=8)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Items are not equal to 8 significant digits:\n",
                "     ACTUAL: 1.234567e-21\n",
                "     DESIRED: 1.2345672e-21\n",
                "\n",
                "    the evaluated condition that raises the exception is\n",
                "\n",
                "    >>> abs(0.12345670e-20/1e-21 - 0.12345672e-20/1e-21) >= 10**-(8-1)\n",
                "    True\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    import numpy as np\n",
                "\n",
                "    (actual, desired) = map(float, (actual, desired))\n",
                "    if desired == actual:\n",
                "        return\n",
                "    # Normalized the numbers to be in range (-10.0,10.0)\n",
                "    # scale = float(pow(10,math.floor(math.log10(0.5*(abs(desired)+abs(actual))))))\n",
                "    with np.errstate(invalid='ignore'):\n",
                "        scale = 0.5*(np.abs(desired) + np.abs(actual))\n",
                "        scale = np.power(10, np.floor(np.log10(scale)))\n",
                "    try:\n",
                "        sc_desired = desired/scale\n",
                "    except ZeroDivisionError:\n",
                "        sc_desired = 0.0\n",
                "    try:\n",
                "        sc_actual = actual/scale\n",
                "    except ZeroDivisionError:\n",
                "        sc_actual = 0.0\n",
                "    msg = build_err_msg(\n",
                "        [actual, desired], err_msg,\n",
                "        header='Items are not equal to %d significant digits:' % significant,\n",
                "        verbose=verbose)\n",
                "    try:\n",
                "        # If one of desired/actual is not finite, handle it specially here:\n",
                "        # check that both are nan if any is a nan, and test for equality\n",
                "        # otherwise\n",
                "        if not (isfinite(desired) and isfinite(actual)):\n",
                "            if isnan(desired) or isnan(actual):\n",
                "                if not (isnan(desired) and isnan(actual)):\n",
                "                    raise AssertionError(msg)\n",
                "            else:\n",
                "                if not desired == actual:\n",
                "                    raise AssertionError(msg)\n",
                "            return\n",
                "    except (TypeError, NotImplementedError):\n",
                "        pass\n",
                "    if np.abs(sc_desired - sc_actual) >= np.power(10., -(significant-1)):\n",
                "        raise AssertionError(msg)\n",
                "\n",
                "\n",
                "@np._no_nep50_warning()\n",
                "def assert_array_compare(comparison, x, y, err_msg='', verbose=True, header='',\n",
                "                         precision=6, equal_nan=True, equal_inf=True,\n",
                "                         *, strict=False, names=('ACTUAL', 'DESIRED')):\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    from numpy._core import (array2string, isnan, inf, errstate,\n",
                "                            all, max, object_)\n",
                "\n",
                "    x = np.asanyarray(x)\n",
                "    y = np.asanyarray(y)\n",
                "\n",
                "    # original array for output formatting\n",
                "    ox, oy = x, y\n",
                "\n",
                "    def isnumber(x):\n",
                "        return x.dtype.char in '?bhilqpBHILQPefdgFDG'\n",
                "\n",
                "    def istime(x):\n",
                "        return x.dtype.char in \"Mm\"\n",
                "\n",
                "    def isvstring(x):\n",
                "        return x.dtype.char == \"T\"\n",
                "\n",
                "    def func_assert_same_pos(x, y, func=isnan, hasval='nan'):\n",
                "        \"\"\"Handling nan/inf.\n",
                "\n",
                "        Combine results of running func on x and y, checking that they are True\n",
                "        at the same locations.\n",
                "\n",
                "        \"\"\"\n",
                "        __tracebackhide__ = True  # Hide traceback for py.test\n",
                "\n",
                "        x_id = func(x)\n",
                "        y_id = func(y)\n",
                "        # We include work-arounds here to handle three types of slightly\n",
                "        # pathological ndarray subclasses:\n",
                "        # (1) all() on `masked` array scalars can return masked arrays, so we\n",
                "        #     use != True\n",
                "        # (2) __eq__ on some ndarray subclasses returns Python booleans\n",
                "        #     instead of element-wise comparisons, so we cast to np.bool() and\n",
                "        #     use isinstance(..., bool) checks\n",
                "        # (3) subclasses with bare-bones __array_function__ implementations may\n",
                "        #     not implement np.all(), so favor using the .all() method\n",
                "        # We are not committed to supporting such subclasses, but it's nice to\n",
                "        # support them if possible.\n",
                "        if np.bool(x_id == y_id).all() != True:\n",
                "            msg = build_err_msg(\n",
                "                [x, y],\n",
                "                err_msg + '\\n%s location mismatch:'\n",
                "                % (hasval), verbose=verbose, header=header,\n",
                "                names=names,\n",
                "                precision=precision)\n",
                "            raise AssertionError(msg)\n",
                "        # If there is a scalar, then here we know the array has the same\n",
                "        # flag as it everywhere, so we should return the scalar flag.\n",
                "        if isinstance(x_id, bool) or x_id.ndim == 0:\n",
                "            return np.bool(x_id)\n",
                "        elif isinstance(y_id, bool) or y_id.ndim == 0:\n",
                "            return np.bool(y_id)\n",
                "        else:\n",
                "            return y_id\n",
                "\n",
                "    try:\n",
                "        if strict:\n",
                "            cond = x.shape == y.shape and x.dtype == y.dtype\n",
                "        else:\n",
                "            cond = (x.shape == () or y.shape == ()) or x.shape == y.shape\n",
                "        if not cond:\n",
                "            if x.shape != y.shape:\n",
                "                reason = f'\\n(shapes {x.shape}, {y.shape} mismatch)'\n",
                "            else:\n",
                "                reason = f'\\n(dtypes {x.dtype}, {y.dtype} mismatch)'\n",
                "            msg = build_err_msg([x, y],\n",
                "                                err_msg\n",
                "                                + reason,\n",
                "                                verbose=verbose, header=header,\n",
                "                                names=names,\n",
                "                                precision=precision)\n",
                "            raise AssertionError(msg)\n",
                "\n",
                "        flagged = np.bool(False)\n",
                "        if isnumber(x) and isnumber(y):\n",
                "            if equal_nan:\n",
                "                flagged = func_assert_same_pos(x, y, func=isnan, hasval='nan')\n",
                "\n",
                "            if equal_inf:\n",
                "                flagged |= func_assert_same_pos(x, y,\n",
                "                                                func=lambda xy: xy == +inf,\n",
                "                                                hasval='+inf')\n",
                "                flagged |= func_assert_same_pos(x, y,\n",
                "                                                func=lambda xy: xy == -inf,\n",
                "                                                hasval='-inf')\n",
                "\n",
                "        elif istime(x) and istime(y):\n",
                "            # If one is datetime64 and the other timedelta64 there is no point\n",
                "            if equal_nan and x.dtype.type == y.dtype.type:\n",
                "                flagged = func_assert_same_pos(x, y, func=isnat, hasval=\"NaT\")\n",
                "\n",
                "        elif isvstring(x) and isvstring(y):\n",
                "            dt = x.dtype\n",
                "            if equal_nan and dt == y.dtype and hasattr(dt, 'na_object'):\n",
                "                is_nan = (isinstance(dt.na_object, float) and\n",
                "                          np.isnan(dt.na_object))\n",
                "                bool_errors = 0\n",
                "                try:\n",
                "                    bool(dt.na_object)\n",
                "                except TypeError:\n",
                "                    bool_errors = 1\n",
                "                if is_nan or bool_errors:\n",
                "                    # nan-like NA object\n",
                "                    flagged = func_assert_same_pos(\n",
                "                        x, y, func=isnan, hasval=x.dtype.na_object)\n",
                "\n",
                "        if flagged.ndim > 0:\n",
                "            x, y = x[~flagged], y[~flagged]\n",
                "            # Only do the comparison if actual values are left\n",
                "            if x.size == 0:\n",
                "                return\n",
                "        elif flagged:\n",
                "            # no sense doing comparison if everything is flagged.\n",
                "            return\n",
                "\n",
                "        val = comparison(x, y)\n",
                "        invalids = np.logical_not(val)\n",
                "\n",
                "        if isinstance(val, bool):\n",
                "            cond = val\n",
                "            reduced = array([val])\n",
                "        else:\n",
                "            reduced = val.ravel()\n",
                "            cond = reduced.all()\n",
                "\n",
                "        # The below comparison is a hack to ensure that fully masked\n",
                "        # results, for which val.ravel().all() returns np.ma.masked,\n",
                "        # do not trigger a failure (np.ma.masked != True evaluates as\n",
                "        # np.ma.masked, which is falsy).\n",
                "        if cond != True:\n",
                "            n_mismatch = reduced.size - reduced.sum(dtype=intp)\n",
                "            n_elements = flagged.size if flagged.ndim != 0 else reduced.size\n",
                "            percent_mismatch = 100 * n_mismatch / n_elements\n",
                "            remarks = [\n",
                "                'Mismatched elements: {} / {} ({:.3g}%)'.format(\n",
                "                    n_mismatch, n_elements, percent_mismatch)]\n",
                "\n",
                "            with errstate(all='ignore'):\n",
                "                # ignore errors for non-numeric types\n",
                "                with contextlib.suppress(TypeError):\n",
                "                    error = abs(x - y)\n",
                "                    if np.issubdtype(x.dtype, np.unsignedinteger):\n",
                "                        error2 = abs(y - x)\n",
                "                        np.minimum(error, error2, out=error)\n",
                "\n",
                "                    reduced_error = error[invalids]\n",
                "                    max_abs_error = max(reduced_error)\n",
                "                    if getattr(error, 'dtype', object_) == object_:\n",
                "                        remarks.append(\n",
                "                            'Max absolute difference among violations: '\n",
                "                            + str(max_abs_error))\n",
                "                    else:\n",
                "                        remarks.append(\n",
                "                            'Max absolute difference among violations: '\n",
                "                            + array2string(max_abs_error))\n",
                "                        \n",
                "                    # note: this definition of relative error matches that one\n",
                "                    # used by assert_allclose (found in np.isclose)\n",
                "                    # Filter values where the divisor would be zero\n",
                "                    nonzero = np.bool(y != 0)\n",
                "                    nonzero_and_invalid = np.logical_and(invalids, nonzero)\n",
                "                    \n",
                "                    if all(~nonzero_and_invalid):\n",
                "                        max_rel_error = array(inf)\n",
                "                    else:\n",
                "                        nonzero_invalid_error = error[nonzero_and_invalid]\n",
                "                        broadcasted_y = np.broadcast_to(y, error.shape)\n",
                "                        nonzero_invalid_y = broadcasted_y[nonzero_and_invalid]\n",
                "                        max_rel_error = max(nonzero_invalid_error \n",
                "                                            / abs(nonzero_invalid_y))\n",
                "\n",
                "                    if getattr(error, 'dtype', object_) == object_: \n",
                "                        remarks.append(\n",
                "                            'Max relative difference among violations: '\n",
                "                            + str(max_rel_error))\n",
                "                    else:               \n",
                "                        remarks.append(\n",
                "                            'Max relative difference among violations: '\n",
                "                            + array2string(max_rel_error))\n",
                "            err_msg = str(err_msg)\n",
                "            err_msg += '\\n' + '\\n'.join(remarks)\n",
                "            msg = build_err_msg([ox, oy], err_msg,\n",
                "                                verbose=verbose, header=header,\n",
                "                                names=names,\n",
                "                                precision=precision)\n",
                "            raise AssertionError(msg)\n",
                "    except ValueError:\n",
                "        import traceback\n",
                "        efmt = traceback.format_exc()\n",
                "        header = f'error during assertion:\\n\\n{efmt}\\n\\n{header}'\n",
                "\n",
                "        msg = build_err_msg([x, y], err_msg, verbose=verbose, header=header,\n",
                "                            names=names, precision=precision)\n",
                "        raise ValueError(msg)\n",
                "\n",
                "\n",
                "@_rename_parameter(['x', 'y'], ['actual', 'desired'], dep_version='2.0.0')\n",
                "def assert_array_equal(actual, desired, err_msg='', verbose=True, *,\n",
                "                       strict=False):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two array_like objects are not equal.\n",
                "\n",
                "    Given two array_like objects, check that the shape is equal and all\n",
                "    elements of these objects are equal (but see the Notes for the special\n",
                "    handling of a scalar). An exception is raised at shape mismatch or\n",
                "    conflicting values. In contrast to the standard usage in numpy, NaNs\n",
                "    are compared like numbers, no assertion is raised if both objects have\n",
                "    NaNs in the same positions.\n",
                "\n",
                "    The usual caution for verifying equality with floating point numbers is\n",
                "    advised.\n",
                "\n",
                "    .. note:: When either `actual` or `desired` is already an instance of\n",
                "        `numpy.ndarray` and `desired` is not a ``dict``, the behavior of\n",
                "        ``assert_equal(actual, desired)`` is identical to the behavior of this\n",
                "        function. Otherwise, this function performs `np.asanyarray` on the\n",
                "        inputs before comparison, whereas `assert_equal` defines special\n",
                "        comparison rules for common Python types. For example, only\n",
                "        `assert_equal` can be used to compare nested Python lists. In new code,\n",
                "        consider using only `assert_equal`, explicitly converting either\n",
                "        `actual` or `desired` to arrays if the behavior of `assert_array_equal`\n",
                "        is desired.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : array_like\n",
                "        The actual object to check.\n",
                "    desired : array_like\n",
                "        The desired, expected object.\n",
                "    err_msg : str, optional\n",
                "        The error message to be printed in case of failure.\n",
                "    verbose : bool, optional\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "    strict : bool, optional\n",
                "        If True, raise an AssertionError when either the shape or the data\n",
                "        type of the array_like objects does not match. The special\n",
                "        handling for scalars mentioned in the Notes section is disabled.\n",
                "\n",
                "        .. versionadded:: 1.24.0\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "        If actual and desired objects are not equal.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_allclose: Compare two array_like objects for equality with desired\n",
                "                     relative and/or absolute precision.\n",
                "    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    When one of `actual` and `desired` is a scalar and the other is array_like,\n",
                "    the function checks that each element of the array_like object is equal to\n",
                "    the scalar. This behaviour can be disabled with the `strict` parameter.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    The first assert does not raise an exception:\n",
                "\n",
                "    >>> np.testing.assert_array_equal([1.0,2.33333,np.nan],\n",
                "    ...                               [np.exp(0),2.33333, np.nan])\n",
                "\n",
                "    Assert fails with numerical imprecision with floats:\n",
                "\n",
                "    >>> np.testing.assert_array_equal([1.0,np.pi,np.nan],\n",
                "    ...                               [1, np.sqrt(np.pi)**2, np.nan])\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not equal\n",
                "    <BLANKLINE>\n",
                "    Mismatched elements: 1 / 3 (33.3%)\n",
                "    Max absolute difference among violations: 4.4408921e-16\n",
                "    Max relative difference among violations: 1.41357986e-16\n",
                "     ACTUAL: array([1.      , 3.141593,      nan])\n",
                "     DESIRED: array([1.      , 3.141593,      nan])\n",
                "\n",
                "    Use `assert_allclose` or one of the nulp (number of floating point values)\n",
                "    functions for these cases instead:\n",
                "\n",
                "    >>> np.testing.assert_allclose([1.0,np.pi,np.nan],\n",
                "    ...                            [1, np.sqrt(np.pi)**2, np.nan],\n",
                "    ...                            rtol=1e-10, atol=0)\n",
                "\n",
                "    As mentioned in the Notes section, `assert_array_equal` has special\n",
                "    handling for scalars. Here the test checks that each value in `x` is 3:\n",
                "\n",
                "    >>> x = np.full((2, 5), fill_value=3)\n",
                "    >>> np.testing.assert_array_equal(x, 3)\n",
                "\n",
                "    Use `strict` to raise an AssertionError when comparing a scalar with an\n",
                "    array:\n",
                "\n",
                "    >>> np.testing.assert_array_equal(x, 3, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not equal\n",
                "    <BLANKLINE>\n",
                "    (shapes (2, 5), () mismatch)\n",
                "     ACTUAL: array([[3, 3, 3, 3, 3],\n",
                "           [3, 3, 3, 3, 3]])\n",
                "     DESIRED: array(3)\n",
                "\n",
                "    The `strict` parameter also ensures that the array data types match:\n",
                "\n",
                "    >>> x = np.array([2, 2, 2])\n",
                "    >>> y = np.array([2., 2., 2.], dtype=np.float32)\n",
                "    >>> np.testing.assert_array_equal(x, y, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not equal\n",
                "    <BLANKLINE>\n",
                "    (dtypes int64, float32 mismatch)\n",
                "     ACTUAL: array([2, 2, 2])\n",
                "     DESIRED: array([2., 2., 2.], dtype=float32)\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    assert_array_compare(operator.__eq__, actual, desired, err_msg=err_msg,\n",
                "                         verbose=verbose, header='Arrays are not equal',\n",
                "                         strict=strict)\n",
                "\n",
                "\n",
                "@np._no_nep50_warning()\n",
                "@_rename_parameter(['x', 'y'], ['actual', 'desired'], dep_version='2.0.0')\n",
                "def assert_array_almost_equal(actual, desired, decimal=6, err_msg='',\n",
                "                              verbose=True):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two objects are not equal up to desired\n",
                "    precision.\n",
                "\n",
                "    .. note:: It is recommended to use one of `assert_allclose`,\n",
                "              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`\n",
                "              instead of this function for more consistent floating point\n",
                "              comparisons.\n",
                "\n",
                "    The test verifies identical shapes and that the elements of ``actual`` and\n",
                "    ``desired`` satisfy::\n",
                "\n",
                "        abs(desired-actual) < 1.5 * 10**(-decimal)\n",
                "\n",
                "    That is a looser test than originally documented, but agrees with what the\n",
                "    actual implementation did up to rounding vagaries. An exception is raised\n",
                "    at shape mismatch or conflicting values. In contrast to the standard usage\n",
                "    in numpy, NaNs are compared like numbers, no assertion is raised if both\n",
                "    objects have NaNs in the same positions.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : array_like\n",
                "        The actual object to check.\n",
                "    desired : array_like\n",
                "        The desired, expected object.\n",
                "    decimal : int, optional\n",
                "        Desired precision, default is 6.\n",
                "    err_msg : str, optional\n",
                "      The error message to be printed in case of failure.\n",
                "    verbose : bool, optional\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "        If actual and desired are not equal up to specified precision.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_allclose: Compare two array_like objects for equality with desired\n",
                "                     relative and/or absolute precision.\n",
                "    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    the first assert does not raise an exception\n",
                "\n",
                "    >>> np.testing.assert_array_almost_equal([1.0,2.333,np.nan],\n",
                "    ...                                      [1.0,2.333,np.nan])\n",
                "\n",
                "    >>> np.testing.assert_array_almost_equal([1.0,2.33333,np.nan],\n",
                "    ...                                      [1.0,2.33339,np.nan], decimal=5)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not almost equal to 5 decimals\n",
                "    <BLANKLINE>\n",
                "    Mismatched elements: 1 / 3 (33.3%)\n",
                "    Max absolute difference among violations: 6.e-05\n",
                "    Max relative difference among violations: 2.57136612e-05\n",
                "     ACTUAL: array([1.     , 2.33333,     nan])\n",
                "     DESIRED: array([1.     , 2.33339,     nan])\n",
                "\n",
                "    >>> np.testing.assert_array_almost_equal([1.0,2.33333,np.nan],\n",
                "    ...                                      [1.0,2.33333, 5], decimal=5)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not almost equal to 5 decimals\n",
                "    <BLANKLINE>\n",
                "    nan location mismatch:\n",
                "     ACTUAL: array([1.     , 2.33333,     nan])\n",
                "     DESIRED: array([1.     , 2.33333, 5.     ])\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    from numpy._core import number, result_type\n",
                "    from numpy._core.numerictypes import issubdtype\n",
                "    from numpy._core.fromnumeric import any as npany\n",
                "\n",
                "    def compare(x, y):\n",
                "        try:\n",
                "            if npany(isinf(x)) or npany(isinf(y)):\n",
                "                xinfid = isinf(x)\n",
                "                yinfid = isinf(y)\n",
                "                if not (xinfid == yinfid).all():\n",
                "                    return False\n",
                "                # if one item, x and y is +- inf\n",
                "                if x.size == y.size == 1:\n",
                "                    return x == y\n",
                "                x = x[~xinfid]\n",
                "                y = y[~yinfid]\n",
                "        except (TypeError, NotImplementedError):\n",
                "            pass\n",
                "\n",
                "        # make sure y is an inexact type to avoid abs(MIN_INT); will cause\n",
                "        # casting of x later.\n",
                "        dtype = result_type(y, 1.)\n",
                "        y = np.asanyarray(y, dtype)\n",
                "        z = abs(x - y)\n",
                "\n",
                "        if not issubdtype(z.dtype, number):\n",
                "            z = z.astype(np.float64)  # handle object arrays\n",
                "\n",
                "        return z < 1.5 * 10.0**(-decimal)\n",
                "\n",
                "    assert_array_compare(compare, actual, desired, err_msg=err_msg,\n",
                "                         verbose=verbose,\n",
                "             header=('Arrays are not almost equal to %d decimals' % decimal),\n",
                "             precision=decimal)\n",
                "\n",
                "\n",
                "def assert_array_less(x, y, err_msg='', verbose=True, *, strict=False):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two array_like objects are not ordered by less\n",
                "    than.\n",
                "\n",
                "    Given two array_like objects `x` and `y`, check that the shape is equal and\n",
                "    all elements of `x` are strictly less than the corresponding elements of\n",
                "    `y` (but see the Notes for the special handling of a scalar). An exception\n",
                "    is raised at shape mismatch or values that are not correctly ordered. In\n",
                "    contrast to the  standard usage in NumPy, no assertion is raised if both\n",
                "    objects have NaNs in the same positions.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x : array_like\n",
                "      The smaller object to check.\n",
                "    y : array_like\n",
                "      The larger object to compare.\n",
                "    err_msg : string\n",
                "      The error message to be printed in case of failure.\n",
                "    verbose : bool\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "    strict : bool, optional\n",
                "        If True, raise an AssertionError when either the shape or the data\n",
                "        type of the array_like objects does not match. The special\n",
                "        handling for scalars mentioned in the Notes section is disabled.\n",
                "\n",
                "        .. versionadded:: 2.0.0\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "      If x is not strictly smaller than y, element-wise.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_array_equal: tests objects for equality\n",
                "    assert_array_almost_equal: test objects for equality up to precision\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    When one of `x` and `y` is a scalar and the other is array_like, the\n",
                "    function performs the comparison as though the scalar were broadcasted\n",
                "    to the shape of the array. This behaviour can be disabled with the `strict`\n",
                "    parameter.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    The following assertion passes because each finite element of `x` is\n",
                "    strictly less than the corresponding element of `y`, and the NaNs are in\n",
                "    corresponding locations.\n",
                "\n",
                "    >>> x = [1.0, 1.0, np.nan]\n",
                "    >>> y = [1.1, 2.0, np.nan]\n",
                "    >>> np.testing.assert_array_less(x, y)\n",
                "\n",
                "    The following assertion fails because the zeroth element of `x` is no\n",
                "    longer strictly less than the zeroth element of `y`.\n",
                "\n",
                "    >>> y[0] = 1\n",
                "    >>> np.testing.assert_array_less(x, y)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not strictly ordered `x < y`\n",
                "    <BLANKLINE>\n",
                "    Mismatched elements: 1 / 3 (33.3%)\n",
                "    Max absolute difference among violations: 0.\n",
                "    Max relative difference among violations: 0.\n",
                "     x: array([ 1.,  1., nan])\n",
                "     y: array([ 1.,  2., nan])\n",
                "\n",
                "    Here, `y` is a scalar, so each element of `x` is compared to `y`, and\n",
                "    the assertion passes.\n",
                "\n",
                "    >>> x = [1.0, 4.0]\n",
                "    >>> y = 5.0\n",
                "    >>> np.testing.assert_array_less(x, y)\n",
                "\n",
                "    However, with ``strict=True``, the assertion will fail because the shapes\n",
                "    do not match.\n",
                "\n",
                "    >>> np.testing.assert_array_less(x, y, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not strictly ordered `x < y`\n",
                "    <BLANKLINE>\n",
                "    (shapes (2,), () mismatch)\n",
                "     x: array([1., 4.])\n",
                "     y: array(5.)\n",
                "\n",
                "    With ``strict=True``, the assertion also fails if the dtypes of the two\n",
                "    arrays do not match.\n",
                "\n",
                "    >>> y = [5, 5]\n",
                "    >>> np.testing.assert_array_less(x, y, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Arrays are not strictly ordered `x < y`\n",
                "    <BLANKLINE>\n",
                "    (dtypes float64, int64 mismatch)\n",
                "     x: array([1., 4.])\n",
                "     y: array([5, 5])\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    assert_array_compare(operator.__lt__, x, y, err_msg=err_msg,\n",
                "                         verbose=verbose,\n",
                "                         header='Arrays are not strictly ordered `x < y`',\n",
                "                         equal_inf=False,\n",
                "                         strict=strict,\n",
                "                         names=('x', 'y'))\n",
                "\n",
                "\n",
                "def runstring(astr, dict):\n",
                "    exec(astr, dict)\n",
                "\n",
                "\n",
                "def assert_string_equal(actual, desired):\n",
                "    \"\"\"\n",
                "    Test if two strings are equal.\n",
                "\n",
                "    If the given strings are equal, `assert_string_equal` does nothing.\n",
                "    If they are not equal, an AssertionError is raised, and the diff\n",
                "    between the strings is shown.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : str\n",
                "        The string to test for equality against the expected string.\n",
                "    desired : str\n",
                "        The expected string.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> np.testing.assert_string_equal('abc', 'abc')\n",
                "    >>> np.testing.assert_string_equal('abc', 'abcd')\n",
                "    Traceback (most recent call last):\n",
                "      File \"<stdin>\", line 1, in <module>\n",
                "    ...\n",
                "    AssertionError: Differences in strings:\n",
                "    - abc+ abcd?    +\n",
                "\n",
                "    \"\"\"\n",
                "    # delay import of difflib to reduce startup time\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    import difflib\n",
                "\n",
                "    if not isinstance(actual, str):\n",
                "        raise AssertionError(repr(type(actual)))\n",
                "    if not isinstance(desired, str):\n",
                "        raise AssertionError(repr(type(desired)))\n",
                "    if desired == actual:\n",
                "        return\n",
                "\n",
                "    diff = list(difflib.Differ().compare(actual.splitlines(True),\n",
                "                desired.splitlines(True)))\n",
                "    diff_list = []\n",
                "    while diff:\n",
                "        d1 = diff.pop(0)\n",
                "        if d1.startswith('  '):\n",
                "            continue\n",
                "        if d1.startswith('- '):\n",
                "            l = [d1]\n",
                "            d2 = diff.pop(0)\n",
                "            if d2.startswith('? '):\n",
                "                l.append(d2)\n",
                "                d2 = diff.pop(0)\n",
                "            if not d2.startswith('+ '):\n",
                "                raise AssertionError(repr(d2))\n",
                "            l.append(d2)\n",
                "            if diff:\n",
                "                d3 = diff.pop(0)\n",
                "                if d3.startswith('? '):\n",
                "                    l.append(d3)\n",
                "                else:\n",
                "                    diff.insert(0, d3)\n",
                "            if d2[2:] == d1[2:]:\n",
                "                continue\n",
                "            diff_list.extend(l)\n",
                "            continue\n",
                "        raise AssertionError(repr(d1))\n",
                "    if not diff_list:\n",
                "        return\n",
                "    msg = f\"Differences in strings:\\n{''.join(diff_list).rstrip()}\"\n",
                "    if actual != desired:\n",
                "        raise AssertionError(msg)\n",
                "\n",
                "\n",
                "def rundocs(filename=None, raise_on_error=True):\n",
                "    \"\"\"\n",
                "    Run doctests found in the given file.\n",
                "\n",
                "    By default `rundocs` raises an AssertionError on failure.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    filename : str\n",
                "        The path to the file for which the doctests are run.\n",
                "    raise_on_error : bool\n",
                "        Whether to raise an AssertionError when a doctest fails. Default is\n",
                "        True.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    The doctests can be run by the user/developer by adding the ``doctests``\n",
                "    argument to the ``test()`` call. For example, to run all tests (including\n",
                "    doctests) for ``numpy.lib``:\n",
                "\n",
                "    >>> np.lib.test(doctests=True)  # doctest: +SKIP\n",
                "    \"\"\"\n",
                "    from numpy.distutils.misc_util import exec_mod_from_location\n",
                "    import doctest\n",
                "    if filename is None:\n",
                "        f = sys._getframe(1)\n",
                "        filename = f.f_globals['__file__']\n",
                "    name = os.path.splitext(os.path.basename(filename))[0]\n",
                "    m = exec_mod_from_location(name, filename)\n",
                "\n",
                "    tests = doctest.DocTestFinder().find(m)\n",
                "    runner = doctest.DocTestRunner(verbose=False)\n",
                "\n",
                "    msg = []\n",
                "    if raise_on_error:\n",
                "        out = lambda s: msg.append(s)\n",
                "    else:\n",
                "        out = None\n",
                "\n",
                "    for test in tests:\n",
                "        runner.run(test, out=out)\n",
                "\n",
                "    if runner.failures > 0 and raise_on_error:\n",
                "        raise AssertionError(\"Some doctests failed:\\n%s\" % \"\\n\".join(msg))\n",
                "\n",
                "\n",
                "def check_support_sve():\n",
                "    \"\"\"\n",
                "    gh-22982\n",
                "    \"\"\"\n",
                "    \n",
                "    import subprocess\n",
                "    cmd = 'lscpu'\n",
                "    try:\n",
                "        output = subprocess.run(cmd, capture_output=True, text=True)\n",
                "        return 'sve' in output.stdout\n",
                "    except OSError:\n",
                "        return False\n",
                "\n",
                "\n",
                "_SUPPORTS_SVE = check_support_sve()\n",
                "\n",
                "#\n",
                "# assert_raises and assert_raises_regex are taken from unittest.\n",
                "#\n",
                "import unittest\n",
                "\n",
                "\n",
                "class _Dummy(unittest.TestCase):\n",
                "    def nop(self):\n",
                "        pass\n",
                "\n",
                "\n",
                "_d = _Dummy('nop')\n",
                "\n",
                "\n",
                "def assert_raises(*args, **kwargs):\n",
                "    \"\"\"\n",
                "    assert_raises(exception_class, callable, *args, **kwargs)\n",
                "    assert_raises(exception_class)\n",
                "\n",
                "    Fail unless an exception of class exception_class is thrown\n",
                "    by callable when invoked with arguments args and keyword\n",
                "    arguments kwargs. If a different type of exception is\n",
                "    thrown, it will not be caught, and the test case will be\n",
                "    deemed to have suffered an error, exactly as for an\n",
                "    unexpected exception.\n",
                "\n",
                "    Alternatively, `assert_raises` can be used as a context manager:\n",
                "\n",
                "    >>> from numpy.testing import assert_raises\n",
                "    >>> with assert_raises(ZeroDivisionError):\n",
                "    ...     1 / 0\n",
                "\n",
                "    is equivalent to\n",
                "\n",
                "    >>> def div(x, y):\n",
                "    ...     return x / y\n",
                "    >>> assert_raises(ZeroDivisionError, div, 1, 0)\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    return _d.assertRaises(*args, **kwargs)\n",
                "\n",
                "\n",
                "def assert_raises_regex(exception_class, expected_regexp, *args, **kwargs):\n",
                "    \"\"\"\n",
                "    assert_raises_regex(exception_class, expected_regexp, callable, *args,\n",
                "                        **kwargs)\n",
                "    assert_raises_regex(exception_class, expected_regexp)\n",
                "\n",
                "    Fail unless an exception of class exception_class and with message that\n",
                "    matches expected_regexp is thrown by callable when invoked with arguments\n",
                "    args and keyword arguments kwargs.\n",
                "\n",
                "    Alternatively, can be used as a context manager like `assert_raises`.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    .. versionadded:: 1.9.0\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    return _d.assertRaisesRegex(exception_class, expected_regexp, *args, **kwargs)\n",
                "\n",
                "\n",
                "def decorate_methods(cls, decorator, testmatch=None):\n",
                "    \"\"\"\n",
                "    Apply a decorator to all methods in a class matching a regular expression.\n",
                "\n",
                "    The given decorator is applied to all public methods of `cls` that are\n",
                "    matched by the regular expression `testmatch`\n",
                "    (``testmatch.search(methodname)``). Methods that are private, i.e. start\n",
                "    with an underscore, are ignored.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    cls : class\n",
                "        Class whose methods to decorate.\n",
                "    decorator : function\n",
                "        Decorator to apply to methods\n",
                "    testmatch : compiled regexp or str, optional\n",
                "        The regular expression. Default value is None, in which case the\n",
                "        nose default (``re.compile(r'(?:^|[\\\\b_\\\\.%s-])[Tt]est' % os.sep)``)\n",
                "        is used.\n",
                "        If `testmatch` is a string, it is compiled to a regular expression\n",
                "        first.\n",
                "\n",
                "    \"\"\"\n",
                "    if testmatch is None:\n",
                "        testmatch = re.compile(r'(?:^|[\\\\b_\\\\.%s-])[Tt]est' % os.sep)\n",
                "    else:\n",
                "        testmatch = re.compile(testmatch)\n",
                "    cls_attr = cls.__dict__\n",
                "\n",
                "    # delayed import to reduce startup time\n",
                "    from inspect import isfunction\n",
                "\n",
                "    methods = [_m for _m in cls_attr.values() if isfunction(_m)]\n",
                "    for function in methods:\n",
                "        try:\n",
                "            if hasattr(function, 'compat_func_name'):\n",
                "                funcname = function.compat_func_name\n",
                "            else:\n",
                "                funcname = function.__name__\n",
                "        except AttributeError:\n",
                "            # not a function\n",
                "            continue\n",
                "        if testmatch.search(funcname) and not funcname.startswith('_'):\n",
                "            setattr(cls, funcname, decorator(function))\n",
                "    return\n",
                "\n",
                "\n",
                "def measure(code_str, times=1, label=None):\n",
                "    \"\"\"\n",
                "    Return elapsed time for executing code in the namespace of the caller.\n",
                "\n",
                "    The supplied code string is compiled with the Python builtin ``compile``.\n",
                "    The precision of the timing is 10 milli-seconds. If the code will execute\n",
                "    fast on this timescale, it can be executed many times to get reasonable\n",
                "    timing accuracy.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    code_str : str\n",
                "        The code to be timed.\n",
                "    times : int, optional\n",
                "        The number of times the code is executed. Default is 1. The code is\n",
                "        only compiled once.\n",
                "    label : str, optional\n",
                "        A label to identify `code_str` with. This is passed into ``compile``\n",
                "        as the second argument (for run-time error messages).\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    elapsed : float\n",
                "        Total elapsed time in seconds for executing `code_str` `times` times.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> times = 10\n",
                "    >>> etime = np.testing.measure('for i in range(1000): np.sqrt(i**2)', times=times)\n",
                "    >>> print(\"Time for a single execution : \", etime / times, \"s\")  # doctest: +SKIP\n",
                "    Time for a single execution :  0.005 s\n",
                "\n",
                "    \"\"\"\n",
                "    frame = sys._getframe(1)\n",
                "    locs, globs = frame.f_locals, frame.f_globals\n",
                "\n",
                "    code = compile(code_str, f'Test name: {label} ', 'exec')\n",
                "    i = 0\n",
                "    elapsed = jiffies()\n",
                "    while i < times:\n",
                "        i += 1\n",
                "        exec(code, globs, locs)\n",
                "    elapsed = jiffies() - elapsed\n",
                "    return 0.01*elapsed\n",
                "\n",
                "\n",
                "def _assert_valid_refcount(op):\n",
                "    \"\"\"\n",
                "    Check that ufuncs don't mishandle refcount of object `1`.\n",
                "    Used in a few regression tests.\n",
                "    \"\"\"\n",
                "    if not HAS_REFCOUNT:\n",
                "        return True\n",
                "\n",
                "    import gc\n",
                "    import numpy as np\n",
                "\n",
                "    b = np.arange(100*100).reshape(100, 100)\n",
                "    c = b\n",
                "    i = 1\n",
                "\n",
                "    gc.disable()\n",
                "    try:\n",
                "        rc = sys.getrefcount(i)\n",
                "        for j in range(15):\n",
                "            d = op(b, c)\n",
                "        assert_(sys.getrefcount(i) >= rc)\n",
                "    finally:\n",
                "        gc.enable()\n",
                "    del d  # for pyflakes\n",
                "\n",
                "\n",
                "def assert_allclose(actual, desired, rtol=1e-7, atol=0, equal_nan=True,\n",
                "                    err_msg='', verbose=True, *, strict=False):\n",
                "    \"\"\"\n",
                "    Raises an AssertionError if two objects are not equal up to desired\n",
                "    tolerance.\n",
                "\n",
                "    Given two array_like objects, check that their shapes and all elements\n",
                "    are equal (but see the Notes for the special handling of a scalar). An\n",
                "    exception is raised if the shapes mismatch or any values conflict. In\n",
                "    contrast to the standard usage in numpy, NaNs are compared like numbers,\n",
                "    no assertion is raised if both objects have NaNs in the same positions.\n",
                "\n",
                "    The test is equivalent to ``allclose(actual, desired, rtol, atol)`` (note\n",
                "    that ``allclose`` has different default values). It compares the difference\n",
                "    between `actual` and `desired` to ``atol + rtol * abs(desired)``.\n",
                "\n",
                "    .. versionadded:: 1.5.0\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    actual : array_like\n",
                "        Array obtained.\n",
                "    desired : array_like\n",
                "        Array desired.\n",
                "    rtol : float, optional\n",
                "        Relative tolerance.\n",
                "    atol : float, optional\n",
                "        Absolute tolerance.\n",
                "    equal_nan : bool, optional.\n",
                "        If True, NaNs will compare equal.\n",
                "    err_msg : str, optional\n",
                "        The error message to be printed in case of failure.\n",
                "    verbose : bool, optional\n",
                "        If True, the conflicting values are appended to the error message.\n",
                "    strict : bool, optional\n",
                "        If True, raise an ``AssertionError`` when either the shape or the data\n",
                "        type of the arguments does not match. The special handling of scalars\n",
                "        mentioned in the Notes section is disabled.\n",
                "\n",
                "        .. versionadded:: 2.0.0\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "        If actual and desired are not equal up to specified precision.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_array_almost_equal_nulp, assert_array_max_ulp\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    When one of `actual` and `desired` is a scalar and the other is\n",
                "    array_like, the function performs the comparison as if the scalar were\n",
                "    broadcasted to the shape of the array.\n",
                "    This behaviour can be disabled with the `strict` parameter.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> x = [1e-5, 1e-3, 1e-1]\n",
                "    >>> y = np.arccos(np.cos(x))\n",
                "    >>> np.testing.assert_allclose(x, y, rtol=1e-5, atol=0)\n",
                "\n",
                "    As mentioned in the Notes section, `assert_allclose` has special\n",
                "    handling for scalars. Here, the test checks that the value of `numpy.sin`\n",
                "    is nearly zero at integer multiples of \u03c0.\n",
                "\n",
                "    >>> x = np.arange(3) * np.pi\n",
                "    >>> np.testing.assert_allclose(np.sin(x), 0, atol=1e-15)\n",
                "\n",
                "    Use `strict` to raise an ``AssertionError`` when comparing an array\n",
                "    with one or more dimensions against a scalar.\n",
                "\n",
                "    >>> np.testing.assert_allclose(np.sin(x), 0, atol=1e-15, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Not equal to tolerance rtol=1e-07, atol=1e-15\n",
                "    <BLANKLINE>\n",
                "    (shapes (3,), () mismatch)\n",
                "     ACTUAL: array([ 0.000000e+00,  1.224647e-16, -2.449294e-16])\n",
                "     DESIRED: array(0)\n",
                "\n",
                "    The `strict` parameter also ensures that the array data types match:\n",
                "\n",
                "    >>> y = np.zeros(3, dtype=np.float32)\n",
                "    >>> np.testing.assert_allclose(np.sin(x), y, atol=1e-15, strict=True)\n",
                "    Traceback (most recent call last):\n",
                "        ...\n",
                "    AssertionError:\n",
                "    Not equal to tolerance rtol=1e-07, atol=1e-15\n",
                "    <BLANKLINE>\n",
                "    (dtypes float64, float32 mismatch)\n",
                "     ACTUAL: array([ 0.000000e+00,  1.224647e-16, -2.449294e-16])\n",
                "     DESIRED: array([0., 0., 0.], dtype=float32)\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    import numpy as np\n",
                "\n",
                "    def compare(x, y):\n",
                "        return np._core.numeric.isclose(x, y, rtol=rtol, atol=atol,\n",
                "                                       equal_nan=equal_nan)\n",
                "\n",
                "    actual, desired = np.asanyarray(actual), np.asanyarray(desired)\n",
                "    header = f'Not equal to tolerance rtol={rtol:g}, atol={atol:g}'\n",
                "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
                "                         verbose=verbose, header=header, equal_nan=equal_nan,\n",
                "                         strict=strict)\n",
                "\n",
                "\n",
                "def assert_array_almost_equal_nulp(x, y, nulp=1):\n",
                "    \"\"\"\n",
                "    Compare two arrays relatively to their spacing.\n",
                "\n",
                "    This is a relatively robust method to compare two arrays whose amplitude\n",
                "    is variable.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x, y : array_like\n",
                "        Input arrays.\n",
                "    nulp : int, optional\n",
                "        The maximum number of unit in the last place for tolerance (see Notes).\n",
                "        Default is 1.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    None\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "        If the spacing between `x` and `y` for one or more elements is larger\n",
                "        than `nulp`.\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_array_max_ulp : Check that all items of arrays differ in at most\n",
                "        N Units in the Last Place.\n",
                "    spacing : Return the distance between x and the nearest adjacent number.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    An assertion is raised if the following condition is not met::\n",
                "\n",
                "        abs(x - y) <= nulp * spacing(maximum(abs(x), abs(y)))\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> x = np.array([1., 1e-10, 1e-20])\n",
                "    >>> eps = np.finfo(x.dtype).eps\n",
                "    >>> np.testing.assert_array_almost_equal_nulp(x, x*eps/2 + x)\n",
                "\n",
                "    >>> np.testing.assert_array_almost_equal_nulp(x, x*eps + x)\n",
                "    Traceback (most recent call last):\n",
                "      ...\n",
                "    AssertionError: Arrays are not equal to 1 ULP (max is 2)\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    import numpy as np\n",
                "    ax = np.abs(x)\n",
                "    ay = np.abs(y)\n",
                "    ref = nulp * np.spacing(np.where(ax > ay, ax, ay))\n",
                "    if not np.all(np.abs(x-y) <= ref):\n",
                "        if np.iscomplexobj(x) or np.iscomplexobj(y):\n",
                "            msg = f\"Arrays are not equal to {nulp} ULP\"\n",
                "        else:\n",
                "            max_nulp = np.max(nulp_diff(x, y))\n",
                "            msg = f\"Arrays are not equal to {nulp} ULP (max is {max_nulp:g})\"\n",
                "        raise AssertionError(msg)\n",
                "\n",
                "\n",
                "def assert_array_max_ulp(a, b, maxulp=1, dtype=None):\n",
                "    \"\"\"\n",
                "    Check that all items of arrays differ in at most N Units in the Last Place.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    a, b : array_like\n",
                "        Input arrays to be compared.\n",
                "    maxulp : int, optional\n",
                "        The maximum number of units in the last place that elements of `a` and\n",
                "        `b` can differ. Default is 1.\n",
                "    dtype : dtype, optional\n",
                "        Data-type to convert `a` and `b` to if given. Default is None.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    ret : ndarray\n",
                "        Array containing number of representable floating point numbers between\n",
                "        items in `a` and `b`.\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    AssertionError\n",
                "        If one or more elements differ by more than `maxulp`.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    For computing the ULP difference, this API does not differentiate between\n",
                "    various representations of NAN (ULP difference between 0x7fc00000 and 0xffc00000\n",
                "    is zero).\n",
                "\n",
                "    See Also\n",
                "    --------\n",
                "    assert_array_almost_equal_nulp : Compare two arrays relatively to their\n",
                "        spacing.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> a = np.linspace(0., 1., 100)\n",
                "    >>> res = np.testing.assert_array_max_ulp(a, np.arcsin(np.sin(a)))\n",
                "\n",
                "    \"\"\"\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    import numpy as np\n",
                "    ret = nulp_diff(a, b, dtype)\n",
                "    if not np.all(ret <= maxulp):\n",
                "        raise AssertionError(\"Arrays are not almost equal up to %g \"\n",
                "                             \"ULP (max difference is %g ULP)\" %\n",
                "                             (maxulp, np.max(ret)))\n",
                "    return ret\n",
                "\n",
                "\n",
                "def nulp_diff(x, y, dtype=None):\n",
                "    \"\"\"For each item in x and y, return the number of representable floating\n",
                "    points between them.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    x : array_like\n",
                "        first input array\n",
                "    y : array_like\n",
                "        second input array\n",
                "    dtype : dtype, optional\n",
                "        Data-type to convert `x` and `y` to if given. Default is None.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    nulp : array_like\n",
                "        number of representable floating point numbers between each item in x\n",
                "        and y.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    For computing the ULP difference, this API does not differentiate between\n",
                "    various representations of NAN (ULP difference between 0x7fc00000 and 0xffc00000\n",
                "    is zero).\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    # By definition, epsilon is the smallest number such as 1 + eps != 1, so\n",
                "    # there should be exactly one ULP between 1 and 1 + eps\n",
                "    >>> nulp_diff(1, 1 + np.finfo(x.dtype).eps)\n",
                "    1.0\n",
                "    \"\"\"\n",
                "    import numpy as np\n",
                "    if dtype:\n",
                "        x = np.asarray(x, dtype=dtype)\n",
                "        y = np.asarray(y, dtype=dtype)\n",
                "    else:\n",
                "        x = np.asarray(x)\n",
                "        y = np.asarray(y)\n",
                "\n",
                "    t = np.common_type(x, y)\n",
                "    if np.iscomplexobj(x) or np.iscomplexobj(y):\n",
                "        raise NotImplementedError(\"_nulp not implemented for complex array\")\n",
                "\n",
                "    x = np.array([x], dtype=t)\n",
                "    y = np.array([y], dtype=t)\n",
                "\n",
                "    x[np.isnan(x)] = np.nan\n",
                "    y[np.isnan(y)] = np.nan\n",
                "\n",
                "    if not x.shape == y.shape:\n",
                "        raise ValueError(\"Arrays do not have the same shape: %s - %s\" %\n",
                "                         (x.shape, y.shape))\n",
                "\n",
                "    def _diff(rx, ry, vdt):\n",
                "        diff = np.asarray(rx-ry, dtype=vdt)\n",
                "        return np.abs(diff)\n",
                "\n",
                "    rx = integer_repr(x)\n",
                "    ry = integer_repr(y)\n",
                "    return _diff(rx, ry, t)\n",
                "\n",
                "\n",
                "def _integer_repr(x, vdt, comp):\n",
                "    # Reinterpret binary representation of the float as sign-magnitude:\n",
                "    # take into account two-complement representation\n",
                "    # See also\n",
                "    # https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/\n",
                "    rx = x.view(vdt)\n",
                "    if not (rx.size == 1):\n",
                "        rx[rx < 0] = comp - rx[rx < 0]\n",
                "    else:\n",
                "        if rx < 0:\n",
                "            rx = comp - rx\n",
                "\n",
                "    return rx\n",
                "\n",
                "\n",
                "def integer_repr(x):\n",
                "    \"\"\"Return the signed-magnitude interpretation of the binary representation\n",
                "    of x.\"\"\"\n",
                "    import numpy as np\n",
                "    if x.dtype == np.float16:\n",
                "        return _integer_repr(x, np.int16, np.int16(-2**15))\n",
                "    elif x.dtype == np.float32:\n",
                "        return _integer_repr(x, np.int32, np.int32(-2**31))\n",
                "    elif x.dtype == np.float64:\n",
                "        return _integer_repr(x, np.int64, np.int64(-2**63))\n",
                "    else:\n",
                "        raise ValueError(f'Unsupported dtype {x.dtype}')\n",
                "\n",
                "\n",
                "@contextlib.contextmanager\n",
                "def _assert_warns_context(warning_class, name=None):\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    with suppress_warnings() as sup:\n",
                "        l = sup.record(warning_class)\n",
                "        yield\n",
                "        if not len(l) > 0:\n",
                "            name_str = f' when calling {name}' if name is not None else ''\n",
                "            raise AssertionError(\"No warning raised\" + name_str)\n",
                "\n",
                "\n",
                "def assert_warns(warning_class, *args, **kwargs):\n",
                "    \"\"\"\n",
                "    Fail unless the given callable throws the specified warning.\n",
                "\n",
                "    A warning of class warning_class should be thrown by the callable when\n",
                "    invoked with arguments args and keyword arguments kwargs.\n",
                "    If a different type of warning is thrown, it will not be caught.\n",
                "\n",
                "    If called with all arguments other than the warning class omitted, may be\n",
                "    used as a context manager::\n",
                "\n",
                "        with assert_warns(SomeWarning):\n",
                "            do_something()\n",
                "\n",
                "    The ability to be used as a context manager is new in NumPy v1.11.0.\n",
                "\n",
                "    .. versionadded:: 1.4.0\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    warning_class : class\n",
                "        The class defining the warning that `func` is expected to throw.\n",
                "    func : callable, optional\n",
                "        Callable to test\n",
                "    *args : Arguments\n",
                "        Arguments for `func`.\n",
                "    **kwargs : Kwargs\n",
                "        Keyword arguments for `func`.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    The value returned by `func`.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> import warnings\n",
                "    >>> def deprecated_func(num):\n",
                "    ...     warnings.warn(\"Please upgrade\", DeprecationWarning)\n",
                "    ...     return num*num\n",
                "    >>> with np.testing.assert_warns(DeprecationWarning):\n",
                "    ...     assert deprecated_func(4) == 16\n",
                "    >>> # or passing a func\n",
                "    >>> ret = np.testing.assert_warns(DeprecationWarning, deprecated_func, 4)\n",
                "    >>> assert ret == 16\n",
                "    \"\"\"\n",
                "    if not args and not kwargs:\n",
                "        return _assert_warns_context(warning_class)\n",
                "    elif len(args) < 1:\n",
                "        if \"match\" in kwargs:\n",
                "            raise RuntimeError(\n",
                "                \"assert_warns does not use 'match' kwarg, \"\n",
                "                \"use pytest.warns instead\"\n",
                "                )\n",
                "        raise RuntimeError(\"assert_warns(...) needs at least one arg\")\n",
                "\n",
                "    func = args[0]\n",
                "    args = args[1:]\n",
                "    with _assert_warns_context(warning_class, name=func.__name__):\n",
                "        return func(*args, **kwargs)\n",
                "\n",
                "\n",
                "@contextlib.contextmanager\n",
                "def _assert_no_warnings_context(name=None):\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "    with warnings.catch_warnings(record=True) as l:\n",
                "        warnings.simplefilter('always')\n",
                "        yield\n",
                "        if len(l) > 0:\n",
                "            name_str = f' when calling {name}' if name is not None else ''\n",
                "            raise AssertionError(f'Got warnings{name_str}: {l}')\n",
                "\n",
                "\n",
                "def assert_no_warnings(*args, **kwargs):\n",
                "    \"\"\"\n",
                "    Fail if the given callable produces any warnings.\n",
                "\n",
                "    If called with all arguments omitted, may be used as a context manager::\n",
                "\n",
                "        with assert_no_warnings():\n",
                "            do_something()\n",
                "\n",
                "    The ability to be used as a context manager is new in NumPy v1.11.0.\n",
                "\n",
                "    .. versionadded:: 1.7.0\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    func : callable\n",
                "        The callable to test.\n",
                "    \\\\*args : Arguments\n",
                "        Arguments passed to `func`.\n",
                "    \\\\*\\\\*kwargs : Kwargs\n",
                "        Keyword arguments passed to `func`.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    The value returned by `func`.\n",
                "\n",
                "    \"\"\"\n",
                "    if not args:\n",
                "        return _assert_no_warnings_context()\n",
                "\n",
                "    func = args[0]\n",
                "    args = args[1:]\n",
                "    with _assert_no_warnings_context(name=func.__name__):\n",
                "        return func(*args, **kwargs)\n",
                "\n",
                "\n",
                "def _gen_alignment_data(dtype=float32, type='binary', max_size=24):\n",
                "    \"\"\"\n",
                "    generator producing data with different alignment and offsets\n",
                "    to test simd vectorization\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    dtype : dtype\n",
                "        data type to produce\n",
                "    type : string\n",
                "        'unary': create data for unary operations, creates one input\n",
                "                 and output array\n",
                "        'binary': create data for unary operations, creates two input\n",
                "                 and output array\n",
                "    max_size : integer\n",
                "        maximum size of data to produce\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    if type is 'unary' yields one output, one input array and a message\n",
                "    containing information on the data\n",
                "    if type is 'binary' yields one output array, two input array and a message\n",
                "    containing information on the data\n",
                "\n",
                "    \"\"\"\n",
                "    ufmt = 'unary offset=(%d, %d), size=%d, dtype=%r, %s'\n",
                "    bfmt = 'binary offset=(%d, %d, %d), size=%d, dtype=%r, %s'\n",
                "    for o in range(3):\n",
                "        for s in range(o + 2, max(o + 3, max_size)):\n",
                "            if type == 'unary':\n",
                "                inp = lambda: arange(s, dtype=dtype)[o:]\n",
                "                out = empty((s,), dtype=dtype)[o:]\n",
                "                yield out, inp(), ufmt % (o, o, s, dtype, 'out of place')\n",
                "                d = inp()\n",
                "                yield d, d, ufmt % (o, o, s, dtype, 'in place')\n",
                "                yield out[1:], inp()[:-1], ufmt % \\\n",
                "                    (o + 1, o, s - 1, dtype, 'out of place')\n",
                "                yield out[:-1], inp()[1:], ufmt % \\\n",
                "                    (o, o + 1, s - 1, dtype, 'out of place')\n",
                "                yield inp()[:-1], inp()[1:], ufmt % \\\n",
                "                    (o, o + 1, s - 1, dtype, 'aliased')\n",
                "                yield inp()[1:], inp()[:-1], ufmt % \\\n",
                "                    (o + 1, o, s - 1, dtype, 'aliased')\n",
                "            if type == 'binary':\n",
                "                inp1 = lambda: arange(s, dtype=dtype)[o:]\n",
                "                inp2 = lambda: arange(s, dtype=dtype)[o:]\n",
                "                out = empty((s,), dtype=dtype)[o:]\n",
                "                yield out, inp1(), inp2(),  bfmt % \\\n",
                "                    (o, o, o, s, dtype, 'out of place')\n",
                "                d = inp1()\n",
                "                yield d, d, inp2(), bfmt % \\\n",
                "                    (o, o, o, s, dtype, 'in place1')\n",
                "                d = inp2()\n",
                "                yield d, inp1(), d, bfmt % \\\n",
                "                    (o, o, o, s, dtype, 'in place2')\n",
                "                yield out[1:], inp1()[:-1], inp2()[:-1], bfmt % \\\n",
                "                    (o + 1, o, o, s - 1, dtype, 'out of place')\n",
                "                yield out[:-1], inp1()[1:], inp2()[:-1], bfmt % \\\n",
                "                    (o, o + 1, o, s - 1, dtype, 'out of place')\n",
                "                yield out[:-1], inp1()[:-1], inp2()[1:], bfmt % \\\n",
                "                    (o, o, o + 1, s - 1, dtype, 'out of place')\n",
                "                yield inp1()[1:], inp1()[:-1], inp2()[:-1], bfmt % \\\n",
                "                    (o + 1, o, o, s - 1, dtype, 'aliased')\n",
                "                yield inp1()[:-1], inp1()[1:], inp2()[:-1], bfmt % \\\n",
                "                    (o, o + 1, o, s - 1, dtype, 'aliased')\n",
                "                yield inp1()[:-1], inp1()[:-1], inp2()[1:], bfmt % \\\n",
                "                    (o, o, o + 1, s - 1, dtype, 'aliased')\n",
                "\n",
                "\n",
                "class IgnoreException(Exception):\n",
                "    \"Ignoring this exception due to disabled feature\"\n",
                "    pass\n",
                "\n",
                "\n",
                "@contextlib.contextmanager\n",
                "def tempdir(*args, **kwargs):\n",
                "    \"\"\"Context manager to provide a temporary test folder.\n",
                "\n",
                "    All arguments are passed as this to the underlying tempfile.mkdtemp\n",
                "    function.\n",
                "\n",
                "    \"\"\"\n",
                "    tmpdir = mkdtemp(*args, **kwargs)\n",
                "    try:\n",
                "        yield tmpdir\n",
                "    finally:\n",
                "        shutil.rmtree(tmpdir)\n",
                "\n",
                "\n",
                "@contextlib.contextmanager\n",
                "def temppath(*args, **kwargs):\n",
                "    \"\"\"Context manager for temporary files.\n",
                "\n",
                "    Context manager that returns the path to a closed temporary file. Its\n",
                "    parameters are the same as for tempfile.mkstemp and are passed directly\n",
                "    to that function. The underlying file is removed when the context is\n",
                "    exited, so it should be closed at that time.\n",
                "\n",
                "    Windows does not allow a temporary file to be opened if it is already\n",
                "    open, so the underlying file must be closed after opening before it\n",
                "    can be opened again.\n",
                "\n",
                "    \"\"\"\n",
                "    fd, path = mkstemp(*args, **kwargs)\n",
                "    os.close(fd)\n",
                "    try:\n",
                "        yield path\n",
                "    finally:\n",
                "        os.remove(path)\n",
                "\n",
                "\n",
                "class clear_and_catch_warnings(warnings.catch_warnings):\n",
                "    \"\"\" Context manager that resets warning registry for catching warnings\n",
                "\n",
                "    Warnings can be slippery, because, whenever a warning is triggered, Python\n",
                "    adds a ``__warningregistry__`` member to the *calling* module.  This makes\n",
                "    it impossible to retrigger the warning in this module, whatever you put in\n",
                "    the warnings filters.  This context manager accepts a sequence of `modules`\n",
                "    as a keyword argument to its constructor and:\n",
                "\n",
                "    * stores and removes any ``__warningregistry__`` entries in given `modules`\n",
                "      on entry;\n",
                "    * resets ``__warningregistry__`` to its previous state on exit.\n",
                "\n",
                "    This makes it possible to trigger any warning afresh inside the context\n",
                "    manager without disturbing the state of warnings outside.\n",
                "\n",
                "    For compatibility with Python 3.0, please consider all arguments to be\n",
                "    keyword-only.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    record : bool, optional\n",
                "        Specifies whether warnings should be captured by a custom\n",
                "        implementation of ``warnings.showwarning()`` and be appended to a list\n",
                "        returned by the context manager. Otherwise None is returned by the\n",
                "        context manager. The objects appended to the list are arguments whose\n",
                "        attributes mirror the arguments to ``showwarning()``.\n",
                "    modules : sequence, optional\n",
                "        Sequence of modules for which to reset warnings registry on entry and\n",
                "        restore on exit. To work correctly, all 'ignore' filters should\n",
                "        filter by one of these modules.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "    >>> import warnings\n",
                "    >>> with np.testing.clear_and_catch_warnings(\n",
                "    ...         modules=[np._core.fromnumeric]):\n",
                "    ...     warnings.simplefilter('always')\n",
                "    ...     warnings.filterwarnings('ignore', module='np._core.fromnumeric')\n",
                "    ...     # do something that raises a warning but ignore those in\n",
                "    ...     # np._core.fromnumeric\n",
                "    \"\"\"\n",
                "    class_modules = ()\n",
                "\n",
                "    def __init__(self, record=False, modules=()):\n",
                "        self.modules = set(modules).union(self.class_modules)\n",
                "        self._warnreg_copies = {}\n",
                "        super().__init__(record=record)\n",
                "\n",
                "    def __enter__(self):\n",
                "        for mod in self.modules:\n",
                "            if hasattr(mod, '__warningregistry__'):\n",
                "                mod_reg = mod.__warningregistry__\n",
                "                self._warnreg_copies[mod] = mod_reg.copy()\n",
                "                mod_reg.clear()\n",
                "        return super().__enter__()\n",
                "\n",
                "    def __exit__(self, *exc_info):\n",
                "        super().__exit__(*exc_info)\n",
                "        for mod in self.modules:\n",
                "            if hasattr(mod, '__warningregistry__'):\n",
                "                mod.__warningregistry__.clear()\n",
                "            if mod in self._warnreg_copies:\n",
                "                mod.__warningregistry__.update(self._warnreg_copies[mod])\n",
                "\n",
                "\n",
                "class suppress_warnings:\n",
                "    \"\"\"\n",
                "    Context manager and decorator doing much the same as\n",
                "    ``warnings.catch_warnings``.\n",
                "\n",
                "    However, it also provides a filter mechanism to work around\n",
                "    https://bugs.python.org/issue4180.\n",
                "\n",
                "    This bug causes Python before 3.4 to not reliably show warnings again\n",
                "    after they have been ignored once (even within catch_warnings). It\n",
                "    means that no \"ignore\" filter can be used easily, since following\n",
                "    tests might need to see the warning. Additionally it allows easier\n",
                "    specificity for testing warnings and can be nested.\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    forwarding_rule : str, optional\n",
                "        One of \"always\", \"once\", \"module\", or \"location\". Analogous to\n",
                "        the usual warnings module filter mode, it is useful to reduce\n",
                "        noise mostly on the outmost level. Unsuppressed and unrecorded\n",
                "        warnings will be forwarded based on this rule. Defaults to \"always\".\n",
                "        \"location\" is equivalent to the warnings \"default\", match by exact\n",
                "        location the warning warning originated from.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    Filters added inside the context manager will be discarded again\n",
                "    when leaving it. Upon entering all filters defined outside a\n",
                "    context will be applied automatically.\n",
                "\n",
                "    When a recording filter is added, matching warnings are stored in the\n",
                "    ``log`` attribute as well as in the list returned by ``record``.\n",
                "\n",
                "    If filters are added and the ``module`` keyword is given, the\n",
                "    warning registry of this module will additionally be cleared when\n",
                "    applying it, entering the context, or exiting it. This could cause\n",
                "    warnings to appear a second time after leaving the context if they\n",
                "    were configured to be printed once (default) and were already\n",
                "    printed before the context was entered.\n",
                "\n",
                "    Nesting this context manager will work as expected when the\n",
                "    forwarding rule is \"always\" (default). Unfiltered and unrecorded\n",
                "    warnings will be passed out and be matched by the outer level.\n",
                "    On the outmost level they will be printed (or caught by another\n",
                "    warnings context). The forwarding rule argument can modify this\n",
                "    behaviour.\n",
                "\n",
                "    Like ``catch_warnings`` this context manager is not threadsafe.\n",
                "\n",
                "    Examples\n",
                "    --------\n",
                "\n",
                "    With a context manager::\n",
                "\n",
                "        with np.testing.suppress_warnings() as sup:\n",
                "            sup.filter(DeprecationWarning, \"Some text\")\n",
                "            sup.filter(module=np.ma.core)\n",
                "            log = sup.record(FutureWarning, \"Does this occur?\")\n",
                "            command_giving_warnings()\n",
                "            # The FutureWarning was given once, the filtered warnings were\n",
                "            # ignored. All other warnings abide outside settings (may be\n",
                "            # printed/error)\n",
                "            assert_(len(log) == 1)\n",
                "            assert_(len(sup.log) == 1)  # also stored in log attribute\n",
                "\n",
                "    Or as a decorator::\n",
                "\n",
                "        sup = np.testing.suppress_warnings()\n",
                "        sup.filter(module=np.ma.core)  # module must match exactly\n",
                "        @sup\n",
                "        def some_function():\n",
                "            # do something which causes a warning in np.ma.core\n",
                "            pass\n",
                "    \"\"\"\n",
                "    def __init__(self, forwarding_rule=\"always\"):\n",
                "        self._entered = False\n",
                "\n",
                "        # Suppressions are either instance or defined inside one with block:\n",
                "        self._suppressions = []\n",
                "\n",
                "        if forwarding_rule not in {\"always\", \"module\", \"once\", \"location\"}:\n",
                "            raise ValueError(\"unsupported forwarding rule.\")\n",
                "        self._forwarding_rule = forwarding_rule\n",
                "\n",
                "    def _clear_registries(self):\n",
                "        if hasattr(warnings, \"_filters_mutated\"):\n",
                "            # clearing the registry should not be necessary on new pythons,\n",
                "            # instead the filters should be mutated.\n",
                "            warnings._filters_mutated()\n",
                "            return\n",
                "        # Simply clear the registry, this should normally be harmless,\n",
                "        # note that on new pythons it would be invalidated anyway.\n",
                "        for module in self._tmp_modules:\n",
                "            if hasattr(module, \"__warningregistry__\"):\n",
                "                module.__warningregistry__.clear()\n",
                "\n",
                "    def _filter(self, category=Warning, message=\"\", module=None, record=False):\n",
                "        if record:\n",
                "            record = []  # The log where to store warnings\n",
                "        else:\n",
                "            record = None\n",
                "        if self._entered:\n",
                "            if module is None:\n",
                "                warnings.filterwarnings(\n",
                "                    \"always\", category=category, message=message)\n",
                "            else:\n",
                "                module_regex = module.__name__.replace('.', r'\\.') + '$'\n",
                "                warnings.filterwarnings(\n",
                "                    \"always\", category=category, message=message,\n",
                "                    module=module_regex)\n",
                "                self._tmp_modules.add(module)\n",
                "                self._clear_registries()\n",
                "\n",
                "            self._tmp_suppressions.append(\n",
                "                (category, message, re.compile(message, re.I), module, record))\n",
                "        else:\n",
                "            self._suppressions.append(\n",
                "                (category, message, re.compile(message, re.I), module, record))\n",
                "\n",
                "        return record\n",
                "\n",
                "    def filter(self, category=Warning, message=\"\", module=None):\n",
                "        \"\"\"\n",
                "        Add a new suppressing filter or apply it if the state is entered.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        category : class, optional\n",
                "            Warning class to filter\n",
                "        message : string, optional\n",
                "            Regular expression matching the warning message.\n",
                "        module : module, optional\n",
                "            Module to filter for. Note that the module (and its file)\n",
                "            must match exactly and cannot be a submodule. This may make\n",
                "            it unreliable for external modules.\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        When added within a context, filters are only added inside\n",
                "        the context and will be forgotten when the context is exited.\n",
                "        \"\"\"\n",
                "        self._filter(category=category, message=message, module=module,\n",
                "                     record=False)\n",
                "\n",
                "    def record(self, category=Warning, message=\"\", module=None):\n",
                "        \"\"\"\n",
                "        Append a new recording filter or apply it if the state is entered.\n",
                "\n",
                "        All warnings matching will be appended to the ``log`` attribute.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        category : class, optional\n",
                "            Warning class to filter\n",
                "        message : string, optional\n",
                "            Regular expression matching the warning message.\n",
                "        module : module, optional\n",
                "            Module to filter for. Note that the module (and its file)\n",
                "            must match exactly and cannot be a submodule. This may make\n",
                "            it unreliable for external modules.\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        log : list\n",
                "            A list which will be filled with all matched warnings.\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        When added within a context, filters are only added inside\n",
                "        the context and will be forgotten when the context is exited.\n",
                "        \"\"\"\n",
                "        return self._filter(category=category, message=message, module=module,\n",
                "                            record=True)\n",
                "\n",
                "    def __enter__(self):\n",
                "        if self._entered:\n",
                "            raise RuntimeError(\"cannot enter suppress_warnings twice.\")\n",
                "\n",
                "        self._orig_show = warnings.showwarning\n",
                "        self._filters = warnings.filters\n",
                "        warnings.filters = self._filters[:]\n",
                "\n",
                "        self._entered = True\n",
                "        self._tmp_suppressions = []\n",
                "        self._tmp_modules = set()\n",
                "        self._forwarded = set()\n",
                "\n",
                "        self.log = []  # reset global log (no need to keep same list)\n",
                "\n",
                "        for cat, mess, _, mod, log in self._suppressions:\n",
                "            if log is not None:\n",
                "                del log[:]  # clear the log\n",
                "            if mod is None:\n",
                "                warnings.filterwarnings(\n",
                "                    \"always\", category=cat, message=mess)\n",
                "            else:\n",
                "                module_regex = mod.__name__.replace('.', r'\\.') + '$'\n",
                "                warnings.filterwarnings(\n",
                "                    \"always\", category=cat, message=mess,\n",
                "                    module=module_regex)\n",
                "                self._tmp_modules.add(mod)\n",
                "        warnings.showwarning = self._showwarning\n",
                "        self._clear_registries()\n",
                "\n",
                "        return self\n",
                "\n",
                "    def __exit__(self, *exc_info):\n",
                "        warnings.showwarning = self._orig_show\n",
                "        warnings.filters = self._filters\n",
                "        self._clear_registries()\n",
                "        self._entered = False\n",
                "        del self._orig_show\n",
                "        del self._filters\n",
                "\n",
                "    def _showwarning(self, message, category, filename, lineno,\n",
                "                     *args, use_warnmsg=None, **kwargs):\n",
                "        for cat, _, pattern, mod, rec in (\n",
                "                self._suppressions + self._tmp_suppressions)[::-1]:\n",
                "            if (issubclass(category, cat) and\n",
                "                    pattern.match(message.args[0]) is not None):\n",
                "                if mod is None:\n",
                "                    # Message and category match, either recorded or ignored\n",
                "                    if rec is not None:\n",
                "                        msg = WarningMessage(message, category, filename,\n",
                "                                             lineno, **kwargs)\n",
                "                        self.log.append(msg)\n",
                "                        rec.append(msg)\n",
                "                    return\n",
                "                # Use startswith, because warnings strips the c or o from\n",
                "                # .pyc/.pyo files.\n",
                "                elif mod.__file__.startswith(filename):\n",
                "                    # The message and module (filename) match\n",
                "                    if rec is not None:\n",
                "                        msg = WarningMessage(message, category, filename,\n",
                "                                             lineno, **kwargs)\n",
                "                        self.log.append(msg)\n",
                "                        rec.append(msg)\n",
                "                    return\n",
                "\n",
                "        # There is no filter in place, so pass to the outside handler\n",
                "        # unless we should only pass it once\n",
                "        if self._forwarding_rule == \"always\":\n",
                "            if use_warnmsg is None:\n",
                "                self._orig_show(message, category, filename, lineno,\n",
                "                                *args, **kwargs)\n",
                "            else:\n",
                "                self._orig_showmsg(use_warnmsg)\n",
                "            return\n",
                "\n",
                "        if self._forwarding_rule == \"once\":\n",
                "            signature = (message.args, category)\n",
                "        elif self._forwarding_rule == \"module\":\n",
                "            signature = (message.args, category, filename)\n",
                "        elif self._forwarding_rule == \"location\":\n",
                "            signature = (message.args, category, filename, lineno)\n",
                "\n",
                "        if signature in self._forwarded:\n",
                "            return\n",
                "        self._forwarded.add(signature)\n",
                "        if use_warnmsg is None:\n",
                "            self._orig_show(message, category, filename, lineno, *args,\n",
                "                            **kwargs)\n",
                "        else:\n",
                "            self._orig_showmsg(use_warnmsg)\n",
                "\n",
                "    def __call__(self, func):\n",
                "        \"\"\"\n",
                "        Function decorator to apply certain suppressions to a whole\n",
                "        function.\n",
                "        \"\"\"\n",
                "        @wraps(func)\n",
                "        def new_func(*args, **kwargs):\n",
                "            with self:\n",
                "                return func(*args, **kwargs)\n",
                "\n",
                "        return new_func\n",
                "\n",
                "\n",
                "@contextlib.contextmanager\n",
                "def _assert_no_gc_cycles_context(name=None):\n",
                "    __tracebackhide__ = True  # Hide traceback for py.test\n",
                "\n",
                "    # not meaningful to test if there is no refcounting\n",
                "    if not HAS_REFCOUNT:\n",
                "        yield\n",
                "        return\n",
                "\n",
                "    assert_(gc.isenabled())\n",
                "    gc.disable()\n",
                "    gc_debug = gc.get_debug()\n",
                "    try:\n",
                "        for i in range(100):\n",
                "            if gc.collect() == 0:\n",
                "                break\n",
                "        else:\n",
                "            raise RuntimeError(\n",
                "                \"Unable to fully collect garbage - perhaps a __del__ method \"\n",
                "                \"is creating more reference cycles?\")\n",
                "\n",
                "        gc.set_debug(gc.DEBUG_SAVEALL)\n",
                "        yield\n",
                "        # gc.collect returns the number of unreachable objects in cycles that\n",
                "        # were found -- we are checking that no cycles were created in the context\n",
                "        n_objects_in_cycles = gc.collect()\n",
                "        objects_in_cycles = gc.garbage[:]\n",
                "    finally:\n",
                "        del gc.garbage[:]\n",
                "        gc.set_debug(gc_debug)\n",
                "        gc.enable()\n",
                "\n",
                "    if n_objects_in_cycles:\n",
                "        name_str = f' when calling {name}' if name is not None else ''\n",
                "        raise AssertionError(\n",
                "            \"Reference cycles were found{}: {} objects were collected, \"\n",
                "            \"of which {} are shown below:{}\"\n",
                "            .format(\n",
                "                name_str,\n",
                "                n_objects_in_cycles,\n",
                "                len(objects_in_cycles),\n",
                "                ''.join(\n",
                "                    \"\\n  {} object with id={}:\\n    {}\".format(\n",
                "                        type(o).__name__,\n",
                "                        id(o),\n",
                "                        pprint.pformat(o).replace('\\n', '\\n    ')\n",
                "                    ) for o in objects_in_cycles\n",
                "                )\n",
                "            )\n",
                "        )\n",
                "\n",
                "\n",
                "def assert_no_gc_cycles(*args, **kwargs):\n",
                "    \"\"\"\n",
                "    Fail if the given callable produces any reference cycles.\n",
                "\n",
                "    If called with all arguments omitted, may be used as a context manager::\n",
                "\n",
                "        with assert_no_gc_cycles():\n",
                "            do_something()\n",
                "\n",
                "    .. versionadded:: 1.15.0\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    func : callable\n",
                "        The callable to test.\n",
                "    \\\\*args : Arguments\n",
                "        Arguments passed to `func`.\n",
                "    \\\\*\\\\*kwargs : Kwargs\n",
                "        Keyword arguments passed to `func`.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    Nothing. The result is deliberately discarded to ensure that all cycles\n",
                "    are found.\n",
                "\n",
                "    \"\"\"\n",
                "    if not args:\n",
                "        return _assert_no_gc_cycles_context()\n",
                "\n",
                "    func = args[0]\n",
                "    args = args[1:]\n",
                "    with _assert_no_gc_cycles_context(name=func.__name__):\n",
                "        func(*args, **kwargs)\n",
                "\n",
                "\n",
                "def break_cycles():\n",
                "    \"\"\"\n",
                "    Break reference cycles by calling gc.collect\n",
                "    Objects can call other objects' methods (for instance, another object's\n",
                "     __del__) inside their own __del__. On PyPy, the interpreter only runs\n",
                "    between calls to gc.collect, so multiple calls are needed to completely\n",
                "    release all cycles.\n",
                "    \"\"\"\n",
                "\n",
                "    gc.collect()\n",
                "    if IS_PYPY:\n",
                "        # a few more, just to make sure all the finalizers are called\n",
                "        gc.collect()\n",
                "        gc.collect()\n",
                "        gc.collect()\n",
                "        gc.collect()\n",
                "\n",
                "\n",
                "def requires_memory(free_bytes):\n",
                "    \"\"\"Decorator to skip a test if not enough memory is available\"\"\"\n",
                "    import pytest\n",
                "\n",
                "    def decorator(func):\n",
                "        @wraps(func)\n",
                "        def wrapper(*a, **kw):\n",
                "            msg = check_free_memory(free_bytes)\n",
                "            if msg is not None:\n",
                "                pytest.skip(msg)\n",
                "\n",
                "            try:\n",
                "                return func(*a, **kw)\n",
                "            except MemoryError:\n",
                "                # Probably ran out of memory regardless: don't regard as failure\n",
                "                pytest.xfail(\"MemoryError raised\")\n",
                "\n",
                "        return wrapper\n",
                "\n",
                "    return decorator\n",
                "\n",
                "\n",
                "def check_free_memory(free_bytes):\n",
                "    \"\"\"\n",
                "    Check whether `free_bytes` amount of memory is currently free.\n",
                "    Returns: None if enough memory available, otherwise error message\n",
                "    \"\"\"\n",
                "    env_var = 'NPY_AVAILABLE_MEM'\n",
                "    env_value = os.environ.get(env_var)\n",
                "    if env_value is not None:\n",
                "        try:\n",
                "            mem_free = _parse_size(env_value)\n",
                "        except ValueError as exc:\n",
                "            raise ValueError(f'Invalid environment variable {env_var}: {exc}')\n",
                "\n",
                "        msg = (f'{free_bytes/1e9} GB memory required, but environment variable '\n",
                "               f'NPY_AVAILABLE_MEM={env_value} set')\n",
                "    else:\n",
                "        mem_free = _get_mem_available()\n",
                "\n",
                "        if mem_free is None:\n",
                "            msg = (\"Could not determine available memory; set NPY_AVAILABLE_MEM \"\n",
                "                   \"environment variable (e.g. NPY_AVAILABLE_MEM=16GB) to run \"\n",
                "                   \"the test.\")\n",
                "            mem_free = -1\n",
                "        else:\n",
                "            msg = f'{free_bytes/1e9} GB memory required, but {mem_free/1e9} GB available'\n",
                "\n",
                "    return msg if mem_free < free_bytes else None\n",
                "\n",
                "\n",
                "def _parse_size(size_str):\n",
                "    \"\"\"Convert memory size strings ('12 GB' etc.) to float\"\"\"\n",
                "    suffixes = {'': 1, 'b': 1,\n",
                "                'k': 1000, 'm': 1000**2, 'g': 1000**3, 't': 1000**4,\n",
                "                'kb': 1000, 'mb': 1000**2, 'gb': 1000**3, 'tb': 1000**4,\n",
                "                'kib': 1024, 'mib': 1024**2, 'gib': 1024**3, 'tib': 1024**4}\n",
                "\n",
                "    size_re = re.compile(r'^\\s*(\\d+|\\d+\\.\\d+)\\s*({0})\\s*$'.format(\n",
                "        '|'.join(suffixes.keys())), re.I)\n",
                "\n",
                "    m = size_re.match(size_str.lower())\n",
                "    if not m or m.group(2) not in suffixes:\n",
                "        raise ValueError(f'value {size_str!r} not a valid size')\n",
                "    return int(float(m.group(1)) * suffixes[m.group(2)])\n",
                "\n",
                "\n",
                "def _get_mem_available():\n",
                "    \"\"\"Return available memory in bytes, or None if unknown.\"\"\"\n",
                "    try:\n",
                "        import psutil\n",
                "        return psutil.virtual_memory().available\n",
                "    except (ImportError, AttributeError):\n",
                "        pass\n",
                "\n",
                "    if sys.platform.startswith('linux'):\n",
                "        info = {}\n",
                "        with open('/proc/meminfo') as f:\n",
                "            for line in f:\n",
                "                p = line.split()\n",
                "                info[p[0].strip(':').lower()] = int(p[1]) * 1024\n",
                "\n",
                "        if 'memavailable' in info:\n",
                "            # Linux >= 3.14\n",
                "            return info['memavailable']\n",
                "        else:\n",
                "            return info['memfree'] + info['cached']\n",
                "\n",
                "    return None\n",
                "\n",
                "\n",
                "def _no_tracing(func):\n",
                "    \"\"\"\n",
                "    Decorator to temporarily turn off tracing for the duration of a test.\n",
                "    Needed in tests that check refcounting, otherwise the tracing itself\n",
                "    influences the refcounts\n",
                "    \"\"\"\n",
                "    if not hasattr(sys, 'gettrace'):\n",
                "        return func\n",
                "    else:\n",
                "        @wraps(func)\n",
                "        def wrapper(*args, **kwargs):\n",
                "            original_trace = sys.gettrace()\n",
                "            try:\n",
                "                sys.settrace(None)\n",
                "                return func(*args, **kwargs)\n",
                "            finally:\n",
                "                sys.settrace(original_trace)\n",
                "        return wrapper\n",
                "\n",
                "\n",
                "def _get_glibc_version():\n",
                "    try:\n",
                "        ver = os.confstr('CS_GNU_LIBC_VERSION').rsplit(' ')[1]\n",
                "    except Exception:\n",
                "        ver = '0.0'\n",
                "\n",
                "    return ver\n",
                "\n",
                "\n",
                "_glibcver = _get_glibc_version()\n",
                "_glibc_older_than = lambda x: (_glibcver != '0.0' and _glibcver < x)"
            ]
        ]
    },
    "partial_orders": [
        {
            "edit_hunk_pair": [
                0,
                1
            ],
            "edit_order": "bi-directional",
            "reason": "import and use"
        },
        {
            "edit_hunk_pair": [
                0,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "import and define"
        },
        {
            "edit_hunk_pair": [
                1,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "use and define"
        },
        {
            "edit_hunk_pair": [
                2,
                4
            ],
            "edit_order": "bi-directional",
            "reason": "use and import"
        },
        {
            "edit_hunk_pair": [
                3,
                4
            ],
            "edit_order": "bi-directional",
            "reason": "refactor"
        },
        {
            "edit_hunk_pair": [
                3,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "def and import"
        },
        {
            "edit_hunk_pair": [
                4,
                6
            ],
            "edit_order": "0 before 1",
            "reason": "move"
        },
        {
            "edit_hunk_pair": [
                5,
                6
            ],
            "edit_order": "bi-directional",
            "reason": "use and import"
        }
    ]
}