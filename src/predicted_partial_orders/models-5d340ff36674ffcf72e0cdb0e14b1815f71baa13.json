{
    "partial_orders": [
        {
            "src": 3,
            "tgt": 5,
            "reason": "Both edits perform an identical textual substitution (changing 'lr=0.1' to 'learning_rate=0.1') on the same type of syntactic construct (tf.keras.optimizers.SGD constructor calls). This is a bulk uniform substitution pattern where both edits are part of the same refactoring operation to update deprecated parameter names. The changes are mechanically identical and would naturally occur as part of a single, contiguous search-and-replace operation across the codebase."
        },
        {
            "src": 5,
            "tgt": 3,
            "reason": "Both edits perform an identical textual substitution (changing 'lr=0.1' to 'learning_rate=0.1') on the same type of syntactic construct (tf.keras.optimizers.SGD constructor calls). This is a bulk uniform substitution pattern where both edits are part of the same refactoring operation to update deprecated parameter names. The changes are mechanically identical and would naturally occur as part of a single, contiguous search-and-replace operation across the codebase."
        },
        {
            "src": 3,
            "tgt": 4,
            "reason": "Both edits perform an identical textual substitution pattern: changing 'lr=0.1' to 'learning_rate=0.1' in tf.keras.optimizers.SGD constructor calls. This is a uniform parameter name update across multiple locations within the same file, targeting the same type of syntactic construct (optimizer constructor calls). Both edits are part of a single, contiguous refactor to update deprecated parameter names. Either edit can be made first, and after making either one, the other becomes an immediate, mechanically obvious next step to maintain consistency in the codebase."
        },
        {
            "src": 4,
            "tgt": 3,
            "reason": "Both edits perform an identical textual substitution pattern: changing 'lr=0.1' to 'learning_rate=0.1' in tf.keras.optimizers.SGD constructor calls. This is a uniform parameter name update across multiple locations within the same file, targeting the same type of syntactic construct (optimizer constructor calls). Both edits are part of a single, contiguous refactor to update deprecated parameter names. Either edit can be made first, and after making either one, the other becomes an immediate, mechanically obvious next step to maintain consistency in the codebase."
        },
        {
            "src": 4,
            "tgt": 5,
            "reason": "Both edits perform an identical textual substitution pattern: changing 'lr=0.1' to 'learning_rate=0.1' in tf.keras.optimizers.SGD constructor calls. This is a uniform refactoring operation targeting the same type of syntactic construct (optimizer instantiation) with the exact same before\u2192after pattern. Both edits would naturally occur as part of a single, contiguous search-and-replace operation to update deprecated parameter names. Either edit can be made first, and after making one, the other becomes an immediate, mechanically obvious next step to complete the uniform substitution pattern."
        },
        {
            "src": 5,
            "tgt": 4,
            "reason": "Both edits perform an identical textual substitution pattern: changing 'lr=0.1' to 'learning_rate=0.1' in tf.keras.optimizers.SGD constructor calls. This is a uniform refactoring operation targeting the same type of syntactic construct (optimizer instantiation) with the exact same before\u2192after pattern. Both edits would naturally occur as part of a single, contiguous search-and-replace operation to update deprecated parameter names. Either edit can be made first, and after making one, the other becomes an immediate, mechanically obvious next step to complete the uniform substitution pattern."
        },
        {
            "src": 6,
            "tgt": 7,
            "reason": "Edit 0 introduces a new variable 'learning_rate' that is assigned based on conditional logic checking the optimizer type. Edit 1 then uses this exact same 'learning_rate' variable in the return dictionary, replacing the direct optimizer call. The changed lines reference the exact same symbol - the 'learning_rate' variable. After making edit 0, edit 1 becomes the immediate next step to use the newly defined variable. After making edit 1, edit 0 would be needed to define the variable being referenced. This is a classic definition-usage relationship within the same function scope."
        },
        {
            "src": 7,
            "tgt": 6,
            "reason": "Edit 0 introduces a new variable 'learning_rate' that is assigned based on conditional logic checking the optimizer type. Edit 1 then uses this exact same 'learning_rate' variable in the return dictionary, replacing the direct optimizer call. The changed lines reference the exact same symbol - the 'learning_rate' variable. After making edit 0, edit 1 becomes the immediate next step to use the newly defined variable. After making edit 1, edit 0 would be needed to define the variable being referenced. This is a classic definition-usage relationship within the same function scope."
        }
    ],
    "allowed_init_edits": [
        0,
        1,
        2
    ]
}